#!/usr/bin/env python3
"""
SAGE Memory-Mapped Queue å¤šè¿›ç¨‹å¹¶å‘è¯»å†™å’Œå¼•ç”¨ä¼ é€’æµ‹è¯•
Multiprocess concurrent read/write and reference passing test for SAGE mmap queue
"""

import os
import sys
import time
import multiprocessing
import threading
import json
from typing import Dict, Any, List, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import traceback

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from sage_queue import SageQueue, SageQueueRef, destroy_queue
    print("âœ“ æˆåŠŸå¯¼å…¥ SageQueue")
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


# ============================================================================
# å¤šè¿›ç¨‹ Worker å‡½æ•° (å¿…é¡»åœ¨æ¨¡å—é¡¶å±‚å®šä¹‰ï¼Œä»¥æ”¯æŒ pickle åºåˆ—åŒ–)
# ============================================================================

def multiprocess_writer_worker(queue_name: str, worker_id: int, num_messages: int) -> Dict[str, Any]:
    """å¤šè¿›ç¨‹å†™å…¥ worker (é€šè¿‡é˜Ÿåˆ—åç§°è¿æ¥)"""
    try:
        # é€šè¿‡é˜Ÿåˆ—åç§°è¿æ¥åˆ°å…±äº«é˜Ÿåˆ—
        queue = SageQueue(queue_name)
        
        start_time = time.time()
        completed = 0
        errors = 0
        
        for i in range(num_messages):
            try:
                message = {
                    'worker_id': worker_id,
                    'msg_id': i,
                    'timestamp': time.time(),
                    'content': f'Worker-{worker_id} Message-{i} Data: {i * worker_id}',
                    'payload': list(range(i % 10))  # å˜é•¿è´Ÿè½½
                }
                
                queue.put(message, timeout=5.0)
                completed += 1
                
                if i % 10 == 0:
                    print(f"  Writer-{worker_id}: {i+1}/{num_messages}")
                    
            except Exception as e:
                errors += 1
                print(f"  Writer-{worker_id}: Error at {i}: {e}")
        
        end_time = time.time()
        duration = end_time - start_time
        
        queue.close()
        
        return {
            'worker_id': worker_id,
            'worker_type': 'writer',
            'completed': completed,
            'errors': errors,
            'duration': duration,
            'ops_per_sec': completed / duration if duration > 0 else 0,
            'success': True
        }
        
    except Exception as e:
        return {
            'worker_id': worker_id,
            'worker_type': 'writer',
            'error': str(e),
            'success': False
        }


def multiprocess_reader_worker(queue_name: str, worker_id: int, expected_messages: int, timeout: float = 30.0) -> Dict[str, Any]:
    """å¤šè¿›ç¨‹è¯»å– worker (é€šè¿‡é˜Ÿåˆ—åç§°è¿æ¥)"""
    try:
        # é€šè¿‡é˜Ÿåˆ—åç§°è¿æ¥åˆ°å…±äº«é˜Ÿåˆ—
        queue = SageQueue(queue_name)
        
        start_time = time.time()
        completed = 0
        errors = 0
        messages = []
        
        deadline = start_time + timeout
        
        while completed < expected_messages and time.time() < deadline:
            try:
                message = queue.get(timeout=1.0)
                completed += 1
                messages.append(message)
                
                if completed % 10 == 0:
                    print(f"  Reader-{worker_id}: {completed}/{expected_messages}")
                    
            except Exception as e:
                if "empty" in str(e).lower() or "timed out" in str(e).lower():
                    # é˜Ÿåˆ—ä¸ºç©ºï¼ŒçŸ­æš‚ç­‰å¾…
                    time.sleep(0.01)
                    continue
                else:
                    errors += 1
                    print(f"  Reader-{worker_id}: Error: {e}")
        
        end_time = time.time()
        duration = end_time - start_time
        
        queue.close()
        
        return {
            'worker_id': worker_id,
            'worker_type': 'reader',
            'completed': completed,
            'errors': errors,
            'duration': duration,
            'ops_per_sec': completed / duration if duration > 0 else 0,
            'messages_sample': messages[:3],  # å‰3æ¡æ¶ˆæ¯ä½œä¸ºæ ·æœ¬
            'success': True
        }
        
    except Exception as e:
        return {
            'worker_id': worker_id,
            'worker_type': 'reader',
            'error': str(e),
            'success': False
        }


def multiprocess_ref_worker(queue_ref_dict: Dict[str, Any], worker_id: int, num_operations: int) -> Dict[str, Any]:
    """é€šè¿‡åºåˆ—åŒ–å¼•ç”¨ä¼ é€’ä½¿ç”¨é˜Ÿåˆ—çš„ worker"""
    try:
        # é‡å»º SageQueueRef å¯¹è±¡
        ref = SageQueueRef.__new__(SageQueueRef)
        ref.__setstate__(queue_ref_dict)
        
        # ä»å¼•ç”¨è·å–é˜Ÿåˆ—å®ä¾‹
        queue = ref.get_queue()
        
        start_time = time.time()
        completed_writes = 0
        completed_reads = 0
        errors = 0
        
        # æ‰§è¡Œæ··åˆè¯»å†™æ“ä½œ
        for i in range(num_operations):
            try:
                # å†™å…¥æ“ä½œ
                message = {
                    'ref_worker_id': worker_id,
                    'op_id': i,
                    'timestamp': time.time(),
                    'data': f'RefWorker-{worker_id} Op-{i}'
                }
                queue.put(message, timeout=3.0)
                completed_writes += 1
                
                # å°è¯•è¯»å–æ“ä½œï¼ˆå¯èƒ½è¯»åˆ°å…¶ä»–è¿›ç¨‹çš„æ¶ˆæ¯ï¼‰
                if i % 2 == 0:  # æ¯ä¸¤æ¬¡å†™å…¥å°è¯•ä¸€æ¬¡è¯»å–
                    try:
                        read_msg = queue.get(timeout=0.5)
                        completed_reads += 1
                    except:
                        pass  # è¯»å–å¤±è´¥ä¸ç®—é”™è¯¯
                        
            except Exception as e:
                errors += 1
                print(f"  RefWorker-{worker_id}: Error at op {i}: {e}")
        
        end_time = time.time()
        duration = end_time - start_time
        
        queue.close()
        
        return {
            'worker_id': worker_id,
            'worker_type': 'ref_worker',
            'completed_writes': completed_writes,
            'completed_reads': completed_reads,
            'total_ops': completed_writes + completed_reads,
            'errors': errors,
            'duration': duration,
            'ops_per_sec': (completed_writes + completed_reads) / duration if duration > 0 else 0,
            'success': True
        }
        
    except Exception as e:
        return {
            'worker_id': worker_id,
            'worker_type': 'ref_worker',
            'error': str(e),
            'success': False
        }


def concurrent_rw_worker(queue_name: str, worker_id: int, num_operations: int, read_write_ratio: float = 0.5) -> Dict[str, Any]:
    """å¹¶å‘è¯»å†™æ··åˆæ“ä½œ worker"""
    try:
        queue = SageQueue(queue_name)
        
        start_time = time.time()
        writes_completed = 0
        reads_completed = 0
        errors = 0
        
        for i in range(num_operations):
            try:
                # æ ¹æ®æ¯”ä¾‹å†³å®šæ˜¯è¯»è¿˜æ˜¯å†™
                if (i / num_operations) < read_write_ratio or queue.empty():
                    # å†™å…¥æ“ä½œ
                    message = {
                        'concurrent_worker_id': worker_id,
                        'operation_type': 'write',
                        'op_id': i,
                        'timestamp': time.time(),
                        'data': f'ConcurrentWorker-{worker_id} Write-{i}'
                    }
                    queue.put(message, timeout=2.0)
                    writes_completed += 1
                else:
                    # è¯»å–æ“ä½œ
                    message = queue.get(timeout=2.0)
                    reads_completed += 1
                    
            except Exception as e:
                errors += 1
                if errors > 5:  # è¿ç»­é”™è¯¯å¤ªå¤šåˆ™é€€å‡º
                    break
        
        end_time = time.time()
        duration = end_time - start_time
        
        queue.close()
        
        return {
            'worker_id': worker_id,
            'worker_type': 'concurrent_rw',
            'writes_completed': writes_completed,
            'reads_completed': reads_completed,
            'total_ops': writes_completed + reads_completed,
            'errors': errors,
            'duration': duration,
            'ops_per_sec': (writes_completed + reads_completed) / duration if duration > 0 else 0,
            'success': True
        }
        
    except Exception as e:
        return {
            'worker_id': worker_id,
            'worker_type': 'concurrent_rw',
            'error': str(e),
            'success': False
        }


# ============================================================================
# æµ‹è¯•å‡½æ•°
# ============================================================================

def test_multiprocess_producers_consumers():
    """æµ‹è¯•å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€…æ¨¡å¼"""
    print("\n" + "="*60)
    print("æµ‹è¯•: å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€…æ¨¡å¼")
    print("="*60)
    
    queue_name = f"test_prod_cons_{int(time.time())}"
    
    try:
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„é˜Ÿåˆ—
        destroy_queue(queue_name)
        
        # åˆ›å»ºé˜Ÿåˆ—
        main_queue = SageQueue(queue_name, maxsize=256*1024)  # 256KB
        print(f"âœ“ åˆ›å»ºé˜Ÿåˆ—: {queue_name}")
        main_queue.close()  # å…³é—­å¥æŸ„ä½†ä¿ç•™å…±äº«å†…å­˜
        
        # æµ‹è¯•å‚æ•°
        num_producers = 3
        num_consumers = 2
        messages_per_producer = 20
        total_messages = num_producers * messages_per_producer
        
        print(f"é…ç½®: {num_producers} ä¸ªç”Ÿäº§è€…ï¼Œ{num_consumers} ä¸ªæ¶ˆè´¹è€…")
        print(f"æ¯ä¸ªç”Ÿäº§è€…å†™å…¥ {messages_per_producer} æ¡æ¶ˆæ¯ï¼Œæ€»è®¡ {total_messages} æ¡")
        
        # å¯åŠ¨ç”Ÿäº§è€…è¿›ç¨‹
        print("\nå¯åŠ¨ç”Ÿäº§è€…è¿›ç¨‹...")
        with ProcessPoolExecutor(max_workers=num_producers + num_consumers) as executor:
            # æäº¤ç”Ÿäº§è€…ä»»åŠ¡
            producer_futures = []
            for i in range(num_producers):
                future = executor.submit(multiprocess_writer_worker, queue_name, i, messages_per_producer)
                producer_futures.append(future)
                print(f"  å¯åŠ¨ç”Ÿäº§è€…-{i}")
            
            # çŸ­æš‚å»¶è¿Ÿåå¯åŠ¨æ¶ˆè´¹è€…
            time.sleep(0.5)
            
            # æäº¤æ¶ˆè´¹è€…ä»»åŠ¡
            consumer_futures = []
            messages_per_consumer = total_messages // num_consumers
            for i in range(num_consumers):
                future = executor.submit(multiprocess_reader_worker, queue_name, i, messages_per_consumer, 20.0)
                consumer_futures.append(future)
                print(f"  å¯åŠ¨æ¶ˆè´¹è€…-{i} (é¢„æœŸè¯»å– {messages_per_consumer} æ¡)")
            
            # æ”¶é›†ç”Ÿäº§è€…ç»“æœ
            print("\nç­‰å¾…ç”Ÿäº§è€…å®Œæˆ...")
            producer_results = []
            for future in as_completed(producer_futures, timeout=30):
                result = future.result()
                producer_results.append(result)
                if result['success']:
                    print(f"  âœ“ ç”Ÿäº§è€…-{result['worker_id']}: {result['completed']} æ¡æ¶ˆæ¯, "
                          f"{result['ops_per_sec']:.1f} ops/sec")
                else:
                    print(f"  âœ— ç”Ÿäº§è€…-{result['worker_id']}: å¤±è´¥ - {result.get('error', 'Unknown')}")
            
            # æ”¶é›†æ¶ˆè´¹è€…ç»“æœ
            print("\nç­‰å¾…æ¶ˆè´¹è€…å®Œæˆ...")
            consumer_results = []
            for future in as_completed(consumer_futures, timeout=35):
                result = future.result()
                consumer_results.append(result)
                if result['success']:
                    print(f"  âœ“ æ¶ˆè´¹è€…-{result['worker_id']}: {result['completed']} æ¡æ¶ˆæ¯, "
                          f"{result['ops_per_sec']:.1f} ops/sec")
                else:
                    print(f"  âœ— æ¶ˆè´¹è€…-{result['worker_id']}: å¤±è´¥ - {result.get('error', 'Unknown')}")
        
        # ç»Ÿè®¡ç»“æœ
        total_produced = sum(r['completed'] for r in producer_results if r['success'])
        total_consumed = sum(r['completed'] for r in consumer_results if r['success'])
        
        # æ£€æŸ¥é˜Ÿåˆ—å‰©ä½™
        check_queue = SageQueue(queue_name)
        remaining = 0
        while not check_queue.empty():
            try:
                check_queue.get_nowait()
                remaining += 1
            except:
                break
        
        stats = check_queue.get_stats()
        check_queue.close()
        
        print(f"\nç»“æœç»Ÿè®¡:")
        print(f"  æ€»ç”Ÿäº§: {total_produced}/{total_messages}")
        print(f"  æ€»æ¶ˆè´¹: {total_consumed}")
        print(f"  é˜Ÿåˆ—å‰©ä½™: {remaining}")
        print(f"  é˜Ÿåˆ—ç»Ÿè®¡: {stats}")
        
        # æ¸…ç†
        destroy_queue(queue_name)
        
        # è¯„ä¼°æµ‹è¯•ç»“æœ
        production_rate = total_produced / total_messages if total_messages > 0 else 0
        consumption_rate = total_consumed / total_produced if total_produced > 0 else 0
        
        print(f"\næµ‹è¯•è¯„ä¼°:")
        print(f"  ç”Ÿäº§æˆåŠŸç‡: {production_rate:.1%}")
        print(f"  æ¶ˆè´¹æˆåŠŸç‡: {consumption_rate:.1%}")
        
        if production_rate >= 0.9 and consumption_rate >= 0.8:
            print("âœ“ å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€…æµ‹è¯• é€šè¿‡")
            return True
        else:
            print("âœ— å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€…æµ‹è¯• å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€…æµ‹è¯•å¼‚å¸¸: {e}")
        traceback.print_exc()
        destroy_queue(queue_name)
        return False


def test_queue_reference_passing():
    """æµ‹è¯•é˜Ÿåˆ—å¼•ç”¨åœ¨å¤šè¿›ç¨‹é—´ä¼ é€’"""
    print("\n" + "="*60)
    print("æµ‹è¯•: é˜Ÿåˆ—å¼•ç”¨ä¼ é€’")
    print("="*60)
    
    queue_name = f"test_ref_pass_{int(time.time())}"
    
    try:
        # æ¸…ç†å¹¶åˆ›å»ºé˜Ÿåˆ—
        destroy_queue(queue_name)
        
        main_queue = SageQueue(queue_name, maxsize=128*1024)
        print(f"âœ“ åˆ›å»ºé˜Ÿåˆ—: {queue_name}")
        
        # è·å–å¯åºåˆ—åŒ–çš„é˜Ÿåˆ—å¼•ç”¨
        queue_ref = main_queue.get_reference()
        queue_ref_dict = queue_ref.__getstate__()  # åºåˆ—åŒ–ä¸ºå­—å…¸
        
        print(f"âœ“ è·å–é˜Ÿåˆ—å¼•ç”¨: {queue_ref}")
        print(f"  å¼•ç”¨æ•°æ®: {queue_ref_dict}")
        
        main_queue.close()
        
        # æµ‹è¯•å‚æ•°
        num_workers = 4
        operations_per_worker = 15
        
        print(f"\nå¯åŠ¨ {num_workers} ä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªæ‰§è¡Œ {operations_per_worker} æ¬¡æ“ä½œ...")
        
        # ä½¿ç”¨ ProcessPoolExecutor å¯åŠ¨å¤šä¸ªè¿›ç¨‹ï¼Œä¼ é€’åºåˆ—åŒ–çš„å¼•ç”¨
        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            for worker_id in range(num_workers):
                future = executor.submit(multiprocess_ref_worker, queue_ref_dict, worker_id, operations_per_worker)
                futures.append(future)
                print(f"  å¯åŠ¨å¼•ç”¨å·¥ä½œè¿›ç¨‹-{worker_id}")
            
            # æ”¶é›†ç»“æœ
            print("\nç­‰å¾…è¿›ç¨‹å®Œæˆ...")
            results = []
            for future in as_completed(futures, timeout=25):
                result = future.result()
                results.append(result)
                if result['success']:
                    print(f"  âœ“ RefWorker-{result['worker_id']}: "
                          f"å†™å…¥ {result['completed_writes']}, è¯»å– {result['completed_reads']}, "
                          f"{result['ops_per_sec']:.1f} ops/sec")
                else:
                    print(f"  âœ— RefWorker-{result['worker_id']}: å¤±è´¥ - {result.get('error', 'Unknown')}")
        
        # æ£€æŸ¥æœ€ç»ˆé˜Ÿåˆ—çŠ¶æ€
        final_queue = SageQueue(queue_name)
        final_stats = final_queue.get_stats()
        
        # è¯»å–å‰©ä½™æ¶ˆæ¯
        remaining_messages = []
        while not final_queue.empty():
            try:
                msg = final_queue.get_nowait()
                remaining_messages.append(msg)
            except:
                break
        
        final_queue.close()
        
        # ç»Ÿè®¡ç»“æœ
        successful_workers = [r for r in results if r['success']]
        total_writes = sum(r['completed_writes'] for r in successful_workers)
        total_reads = sum(r['completed_reads'] for r in successful_workers)
        total_errors = sum(r['errors'] for r in successful_workers)
        
        print(f"\nç»“æœç»Ÿè®¡:")
        print(f"  æˆåŠŸè¿›ç¨‹: {len(successful_workers)}/{num_workers}")
        print(f"  æ€»å†™å…¥: {total_writes}")
        print(f"  æ€»è¯»å–: {total_reads}")
        print(f"  æ€»é”™è¯¯: {total_errors}")
        print(f"  å‰©ä½™æ¶ˆæ¯: {len(remaining_messages)}")
        print(f"  é˜Ÿåˆ—æœ€ç»ˆç»Ÿè®¡: {final_stats}")
        
        # æ˜¾ç¤ºéƒ¨åˆ†å‰©ä½™æ¶ˆæ¯ä½œä¸ºæ ·æœ¬
        if remaining_messages:
            print(f"  å‰©ä½™æ¶ˆæ¯æ ·æœ¬ (å‰3æ¡):")
            for i, msg in enumerate(remaining_messages[:3]):
                print(f"    {i+1}: {msg}")
        
        # æ¸…ç†
        destroy_queue(queue_name)
        
        # è¯„ä¼°æµ‹è¯•ç»“æœ
        success_rate = len(successful_workers) / num_workers
        write_efficiency = total_writes / (num_workers * operations_per_worker) if num_workers * operations_per_worker > 0 else 0
        
        print(f"\næµ‹è¯•è¯„ä¼°:")
        print(f"  è¿›ç¨‹æˆåŠŸç‡: {success_rate:.1%}")
        print(f"  å†™å…¥æ•ˆç‡: {write_efficiency:.1%}")
        
        if success_rate >= 0.8 and write_efficiency >= 0.8:
            print("âœ“ é˜Ÿåˆ—å¼•ç”¨ä¼ é€’æµ‹è¯• é€šè¿‡")
            return True
        else:
            print("âœ— é˜Ÿåˆ—å¼•ç”¨ä¼ é€’æµ‹è¯• å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— é˜Ÿåˆ—å¼•ç”¨ä¼ é€’æµ‹è¯•å¼‚å¸¸: {e}")
        traceback.print_exc()
        destroy_queue(queue_name)
        return False


def test_concurrent_read_write():
    """æµ‹è¯•é«˜å¹¶å‘æ··åˆè¯»å†™"""
    print("\n" + "="*60)
    print("æµ‹è¯•: é«˜å¹¶å‘æ··åˆè¯»å†™")
    print("="*60)
    
    queue_name = f"test_concurrent_rw_{int(time.time())}"
    
    try:
        # æ¸…ç†å¹¶åˆ›å»ºé˜Ÿåˆ—
        destroy_queue(queue_name)
        
        main_queue = SageQueue(queue_name, maxsize=512*1024)  # æ›´å¤§ç¼“å†²åŒº
        print(f"âœ“ åˆ›å»ºé˜Ÿåˆ—: {queue_name}")
        
        # é¢„å¡«å……ä¸€äº›æ¶ˆæ¯ä»¥ä¾¿è¯»å–
        print("é¢„å¡«å……é˜Ÿåˆ—...")
        for i in range(20):
            main_queue.put({
                'type': 'prefill',
                'id': i,
                'data': f'Prefill message {i}'
            })
        
        initial_stats = main_queue.get_stats()
        print(f"  åˆå§‹çŠ¶æ€: {initial_stats}")
        main_queue.close()
        
        # æµ‹è¯•å‚æ•°
        num_workers = 6
        operations_per_worker = 25
        read_write_ratio = 0.4  # 40% å†™å…¥, 60% è¯»å–
        
        print(f"\nå¯åŠ¨ {num_workers} ä¸ªå¹¶å‘è¯»å†™è¿›ç¨‹...")
        print(f"æ¯ä¸ªè¿›ç¨‹æ‰§è¡Œ {operations_per_worker} æ¬¡æ“ä½œ (å†™å…¥æ¯”ä¾‹: {read_write_ratio:.0%})")
        
        # å¯åŠ¨å¹¶å‘è¯»å†™è¿›ç¨‹
        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            for worker_id in range(num_workers):
                future = executor.submit(concurrent_rw_worker, queue_name, worker_id, operations_per_worker, read_write_ratio)
                futures.append(future)
                print(f"  å¯åŠ¨å¹¶å‘å·¥ä½œè¿›ç¨‹-{worker_id}")
            
            # æ”¶é›†ç»“æœ
            print("\nç­‰å¾…è¿›ç¨‹å®Œæˆ...")
            results = []
            for future in as_completed(futures, timeout=30):
                result = future.result()
                results.append(result)
                if result['success']:
                    print(f"  âœ“ ConcurrentWorker-{result['worker_id']}: "
                          f"å†™å…¥ {result['writes_completed']}, è¯»å– {result['reads_completed']}, "
                          f"é”™è¯¯ {result['errors']}, {result['ops_per_sec']:.1f} ops/sec")
                else:
                    print(f"  âœ— ConcurrentWorker-{result['worker_id']}: å¤±è´¥ - {result.get('error', 'Unknown')}")
        
        # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
        final_queue = SageQueue(queue_name)
        final_stats = final_queue.get_stats()
        
        remaining_count = 0
        sample_messages = []
        while not final_queue.empty() and remaining_count < 100:  # é™åˆ¶è¯»å–æ•°é‡
            try:
                msg = final_queue.get_nowait()
                remaining_count += 1
                if len(sample_messages) < 5:
                    sample_messages.append(msg)
            except:
                break
        
        final_queue.close()
        
        # ç»Ÿè®¡ç»“æœ
        successful_workers = [r for r in results if r['success']]
        total_writes = sum(r['writes_completed'] for r in successful_workers)
        total_reads = sum(r['reads_completed'] for r in successful_workers)
        total_ops = sum(r['total_ops'] for r in successful_workers)
        total_errors = sum(r['errors'] for r in successful_workers)
        avg_ops_per_sec = sum(r['ops_per_sec'] for r in successful_workers) / len(successful_workers) if successful_workers else 0
        
        print(f"\nç»“æœç»Ÿè®¡:")
        print(f"  æˆåŠŸè¿›ç¨‹: {len(successful_workers)}/{num_workers}")
        print(f"  æ€»æ“ä½œæ•°: {total_ops}")
        print(f"  æ€»å†™å…¥: {total_writes}")
        print(f"  æ€»è¯»å–: {total_reads}")
        print(f"  æ€»é”™è¯¯: {total_errors}")
        print(f"  å¹³å‡ååé‡: {avg_ops_per_sec:.1f} ops/sec")
        print(f"  æœ€ç»ˆé˜Ÿåˆ—å‰©ä½™: {remaining_count}")
        print(f"  æœ€ç»ˆé˜Ÿåˆ—ç»Ÿè®¡: {final_stats}")
        
        # æ˜¾ç¤ºæ ·æœ¬æ¶ˆæ¯
        if sample_messages:
            print(f"  å‰©ä½™æ¶ˆæ¯æ ·æœ¬:")
            for i, msg in enumerate(sample_messages):
                print(f"    {i+1}: {msg}")
        
        # æ¸…ç†
        destroy_queue(queue_name)
        
        # è¯„ä¼°æµ‹è¯•ç»“æœ
        success_rate = len(successful_workers) / num_workers
        error_rate = total_errors / total_ops if total_ops > 0 else 0
        
        print(f"\næµ‹è¯•è¯„ä¼°:")
        print(f"  è¿›ç¨‹æˆåŠŸç‡: {success_rate:.1%}")
        print(f"  é”™è¯¯ç‡: {error_rate:.2%}")
        print(f"  å¹³å‡ååé‡: {avg_ops_per_sec:.1f} ops/sec")
        
        if success_rate >= 0.8 and error_rate <= 0.05 and avg_ops_per_sec > 100:
            print("âœ“ é«˜å¹¶å‘æ··åˆè¯»å†™æµ‹è¯• é€šè¿‡")
            return True
        else:
            print("âœ— é«˜å¹¶å‘æ··åˆè¯»å†™æµ‹è¯• å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— é«˜å¹¶å‘æ··åˆè¯»å†™æµ‹è¯•å¼‚å¸¸: {e}")
        traceback.print_exc()
        destroy_queue(queue_name)
        return False


def generate_usage_summary():
    """ç”Ÿæˆä½¿ç”¨æ–¹æ³•æ€»ç»“"""
    usage_summary = """
# SAGE Memory-Mapped Queue å¤šè¿›ç¨‹ä½¿ç”¨æ–¹æ³•æ€»ç»“

## æ ¸å¿ƒæ¦‚å¿µ

SAGE Memory-Mapped Queue åŸºäºå…±äº«å†…å­˜å®ç°è·¨è¿›ç¨‹é€šä¿¡ï¼Œæ”¯æŒï¼š
- é«˜æ€§èƒ½å†…å­˜æ˜ å°„ç¯å½¢ç¼“å†²åŒº
- è·¨è¿›ç¨‹é›¶æ‹·è´æ•°æ®ä¼ é€’
- çº¿ç¨‹å®‰å…¨çš„å¹¶å‘è¯»å†™æ“ä½œ
- å¯åºåˆ—åŒ–çš„é˜Ÿåˆ—å¼•ç”¨ä¼ é€’

## ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬é˜Ÿåˆ—åˆ›å»ºå’Œä½¿ç”¨

```python
from sage_queue import SageQueue, destroy_queue

# åˆ›å»ºé˜Ÿåˆ—
queue_name = "my_shared_queue"
queue = SageQueue(queue_name, maxsize=64*1024)  # 64KB ç¼“å†²åŒº

# å†™å…¥æ•°æ®
queue.put({"message": "Hello, World!", "data": [1, 2, 3]})

# è¯»å–æ•°æ®
message = queue.get()
print(message)  # {'message': 'Hello, World!', 'data': [1, 2, 3]}

# å…³é—­é˜Ÿåˆ—
queue.close()

# é”€æ¯å…±äº«å†…å­˜ï¼ˆå¯é€‰ï¼Œç¨‹åºç»“æŸæ—¶è‡ªåŠ¨æ¸…ç†ï¼‰
destroy_queue(queue_name)
```

### 2. å¤šè¿›ç¨‹å…±äº«é˜Ÿåˆ—ï¼ˆæ–¹æ³•ä¸€ï¼šé€šè¿‡é˜Ÿåˆ—åç§°ï¼‰

```python
import multiprocessing
from sage_queue import SageQueue

def worker_process(queue_name, worker_id):
    # é€šè¿‡åç§°è¿æ¥åˆ°åŒä¸€ä¸ªå…±äº«é˜Ÿåˆ—
    queue = SageQueue(queue_name)
    
    # å†™å…¥æ•°æ®
    for i in range(10):
        queue.put(f"Worker-{worker_id} Message-{i}")
    
    queue.close()

if __name__ == "__main__":
    queue_name = "shared_queue_example"
    
    # åˆ›å»ºä¸»é˜Ÿåˆ—
    main_queue = SageQueue(queue_name, maxsize=128*1024)
    main_queue.close()  # å…³é—­å¥æŸ„ä½†ä¿ç•™å…±äº«å†…å­˜
    
    # å¯åŠ¨å¤šä¸ªè¿›ç¨‹
    processes = []
    for i in range(4):
        p = multiprocessing.Process(target=worker_process, args=(queue_name, i))
        p.start()
        processes.append(p)
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    # è¯»å–æ‰€æœ‰æ¶ˆæ¯
    read_queue = SageQueue(queue_name)
    while not read_queue.empty():
        print(read_queue.get())
    read_queue.close()
    
    destroy_queue(queue_name)
```

### 3. å¤šè¿›ç¨‹å¼•ç”¨ä¼ é€’ï¼ˆæ–¹æ³•äºŒï¼šåºåˆ—åŒ–å¼•ç”¨ï¼‰

```python
import multiprocessing
from concurrent.futures import ProcessPoolExecutor
from sage_queue import SageQueue

def ref_worker_process(queue_ref_dict, worker_id):
    # ä»åºåˆ—åŒ–å¼•ç”¨é‡å»ºé˜Ÿåˆ—å¼•ç”¨
    from sage_queue import SageQueueRef
    
    ref = SageQueueRef.__new__(SageQueueRef)
    ref.__setstate__(queue_ref_dict)
    
    # è·å–é˜Ÿåˆ—å®ä¾‹
    queue = ref.get_queue()
    
    # ä½¿ç”¨é˜Ÿåˆ—
    for i in range(5):
        queue.put(f"RefWorker-{worker_id} Data-{i}")
    
    queue.close()
    return f"Worker-{worker_id} completed"

if __name__ == "__main__":
    # åˆ›å»ºé˜Ÿåˆ—å¹¶è·å–å¼•ç”¨
    queue = SageQueue("ref_example", maxsize=64*1024)
    queue_ref = queue.get_reference()
    queue_ref_dict = queue_ref.__getstate__()  # åºåˆ—åŒ–ä¸ºå­—å…¸
    queue.close()
    
    # ä½¿ç”¨ ProcessPoolExecutor ä¼ é€’å¼•ç”¨
    with ProcessPoolExecutor(max_workers=3) as executor:
        futures = []
        for i in range(3):
            future = executor.submit(ref_worker_process, queue_ref_dict, i)
            futures.append(future)
        
        # æ”¶é›†ç»“æœ
        for future in futures:
            print(future.result())
    
    # è¯»å–ç»“æœ
    result_queue = SageQueue("ref_example")
    while not result_queue.empty():
        print(result_queue.get())
    result_queue.close()
    
    destroy_queue("ref_example")
```

### 4. ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼

```python
import multiprocessing
from concurrent.futures import ProcessPoolExecutor

def producer_worker(queue_name, producer_id, num_messages):
    queue = SageQueue(queue_name)
    for i in range(num_messages):
        message = {
            'producer_id': producer_id,
            'message_id': i,
            'content': f'Message from Producer-{producer_id}',
            'timestamp': time.time()
        }
        queue.put(message)
    queue.close()
    return f"Producer-{producer_id} sent {num_messages} messages"

def consumer_worker(queue_name, consumer_id, max_messages):
    queue = SageQueue(queue_name)
    consumed = 0
    messages = []
    
    while consumed < max_messages:
        try:
            message = queue.get(timeout=5.0)
            messages.append(message)
            consumed += 1
        except:
            break  # è¶…æ—¶æˆ–é˜Ÿåˆ—ä¸ºç©º
    
    queue.close()
    return f"Consumer-{consumer_id} consumed {consumed} messages"

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    queue_name = "prod_cons_example"
    SageQueue(queue_name, maxsize=256*1024).close()  # åˆ›å»ºé˜Ÿåˆ—
    
    with ProcessPoolExecutor() as executor:
        # å¯åŠ¨ç”Ÿäº§è€…
        producer_futures = [
            executor.submit(producer_worker, queue_name, i, 20) 
            for i in range(2)
        ]
        
        # å¯åŠ¨æ¶ˆè´¹è€…
        consumer_futures = [
            executor.submit(consumer_worker, queue_name, i, 20) 
            for i in range(2)
        ]
        
        # ç­‰å¾…å®Œæˆ
        for future in producer_futures + consumer_futures:
            print(future.result())
    
    destroy_queue(queue_name)
```

## å…³é”®è¦ç‚¹

### 1. Worker å‡½æ•°å¿…é¡»åœ¨æ¨¡å—é¡¶å±‚
```python
# âœ“ æ­£ç¡®ï¼šå®šä¹‰åœ¨æ¨¡å—é¡¶å±‚
def my_worker(queue_name, data):
    queue = SageQueue(queue_name)
    # ... å¤„ç†é€»è¾‘
    queue.close()

def main():
    # âœ— é”™è¯¯ï¼šä¸èƒ½åœ¨å‡½æ•°å†…éƒ¨å®šä¹‰ worker
    def inner_worker(queue_name):  # è¿™ä¼šå¯¼è‡´ pickle é”™è¯¯
        pass
    
    # ä½¿ç”¨ my_worker è€Œä¸æ˜¯ inner_worker
    process = multiprocessing.Process(target=my_worker, args=("queue", "data"))
    process.start()
```

### 2. é˜Ÿåˆ—ç”Ÿå‘½å‘¨æœŸç®¡ç†
```python
# åˆ›å»ºé˜Ÿåˆ—
queue = SageQueue("my_queue", maxsize=64*1024)

# ä½¿ç”¨å®Œæ¯•åå…³é—­
queue.close()  # å…³é—­å¥æŸ„ï¼Œå…±äº«å†…å­˜ä»å­˜åœ¨

# å½»åº•é”€æ¯ï¼ˆå¯é€‰ï¼‰
destroy_queue("my_queue")  # åˆ é™¤å…±äº«å†…å­˜
```

### 3. é”™è¯¯å¤„ç†
```python
from queue import Empty, Full

try:
    # éé˜»å¡æ“ä½œ
    message = queue.get_nowait()
except Empty:
    print("é˜Ÿåˆ—ä¸ºç©º")

try:
    queue.put_nowait(data)
except Full:
    print("é˜Ÿåˆ—å·²æ»¡")

# å¸¦è¶…æ—¶çš„æ“ä½œ
try:
    message = queue.get(timeout=5.0)
except Empty:
    print("è·å–è¶…æ—¶")
```

### 4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

- é€‰æ‹©åˆé€‚çš„ç¼“å†²åŒºå¤§å°ï¼ˆmaxsizeï¼‰
- é¿å…é¢‘ç¹çš„å°æ•°æ®ä¼ è¾“
- ä½¿ç”¨æ‰¹é‡æ“ä½œå‡å°‘ç³»ç»Ÿè°ƒç”¨
- é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- åŠæ—¶æ¸…ç†ä¸ä½¿ç”¨çš„é˜Ÿåˆ—

## æµ‹è¯•ç»“æœç¤ºä¾‹

æ ¹æ®åŸºå‡†æµ‹è¯•ç»“æœï¼ŒSAGE Memory-Mapped Queue å¯ä»¥è¾¾åˆ°ï¼š
- ååé‡ï¼š200K+ ops/sec (è¯»å†™)
- å»¶è¿Ÿï¼š3-5ms (å¹³å‡å¾€è¿”å»¶è¿Ÿ)
- å†…å­˜æ•ˆç‡ï¼š>90% ç¼“å†²åŒºåˆ©ç”¨ç‡
- å¹¶å‘æ€§èƒ½ï¼šæ”¯æŒå¤šè¿›ç¨‹æ— é”å¹¶å‘è®¿é—®

## å¸¸è§é—®é¢˜

1. **"Can't pickle local object" é”™è¯¯**
   - ç¡®ä¿ worker å‡½æ•°å®šä¹‰åœ¨æ¨¡å—é¡¶å±‚ï¼Œä¸åœ¨å…¶ä»–å‡½æ•°å†…éƒ¨

2. **é˜Ÿåˆ—æ»¡æˆ–ç©ºçš„å¤„ç†**
   - ä½¿ç”¨ timeout å‚æ•°é¿å…æ— é™é˜»å¡
   - åˆç†è®¾è®¡ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…çš„é€Ÿåº¦åŒ¹é…

3. **å…±äº«å†…å­˜æ¸…ç†**
   - æ­£å¸¸æƒ…å†µä¸‹ç¨‹åºç»“æŸæ—¶è‡ªåŠ¨æ¸…ç†
   - å¼‚å¸¸é€€å‡ºå¯èƒ½éœ€è¦æ‰‹åŠ¨è°ƒç”¨ destroy_queue()

4. **è·¨è¿›ç¨‹æ•°æ®ä¸€è‡´æ€§**
   - SAGE Queue ä¿è¯æ•°æ®çš„åŸå­æ€§è¯»å†™
   - å¤æ‚çš„æ•°æ®ç»“æ„ä¼šè¢«åºåˆ—åŒ–ï¼Œæ³¨æ„æ€§èƒ½å½±å“
"""
    
    return usage_summary


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("SAGE Memory-Mapped Queue å¤šè¿›ç¨‹å¹¶å‘æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    print(f"CPU æ ¸å¿ƒæ•°: {multiprocessing.cpu_count()}")
    print(f"å½“å‰è¿›ç¨‹ PID: {os.getpid()}")
    
    # è¿è¡Œæµ‹è¯•
    test_results = []
    
    try:
        # æµ‹è¯•1: å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€…
        result1 = test_multiprocess_producers_consumers()
        test_results.append(("å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€…", result1))
        
        time.sleep(2)  # é—´éš”
        
        # æµ‹è¯•2: é˜Ÿåˆ—å¼•ç”¨ä¼ é€’
        result2 = test_queue_reference_passing()
        test_results.append(("é˜Ÿåˆ—å¼•ç”¨ä¼ é€’", result2))
        
        time.sleep(2)  # é—´éš”
        
        # æµ‹è¯•3: é«˜å¹¶å‘è¯»å†™
        result3 = test_concurrent_read_write()
        test_results.append(("é«˜å¹¶å‘è¯»å†™", result3))
        
    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\næµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        traceback.print_exc()
    
    # æ€»ç»“ç»“æœ
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*60)
    
    passed_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed_tests += 1
    
    if total_tests > 0:
        print(f"\næ€»ä½“ç»“æœ: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡ ({passed_tests/total_tests:.1%})")
        
        if passed_tests == total_tests:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼SAGE Memory-Mapped Queue å¤šè¿›ç¨‹åŠŸèƒ½æ­£å¸¸ã€‚")
        elif passed_tests >= total_tests * 0.7:
            print("âš ï¸  å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½éœ€è¦ä¼˜åŒ–ã€‚")
        else:
            print("âŒ å¤šæ•°æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°ã€‚")
    
    # ç”Ÿæˆä½¿ç”¨æ–¹æ³•æ€»ç»“
    print("\n" + "="*60)
    print("ç”Ÿæˆä½¿ç”¨æ–¹æ³•æ€»ç»“...")
    usage_summary = generate_usage_summary()
    
    # ä¿å­˜ä½¿ç”¨æ–¹æ³•åˆ°æ–‡ä»¶
    summary_file = os.path.join(os.path.dirname(__file__), "USAGE_SUMMARY.md")
    try:
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(usage_summary)
        print(f"âœ“ ä½¿ç”¨æ–¹æ³•æ€»ç»“å·²ä¿å­˜åˆ°: {summary_file}")
    except Exception as e:
        print(f"âœ— ä¿å­˜ä½¿ç”¨æ–¹æ³•æ€»ç»“å¤±è´¥: {e}")
        print("\nä½¿ç”¨æ–¹æ³•æ€»ç»“:")
        print(usage_summary)


if __name__ == "__main__":
    multiprocessing.set_start_method('spawn', force=True)  # ç¡®ä¿å…¼å®¹æ€§
    main()
