import logging
import re
import json
from src.core.query_engine.operators.base_operator import BaseOperator
from src.core.prompts.utils import generate_prompt
from transformers import AutoTokenizer, LlamaForCausalLM
from src.utils.file_path import QA_DOMAIN_CLASSIFICATION_TEMPLATE

class DomainClassifier(BaseOperator):
    """
    Operator for classifying the domain of a given query. It would be classified into one of the following domains:"finance", "sports", "music", "movie", "open"
    """
    
    def __init__(self, prompt_template, model_name = "meta-llama/Meta-Llama-3-8B-Instruct"):
        """
        Initialize the DomainClassifier.
        :param prompt_template: Path to the prompt template.
        :param model_name: Name of the pre-trained model to use. Default is "meta-llama/Meta-Llama-3-8B-Instruct".
        """
        super().__init__()
        with open(prompt_template, "r") as f:
            self.system_prompt_template = f.read()
        self.llm = LlamaForCausalLM.from_pretrained(model_name)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name) 
        self.logger = logging.getLogger(self.__class__.__name__)

    def execute(self, input_data, **kwargs):
        """
        Generate a prompt using the provided template.
        :param input_data: (natural_query, query_time)
        :param kwargs: Additional parameters for prompt generation.
        :return: Generated prompt.
        """
        try:
            query, query_time = input_data[0]   
            formatted_prompts = self._format_prompts_for_entity_extraction(query, query_time)

            inputs = self.tokenizer(formatted_prompts, return_tensors="pt")
            responses = self.llm.generate(
                **inputs,
                max_new_tokens=4096,  # Maximum number of tokens to generate per output sequence.
                do_sample=True,
                top_p=0.9,  # Float that controls the cumulative probability of the top tokens to consider.
                temperature=0.1,  # Randomness of the sampling
                num_return_sequences=1  # Number of output sequences to return for each prompt.
            )
            response_text = self.tokenizer.decode(responses[0], skip_special_tokens=True)
            # print(f"Domain Classification Generated response: {response_text}")

            # Extract the domain from the generated response
            domain_json = self._extract_domain(response_text)
            domain = domain_json.get("domain", "open")
            self.logger.info(f"Classification Result: This query belongs to the '{domain}' domain.")
            
            self.emit((query, query_time, domain))
            self.logger.debug("Domain classification completed.")
        except Exception as e:
            self.logger.error(f"Error during domain classification: {str(e)}")
            raise RuntimeError(f"Domain classification failed: {str(e)}")
        

    def _format_prompts_for_entity_extraction(self, query, query_time): 
        """
        Format prompts for entity extraction using the provided queries and query times.
        :param query_times: List of query times corresponding to each query.
        :param queries: List of queries to be formatted.
        :return: List of formatted prompts.
        """    
        formatted_prompts = []
        user_message = ""
        user_message += f"Query: {query}\n"
        user_message += f"Query Time: {query_time}\n"
        

        formatted_prompts.append(
            self.tokenizer.apply_chat_template(
                [
                    {"role": "system", "content": self.system_prompt_template},
                    {"role": "user", "content": user_message},
                ],
                tokenize=False,
                add_generation_prompt=True,
            )
        )
        return formatted_prompts

    def _extract_domain(self, response_text):
        """
        Extract the domain from the generated response.
        :param response_text: The full text generated by the model.
        :return: The extracted domain.
        """
        # Extract the domain portion
        if "assistant" in response_text:
            after_assistant = response_text.split("assistant")[1].strip()
            # Extract the JSON object
            json_match = re.search(r'\{.*?\}', after_assistant, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                try:
                    json_obj = json.loads(json_str)
                    return json_obj
                except json.JSONDecodeError as e:
                    print(f"Error decoding JSON: {e}")
                    return json_str  # Return the raw JSON string if parsing fails
            else:
                return after_assistant  # Return the text after "assistant" if no JSON is found
        return response_text.strip()  

    
