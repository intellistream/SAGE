from __future__ import annotations
from typing import Dict, List
from sage_core.api.env import BaseEnvironment
from sage_core.core.operator.transformation import Transformation
from sage_utils.custom_logger import CustomLogger

class GraphNode:
    def __init__(self, name: str,env:BaseEnvironment, transformation: Transformation, parallel_index: int):
        self.name: str = name
        self.transformation: Transformation = transformation
        self.env: BaseEnvironment = env  # æ‰€å±çš„ç¯å¢ƒ
        self.parallel_index: int = parallel_index  # åœ¨è¯¥transformationä¸­çš„å¹¶è¡Œç´¢å¼•
        
        # è¾“å…¥è¾“å‡ºchannelsï¼šæ¯ä¸ªchannelæ˜¯ä¸€ä¸ªè¾¹çš„åˆ—è¡¨
        self.input_channels: List[List[GraphEdge]] = []
        # è¡¨ç¤ºè‡ªå·±ç¬¬iä¸ªinput channelæ¥å—çš„æ‰€æœ‰ä¸Šæ¸¸å¹¶è¡ŒèŠ‚ç‚¹çš„è¾“å…¥
        self.output_channels: List[List[List[GraphEdge]]] = []
        # è¡¨ç¤ºè‡ªå·±ç¬¬iä¸ªoutput channelè¾“å‡ºçš„æ‰€æœ‰â€œå¹¿æ’­ç›®æ ‡â€ï¼Œå…¶ä¸­æ¯ä¸€ä¸ªç›®æ ‡å¯ä»¥æ˜¯å¹¶è¡Œçš„ä¸€ç»„ä¸‹æ¸¸èŠ‚ç‚¹

        for _ in range(len(transformation.upstreams)):
            self.input_channels.append([])
        for _ in range(len(transformation.downstreams)):
            self.output_channels.append([])


class GraphEdge:
    def __init__(self,name:str,  upstream_node: GraphNode, upstream_channel: int, downstream_node:GraphNode = None, downstream_channel: int = None):
        """
        Initialize a compiler edge with a source and target node.
        Args:
            source (str): The name of the source node.
            target (str): The name of the target node.
        """
        self.name: str = name
        self.upstream_node:GraphNode = upstream_node
        self.upstream_channel: int = upstream_channel
        self.downstream_node:GraphNode = downstream_node
        self.downstream_channel: int = downstream_channel

class Compiler:
    def __init__(self, env:BaseEnvironment):
        self.env = env
        self.name = env.name
        self.nodes:Dict[str, GraphNode] = {}
        self.edges:Dict[str, GraphEdge] = {}
        # æ„å»ºæ•°æ®æµä¹‹é—´çš„è¿æ¥æ˜ å°„

        self.logger = CustomLogger(
            object_name=f"Compiler_{env.name}",
            log_level="DEBUG",
            console_output=False,
            file_output=True
        )
        # æ„å»ºåŸºç¡€å›¾ç»“æ„
        self._build_graph_from_pipeline(env)
        
        self.logger.info(f"Successfully converted and optimized pipeline '{env.name}' to compiler with {len(self.nodes)} nodes and {len(self.edges)} edges")

    def _build_graph_from_pipeline(self, env: BaseEnvironment):
        """
        æ ¹æ®transformation pipelineæ„å»ºå›¾, æ”¯æŒå¹¶è¡Œåº¦å’Œå¤šå¯¹å¤šè¿æ¥
        åˆ†ä¸ºä¸‰æ­¥: 1) ç”Ÿæˆå¹¶è¡ŒèŠ‚ç‚¹ 2) ç”Ÿæˆç‰©ç†è¾¹ 3) åˆ›å»ºå›¾ç»“æ„
        """
        trans_to_parallel_node_names = {}  # transformation -> list of node names
        
        # ç¬¬ä¸€æ­¥ï¼šä¸ºæ¯ä¸ªtransformationç”Ÿæˆå¹¶è¡ŒèŠ‚ç‚¹åå­—è¡¨ï¼ŒåŒæ—¶åˆ›å»ºèŠ‚ç‚¹
        self.logger.debug("Step 1: Generating parallel nodes for each transformation")
        node_count = 0
        for transformation in env.pipeline:
            node_names = []
            for i in range(transformation.parallelism):
                try:
                    node_name = f"{transformation.function_class.__name__}_{node_count}"
                    node_count += 1
                    node_names.append(node_name)
                    self.nodes[node_name] = GraphNode(node_name, env,  transformation, i)
                    self.logger.debug(f"Created node: {node_name} (parallel index: {i})")
                except Exception as e:
                    self.logger.error(f"Error creating node {node_name}: {e}")
                    raise
            trans_to_parallel_node_names[transformation] = node_names
            self.logger.debug(f"Generated {len(node_names)} parallel nodes for {transformation.operator_class.__name__}: {node_names}")
        
        # ç¬¬äºŒæ­¥ï¼šè®¡ç®—é€»è¾‘è¾¹æ•°é‡ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        self.logger.debug("Step 2: Counting logical edges")
        logical_edge_count = 0
        physical_edge_count = 0
        for transformation in env.pipeline:
            for upstream_transformation,upstream_channel in transformation.upstreams:
                logical_edge_count += 1
                upstream_parallelism = len(trans_to_parallel_node_names[upstream_transformation])
                downstream_parallelism = len(trans_to_parallel_node_names[transformation])
                physical_edge_count += upstream_parallelism * downstream_parallelism
        
        self.logger.debug(f"Total logical edges: {logical_edge_count}, total physical edges: {physical_edge_count}")
        
        # ç¬¬ä¸‰æ­¥ï¼šä¸ºæ¯æ¡é€»è¾‘è¾¹åˆ›å»ºç‰©ç†è¾¹å¹¶è¿æ¥èŠ‚ç‚¹
        self.logger.debug("Step 3: Creating compiler structure")

        for transformation in env.pipeline:
            downstream_nodes = trans_to_parallel_node_names[transformation]
            
            for downstream_input_channel, (upstream_trans, upstream_output_channel) in enumerate(transformation.upstreams):
                upstream_nodes = trans_to_parallel_node_names[upstream_trans]
                
                # æ‰¾åˆ°downstream_transformationåœ¨upstream_transformation.downstreamä¸­çš„ä½ç½®
                # downstream_idx = upstream_trans.downstream.index(transformation)
                # åˆ›å»ºm*næ¡ç‰©ç†è¾¹
                for i, upstream_node_name in enumerate(upstream_nodes):
                    upstream_node = self.nodes[upstream_node_name]
                    output_group_edges = []
                    for j, downstream_node_name in enumerate(downstream_nodes):
                        # åˆ›å»ºè¾¹å
                        edge_name = f"({upstream_node_name}, {upstream_output_channel})->({downstream_node_name},{downstream_input_channel})"
                        
                        # è·å–èŠ‚ç‚¹å¯¹è±¡
                        downstream_node = self.nodes[downstream_node_name]
                        
                        # åˆ›å»ºè¾¹å¯¹è±¡å¹¶è¿æ¥
                        edge = GraphEdge(
                            name=edge_name,
                            upstream_node=upstream_node,
                            upstream_channel=upstream_output_channel,
                            downstream_node=downstream_node,
                            downstream_channel=downstream_input_channel
                        )
                        self.logger.debug(f"Creating edge: {edge_name} ")
                        # å°†è¾¹æ·»åŠ åˆ°èŠ‚ç‚¹çš„channelsä¸­
                        #upstream_node.output_channels[upstream_output_channel].append(edge)
                        output_group_edges.append(edge)
                        downstream_node.input_channels[downstream_input_channel].append(edge)
                        
                        # å°†è¾¹æ·»åŠ åˆ°å›¾ä¸­
                        self.edges[edge_name] = edge
                    upstream_node.output_channels[upstream_output_channel].append(output_group_edges)



                self.logger.debug(f"Connected {len(upstream_nodes)}Ã—{len(downstream_nodes)} physical edges "
                                f"between {upstream_trans.operator_class.__name__} -> "
                                f"{transformation.operator_class.__name__}")
        
        self.logger.info(f"Graph construction completed: {len(self.nodes)} nodes, {len(self.edges)} edges")

    def debug_print_graph(self):
        """
        è°ƒè¯•æ–¹æ³•ï¼šæ‰“å°å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹åå­—ã€å¯¹åº”çš„transformation.functionä»¥åŠä¸Šä¸‹æ¸¸è¿æ¥ä¿¡æ¯
        æ”¯æŒæ–°çš„channelç»“æ„ï¼šinput_channelåŒ…å«æ¥è‡ªä¸Šæ¸¸å¹¶è¡ŒèŠ‚ç‚¹çš„è¾¹ï¼Œoutput_channelåŒ…å«å¤šç»„å¹¿æ’­ç›®æ ‡
        """
        lines = []
        lines.append("\n")
        lines.append("=" * 80)
        lines.append(f"Graph Debug Information for '{self.name}'")
        lines.append("=" * 80)
        
        if not self.nodes:
            lines.append("No nodes in the graph")
            self.logger.debug("\n".join(lines))
            return
        
        # æŒ‰transformationç±»å‹åˆ†ç»„æ˜¾ç¤ºèŠ‚ç‚¹
        transformation_groups = {}
        for node in self.nodes.values():
            transformation_name = node.transformation.operator_class.__name__
            if transformation_name not in transformation_groups:
                transformation_groups[transformation_name] = []
            transformation_groups[transformation_name].append(node)
        
        for transformation_name, nodes in transformation_groups.items():
            lines.append(f"\nğŸ“Š Transformation: {transformation_name}")
            lines.append(f"   Type: {nodes[0].transformation.type.value}")
            lines.append(f"   Parallelism: {len(nodes)}")
            
            # æ˜¾ç¤ºfunctionä¿¡æ¯
            sample_transformation = nodes[0].transformation
            if sample_transformation.is_instance:
                function_info = f"Instance of {sample_transformation.operator_class.__name__}"
            else:
                function_info = f"Class {sample_transformation.operator_class.__name__} (not instantiated)"
            lines.append(f"   Function: {function_info}")
            
            # æ˜¾ç¤ºæ¯ä¸ªå¹¶è¡ŒèŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
            for node in nodes:
                lines.append(f"\n   ğŸ”— Node: {node.name} (parallel_index: {node.parallel_index})")
                
                # æ˜¾ç¤ºè¾“å…¥è¿æ¥ä¿¡æ¯
                if node.input_channels:
                    lines.append(f"      ğŸ“¥ Input Channels ({len(node.input_channels)} channels):")
                    for channel_idx, channel_edges in enumerate(node.input_channels):
                        if channel_edges:
                            # ç»Ÿè®¡æ¥è‡ªä¸åŒä¸Šæ¸¸èŠ‚ç‚¹çš„è¾¹
                            upstream_info = {}
                            for edge in channel_edges:
                                upstream_trans = edge.upstream_node.transformation.operator_class.__name__
                                if upstream_trans not in upstream_info:
                                    upstream_info[upstream_trans] = []
                                upstream_info[upstream_trans].append(edge.upstream_node.name)
                            
                            lines.append(f"         Channel {channel_idx}: {len(channel_edges)} edges")
                            for upstream_trans, upstream_nodes in upstream_info.items():
                                lines.append(f"           from {upstream_trans}: {upstream_nodes}")
                        else:
                            lines.append(f"         Channel {channel_idx}: No incoming edges")
                else:
                    lines.append(f"      ğŸ“¥ Input: No input channels (source node)")
                
                # æ˜¾ç¤ºè¾“å‡ºè¿æ¥ä¿¡æ¯
                if node.output_channels:
                    lines.append(f"      ğŸ“¤ Output Channels ({len(node.output_channels)} channels):")
                    for channel_idx, broadcast_groups in enumerate(node.output_channels):
                        if broadcast_groups:
                            lines.append(f"         Channel {channel_idx}: {len(broadcast_groups)} broadcast groups")
                            for group_idx, group_edges in enumerate(broadcast_groups):
                                if group_edges:
                                    # ç»Ÿè®¡å‘é€åˆ°ä¸åŒä¸‹æ¸¸èŠ‚ç‚¹çš„è¾¹
                                    downstream_info = {}
                                    for edge in group_edges:
                                        downstream_trans = edge.downstream_node.transformation.operator_class.__name__
                                        if downstream_trans not in downstream_info:
                                            downstream_info[downstream_trans] = []
                                        downstream_info[downstream_trans].append(edge.downstream_node.name)
                                    
                                    lines.append(f"           Group {group_idx}: {len(group_edges)} edges")
                                    for downstream_trans, downstream_nodes in downstream_info.items():
                                        lines.append(f"             to {downstream_trans}: {downstream_nodes}")
                        else:
                            lines.append(f"         Channel {channel_idx}: No outgoing edges")
                else:
                    lines.append(f"      ğŸ“¤ Output: No output channels (sink node)")
        
        # æ˜¾ç¤ºå›¾çš„ç»Ÿè®¡ä¿¡æ¯
        lines.append(f"\nğŸ“ˆ Graph Statistics:")
        lines.append(f"   Total Nodes: {len(self.nodes)}")
        lines.append(f"   Total Edges: {len(self.edges)}")
        lines.append(f"   Transformations: {len(transformation_groups)}")
        
        # æ˜¾ç¤ºè¿æ¥æ‹“æ‰‘ï¼ˆåŸºäºtransformationçº§åˆ«ï¼‰
        lines.append(f"\nğŸ”„ Connection Topology:")
        transformation_connections = {}
        for transformation_name, nodes in transformation_groups.items():
            downstream_transformations = set()
            for node in nodes:
                for channel in node.output_channels:
                    for group in channel:
                        for edge in group:
                            downstream_transformations.add(edge.downstream_node.transformation.operator_class.__name__)
            transformation_connections[transformation_name] = list(downstream_transformations)
        
        for transformation_name, downstream_list in transformation_connections.items():
            if downstream_list:
                lines.append(f"   {transformation_name} -> {downstream_list}")
            else:
                lines.append(f"   {transformation_name} -> [SINK]")
        
        # æ˜¾ç¤ºæ•°æ®åˆ†å‘æ¨¡å¼ä¿¡æ¯
        lines.append(f"\nğŸ“¡ Data Distribution Patterns:")
        for transformation_name, nodes in transformation_groups.items():
            sample_node = nodes[0]
            if sample_node.output_channels:
                for channel_idx, broadcast_groups in enumerate(sample_node.output_channels):
                    if broadcast_groups:
                        distribution_type = "Round-robin/Key-by" if len(broadcast_groups) > 1 else "Broadcast"
                        lines.append(f"   {transformation_name} Channel {channel_idx}: {distribution_type} ({len(broadcast_groups)} groups)")
        
        lines.append("=" * 80)
        
        # ä¸€æ¬¡æ€§è¾“å‡ºæ‰€æœ‰è°ƒè¯•ä¿¡æ¯
        self.logger.debug("\n".join(lines))