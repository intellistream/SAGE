# Benchmark ANNS - æµå¼å‘é‡ç´¢å¼•åŸºå‡†æµ‹è¯•æ¡†æ¶

ä¸€ä¸ªå®Œæ•´çš„æµå¼ç´¢å¼•åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œä¸“æ³¨äºè¯„ä¼°å‘é‡ç´¢å¼•åœ¨åŠ¨æ€æ•°æ®åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚

**ç‰¹ç‚¹**: åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç¬¬ä¸‰æ–¹åº“æºä»£ç ï¼Œå¼€ç®±å³ç”¨ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
benchmark_anns/
â”œâ”€â”€ datasets/           # æ•°æ®é›†ç®¡ç†
â”‚   â”œâ”€â”€ base.py        # æ•°æ®é›†åŸºç±»
â”‚   â”œâ”€â”€ loaders.py     # æ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ registry.py    # æ•°æ®é›†æ³¨å†Œï¼ˆSIFT, Glove, éšæœºæ•°æ®ç­‰ï¼‰
â”‚
â”œâ”€â”€ bench/              # æ ¸å¿ƒæµ‹è¯•æ¡†æ¶
â”‚   â”œâ”€â”€ runner.py      # æµ‹è¯•è¿è¡Œå™¨
â”‚   â”œâ”€â”€ worker.py      # å·¥ä½œçº¿ç¨‹ï¼ˆæ”¯æŒæ‹¥å¡ä¸¢å¼ƒï¼‰
â”‚   â”œâ”€â”€ metrics.py     # æ€§èƒ½æŒ‡æ ‡è®¡ç®—
â”‚   â”œâ”€â”€ maintenance.py # ç´¢å¼•ç»´æŠ¤ç­–ç•¥
â”‚   â””â”€â”€ algorithms/    # ç®—æ³•æ¥å£
â”‚       â”œâ”€â”€ base.py    # BaseANN, BaseStreamingANN
â”‚       â””â”€â”€ registry.py # ç®—æ³•æ³¨å†Œè¡¨
â”‚
â”œâ”€â”€ algorithms_impl/    # ç®—æ³•å®ç°ä¸ç¬¬ä¸‰æ–¹åº“
â”‚   â”œâ”€â”€ faiss/         # Faiss å®Œæ•´æºç 
â”‚   â”œâ”€â”€ DiskANN/       # DiskANN å®Œæ•´æºç 
â”‚   â”œâ”€â”€ puck/          # Puck å®Œæ•´æºç 
â”‚   â”œâ”€â”€ SPTAG/         # SPTAG å®Œæ•´æºç 
â”‚   â”œâ”€â”€ candy/         # CANDY æºç 
â”‚   â”œâ”€â”€ bindings/      # Python ç»‘å®šï¼ˆPyCANDYï¼‰
â”‚   â”œâ”€â”€ build.sh       # ç¼–è¯‘è„šæœ¬
â”‚   â””â”€â”€ README.md      # è¯¦ç»†ç¼–è¯‘è¯´æ˜
â”‚
â”œâ”€â”€ runbooks/           # å®éªŒé…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ simple.yaml    # ç®€å•ç¤ºä¾‹
â”‚   â”œâ”€â”€ baseline.yaml  # åŸºå‡†æµ‹è¯•
â”‚   â””â”€â”€ experiments/   # å„ç±»å®éªŒåœºæ™¯
â”‚
â”œâ”€â”€ tests/              # æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ test_streaming.py  # æµå¼æµ‹è¯•
â”‚   â””â”€â”€ test_datasets.py   # æ•°æ®é›†æµ‹è¯•
â”‚
â””â”€â”€ utils/              # å·¥å…·å‡½æ•°
    â”œâ”€â”€ io.py          # æ–‡ä»¶ I/O
    â”œâ”€â”€ system.py      # ç³»ç»Ÿå·¥å…·
    â””â”€â”€ timestamp.py   # æ—¶é—´æˆ³å¤„ç†
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1: è‡ªåŠ¨å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# å…‹éš†ä»“åº“
git clone --recursive https://github.com/intellistream/SAGE-DB-Bench.git
cd SAGE-DB-Bench

# è¿è¡Œå®‰è£…è„šæœ¬
./install.sh

# æ¿€æ´»ç¯å¢ƒ
source venv/bin/activate
```

### æ–¹å¼2: Dockerï¼ˆå¿«é€Ÿä½“éªŒï¼‰

```bash
# æ„å»ºå¹¶è¿è¡Œ
docker-compose up sage-bench-dev

# æˆ–ä½¿ç”¨Docker
docker build -t sage-db-bench .
docker run -it -v $(pwd)/results:/app/results sage-db-bench
```

**âš ï¸ æ³¨æ„**: Dockeré€‚åˆåŠŸèƒ½æµ‹è¯•å’Œå¼€å‘ï¼Œ**ä¸æ¨èç”¨äºç²¾ç¡®çš„æ€§èƒ½æµ‹è¯•**ï¼ˆcache missã€CPUæ€§èƒ½ç­‰ä¼šå—å®¹å™¨å½±å“ï¼‰ã€‚

### æ–¹å¼3: æ‰‹åŠ¨å®‰è£…

è¯¦è§ [INSTALL.md](INSTALL.md) è·å–å®Œæ•´å®‰è£…æŒ‡å—ã€‚

```bash
# 1. å…‹éš†ä»“åº“
git clone --recursive https://github.com/intellistream/SAGE-DB-Bench.git
cd SAGE-DB-Bench

# 2. å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# 3. ç¼–è¯‘ç®—æ³•åº“ï¼ˆå¯é€‰ï¼Œç”¨äºC++ç®—æ³•ï¼‰
cd algorithms_impl
./build.sh

# 4. è¿è¡Œæµ‹è¯•
python tests/test_streaming.py
```

### è¿è¡ŒåŸºå‡†æµ‹è¯•

```bash
# ä½¿ç”¨ç®€å•é…ç½®
python __main__.py --config runbooks/simple.yaml --output results/test1

# ä½¿ç”¨åŸºå‡†é…ç½®
python __main__.py --config runbooks/baseline.yaml --output results/baseline
```

## ğŸ“Š æ”¯æŒçš„å®éªŒåœºæ™¯

åœ¨ `runbooks/` ç›®å½•ä¸‹æä¾›äº†å¤šç§å®éªŒé…ç½®ï¼š

### åŸºç¡€åœºæ™¯

- **baseline.yaml** - åŸºå‡†æ€§èƒ½æµ‹è¯•
- **simple.yaml** - ç®€å•ç¤ºä¾‹

### é«˜çº§åœºæ™¯ï¼ˆexperiments/ å­ç›®å½•ï¼‰

- **stress_tests/** - å‹åŠ›æµ‹è¯•
- **batch_sizes/** - æ‰¹æ¬¡å¤§å°å½±å“
- **event_rates/** - ä¸åŒäº‹ä»¶ç‡æµ‹è¯•
- **data_volumes/** - æ•°æ®è§„æ¨¡æµ‹è¯•
- **search_patterns/** - æŸ¥è¯¢æ¨¡å¼æµ‹è¯•
- **deletion_patterns/** - åˆ é™¤æ¨¡å¼æµ‹è¯•
- **concept_drift/** - æ•°æ®æ¼‚ç§»åœºæ™¯
- **out_of_order/** - ä¹±åºæ•°æ®å¤„ç†
- **random_contamination/** - éšæœºæ±¡æŸ“
- **random_drop/** - éšæœºä¸¢å¼ƒ

## ğŸ“ Runbook é…ç½®ç¤ºä¾‹

```yaml
name: "my_test"
description: "æµå¼ç´¢å¼•æµ‹è¯•"

# æ•°æ®é›†é…ç½®
dataset:
  name: "sift-small"  # å¯é€‰: sift, glove, random-xs ç­‰

# ç®—æ³•é…ç½®
algorithm:
  name: "faiss_hnsw"
  parameters:
    M: 16
    efConstruction: 200
    efSearch: 100

# æµ‹è¯•å‚æ•°
test:
  k: 10                # æŸ¥è¯¢è¿”å›æ•°é‡
  num_workers: 1       # å·¥ä½œçº¿ç¨‹æ•°

# æµå¼æ“ä½œåºåˆ—
operations:
  - type: initial_load
    count: 10000

  - type: batch_insert
    count: 50000
    batch_size: 1000
    event_rate: 1000   # æ¯ç§’äº‹ä»¶æ•°

  - type: search
    num_queries: 1000

  - type: maintenance_rebuild

# è¾“å‡ºé…ç½®
output:
  output_dir: "results/my_test"
  save_timestamps: true
  save_metrics: true
```

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### æ”¯æŒçš„æ“ä½œç±»å‹

1. **initial_load** - åˆå§‹æ•°æ®åŠ è½½
1. **batch_insert** - æ‰¹é‡æµå¼æ’å…¥
1. **search** - æœç´¢æ€§èƒ½æµ‹è¯•
1. **batch_delete** - æ‰¹é‡åˆ é™¤
1. **maintenance_rebuild** - ç´¢å¼•é‡å»º
1. **replace** - æ•°æ®æ›¿æ¢

### æµå¼ç‰¹æ€§

- âœ… **äº‹ä»¶æ—¶é—´æˆ³æ¨¡æ‹Ÿ** - çœŸå®çš„æ—¶é—´åºåˆ—æ•°æ®æµ
- âœ… **å¹¶å‘æŸ¥è¯¢** - åœ¨æ’å…¥è¿‡ç¨‹ä¸­æŒç»­æŸ¥è¯¢
- âœ… **æ‹¥å¡ä¸¢å¼ƒ** - å½“ç³»ç»Ÿè¿‡è½½æ—¶è‡ªåŠ¨ä¸¢å¼ƒæ•°æ®
- âœ… **ç»´æŠ¤ç­–ç•¥** - æ”¯æŒå®šæœŸé‡å»ºå’Œå¢é‡æ›´æ–°
- âœ… **å†…å­˜ç›‘æ§** - å®æ—¶è¿½è¸ªå†…å­˜ä½¿ç”¨
- âœ… **ä¹±åºå¤„ç†** - æ¨¡æ‹Ÿä¹±åºæ•°æ®åˆ°è¾¾
- âœ… **æ•°æ®æ±¡æŸ“** - æµ‹è¯•å¯¹å™ªå£°æ•°æ®çš„é²æ£’æ€§

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

æ¡†æ¶ä¼šè‡ªåŠ¨è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡ï¼š

- **å»¶è¿Ÿ (Latency)**: P50, P95, P99 å»¶è¿Ÿ
- **ååé‡ (Throughput)**: æ¯ç§’å¤„ç†çš„äº‹ä»¶æ•°
- **Drop Rate**: æ•°æ®ä¸¢å¼ƒç‡
- **Recall@k**: æŸ¥è¯¢å¬å›ç‡
- **QPS**: æ¯ç§’æŸ¥è¯¢æ•°
- **å†…å­˜ä½¿ç”¨**: å³°å€¼å’Œå¹³å‡å†…å­˜å ç”¨

## ğŸ¯ é›†æˆæ–°ç®—æ³•

### 1. å®ç°ç®—æ³•æ¥å£

```python
from benchmark_anns.bench.algorithms import BaseStreamingANN

class MyAlgorithm(BaseStreamingANN):
    def __init__(self, **params):
        super().__init__()
        # åˆå§‹åŒ–ç®—æ³•

    def insert(self, vectors, ids):
        # å®ç°æ’å…¥é€»è¾‘
        pass

    def delete(self, ids):
        # å®ç°åˆ é™¤é€»è¾‘
        pass

    def query(self, vectors, k):
        # å®ç°æŸ¥è¯¢é€»è¾‘
        pass
```

### 2. æ³¨å†Œç®—æ³•

```python
# åœ¨ bench/algorithms/registry.py ä¸­
from .my_algorithm import MyAlgorithm

def register_algorithm(name, algorithm_class, **default_params):
    ALGORITHMS[name] = {
        'class': algorithm_class,
        'params': default_params
    }

# æ³¨å†Œ
register_algorithm('my_algo', MyAlgorithm, param1=10, param2='value')
```

### 3. åˆ›å»ºé…ç½®æ–‡ä»¶

åœ¨ `runbooks/` ä¸‹åˆ›å»º YAML é…ç½®æ–‡ä»¶ï¼ŒæŒ‡å®š `algorithm.name: "my_algo"`ã€‚

## ğŸ“š æ”¯æŒçš„ç®—æ³•

### Python å®ç°

- **DummyStreamingANN** - æµ‹è¯•ç”¨è™šæ‹Ÿç®—æ³•

### C++ å®ç°ï¼ˆéœ€ç¼–è¯‘ï¼‰

- **Faiss HNSW** - é«˜æ€§èƒ½è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢
- **Faiss IVFPQ** - å€’æ’æ–‡ä»¶ + ä¹˜ç§¯é‡åŒ–
- **DiskANN** - åŸºäºç£ç›˜çš„å¤§è§„æ¨¡ç´¢å¼•
- **Puck** - é«˜æ•ˆå‘é‡æ£€ç´¢
- **CANDY** - æ‹¥å¡æ„ŸçŸ¥åŠ¨æ€ç´¢å¼•ç³»åˆ—
  - CANDY-MNRU
  - CANDY-LSHAPG
  - CANDY-SPTAG

## ğŸ—ƒï¸ æ”¯æŒçš„æ•°æ®é›†

### å†…ç½®æ•°æ®é›†

- **sift** - SIFT 1M æ•°æ®é›†
- **sift-small** - SIFT 100K æ•°æ®é›†
- **glove** - GloVe è¯å‘é‡
- **msong** - Million Song Dataset
- **coco** - COCO å›¾åƒç‰¹å¾
- **random-xs/s/m/l** - éšæœºç”Ÿæˆæ•°æ®ï¼ˆä¸åŒè§„æ¨¡ï¼‰

### æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†

```python
# åœ¨ datasets/registry.py ä¸­
from .base import Dataset

class MyDataset(Dataset):
    def __init__(self):
        super().__init__()
        self.nb = 100000  # åŸºç¡€æ•°æ®é‡
        self.nq = 1000    # æŸ¥è¯¢æ•°é‡
        self.d = 128      # å‘é‡ç»´åº¦

    def prepare(self):
        # åŠ è½½æˆ–ç”Ÿæˆæ•°æ®
        pass

    def get_dataset(self):
        # è¿”å›åŸºç¡€æ•°æ® (nb, d)
        pass

    def get_queries(self):
        # è¿”å›æŸ¥è¯¢æ•°æ® (nq, d)
        pass

# æ³¨å†Œ
DATASETS['my-dataset'] = lambda: MyDataset()
```

## ğŸ” æŸ¥çœ‹ç»“æœ

æµ‹è¯•ç»“æœä¼šä¿å­˜åœ¨æŒ‡å®šçš„è¾“å‡ºç›®å½•ä¸‹ï¼š

```
results/my_test/
â”œâ”€â”€ metrics.json       # æ€§èƒ½æŒ‡æ ‡
â”œâ”€â”€ timestamps.csv     # è¯¦ç»†æ—¶é—´æˆ³æ•°æ®
â”œâ”€â”€ config.yaml        # è¿è¡Œé…ç½®å‰¯æœ¬
â””â”€â”€ visualizations/    # å¯è§†åŒ–å›¾è¡¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
```

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### é¡¹ç›®æ¶æ„

- **æ•°æ®å±‚** (`datasets/`) - è´Ÿè´£æ•°æ®åŠ è½½å’Œç®¡ç†
- **ç®—æ³•å±‚** (`bench/algorithms/`) - å®šä¹‰ç®—æ³•æ¥å£
- **æ‰§è¡Œå±‚** (`bench/`) - æµ‹è¯•æµç¨‹æ§åˆ¶å’ŒæŒ‡æ ‡è®¡ç®—
- **å®ç°å±‚** (`algorithms_impl/`) - å…·ä½“ç®—æ³•å®ç°

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python tests/test_streaming.py
python tests/test_datasets.py

# éªŒè¯é¡¹ç›®ç»“æ„
bash tests/test_verify_project.sh
```

## ğŸ“Š æ‰¹æ¬¡çº§åˆ«æŒ‡æ ‡ï¼ˆBatch Metricsï¼‰

æ¡†æ¶ä¼šåœ¨æ¯ä¸ªæ‰¹æ¬¡æ“ä½œæ—¶ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡ï¼Œä¿å­˜åœ¨ CSV æ–‡ä»¶ä¸­ï¼š

### æ’å…¥æ“ä½œæŒ‡æ ‡ï¼ˆ\*\_inserts.csvï¼‰

- **timestamp**: æ‰¹æ¬¡å¼€å§‹æ—¶é—´
- **batch_size**: æ‰¹æ¬¡å¤§å°
- **batch_duration**: æ‰¹æ¬¡è€—æ—¶ï¼ˆç§’ï¼‰
- **insert_qps**: æ’å…¥QPSï¼ˆå‘é‡æ•°/ç§’ï¼‰
- **num_queries**: å¹¶å‘æŸ¥è¯¢æ•°
- **query_qps**: æŸ¥è¯¢QPSï¼ˆæŸ¥è¯¢æ•°/ç§’ï¼‰
- **query_latency_p50/p95/p99**: æŸ¥è¯¢å»¶è¿Ÿåˆ†ä½æ•°ï¼ˆç§’ï¼‰

### æŸ¥è¯¢æ“ä½œæŒ‡æ ‡ï¼ˆ\*\_queries.csvï¼‰

- **timestamp**: æŸ¥è¯¢æ—¶é—´æˆ³
- **num_queries**: æŸ¥è¯¢æ•°é‡
- **query_duration**: æŸ¥è¯¢æ€»è€—æ—¶
- **query_qps**: æŸ¥è¯¢QPS
- **query_latency_p50/p95/p99**: å»¶è¿Ÿåˆ†ä½æ•°

### ä½¿ç”¨åœºæ™¯

1. **æ€§èƒ½åˆ†æ** - æŸ¥çœ‹æ’å…¥ååé‡éšæ—¶é—´å˜åŒ–
1. **å¹¶å‘å½±å“** - åˆ†ææ’å…¥ä¸æŸ¥è¯¢çš„ç›¸äº’å½±å“
1. **å»¶è¿Ÿç›‘æ§** - è¿½è¸ªæŸ¥è¯¢å»¶è¿Ÿçš„å˜åŒ–è¶‹åŠ¿
1. **ç“¶é¢ˆè¯†åˆ«** - å‘ç°æ€§èƒ½ç“¶é¢ˆå’Œå¼‚å¸¸æ‰¹æ¬¡

## ğŸ¯ è®¡ç®—çœŸå€¼ï¼ˆGround Truthï¼‰

### åŸºæœ¬ç”¨æ³•

```bash
# è®¡ç®—æ•°æ®é›†çš„çœŸå€¼
python compute_gt.py --dataset sift --runbook runbooks/general_experiment.yaml

# å‚æ•°è¯´æ˜ï¼š
# --dataset: æ•°æ®é›†åç§°ï¼ˆå¦‚ sift, gloveï¼‰
# --runbook: runbook é…ç½®æ–‡ä»¶è·¯å¾„
# --k: è¿‘é‚»æ•°é‡ï¼ˆé»˜è®¤ 100ï¼‰
```

### çœŸå€¼æ–‡ä»¶

è®¡ç®—å®Œæˆåä¼šåœ¨ `raw_data/{dataset}/{size}/{runbook_name}/` ä¸‹ç”Ÿæˆï¼š

- `.gt100` - çœŸå€¼ç´¢å¼•æ–‡ä»¶
- `.tags` - ID æ˜ å°„æ–‡ä»¶
- `.data` - ä¸´æ—¶æ•°æ®æ–‡ä»¶

### æ³¨æ„äº‹é¡¹

1. **DiskANN ä¾èµ–** - ä½¿ç”¨ DiskANN çš„ `compute_groundtruth` å·¥å…·
1. **å†…å­˜éœ€æ±‚** - å¤§æ•°æ®é›†éœ€è¦è¶³å¤Ÿå†…å­˜
1. **é‡è¦å®éªŒ** - æ¡†æ¶ä¼šè‡ªåŠ¨ä¸ºæ ‡è®°ä¸ºé‡è¦çš„å®éªŒç”Ÿæˆæ‰€æœ‰é˜¶æ®µçš„çœŸå€¼

## ğŸ“¤ ç»“æœå¯¼å‡º

### å¬å›ç‡è®¡ç®—

è¿è¡Œå®Œæµ‹è¯•åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®¡ç®—å¬å›ç‡ï¼š

```bash
python -c "from bench.runner import StreamingANNRunner; \
    StreamingANNRunner('path/to/output_dir').compute_and_export_recall()"
```

### å¯¼å‡ºæ–‡ä»¶

- **results_with_recall.csv** - åŒ…å«å¬å›ç‡çš„å®Œæ•´ç»“æœ
- åŒ…å«å­—æ®µï¼š
  - operation_type: æ“ä½œç±»å‹
  - timestamp: æ—¶é—´æˆ³
  - recall@k: å¬å›ç‡
  - latency_p50/p95/p99: å»¶è¿Ÿåˆ†ä½æ•°
  - qps: æŸ¥è¯¢ååé‡

### æ‰¹é‡å¯¼å‡º

å¯¹å¤šä¸ªå®éªŒç»“æœç»Ÿä¸€è®¡ç®—å¬å›ç‡ï¼š

```bash
for dir in results/*/; do
    python -c "from bench.runner import StreamingANNRunner; \
        StreamingANNRunner('$dir').compute_and_export_recall()"
done
```

## âš ï¸ å·²çŸ¥é—®é¢˜ï¼ˆKnown Issuesï¼‰

### runner.py å¾…ä¿®å¤é—®é¢˜

1. **çœŸå€¼è·¯å¾„é—®é¢˜**

   - é—®é¢˜ï¼šæœç´¢æ“ä½œæ—¶çœŸå€¼æ–‡ä»¶è·¯å¾„ä¸æ­£ç¡®
   - å½±å“ï¼šæ— æ³•æ­£ç¡®è®¡ç®—å¬å›ç‡
   - ä¸´æ—¶æ–¹æ¡ˆï¼šæ‰‹åŠ¨æŒ‡å®šçœŸå€¼æ–‡ä»¶è·¯å¾„

1. **initial_load vs fit æ··æ·†**

   - é—®é¢˜ï¼š`initial_load` æ“ä½œè°ƒç”¨äº† `fit()` æ–¹æ³•ï¼Œä½†å¾ˆå¤šç®—æ³•æ²¡å®ç° `fit()`
   - å½±å“ï¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
   - ä¸´æ—¶æ–¹æ¡ˆï¼šåœ¨ç®—æ³•ä¸­å®ç° `fit()` æ–¹æ³•æˆ–æ”¹ç”¨ `batch_insert`

1. **çœŸå€¼æ–‡ä»¶åŠ è½½**

   - é—®é¢˜ï¼šçœŸå€¼æ–‡ä»¶åŠ è½½é€»è¾‘éœ€è¦æ”¹è¿›
   - å½±å“ï¼šæŸäº›åœºæ™¯ä¸‹æ— æ³•æ­£ç¡®åŠ è½½çœŸå€¼
   - å»ºè®®ï¼šé‡æ„çœŸå€¼æ–‡ä»¶ç®¡ç†é€»è¾‘

1. **æ­¥éª¤çº§çœŸå€¼**

   - é—®é¢˜ï¼šéœ€è¦æ”¯æŒæ¯ä¸ªæ“ä½œæ­¥éª¤çš„ç‹¬ç«‹çœŸå€¼æ–‡ä»¶
   - å½±å“ï¼šæ— æ³•å‡†ç¡®è¯„ä¼°æ¯ä¸ªé˜¶æ®µçš„æ€§èƒ½
   - è®¡åˆ’ï¼šæ”¯æŒ `step_0.gt100`, `step_1.gt100` ç­‰æ ¼å¼

## ğŸ“– æ›´å¤šæ–‡æ¡£

- `algorithms_impl/README.md` - ç®—æ³•ç¼–è¯‘å’Œå®ç°è¯¦ç»†è¯´æ˜
- `runbooks/README.md` - Runbook é…ç½®è¯¦ç»†è¯´æ˜
- `datasets/README.md` - æ•°æ®é›†è¯´æ˜

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®æ–°çš„ç®—æ³•å®ç°ã€æ•°æ®é›†æ”¯æŒå’Œå®éªŒåœºæ™¯ï¼

## ğŸ“„ è®¸å¯è¯

éµå¾ªé¡¹ç›®åŸå§‹è®¸å¯è¯ã€‚
