"""
Experiment Utilities - å®éªŒå…±äº«å·¥å…·å‡½æ•°

ä¸ºæ‰€æœ‰ Paper 1 å®éªŒæä¾›ç»Ÿä¸€çš„:
- ç¯å¢ƒè®¾ç½®
- æ•°æ®åŠ è½½
- ç»“æœä¿å­˜
- å®¢æˆ·ç«¯è·å–
- è¿›åº¦æ˜¾ç¤º
"""

from __future__ import annotations

import json
import os
import random
import urllib.request
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

import numpy as np

# =============================================================================
# æ§åˆ¶å˜é‡é…ç½® (ä» adapter_registry åŒæ­¥)
# =============================================================================
RANDOM_SEED = 42
BENCHMARK_EMBEDDING_MODEL = "BAAI/bge-small-zh-v1.5"
BENCHMARK_LLM_TEMPERATURE = 0.1

# =============================================================================
# è·¯å¾„é…ç½®
# =============================================================================
SCRIPT_DIR = Path(__file__).resolve().parent
BENCHMARK_AGENT_DIR = SCRIPT_DIR.parent.parent
BENCHMARK_ROOT = BENCHMARK_AGENT_DIR.parent.parent.parent.parent

# å°è¯•å¯¼å…¥æ•°æ®è·¯å¾„æ¨¡å—
try:
    from sage.benchmark.benchmark_agent.data_paths import get_runtime_paths

    _runtime_paths = get_runtime_paths()
    DEFAULT_OUTPUT_DIR = _runtime_paths.results_root.parent / "paper1"
    DEFAULT_DATA_DIR = _runtime_paths.data_root
except ImportError:
    SAGE_ROOT = BENCHMARK_ROOT.parent.parent
    DEFAULT_OUTPUT_DIR = SAGE_ROOT / ".sage" / "benchmark" / "paper1"
    DEFAULT_DATA_DIR = SAGE_ROOT / ".sage" / "benchmark" / "data"


# =============================================================================
# ç¯å¢ƒè®¾ç½®
# =============================================================================
def ensure_hf_endpoint_configured(verbose: bool = False) -> tuple[bool, bool]:
    """ç¡®ä¿ HuggingFace ç«¯ç‚¹å¯ç”¨ï¼ˆå¿…è¦æ—¶è‡ªåŠ¨åˆ‡æ¢é•œåƒï¼‰ã€‚"""

    configured_endpoint = False
    synced_hub = False

    endpoint = os.environ.get("HF_ENDPOINT", "").strip()
    if not endpoint:
        try:
            urllib.request.urlopen("https://huggingface.co", timeout=3)
        except Exception:
            endpoint = "https://hf-mirror.com"
            os.environ["HF_ENDPOINT"] = endpoint
            configured_endpoint = True
            if verbose:
                print(f"  Auto-configured HF mirror: {endpoint}")
    else:
        endpoint = endpoint.rstrip("/")
        os.environ["HF_ENDPOINT"] = endpoint

    if os.environ.get("HF_ENDPOINT") and not os.environ.get("HF_HUB_ENDPOINT"):
        os.environ["HF_HUB_ENDPOINT"] = os.environ["HF_ENDPOINT"]
        synced_hub = True
        if verbose:
            print(f"  HF_HUB_ENDPOINT synchronized to {os.environ['HF_HUB_ENDPOINT']}")

    return configured_endpoint, synced_hub


# åœ¨æ¨¡å—å¯¼å…¥æ—¶å°½æ—©é…ç½®é•œåƒï¼Œé¿å…åç»­å¯¼å…¥ transformers æ—¶å‘½ä¸­é»˜è®¤åŸŸå
ensure_hf_endpoint_configured(verbose=False)


def setup_experiment_env(seed: int = RANDOM_SEED, verbose: bool = True) -> None:
    """
    è®¾ç½®å®éªŒç¯å¢ƒï¼Œç¡®ä¿å¯å¤ç°æ€§ã€‚

    Args:
        seed: éšæœºç§å­
        verbose: æ˜¯å¦æ‰“å°è®¾ç½®ä¿¡æ¯
    """
    # è®¾ç½® Python éšæœºæ•°
    random.seed(seed)

    # è®¾ç½® NumPy éšæœºæ•°
    np.random.seed(seed)

    # è®¾ç½® PyTorch éšæœºæ•° (å¦‚æœå¯ç”¨)
    try:
        import torch

        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
            # ç¡®å®šæ€§ç®—æ³• (å¯èƒ½é™ä½æ€§èƒ½)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
    except ImportError:
        pass

    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ.setdefault("SAGE_TEST_MODE", "true")
    os.environ.setdefault("PYTHONHASHSEED", str(seed))

    # vLLM é…ç½®
    os.environ.setdefault("VLLM_ATTENTION_BACKEND", "FLASH_ATTN")

    # PyTorch åˆ†å¸ƒå¼è­¦å‘ŠæŠ‘åˆ¶
    os.environ.setdefault("GLOO_SOCKET_IFNAME", "lo")
    os.environ.setdefault("NCCL_SOCKET_IFNAME", "lo")
    os.environ.setdefault("TORCH_DISTRIBUTED_DEBUG", "OFF")

    ensure_hf_endpoint_configured(verbose=verbose)

    if verbose:
        print(f"  Random seed: {seed}")
        print(f"  Embedding model: {BENCHMARK_EMBEDDING_MODEL}")
        print(f"  LLM temperature: {BENCHMARK_LLM_TEMPERATURE}")


# =============================================================================
# æ•°æ®åŠ è½½
# =============================================================================
def load_benchmark_data(
    challenge: str,
    split: str = "test",
    max_samples: Optional[int] = None,
    data_dir: Optional[Path] = None,
) -> list[dict]:
    """
    åŠ è½½ benchmark æ•°æ®ã€‚

    Args:
        challenge: æŒ‘æˆ˜ç±»å‹ ("timing", "planning", "selection")
        split: æ•°æ®é›†åˆ’åˆ† ("train", "dev", "test")
        max_samples: æœ€å¤§æ ·æœ¬æ•° (None è¡¨ç¤ºå…¨éƒ¨)
        data_dir: æ•°æ®ç›®å½• (None ä½¿ç”¨é»˜è®¤)

    Returns:
        æ ·æœ¬åˆ—è¡¨
    """
    data_dir = data_dir or DEFAULT_DATA_DIR

    # æ˜ å°„ challenge åˆ°æ•°æ®ç›®å½•
    challenge_dirs = {
        "timing": "timing_judgment",
        "planning": "task_planning",
        "selection": "tool_selection",
    }

    if challenge not in challenge_dirs:
        raise ValueError(f"Unknown challenge: {challenge}. Use: {list(challenge_dirs.keys())}")

    data_file = data_dir / challenge_dirs[challenge] / f"{split}.jsonl"

    if not data_file.exists():
        print(f"  Warning: Data file not found: {data_file}")
        return []

    samples = []
    with open(data_file, encoding="utf-8") as f:
        for line in f:
            if line.strip():
                samples.append(json.loads(line))

    if max_samples is not None and max_samples > 0:
        samples = samples[:max_samples]

    return samples


def load_jsonl(file_path: Path) -> list[dict]:
    """åŠ è½½ JSONL æ–‡ä»¶ã€‚"""
    if not file_path.exists():
        return []

    samples = []
    with open(file_path, encoding="utf-8") as f:
        for line in f:
            if line.strip():
                samples.append(json.loads(line))
    return samples


# =============================================================================
# ç»“æœä¿å­˜
# =============================================================================
def save_results(
    results: dict[str, Any],
    section: str,
    name: str,
    output_dir: Optional[Path] = None,
) -> Path:
    """
    ä¿å­˜å®éªŒç»“æœã€‚

    Args:
        results: ç»“æœå­—å…¸
        section: è®ºæ–‡ç« èŠ‚ ("5_2_main", "5_3_analysis", "5_4_generalization")
        name: ç»“æœåç§° (å¦‚ "timing", "error_analysis")
        output_dir: è¾“å‡ºç›®å½• (None ä½¿ç”¨é»˜è®¤)

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    output_dir = output_dir or DEFAULT_OUTPUT_DIR

    # åˆ›å»ºç« èŠ‚ç›®å½•
    section_dir = output_dir / f"section_{section}"
    section_dir.mkdir(parents=True, exist_ok=True)

    # æ·»åŠ å…ƒæ•°æ®
    results["_metadata"] = {
        "timestamp": datetime.now().isoformat(),
        "seed": RANDOM_SEED,
        "embedding_model": BENCHMARK_EMBEDDING_MODEL,
        "llm_temperature": BENCHMARK_LLM_TEMPERATURE,
    }

    # ä¿å­˜ JSON
    output_file = section_dir / f"{name}_results.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    return output_file


def get_output_dir(section: str, output_dir: Optional[Path] = None) -> Path:
    """è·å–æŒ‡å®šç« èŠ‚çš„è¾“å‡ºç›®å½•ã€‚"""
    output_dir = output_dir or DEFAULT_OUTPUT_DIR
    section_dir = output_dir / f"section_{section}"
    section_dir.mkdir(parents=True, exist_ok=True)
    return section_dir


def get_figures_dir(output_dir: Optional[Path] = None) -> Path:
    """è·å– figures ç›®å½•ã€‚"""
    output_dir = output_dir or DEFAULT_OUTPUT_DIR
    figures_dir = output_dir / "figures"
    figures_dir.mkdir(parents=True, exist_ok=True)
    return figures_dir


def get_tables_dir(output_dir: Optional[Path] = None) -> Path:
    """è·å– tables ç›®å½•ã€‚"""
    output_dir = output_dir or DEFAULT_OUTPUT_DIR
    tables_dir = output_dir / "tables"
    tables_dir.mkdir(parents=True, exist_ok=True)
    return tables_dir


# =============================================================================
# å®¢æˆ·ç«¯è·å–
# =============================================================================
def get_llm_client():
    """
    è·å–ç»Ÿä¸€ LLM å®¢æˆ·ç«¯ã€‚

    Returns:
        UnifiedInferenceClient å®ä¾‹
    """
    try:
        from sage.llm import UnifiedInferenceClient

        return UnifiedInferenceClient.create()
    except ImportError as e:
        print(f"  Warning: Could not create LLM client: {e}")
        return None


def get_embedding_client():
    """
    è·å– Embedding å®¢æˆ·ç«¯ã€‚

    Returns:
        EmbeddingClientAdapter å®ä¾‹
    """
    try:
        from sage.common.components.sage_embedding import (
            EmbeddingClientAdapter,
            EmbeddingFactory,
        )

        raw_embedder = EmbeddingFactory.create("hf", model=BENCHMARK_EMBEDDING_MODEL)
        return EmbeddingClientAdapter(raw_embedder)
    except ImportError as e:
        print(f"  Warning: Could not create embedding client: {e}")
        return None


# =============================================================================
# è¿›åº¦æ˜¾ç¤º
# =============================================================================
def create_progress_bar(total: int, desc: str = "Processing"):
    """
    åˆ›å»ºè¿›åº¦æ¡ã€‚

    Args:
        total: æ€»æ•°
        desc: æè¿°

    Returns:
        tqdm è¿›åº¦æ¡æˆ–ç®€å•è¿­ä»£å™¨
    """
    try:
        from tqdm import tqdm

        return tqdm(total=total, desc=desc, ncols=80)
    except ImportError:
        # ç®€å•çš„è¿›åº¦æ˜¾ç¤º
        class SimpleProgress:
            def __init__(self, total, desc):
                self.total = total
                self.current = 0
                self.desc = desc

            def update(self, n=1):
                self.current += n
                if self.current % max(1, self.total // 10) == 0:
                    print(f"  {self.desc}: {self.current}/{self.total}")

            def close(self):
                print(f"  {self.desc}: Complete ({self.total})")

            def __enter__(self):
                return self

            def __exit__(self, *args):
                self.close()

        return SimpleProgress(total, desc)


# =============================================================================
# å®éªŒç»“æœæ•°æ®ç±»
# =============================================================================
from dataclasses import dataclass, field


@dataclass
class ExperimentResult:
    """å•ä¸ªç­–ç•¥çš„å®éªŒç»“æœã€‚"""

    challenge: str
    strategy: str
    metrics: dict[str, float]
    metadata: dict[str, Any] = field(default_factory=dict)
    passed: bool = False
    target: float = 0.0


@dataclass
class ExperimentSummary:
    """å®éªŒæ±‡æ€»ã€‚"""

    section: str
    challenge: str
    results: list[ExperimentResult] = field(default_factory=list)
    best_strategy: Optional[str] = None
    best_metric: Optional[float] = None
    target_met: bool = False

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸ã€‚"""
        return {
            "section": self.section,
            "challenge": self.challenge,
            "results": [
                {
                    "strategy": r.strategy,
                    "metrics": r.metrics,
                    "passed": r.passed,
                    "target": r.target,
                }
                for r in self.results
            ],
            "best_strategy": self.best_strategy,
            "best_metric": self.best_metric,
            "target_met": self.target_met,
        }


# =============================================================================
# æ‰“å°å·¥å…·
# =============================================================================
def print_section_header(title: str, width: int = 70) -> None:
    """æ‰“å°ç« èŠ‚æ ‡é¢˜ã€‚"""
    print("\n" + "=" * width)
    print(f"ğŸ“Š {title}")
    print("=" * width)


def print_subsection_header(title: str) -> None:
    """æ‰“å°å­ç« èŠ‚æ ‡é¢˜ã€‚"""
    print(f"\n  â–¸ {title}")
    print("  " + "-" * 50)


def print_result_row(strategy: str, metrics: dict, passed: bool, target: float) -> None:
    """æ‰“å°ç»“æœè¡Œã€‚"""
    primary_metric = list(metrics.values())[0] if metrics else 0.0
    status = "âœ… PASS" if passed else "âŒ FAIL"
    print(
        f"    {strategy:20s} | {primary_metric * 100:6.1f}% (target: {target * 100:.0f}%) {status}"
    )


def print_metrics_detail(metrics: dict) -> None:
    """æ‰“å°è¯¦ç»†æŒ‡æ ‡ã€‚"""
    for name, value in metrics.items():
        if isinstance(value, float):
            print(f"      - {name}: {value * 100:.1f}%")
        else:
            print(f"      - {name}: {value}")
