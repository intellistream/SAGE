# SAGE-Bench è¯„æµ‹æ¡†æ¶# SAGE-Bench è¯„æµ‹æ¡†æ¶

> æ”¯æŒ **15+ ç§æ–¹æ³•** å’Œ **8+ æ•°æ®é›†** çš„ Agent èƒ½åŠ›è¯„æµ‹æ¡†æ¶> æ”¯æŒ **15+ ç§æ–¹æ³•** å’Œ **6+ å¤–éƒ¨æ•°æ®é›†** çš„ Agent èƒ½åŠ›è¯„æµ‹æ¡†æ¶

æœ¬æ¡†æ¶æœåŠ¡äºä¸¤ç¯‡è®ºæ–‡ï¼šæœ¬æ¡†æ¶æœåŠ¡äºä¸¤ç¯‡è®ºæ–‡ï¼š

1. **Paper 1 (Benchmark)**: SAGE-Bench - ç»Ÿä¸€è¯„æµ‹æ¡†æ¶ï¼Œå¯¹æ¯”ç°æœ‰ SOTA æ–¹æ³•1. **Paper 1 (Benchmark)**: SAGE-Bench -
   ç»Ÿä¸€è¯„æµ‹æ¡†æ¶ï¼Œå¯¹æ¯”ç°æœ‰ SOTA æ–¹æ³•

1. **Paper 2 (Method)**: SAGE-Agent - Streaming Adaptive Learning æ¡†æ¶1. **Paper 2 (Method)**:
   SAGE-Agent - Streaming Adaptive Learning æ¡†æ¶

---\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

## ğŸš€ å¿«é€Ÿå¼€å§‹## ğŸ“ è„šæœ¬æ¶æ„

### ç»Ÿä¸€ CLI å…¥å£ (æ¨è)### ç»Ÿä¸€å…¥å£ (æ¨è)

æ‰€æœ‰åŠŸèƒ½é€šè¿‡ `sage-bench` CLI è®¿é—®ï¼š\`\`\`bash

# äº¤äº’å¼è¿è¡Œ

````bashpython sage_benchmark_cli.py

# åˆ—å‡ºå¯ç”¨æ•°æ®é›†

sage-bench list datasets# æˆ–ç›´æ¥æŒ‡å®šå®éªŒ

python sage_benchmark_cli.py --paper 1 --experiment tool_selection

# åˆ—å‡ºå¯ç”¨æ–¹æ³•python sage_benchmark_cli.py --paper 2 --experiment sage_agent_full

sage-bench list methods```



# å·¥å…·é€‰æ‹©è¯„æµ‹### è„šæœ¬å¯¹ç…§è¡¨

sage-bench eval --dataset sage --samples 100

sage-bench eval --dataset acebench --methods keyword,embedding,gorilla| è„šæœ¬                              | Paper | ç”¨é€”                                    |

sage-bench eval --dataset all        # è·¨æ•°æ®é›†å¯¹æ¯”| --------------------------------- | ----- | --------------------------------------- |

| `sage_benchmark_cli.py`           | 1 & 2 | **ç»Ÿä¸€äº¤äº’å¼å…¥å£**                      |

# è¿è¡Œå®Œæ•´ Benchmark (ä¸‰ä¸ª Challenge)| `run_all_experiments.py`          | 1     | Benchmark: ä¸‰ä¸ª Challenge å…¨é‡è¯„æµ‹      |

sage-bench run --quick               # å¿«é€Ÿæ¨¡å¼| `run_unified_eval.py`             | 1     | Benchmark: è·¨æ•°æ®é›† Tool Selection å¯¹æ¯” |

sage-bench run --challenge timing    # å•ä¸ª Challenge| `run_full_training_comparison.py` | 2     | Method: SAGE-Agent æ–¹æ³•å¯¹æ¯”             |

| `run_acebench_comparison.py`      | 1     | Benchmark: å¤–éƒ¨æ•°æ®é›†éªŒè¯               |

# è®­ç»ƒæ–¹æ³•å¯¹æ¯” (Paper 2)

sage-bench train --quick______________________________________________________________________

sage-bench train --methods A_baseline,D_combined

## ğŸ¯ æ–¹æ³•åˆ†ç±»

# LLM æœåŠ¡ç®¡ç†

sage-bench llm status### ğŸ“˜ Paper 1: Benchmark (ç°æœ‰ SOTA æ–¹æ³•å¯¹æ¯”)

sage-bench llm start --model Qwen/Qwen2.5-7B-Instruct

sage-bench llm stopè¿™äº›æ˜¯ **æ–‡çŒ®ä¸­å·²æœ‰çš„æ–¹æ³•**ï¼Œç”¨äºå»ºç«‹ baseline å¯¹æ¯”ã€‚ **Benchmark è®ºæ–‡ä¸æå‡ºæ–°æ–¹æ³•ï¼Œåªåšç³»ç»Ÿæ€§è¯„æµ‹ã€‚**



# äº¤äº’å¼æ¨¡å¼#### Challenge 1: Timing Judgment

sage-bench interactive

```| æ–¹æ³• ID             | åç§°       | æ¥æº   | æè¿°                  |

| ------------------- | ---------- | ------ | --------------------- |

---| `timing.rule_based` | Rule-based | Common | å…³é”®è¯åŒ¹é… + æ­£åˆ™æ¨¡å¼ |

| `timing.llm_based`  | LLM-based  | Common | ç›´æ¥ç”¨ LLM åˆ¤æ–­       |

## ğŸ“ è„šæœ¬æ¶æ„| `timing.hybrid`     | Hybrid     | Common | Rule åˆç­› + LLM ç²¾åˆ¤  |

| `timing.embedding`  | Embedding  | Common | è¯­ä¹‰ç›¸ä¼¼åº¦åˆ¤æ–­        |

````

scripts/#### Challenge 2: Task Planning

â”œâ”€â”€ sage_bench # ğŸŒŸ ç»Ÿä¸€ CLI å…¥å£ (æ¨èä½¿ç”¨)

â”œâ”€â”€ \_internal/ # å†…éƒ¨æ¨¡å— (ä¸è¦ç›´æ¥è°ƒç”¨)| æ–¹æ³• ID | åç§° | æ¥æº | å‚è€ƒæ–‡çŒ® |

â”‚ â”œâ”€â”€ unified_eval.py # å·¥å…·é€‰æ‹©è¯„æµ‹| ---------------------- | ---------------- | ------ |
\---------------- |

â”‚ â”œâ”€â”€ all_experiments.py # å®Œæ•´ Benchmark| `planner.simple` | Simple (Greedy) | Common | - |

â”‚ â”œâ”€â”€ training_comparison.py # è®­ç»ƒå¯¹æ¯”| `planner.hierarchical` | Hierarchical | Common | - |

â”‚ â””â”€â”€ interactive.py # äº¤äº’æ¨¡å¼| `planner.llm_based` | LLM-based | Common | - |

â”œâ”€â”€ run_unified_eval.py # åŠŸèƒ½æ¨¡å— (æ”¯æŒç›´æ¥è°ƒç”¨ï¼Œå»ºè®®ç”¨ CLI)| `planner.react` | ReAct | SOTA | Yao et al., 2023 |

â”œâ”€â”€ run_all_experiments.py # åŠŸèƒ½æ¨¡å— (æ”¯æŒç›´æ¥è°ƒç”¨ï¼Œå»ºè®®ç”¨ CLI)| `planner.tot` | Tree-of-Thoughts | SOTA | Yao et
al., 2023 |

â””â”€â”€ ...

````#### Challenge 3: Tool Selection



### CLI å­å‘½ä»¤| æ–¹æ³• ID              | åç§°            | æ¥æº    | å‚è€ƒæ–‡çŒ®           |

| -------------------- | --------------- | ------- | ------------------ |

| å‘½ä»¤ | åŠŸèƒ½ | ç¤ºä¾‹ || `selector.keyword`   | Keyword (BM25)  | Classic | Robertson et al.   |

|------|------|------|| `selector.embedding` | Embedding       | Common  | BGE-M3 (BAAI)      |

| `eval` | å·¥å…·é€‰æ‹©è¯„æµ‹ | `sage-bench eval --dataset all` || `selector.hybrid`    | Hybrid (RRF)    | Common  | -                  |

| `run` | å®Œæ•´ Benchmark | `sage-bench run --quick` || `selector.gorilla`   | Gorilla         | SOTA    | Patil et al., 2023 |

| `train` | è®­ç»ƒæ–¹æ³•å¯¹æ¯” | `sage-bench train --dry-run` || `selector.dfsdt`     | DFSDT (ToolLLM) | SOTA    | Qin et al., 2023   |

| `llm` | LLM æœåŠ¡ç®¡ç† | `sage-bench llm status` || `llm_direct`         | LLM Direct      | Common  | -                  |

| `list` | åˆ—å‡ºå¯ç”¨èµ„æº | `sage-bench list datasets` |

| `interactive` | äº¤äº’å¼æ¨¡å¼ | `sage-bench interactive` |______________________________________________________________________



---### ğŸ“™ Paper 2: SAGE-Agent (åŸåˆ›æ–¹æ³•)



## ğŸ“Š æ”¯æŒçš„æ•°æ®é›†**æ ¸å¿ƒåˆ›æ–°**: å°† Agent å­¦ä¹ é‡æ–°å®šä¹‰ä¸º **åœ¨çº¿æµå­¦ä¹ é—®é¢˜**ï¼Œæå‡º Streaming Adaptive Learning æ¡†æ¶ã€‚



| æ•°æ®é›† | æ¥æº | æè¿° |#### æ¶æ„æ¦‚è§ˆ

|--------|------|------|

| `sage` | Built-in | SAGE-Bench (1200 synthetic tools) |```

| `acebench` | HuggingFace | ToolACE from Team-ACE |â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

| `apibank` | External | API-Bank (Microsoft/Alibaba) |â”‚                    SAGE-Agent Framework                      â”‚

| `toolalpaca` | External | ToolAlpaca (Microsoft) |â”‚                                                             â”‚

| `bfcl` | External | Berkeley Function Calling Leaderboard |â”‚  Query Stream â”€â”€â†’ [SSIS] â”€â”€â†’ [Priority Buffer] â”€â”€â†’ [Train]  â”‚

| `toolbench` | External | ToolBench (Tsinghua/OpenBMB) |â”‚       â”‚              â”‚              â”‚                â”‚      â”‚

| `taskbench` | External | TaskBench (PKU) |â”‚       â”‚     Importance Score   Experience      Online Update â”‚

| `metatool` | External | MetaTool (Tsinghua) |â”‚       â”‚     (U + D + F)        Replay               â”‚      â”‚

â”‚       â”‚                                              â”‚      â”‚

æŸ¥çœ‹æ‰€æœ‰æ•°æ®é›†ï¼šâ”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚

```bashâ”‚                                                             â”‚

sage-bench list datasetsâ”‚  [Unified Multi-Task Network]                               â”‚

```â”‚  â”œâ”€â”€ Timing Head    â†â”€â”€â”                                    â”‚

â”‚  â”œâ”€â”€ Selection Head â†â”€â”€â”¼â”€â”€ Cross-Task Attention             â”‚

---â”‚  â””â”€â”€ Planning Head  â†â”€â”€â”˜                                    â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸ¯ æ”¯æŒçš„æ–¹æ³•```



### Challenge 3: Tool Selection#### ä¸‰å¤§æ ¸å¿ƒç»„ä»¶



| æ–¹æ³• | æ¥æº | æè¿° || ç»„ä»¶                     | å…¨ç§°                               | åŠŸèƒ½                 | åˆ›æ–°ç‚¹                                            |

|------|------|------|| ------------------------ | ---------------------------------- | -------------------- | ------------------------------------------------- |

| `keyword` | Classic | BM25 keyword matching || **SSIS**                 | Streaming Sample Importance Scorer | å®æ—¶è¯„ä¼°æ ·æœ¬è®­ç»ƒä»·å€¼ | ä¸‰ç»´åº¦è¯„åˆ† (Uncertainty + Diversity + Forgetting) |

| `embedding` | Common | Semantic embedding similarity || **Priority Replay**      | Importance-Weighted Replay Buffer  | ä¼˜å…ˆçº§ç»éªŒå›æ”¾       | Sum-tree O(log n) é‡‡æ · + IS æƒé‡æ ¡æ­£              |

| `hybrid` | Common | Keyword + Embedding fusion (RRF) || **Cross-Task Attention** | Unified Multi-Task Network         | è·¨ä»»åŠ¡ä¿¡æ¯å…±äº«       | Timing â†” Selection â†” Planning ååŒ                |

| `gorilla` | Berkeley | Retrieval + LLM reranking |

| `dfsdt` | Tsinghua | Tree search (ToolLLM) |#### æ¶ˆèå®éªŒé…ç½®

| `llm_direct` | Baseline | Direct LLM prompting |

| æ–¹æ³• ID             | åç§°                | SSIS | Replay | CrossTask | è¯´æ˜               |

æŸ¥çœ‹æ‰€æœ‰æ–¹æ³•ï¼š| ------------------- | ------------------- | :--: | :----: | :-------: | ------------------ |

```bash| `SAGE_sft_baseline` | Baseline SFT        |  âŒ  |   âŒ   |    âŒ     | æ¶ˆèåŸºå‡†           |

sage-bench list methods| `SAGE_ssis_only`    | +SSIS               |  âœ…  |   âŒ   |    âŒ     | åŠ å…¥æ ·æœ¬é‡è¦æ€§è¯„ä¼° |

```| `SAGE_ssis_replay`  | +SSIS +Replay       |  âœ…  |   âœ…   |    âŒ     | åŠ å…¥ä¼˜å…ˆçº§å›æ”¾     |

| `SAGE_full`         | **Full SAGE-Agent** |  âœ…  |   âœ…   |    âœ…     | å®Œæ•´æ–¹æ³•           |

---

#### é¢„æœŸæ€§èƒ½æå‡

## ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹

| Challenge               | Baseline Best | SAGE-Agent | æå‡ |

### Paper 1: Benchmark å®éªŒ| ----------------------- | ------------- | ---------- | ---- |

| Tool Selection (Top-5)  | 82%           | **94%**    | +12% |

```bash| Task Planning (Success) | 27%           | **85%**    | +58% |

# 1. å¿«é€Ÿè¯„æµ‹ (è·³è¿‡ LLM æ–¹æ³•)| Timing Judgment (Acc)   | 76%           | **95%**    | +19% |

sage-bench run --quick --skip-llm

#### æ•ˆç‡æå‡

# 2. è·¨æ•°æ®é›†å·¥å…·é€‰æ‹©å¯¹æ¯”

sage-bench eval --dataset all --methods keyword,embedding,hybrid,gorilla --samples 100| æŒ‡æ ‡                   | ä¼ ç»Ÿ SFT | SAGE-Agent | æå‡       |

| ---------------------- | -------- | ---------- | ---------- |

# 3. å•ä¸ª Challenge è¯„æµ‹| è®­ç»ƒæ—¶é—´               | 1.0x     | **0.4x**   | 2.5x æ›´å¿«  |

sage-bench run --challenge tool_selection| æ•°æ®åˆ©ç”¨               | 100%     | **~35%**   | æ›´é«˜æ•ˆ     |

sage-bench run --challenge timing| åœ¨çº¿é€‚åº” (æ€§èƒ½ä¸‹é™/è½®) | -8%      | **-0.5%**  | 16x æ›´ç¨³å®š |

sage-bench run --challenge planning

```______________________________________________________________________



### Paper 2: SAGE-Agent å®éªŒ## ğŸ“š æ•°æ®é›†



```bash### SAGE-Bench åŸç”Ÿæ•°æ®

# 1. å¿«é€Ÿè®­ç»ƒå¯¹æ¯”

sage-bench train --quick| ä»»åŠ¡            | æ ·æœ¬æ•°    | Train | Dev | Test |

| --------------- | --------- | ----- | --- | ---- |

# 2. å®Œæ•´æ¶ˆèå®éªŒ| Tool Selection  | 600       | 420   | 90  | 90   |

sage-bench train --methods A_baseline,B_coreset,C_continual,D_combined| Task Planning   | 300       | 210   | 45  | 45   |

| Timing Judgment | 300       | 210   | 45  | 45   |

# 3. æ¨¡æ‹Ÿè¿è¡Œ (ä¸å®é™…è®­ç»ƒ)| **Total**       | **1,200** | 840   | 180 | 180  |

sage-bench train --dry-run

```### å¤–éƒ¨æ•°æ®é›†é›†æˆ



### LLM æœåŠ¡ç®¡ç†| æ•°æ®é›†     | æ¥æº                   | æ ·æœ¬æ•°  | ç”¨é€”           |

| ---------- | ---------------------- | ------- | -------------- |

```bash| ACEBench   | Team-ACE (HuggingFace) | 10,000+ | è·¨æ•°æ®é›†éªŒè¯   |

# æ£€æŸ¥æœåŠ¡çŠ¶æ€| API-Bank   | Microsoft/Alibaba      | 2,138   | å¤šè½® API å¯¹è¯  |

sage-bench llm status| ToolAlpaca | Microsoft              | 3,928   | å·¥å…·å­¦ä¹ å¯¹è¯   |

| ToolBench  | Tsinghua/OpenBMB       | 16,000+ | å¤§è§„æ¨¡å·¥å…·æ£€ç´¢ |

# å¯åŠ¨ vLLM æœåŠ¡

sage-bench llm start --model Qwen/Qwen2.5-0.5B-Instruct --port 8901______________________________________________________________________



# åœæ­¢æœåŠ¡## ğŸš€ å¿«é€Ÿå¼€å§‹

sage-bench llm stop

```### Paper 1: Benchmark å®éªŒ



---```bash

# 1. è¿è¡Œå®Œæ•´ Benchmark (ä¸‰ä¸ª Challenge)

## ğŸ“ è¾“å‡ºç»“æ„python run_all_experiments.py --quick  # å¿«é€Ÿæµ‹è¯•

python run_all_experiments.py          # å®Œæ•´è¯„æµ‹

æ‰€æœ‰ç»“æœä¿å­˜åœ¨ `~/.sage/benchmark/results/`:

# 2. è·¨æ•°æ®é›†éªŒè¯

```python run_unified_eval.py --datasets sage acebench --samples 100

~/.sage/benchmark/results/

â”œâ”€â”€ unified_eval_results.json      # å·¥å…·é€‰æ‹©è¯„æµ‹ç»“æœ# 3. å•ç‹¬è¯„æµ‹ Tool Selection

â”œâ”€â”€ all_results.json               # å®Œæ•´ Benchmark ç»“æœpython sage_benchmark_cli.py --paper 1 --experiment tool_selection

â”œâ”€â”€ figures/                       # ç”Ÿæˆçš„å›¾è¡¨```

â”‚   â”œâ”€â”€ fig4_overall_comparison.pdf

â”‚   â””â”€â”€ fig5_planning_by_complexity.pdf### Paper 2: SAGE-Agent å®éªŒ

â””â”€â”€ tables/                        # LaTeX è¡¨æ ¼

    â”œâ”€â”€ table1_projected_performance.tex```bash

    â””â”€â”€ table2_observed_benchmark.tex# 1. å®Œæ•´æ¶ˆèå®éªŒ

```python run_full_training_comparison.py --quick  # å¿«é€Ÿæµ‹è¯•

python run_full_training_comparison.py          # A100 å®Œæ•´è®­ç»ƒ

---

# 2. å•ç‹¬æµ‹è¯• SAGE-Agent Full

## ğŸ”§ å¼€å‘è€…æŒ‡å—python sage_benchmark_cli.py --paper 2 --experiment sage_agent_full



### æ·»åŠ æ–°æ•°æ®é›†# 3. åœ¨çº¿é€‚åº”å®éªŒ (åŠ¨æ€å·¥å…·åº“)

python sage_benchmark_cli.py --paper 2 --experiment online_adaptation

1. åœ¨ `external_benchmarks/` ä¸­æ·»åŠ ä¸‹è½½è„šæœ¬```

2. åœ¨ `EXTERNAL_BENCHMARKS` å­—å…¸ä¸­æ³¨å†Œ

3. æ›´æ–° `sage-bench list datasets` è¾“å‡º______________________________________________________________________



### æ·»åŠ æ–°æ–¹æ³•## ğŸ“Š ç»“æœè¾“å‡º



1. å®ç° `BaseSelectorAdapter` æ¥å£æ‰€æœ‰å®éªŒç»“æœä¿å­˜åœ¨ `outputs/` ç›®å½•ï¼š

2. åœ¨ `create_evaluator()` ä¸­æ³¨å†Œ

3. æ›´æ–° `sage-bench list methods` è¾“å‡º```

outputs/

---â”œâ”€â”€ paper1_benchmark/

â”‚   â”œâ”€â”€ timing_results.json

## ğŸ“ å¼•ç”¨â”‚   â”œâ”€â”€ planning_results.json

â”‚   â”œâ”€â”€ tool_selection_results.json

```bibtexâ”‚   â””â”€â”€ cross_dataset_validation.json

@inproceedings{sage-bench-2026,â”‚

  title={SAGE-Bench: A Unified Benchmark for Evaluating Agent Capabilities},â””â”€â”€ paper2_method/

  author={...},    â”œâ”€â”€ ablation_study/

  booktitle={ICML},    â”‚   â”œâ”€â”€ SAGE_sft_baseline.json

  year={2026}    â”‚   â”œâ”€â”€ SAGE_ssis_only.json

}    â”‚   â”œâ”€â”€ SAGE_ssis_replay.json

```    â”‚   â””â”€â”€ SAGE_full.json

    â”œâ”€â”€ efficiency_analysis.json
    â””â”€â”€ online_adaptation.json
````

______________________________________________________________________

## ğŸ“– ç›¸å…³è®ºæ–‡

### Paper 1: SAGE-Bench (Benchmark)

- **å®šä½**: Dataset & Benchmark Track
- **è´¡çŒ®**: ç»Ÿä¸€è¯„æµ‹æ¡†æ¶ + æ•°æ®é›† + ç°æœ‰æ–¹æ³•ç³»ç»Ÿå¯¹æ¯”
- **ä¸åŒ…å«**: æ–°æ–¹æ³•æå‡º

### Paper 2: SAGE-Agent (Method)

- **å®šä½**: Method Paper
- **è´¡çŒ®**: Streaming Adaptive Learning æ¡†æ¶
- **æ ¸å¿ƒç»„ä»¶**: SSIS + Priority Replay + Cross-Task Attention
- **èƒŒæ™¯**: åŸºäºæµè®¡ç®—å’Œåœ¨çº¿æŒç»­å­¦ä¹ çš„ç ”ç©¶ç»éªŒ

______________________________________________________________________

## ğŸ”§ å¼€å‘è€…æŒ‡å—

### æ·»åŠ æ–°æ–¹æ³•

1. åœ¨ `adapter_registry.py` ä¸­æ³¨å†Œå·¥å‚å‡½æ•°
1. å®ç°ç¬¦åˆ `SelectorAdapter`/`PlannerAdapter`/`TimingAdapter` æ¥å£
1. åœ¨ README ä¸­æ·»åŠ æ–¹æ³•æè¿°
1. è¿è¡Œæµ‹è¯•éªŒè¯

### æ·»åŠ æ–°æ•°æ®é›†

1. å®ç° `DataLoader` æ¥å£
1. åœ¨ `DataManager` ä¸­æ³¨å†Œ
1. æ·»åŠ æ•°æ®é›†æè¿°åˆ°æ–‡æ¡£

______________________________________________________________________

## ğŸ“ å¼•ç”¨

```bibtex
@inproceedings{sage-bench-2026,
  title={SAGE-Bench: A Unified Benchmark for Evaluating Agent Capabilities in Tool-Augmented LLMs},
  author={...},
  booktitle={ICML},
  year={2026}
}

@inproceedings{sage-agent-2026,
  title={SAGE-Agent: Streaming Adaptive Learning for Tool-Augmented LLM Agents},
  author={...},
  booktitle={ICML},
  year={2026}
}
```
