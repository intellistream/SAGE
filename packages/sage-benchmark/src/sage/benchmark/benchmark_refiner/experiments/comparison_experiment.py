"""
Refiner Comparison Experiment
=============================

å¤šç®—æ³•å¯¹æ¯”è¯„æµ‹å®éªŒï¼Œè¿è¡Œå¤šç§ Refiner ç®—æ³•å¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šã€‚
"""

import statistics
import time
from datetime import datetime
from typing import Any

from sage.benchmark.benchmark_refiner.experiments.base_experiment import (
    AlgorithmMetrics,
    BaseRefinerExperiment,
    ExperimentResult,
    RefinerExperimentConfig,
)


class ComparisonExperiment(BaseRefinerExperiment):
    """
    å¤šç®—æ³•å¯¹æ¯”å®éªŒ

    å¯¹å¤šç§ Refiner ç®—æ³•åœ¨åŒä¸€æ•°æ®é›†ä¸Šè¿›è¡Œè¯„æµ‹ï¼Œ
    æ”¶é›†è´¨é‡ã€å‹ç¼©ç‡ã€å»¶è¿Ÿç­‰æŒ‡æ ‡å¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šã€‚

    ä½¿ç”¨ç¤ºä¾‹:
        config = RefinerExperimentConfig(
            name="algorithm_comparison",
            algorithms=["baseline", "longrefiner", "reform", "provence"],
            max_samples=100,
            budget=2048,
        )
        experiment = ComparisonExperiment(config)
        result = experiment.run_full()
    """

    def __init__(self, config: RefinerExperimentConfig):
        super().__init__(config)
        self.sample_results: dict[str, list[dict[str, Any]]] = {}

    def run(self) -> ExperimentResult:
        """
        è¿è¡Œå¯¹æ¯”å®éªŒ

        å¯¹æ¯ç§ç®—æ³•ï¼š
        1. åŠ è½½å¯¹åº”çš„ Pipeline é…ç½®
        2. è¿è¡Œ Pipeline
        3. æ”¶é›†è¯„æµ‹æŒ‡æ ‡

        Returns:
            ExperimentResult åŒ…å«æ‰€æœ‰ç®—æ³•çš„å¯¹æ¯”ç»“æœ
        """
        start_time = datetime.now()

        result = ExperimentResult(
            experiment_id=self.experiment_id,
            config=self.config.to_dict(),
            start_time=start_time.isoformat(),
        )

        for algorithm in self.config.algorithms:
            self._log(f"\n{'â”€' * 40}")
            self._log(f"ğŸ”§ Running algorithm: {algorithm}")
            self._log(f"{'â”€' * 40}")

            try:
                metrics = self._run_algorithm(algorithm)
                result.algorithm_metrics[algorithm] = metrics
                self._log(f"   âœ… Completed: F1={metrics.avg_f1:.4f}, "
                         f"Compression={metrics.avg_compression_rate:.2f}x")
            except Exception as e:
                self._log(f"   âŒ Failed: {e}")
                # è®°å½•å¤±è´¥ä½†ç»§ç»­å…¶ä»–ç®—æ³•
                result.algorithm_metrics[algorithm] = AlgorithmMetrics(
                    algorithm=algorithm,
                    num_samples=0,
                )

        end_time = datetime.now()
        result.end_time = end_time.isoformat()
        result.duration_seconds = (end_time - start_time).total_seconds()

        # æ”¶é›†åŸå§‹ç»“æœ
        if self.config.save_raw_results:
            for algo, samples in self.sample_results.items():
                for sample in samples:
                    sample["algorithm"] = algo
                    result.raw_results.append(sample)

        return result

    def _run_algorithm(self, algorithm: str) -> AlgorithmMetrics:
        """
        è¿è¡Œå•ä¸ªç®—æ³•çš„è¯„æµ‹

        Args:
            algorithm: ç®—æ³•åç§°

        Returns:
            AlgorithmMetrics è¯¥ç®—æ³•çš„è¯„æµ‹æŒ‡æ ‡
        """
        # æ”¶é›†æ¯ä¸ªæ ·æœ¬çš„æŒ‡æ ‡
        f1_scores: list[float] = []
        compression_rates: list[float] = []
        original_tokens_list: list[float] = []
        compressed_tokens_list: list[float] = []
        retrieve_times: list[float] = []
        refine_times: list[float] = []
        generate_times: list[float] = []
        total_times: list[float] = []

        # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿè¿è¡Œ Pipeline å¹¶æ”¶é›†ç»“æœ
        # å®é™…å®ç°ä¸­ä¼šè°ƒç”¨å¯¹åº”çš„ Pipeline
        sample_results = self._execute_pipeline(algorithm)
        self.sample_results[algorithm] = sample_results

        for sample in sample_results:
            if "f1" in sample:
                f1_scores.append(sample["f1"])
            if "compression_rate" in sample:
                compression_rates.append(sample["compression_rate"])
            if "original_tokens" in sample:
                original_tokens_list.append(sample["original_tokens"])
            if "compressed_tokens" in sample:
                compressed_tokens_list.append(sample["compressed_tokens"])
            if "retrieve_time" in sample:
                retrieve_times.append(sample["retrieve_time"])
            if "refine_time" in sample:
                refine_times.append(sample["refine_time"])
            if "generate_time" in sample:
                generate_times.append(sample["generate_time"])
            if "total_time" in sample:
                total_times.append(sample["total_time"])

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        metrics = AlgorithmMetrics(
            algorithm=algorithm,
            num_samples=len(sample_results),
        )

        if f1_scores:
            metrics.avg_f1 = statistics.mean(f1_scores)
            metrics.std_f1 = statistics.stdev(f1_scores) if len(f1_scores) > 1 else 0.0

        if compression_rates:
            metrics.avg_compression_rate = statistics.mean(compression_rates)
            metrics.std_compression_rate = (
                statistics.stdev(compression_rates) if len(compression_rates) > 1 else 0.0
            )

        if original_tokens_list:
            metrics.avg_original_tokens = statistics.mean(original_tokens_list)

        if compressed_tokens_list:
            metrics.avg_compressed_tokens = statistics.mean(compressed_tokens_list)

        if retrieve_times:
            metrics.avg_retrieve_time = statistics.mean(retrieve_times)

        if refine_times:
            metrics.avg_refine_time = statistics.mean(refine_times)

        if generate_times:
            metrics.avg_generate_time = statistics.mean(generate_times)

        if total_times:
            metrics.avg_total_time = statistics.mean(total_times)
            metrics.std_total_time = statistics.stdev(total_times) if len(total_times) > 1 else 0.0

        return metrics

    def _execute_pipeline(self, algorithm: str) -> list[dict[str, Any]]:
        """
        æ‰§è¡ŒæŒ‡å®šç®—æ³•çš„ Pipeline

        å®é™…å®ç°ä¸­ä¼šï¼š
        1. åŠ è½½å¯¹åº”é…ç½®æ–‡ä»¶
        2. åˆ›å»º Pipeline
        3. è¿è¡Œå¹¶æ”¶é›†ç»“æœ

        Args:
            algorithm: ç®—æ³•åç§°

        Returns:
            æ¯ä¸ªæ ·æœ¬çš„è¯„æµ‹ç»“æœåˆ—è¡¨
        """
        # TODO: é›†æˆå®é™…çš„ Pipeline æ‰§è¡Œ
        # å½“å‰è¿”å›å ä½æ•°æ®ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ›¿æ¢ä¸ºçœŸå® Pipeline è°ƒç”¨

        self._log(f"   ğŸ“Š Processing {self.config.max_samples} samples...")

        results = []
        for i in range(min(self.config.max_samples, 10)):  # æ¼”ç¤ºç”¨ï¼Œé™åˆ¶æ•°é‡
            # æ¨¡æ‹Ÿå•ä¸ªæ ·æœ¬çš„å¤„ç†
            sample_start = time.time()

            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„ Pipeline
            # ç›®å‰ä½¿ç”¨å ä½æ•°æ®
            sample_result = self._process_sample_placeholder(algorithm, i)

            sample_result["total_time"] = time.time() - sample_start
            results.append(sample_result)

            if (i + 1) % 10 == 0:
                self._log(f"   ... processed {i + 1}/{self.config.max_samples} samples")

        return results

    def _process_sample_placeholder(self, algorithm: str, sample_idx: int) -> dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæ ·æœ¬çš„å ä½å®ç°

        å®é™…ä½¿ç”¨æ—¶åº”æ›¿æ¢ä¸ºçœŸå®çš„ Pipeline è°ƒç”¨ã€‚
        """
        import random

        random.seed(self.config.seed + sample_idx)

        # æ¨¡æ‹Ÿä¸åŒç®—æ³•çš„ç‰¹æ€§
        base_f1 = 0.35

        if algorithm == "baseline":
            f1_bonus = 0.0
            compression = 1.0
            refine_time = 0.0
        elif algorithm == "longrefiner":
            f1_bonus = 0.03 + random.uniform(-0.02, 0.02)
            compression = 3.0 + random.uniform(-0.5, 0.5)
            refine_time = 0.8 + random.uniform(-0.2, 0.2)
        elif algorithm == "reform":
            f1_bonus = 0.01 + random.uniform(-0.02, 0.02)
            compression = 2.5 + random.uniform(-0.3, 0.3)
            refine_time = 0.3 + random.uniform(-0.1, 0.1)
        elif algorithm == "provence":
            f1_bonus = 0.02 + random.uniform(-0.02, 0.02)
            compression = 2.0 + random.uniform(-0.3, 0.3)
            refine_time = 0.1 + random.uniform(-0.05, 0.05)
        else:
            f1_bonus = 0.0
            compression = 1.0
            refine_time = 0.0

        original_tokens = 5000 + random.randint(-1000, 1000)
        compressed_tokens = int(original_tokens / compression)

        return {
            "sample_idx": sample_idx,
            "f1": base_f1 + f1_bonus + random.uniform(-0.05, 0.05),
            "compression_rate": compression,
            "original_tokens": original_tokens,
            "compressed_tokens": compressed_tokens,
            "retrieve_time": 1.5 + random.uniform(-0.5, 0.5),
            "refine_time": refine_time,
            "generate_time": 1.0 + random.uniform(-0.3, 0.3),
        }


class QualityExperiment(BaseRefinerExperiment):
    """
    è´¨é‡è¯„æµ‹å®éªŒ

    ä¸“æ³¨äºè¯„æµ‹ Refiner å¯¹ç­”æ¡ˆè´¨é‡çš„å½±å“ï¼š
    - F1 Score
    - Recall
    - ROUGE-L
    - Accuracy
    """

    def run(self) -> ExperimentResult:
        """è¿è¡Œè´¨é‡è¯„æµ‹å®éªŒ"""
        # ä½¿ç”¨ ComparisonExperiment çš„é€»è¾‘ï¼Œä½†ä¸“æ³¨äºè´¨é‡æŒ‡æ ‡
        comparison = ComparisonExperiment(self.config)
        return comparison.run()


class LatencyExperiment(BaseRefinerExperiment):
    """
    å»¶è¿Ÿè¯„æµ‹å®éªŒ

    ä¸“æ³¨äºè¯„æµ‹ Refiner çš„å»¶è¿Ÿè¡¨ç°ï¼š
    - Retrieve Time
    - Refine Time
    - Generate Time
    - End-to-End Latency
    """

    def run(self) -> ExperimentResult:
        """è¿è¡Œå»¶è¿Ÿè¯„æµ‹å®éªŒ"""
        # ä½¿ç”¨ ComparisonExperiment çš„é€»è¾‘ï¼Œä½†ä¸“æ³¨äºå»¶è¿ŸæŒ‡æ ‡
        comparison = ComparisonExperiment(self.config)
        return comparison.run()


class CompressionExperiment(BaseRefinerExperiment):
    """
    å‹ç¼©ç‡è¯„æµ‹å®éªŒ

    ä¸“æ³¨äºè¯„æµ‹ Refiner çš„å‹ç¼©æ•ˆæœï¼š
    - Compression Rate
    - Original Tokens
    - Compressed Tokens
    - Token Budget éµå®ˆæƒ…å†µ
    """

    def run(self) -> ExperimentResult:
        """è¿è¡Œå‹ç¼©ç‡è¯„æµ‹å®éªŒ"""
        # ä½¿ç”¨ ComparisonExperiment çš„é€»è¾‘ï¼Œä½†ä¸“æ³¨äºå‹ç¼©æŒ‡æ ‡
        comparison = ComparisonExperiment(self.config)
        return comparison.run()
