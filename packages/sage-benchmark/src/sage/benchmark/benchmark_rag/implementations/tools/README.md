# RAG Tools and Utilities

Supporting tools for building and preparing RAG systems.

## ğŸ“ Structure

```
tools/
â”œâ”€â”€ Index Building
â”‚   â”œâ”€â”€ build_chroma_index.py          # Build ChromaDB index
â”‚   â”œâ”€â”€ build_milvus_index.py          # Build basic Milvus index
â”‚   â”œâ”€â”€ build_milvus_dense_index.py    # Build Milvus dense index
â”‚   â””â”€â”€ build_milvus_sparse_index.py   # Build Milvus sparse index
â”‚
â””â”€â”€ Document Loaders
    â””â”€â”€ loaders/
        â””â”€â”€ document_loaders.py         # Load various document formats
```

## ğŸš€ Usage

### Building Vector Indices

**ChromaDB:**
```bash
python -m sage.benchmark.benchmark_rag.implementations.tools.build_chroma_index
```

**Milvus Dense:**
```bash
python -m sage.benchmark.benchmark_rag.implementations.tools.build_milvus_dense_index
```

**Milvus Sparse:**
```bash
python -m sage.benchmark.benchmark_rag.implementations.tools.build_milvus_sparse_index
```

### Using Document Loaders

```python
from sage.benchmark.benchmark_rag.implementations.tools.loaders.document_loaders import load_documents

# Load documents from various formats
docs = load_documents("path/to/documents")
```

## ğŸ“Š Workflow

Typical workflow for RAG benchmarking:

1. **Prepare Data**: Use document loaders to load your corpus
2. **Build Index**: Use build_*_index.py scripts to create vector indices
3. **Run Pipelines**: Execute RAG pipelines from `../pipelines/`
4. **Evaluate**: Use evaluation framework in `../../evaluation/`

## âš™ï¸ Configuration

Index building scripts use configurations from `../../config/`:
- Data paths
- Embedding models
- Index parameters
- Collection names

## ğŸ“– Notes

- Run index building scripts before running RAG pipelines
- Indices are typically stored in local directories or remote vector databases
- Make sure vector database services (Milvus, ChromaDB) are running if needed
