# ChromaDB 专用 QA 配置文件
# 适用于 qa_openai.py 的简化配置


source:
  data_path: "packages/sage-benchmark/src/sage/benchmark/benchmark_rag/data/queries.jsonl"  # 相对于 SAGE 根目录
  platform: "local"

retriever:
  # ChromaDB 专用配置
  dimension: 384    # 修改为与 HuggingFace all-MiniLM-L6-v2 匹配
  top_k: 2
  
  chroma:
    persistence_path: "./data/chroma_qa_database"
    collection_name: "qa_knowledge_base"
    use_embedding_query: true
    
    # 知识库已预加载，注释掉自动加载
    # knowledge_file: "../../data/qa_knowledge_base.txt"
    
    # ChromaDB 元数据配置 (简化格式)
    metadata:
      hnsw:space: "cosine"           # 距离度量
  
  # 嵌入模型配置
  embedding:
    method: "hf"
    model: "sentence-transformers/all-MiniLM-L6-v2"

promptor:
  template: |
    基于以下检索到的相关文档，回答用户问题：
    
    相关文档：
    {retrieved_documents}
    
    用户问题：{query}
    
    请提供准确、有用的回答：

generator:
  vllm:
    api_key: ""
    method: "openai"
    model_name: "meta-llama/Llama-2-7b-chat-hf"
    base_url: "http://sage3:8000/v1"
    seed: 42

sink:
  enable_log: true

reranker:
  platform: "local"
  model_name: "BAAI/bge-reranker-v2-m3"
  topk: 1