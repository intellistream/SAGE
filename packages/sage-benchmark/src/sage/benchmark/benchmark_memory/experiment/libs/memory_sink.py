import json
import os

from sage.benchmark.benchmark_memory.experiment.utils import (
    get_project_root,
    get_runtime_timestamp,
    get_time_filename,
)
from sage.common.core import SinkFunction


class MemorySink(SinkFunction):
    """æ”¶é›†æµ‹è¯•ç»“æœå¹¶ä¿å­˜ä¸º JSON æ ¼å¼çš„ Sink"""

    def __init__(self, config):
        """åˆå§‹åŒ– MemorySink

        Args:
            config: RuntimeConfig å¯¹è±¡ï¼Œä»ä¸­è·å– dataset å’Œ task_id
        """
        self.dataset = config.get("dataset")
        self.task_id = config.get("task_id")
        self.test_segments = config.get("runtime.test_segments", 10)
        self.memory_name = config.get("runtime.memory_name", "default")

        # è·å–é¡¹ç›®æ ¹ç›®å½•
        project_root = get_project_root()

        # åˆ›å»ºæ—¶é—´æˆ³ç›®å½•ç»“æ„ï¼ŒåŒ…å« memory_name
        time_str = get_time_filename()
        self.output_dir = os.path.join(
            project_root,
            f".sage/benchmarks/benchmark_memory/{self.dataset}/{time_str}/{self.memory_name}",
        )
        os.makedirs(self.output_dir, exist_ok=True)

        # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆæ ¼å¼ï¼štask_id_HHMM.jsonï¼‰
        runtime_stamp = get_runtime_timestamp()
        self.output_file = os.path.join(self.output_dir, f"{self.task_id}_{runtime_stamp}.json")
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {self.output_file}")

        # æ”¶é›†æ‰€æœ‰æµ‹è¯•ç»“æœ
        self.test_results = []

        # åˆ†ç¦»å­˜å‚¨ä¸¤ç§ timing æ•°æ®
        self.all_insert_timings = []  # æ’å…¥é˜¶æ®µï¼šæ¯ä¸ª dialog çš„ timingï¼ˆ214æ¡ï¼‰
        self.all_test_timings = []  # æ£€ç´¢é˜¶æ®µï¼šæ¯æ¬¡æµ‹è¯•çš„ timingï¼ˆ10æ¬¡æµ‹è¯•ï¼‰

        # æ”¶é›†è®°å¿†ä½“ç»Ÿè®¡æ•°æ®ï¼ˆæ¯æ¬¡æµ‹è¯•ä¸€æ¡ï¼‰
        self.all_memory_stats = []

        # åˆå§‹åŒ– DataLoaderï¼ˆç”¨äºè·å–ç»Ÿè®¡ä¿¡æ¯ï¼‰
        self.loader = self._init_loader(self.dataset)

    def _init_loader(self, dataset):
        """æ ¹æ®æ•°æ®é›†ç±»å‹åˆå§‹åŒ– DataLoader

        Args:
            dataset: æ•°æ®é›†åç§°

        Returns:
            DataLoader å®ä¾‹
        """
        if dataset == "locomo":
            from sage.data.sources.locomo.dataloader import LocomoDataLoader

            return LocomoDataLoader()
        elif dataset == "conflict_resolution":
            from sage.data.sources.memagentbench.conflict_resolution_loader import (
                ConflictResolutionDataLoader,
            )

            return ConflictResolutionDataLoader()
        elif dataset == "conflict_resolution_v1":
            from sage.data.sources.memagentbench.conflict_resolution_loader_v1 import (
                ConflictResolutionDataLoaderV1,
            )

            return ConflictResolutionDataLoaderV1()
        elif dataset == "conflict_resolution_v2":
            from sage.data.sources.memagentbench.conflict_resolution_loader_v2 import (
                ConflictResolutionDataLoaderV2,
            )

            return ConflictResolutionDataLoaderV2()
        elif dataset == "longmemeval":
            from sage.data.sources.longmemeval import LongMemEvalDataLoader

            return LongMemEvalDataLoader()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset}")

    def execute(self, data):
        """æ¥æ”¶å¹¶å¤„ç†æµ‹è¯•ç»“æœ

        Args:
            data: æ¥è‡ª PipelineCaller çš„çº¯æ•°æ®å­—å…¸
                - None: æœªè§¦å‘æµ‹è¯•
                - dict: æµ‹è¯•ç»“æœæˆ–å®Œæˆä¿¡å·
                    - completed: True è¡¨ç¤ºæœ€åä¸€ä¸ªåŒ…
                    - question_range, answers: æµ‹è¯•æ•°æ®
        """
        if not data:
            # None è¡¨ç¤ºæœªè§¦å‘æµ‹è¯•ï¼Œç›´æ¥è¿”å›
            return

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æµ‹è¯•ç»“æœæˆ– timing æ•°æ®
        # æ³¨æ„ï¼šæœ€åä¸€ä¸ªåŒ…å¯èƒ½åŒæ—¶æœ‰ completed=True å’Œ stage_timingsï¼ˆå‰©ä½™æ•°æ®ï¼‰
        if "answers" in data or "stage_timings" in data:
            # å¦‚æœæœ‰ answersï¼Œæ”¶é›†æµ‹è¯•ç»“æœ
            if "answers" in data:
                test_result = {
                    "test_index": len(self.test_results) + 1,
                    "question_range": data.get("question_range"),
                    "dialogs_inserted_count": data.get("dialogs_inserted"),
                    "answers": data.get("answers", []),
                }
                self.test_results.append(test_result)

            # æ”¶é›†æ—¶é—´æ•°æ®ï¼ˆæ— è®ºæ˜¯å¦æœ‰ answersï¼‰
            if "stage_timings" in data:
                stage_timings = data["stage_timings"]
                print(f"[DEBUG MemorySink] stage_timings keys: {stage_timings.keys()}")

                # æ”¶é›†æ’å…¥é˜¶æ®µçš„æ—¶é—´ï¼ˆæ’å…¥é˜¶æ®µçš„å€¼æ˜¯åˆ—è¡¨ï¼Œéœ€è¦å±•å¼€ååˆå¹¶ï¼‰
                if "insert" in stage_timings:
                    insert_timing = stage_timings["insert"]
                    print(f"[DEBUG MemorySink] insert_timing type: {type(insert_timing)}")
                    print(
                        f"[DEBUG MemorySink] insert_timing keys: {insert_timing.keys() if isinstance(insert_timing, dict) else 'not a dict'}"
                    )
                    if isinstance(insert_timing, dict) and insert_timing:
                        first_key = next(iter(insert_timing.keys()))
                        first_value = insert_timing[first_key]
                        print(
                            f"[DEBUG MemorySink] first_key={first_key}, value type={type(first_value)}, is_list={isinstance(first_value, list)}"
                        )
                        if isinstance(first_value, list):
                            print(f"[DEBUG MemorySink] list length={len(first_value)}")

                    # å°†æ’å…¥é˜¶æ®µçš„åˆ—è¡¨æ ¼å¼æ•°æ®å±•å¼€ä¸ºå•ç‹¬çš„timingè®°å½•
                    # insert_timing = {"pre_insert_ms": [0.01, 0.01], "memory_insert_ms": [3.2, 3.5], ...}
                    # éœ€è¦è½¬æ¢ä¸º: [{"pre_insert_ms": 0.01, "memory_insert_ms": 3.2, ...}, ...]
                    if insert_timing:
                        # è·å–åˆ—è¡¨é•¿åº¦ï¼ˆæ‰€æœ‰å­—æ®µçš„åˆ—è¡¨é•¿åº¦åº”è¯¥ç›¸åŒï¼‰
                        first_key = next(iter(insert_timing.keys()))
                        if isinstance(insert_timing[first_key], list):
                            list_len = len(insert_timing[first_key])
                            # è½¬ç½®ï¼šå°†å­—å…¸çš„åˆ—è¡¨å€¼è½¬æ¢ä¸ºåˆ—è¡¨çš„å­—å…¸å€¼
                            for i in range(list_len):
                                single_timing = {k: v[i] for k, v in insert_timing.items()}
                                self.all_insert_timings.append(single_timing)
                            print(f"[DEBUG MemorySink] Expanded {list_len} insert timings")
                        else:
                            # å¦‚æœä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œç›´æ¥æ·»åŠ ï¼ˆå‘åå…¼å®¹ï¼‰
                            self.all_insert_timings.append(insert_timing)
                            print("[DEBUG MemorySink] Added 1 insert timing (not list format)")

                # æ”¶é›†æµ‹è¯•é˜¶æ®µçš„æ—¶é—´ï¼ˆç°åœ¨æ˜¯æ¯æ¬¡æµ‹è¯•çš„å¹³å‡å€¼å­—å…¸ï¼‰
                if "test" in stage_timings:
                    test_timing = stage_timings["test"]
                    if test_timing:  # éç©ºå­—å…¸
                        # test_timing æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æœ¬æ¬¡æµ‹è¯•çš„å¹³å‡å€¼
                        # {"pre_retrieval_ms": 0.03, "memory_retrieval_ms": 3.5, ...}
                        self.all_test_timings.append(test_timing)
                        print(
                            "[DEBUG MemorySink] Added 1 test timing (average of multiple questions)"
                        )

            # æ”¶é›†è®°å¿†ä½“ç»Ÿè®¡æ•°æ®ï¼ˆç°åœ¨åœ¨ stage_timings å†…éƒ¨ï¼‰
            if "stage_timings" in data and "memory_stats" in data["stage_timings"]:
                memory_stats = data["stage_timings"]["memory_stats"]
                if memory_stats:
                    self.all_memory_stats.append(memory_stats)
                    print("[DEBUG MemorySink] Added 1 memory_stats")

        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        print(
            f"\n[DEBUG MemorySink] æ”¶åˆ°æ•°æ®: completed={data.get('completed')}, keys={list(data.keys())}"
        )
        if data.get("completed", False):
            print("[DEBUG MemorySink] completed=Trueï¼Œè°ƒç”¨ _save_results")
            self._save_results(data)
        else:
            print("[DEBUG MemorySink] completed=Falseï¼Œä¸ä¿å­˜")

    def _save_results(self, data):
        """ä¿å­˜æœ€ç»ˆç»“æœ

        Args:
            data: åŒ…å« dataset å’Œ task_id çš„æ•°æ®
        """
        dataset = data.get("dataset", self.dataset)
        task_id = data.get("task_id", self.task_id)

        # ä» DataLoader è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        dataset_stats = self.loader.get_dataset_statistics(task_id)

        # æ„é€ æ–°çš„ timing_summary æ ¼å¼
        timing_summary = {
            "insert_timings": self._format_insert_timings(),  # pre_insert, memory_insert, post_insert çš„è¯¦ç»†ç»Ÿè®¡
            "retrieval_timings": self._format_retrieval_timings(),  # pre_retrieval, memory_retrieval, post_retrieval çš„è¯¦ç»†ç»Ÿè®¡
        }

        # æ ¼å¼åŒ– memory_snapshotsï¼ˆæŒ‰ test_index ç»„ç»‡ï¼‰
        memory_snapshots = self._format_memory_snapshots()

        # æ„é€ è¾“å‡º JSON ç»“æ„
        output_data = {
            "experiment_info": {
                "dataset": dataset,
                "task_id": task_id,
            },
            "dataset_statistics": dataset_stats,
            "test_summary": {
                "total_tests": len(self.test_results),
                "test_segments": self.test_segments,
                "test_threshold": f"1/{self.test_segments} of total questions",
            },
            "test_results": self._format_test_results(self.test_results),
            "timing_summary": timing_summary,
            "memory_snapshots": memory_snapshots,
        }

        # ä¿å­˜ä¸º JSON
        print(f"[DEBUG MemorySink] å‡†å¤‡ä¿å­˜åˆ°: {self.output_file}")
        print(f"[DEBUG MemorySink] test_results æ•°é‡: {len(self.test_results)}")
        try:
            with open(self.output_file, "w", encoding="utf-8") as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            print(f"\nâœ… æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {self.output_file}")
        except Exception as e:
            print(f"[DEBUG MemorySink] ä¿å­˜å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()

    def _format_test_results(self, test_results):
        """æ ¼å¼åŒ–æµ‹è¯•ç»“æœä¸ºé€šç”¨æ ¼å¼

        Args:
            test_results: æµ‹è¯•ç»“æœåˆ—è¡¨

        Returns:
            list: æ ¼å¼åŒ–åçš„æµ‹è¯•ç»“æœ
        """
        formatted_results = []

        for test in test_results:
            formatted_test = {
                "test_index": test.get("test_index"),
                "question_range": test.get("question_range"),
                "dialogs_inserted_count": test.get("dialogs_inserted_count"),
                "questions": [],
            }

            # æ ¼å¼åŒ–æ¯ä¸ªé—®é¢˜çš„ç­”æ¡ˆ
            for answer in test.get("answers", []):
                metadata = answer.get("metadata", {})

                question_data = {
                    "question_index": answer.get("question_index"),
                    "question_text": answer.get("question"),
                    "predicted_answer": answer.get("predicted_answer"),
                }

                # æ·»åŠ å‚è€ƒç­”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "answer" in metadata:
                    question_data["reference_answer"] = metadata["answer"]

                # æ·»åŠ è¯æ®ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "evidence" in metadata:
                    question_data["evidence"] = metadata["evidence"]

                # æ·»åŠ åˆ†ç±»ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "category" in metadata:
                    question_data["category"] = metadata["category"]

                # æ·»åŠ é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "error" in answer:
                    question_data["error"] = answer["error"]

                formatted_test["questions"].append(question_data)

            formatted_results.append(formatted_test)

        return formatted_results

    def _format_insert_timings(self) -> dict:
        """æ ¼å¼åŒ–æ’å…¥é˜¶æ®µçš„ timing ç»Ÿè®¡

        Returns:
            dict: åŒ…å«æ€»ç»Ÿè®¡å’Œæ¯æ¡è®°å½•çš„è¯¦ç»†ç»Ÿè®¡
            {
                "summary": {
                    "pre_insert_ms": {"avg": ..., "min": ..., "max": ..., "count": 214},
                    "memory_insert_ms": {...},
                    "post_insert_ms": {...}
                },
                "details": [
                    {"pre_insert_ms": 0.01, "memory_insert_ms": 3.2, "post_insert_ms": 0.02},
                    ...  # 214æ¡è®°å½•
                ]
            }
        """
        if not self.all_insert_timings:
            return {"summary": {}, "details": []}

        # è®¡ç®—æ€»ç»Ÿè®¡
        summary = {}
        stage_names = ["pre_insert_ms", "memory_insert_ms", "post_insert_ms"]

        for stage_name in stage_names:
            values = [timing.get(stage_name, 0) for timing in self.all_insert_timings]
            if values:
                summary[stage_name] = {
                    "avg_ms": sum(values) / len(values),
                    "min_ms": min(values),
                    "max_ms": max(values),
                    "count": len(values),
                }

        return {
            "summary": summary,
            "details": self.all_insert_timings,  # 214æ¡è®°å½•
        }

    def _format_retrieval_timings(self) -> dict:
        """æ ¼å¼åŒ–æ£€ç´¢é˜¶æ®µçš„ timing ç»Ÿè®¡

        Returns:
            dict: åŒ…å«æ€»ç»Ÿè®¡å’Œæ¯æ¬¡æµ‹è¯•çš„è¯¦ç»†ç»Ÿè®¡
            {
                "summary": {
                    "pre_retrieval_ms": {"avg": ..., "min": ..., "max": ..., "count": 10},
                    "memory_retrieval_ms": {...},
                    "post_retrieval_ms": {...}
                },
                "details": [
                    {"test_index": 1, "pre_retrieval_ms": 0.03, "memory_retrieval_ms": 4.2, "post_retrieval_ms": 0.18},
                    ...  # 10æ¡è®°å½•
                ]
            }
        """
        if not self.all_test_timings:
            return {"summary": {}, "details": []}

        # è®¡ç®—æ€»ç»Ÿè®¡
        summary = {}
        stage_names = ["pre_retrieval_ms", "memory_retrieval_ms", "post_retrieval_ms"]

        for stage_name in stage_names:
            values = [timing.get(stage_name, 0) for timing in self.all_test_timings]
            if values:
                summary[stage_name] = {
                    "avg_ms": sum(values) / len(values),
                    "min_ms": min(values),
                    "max_ms": max(values),
                    "count": len(values),
                }

        # æ ¼å¼åŒ–è¯¦ç»†è®°å½•ï¼ˆæ·»åŠ  test_indexï¼‰
        details = []
        for idx, timing in enumerate(self.all_test_timings, start=1):
            detail = {"test_index": idx}
            detail.update(timing)
            details.append(detail)

        return {
            "summary": summary,
            "details": details,  # 10æ¡è®°å½•
        }

    def _format_memory_snapshots(self) -> list[dict]:
        """æ ¼å¼åŒ–å†…å­˜å¿«ç…§ï¼ˆæŒ‰ test_index ç»„ç»‡ï¼‰

        Returns:
            list: æ¯æ¬¡æµ‹è¯•çš„å†…å­˜å¿«ç…§
            [
                {"test_index": 1, "memory_count": 5, "max_capacity": 5, ...},
                ...  # 10æ¡è®°å½•
            ]
        """
        if not self.all_memory_stats:
            return []

        snapshots = []
        for idx, stats in enumerate(self.all_memory_stats, start=1):
            snapshot = {"test_index": idx}
            snapshot.update(stats)
            snapshots.append(snapshot)

        return snapshots
