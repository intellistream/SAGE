"""PostRetrieval Operator - è®°å¿†æ£€ç´¢åå¤„ç†ç®—å­

Pipeline ä½ç½®: ç¬¬ 4 å±‚ï¼ˆæ£€ç´¢åï¼‰
è®¿é—®æƒé™: å…è®¸å¤šæ¬¡æ£€ç´¢è®°å¿†æœåŠ¡ï¼ˆä¸å…è®¸æ’å…¥/åˆ é™¤ï¼‰

é‡‡ç”¨ç­–ç•¥æ¨¡å¼ï¼Œé€šè¿‡ Action æ³¨å†Œè¡¨åŠ¨æ€é€‰æ‹©å’Œæ‰§è¡Œåå¤„ç†ç­–ç•¥ã€‚
"""

from __future__ import annotations

import time
from typing import Any

from sage.benchmark.benchmark_memory.experiment.utils import (
    EmbeddingGenerator,
    LLMGenerator,
)
from sage.common.core import MapFunction

from .base import (
    BasePostRetrievalAction,
    MemoryItem,
    PostRetrievalInput,
    PostRetrievalOutput,
)
from .registry import PostRetrievalActionRegistry


class _ServiceProxy:
    """Service proxy to wrap call_service calls into method-like interface

    Note: PostRetrieval stage only allows search operations (multiple times allowed).
    No insert/update/delete permissions according to pipeline design.
    """

    def __init__(self, operator: MapFunction, service_name: str):
        self._operator = operator
        self._service_name = service_name

    def search(self, **kwargs) -> list[dict[str, Any]]:
        """Search for similar memories (multiple searches allowed)"""
        return self._operator.call_service(self._service_name, method="search", **kwargs)

    def retrieve(self, **kwargs) -> list[dict[str, Any]]:
        """Retrieve memories (GraphMemoryService)"""
        return self._operator.call_service(self._service_name, method="retrieve", **kwargs)


class PostRetrieval(MapFunction):
    """è®°å¿†æ£€ç´¢åçš„åå¤„ç†ç®—å­ï¼ˆé‡æ„ç‰ˆï¼‰"""

    def __init__(self, config):
        super().__init__()
        self.config = config
        self.service_name = config.get("services.register_memory_service", "short_term_memory")
        self._llm_generator = LLMGenerator.from_config(self.config)
        self._embedding_generator = EmbeddingGenerator.from_config(self.config)
        action_config = config.get("operators.post_retrieval", {})
        self.action_name = action_config.get("action", "none")
        action_type = None
        if self.action_name in ["rerank", "filter", "merge"]:
            type_key = f"{self.action_name}_type"
            action_type = action_config.get(type_key)
        action_key = f"{self.action_name}.{action_type}" if action_type else self.action_name
        try:
            action_class = PostRetrievalActionRegistry.get(action_key)
            self.action: BasePostRetrievalAction = action_class(action_config)
        except ValueError as e:
            print(f"[WARNING] {e}, using NoneAction as fallback")
            from .none_action import NoneAction

            self.action = NoneAction(action_config)
        if hasattr(self.action, "set_llm_generator"):
            self.action.set_llm_generator(self._llm_generator)
        if hasattr(self.action, "set_embedding_generator"):
            self.action.set_embedding_generator(self._embedding_generator)
        self._conversation_format_prompt = action_config.get(
            "conversation_format_prompt", "The following is some history information.\n"
        )
        # è§£æåˆ†å±‚æ£€ç´¢é™åˆ¶
        self._tier_retrieval_limits = action_config.get("tier_retrieval_limits", {})

    def execute(self, data: dict[str, Any]) -> dict[str, Any]:
        start_time = time.perf_counter()
        print(f"\n{'=' * 80}")
        print(f"ğŸ¯ [PostRetrieval] å¼€å§‹æ‰§è¡Œ action={self.action_name}")
        print(f"{'=' * 80}")

        input_data = PostRetrievalInput(
            data=data,
            config=self.config.get("operators.post_retrieval", {}),
            service_name=self.service_name,
        )
        # Create service proxy for actions that need multiple searches
        service_proxy = _ServiceProxy(self, self.service_name)
        output: PostRetrievalOutput = self.action.execute(
            input_data,
            service=service_proxy,
            llm=self._llm_generator if self._llm_generator else None,
        )
        # åº”ç”¨åˆ†å±‚æ£€ç´¢é™åˆ¶
        output.memory_items = self._apply_tier_limits(output.memory_items)
        formatted_memory = self._format_conversation_history(output.memory_items)
        data["history_text"] = formatted_memory
        if output.memory_items:
            data["processed_memory_items"] = [
                {"text": item.text, "score": item.score, "metadata": item.metadata}
                for item in output.memory_items
            ]
        if output.metadata:
            data.setdefault("metadata", {}).update(output.metadata)
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        data.setdefault("stage_timings", {})["post_retrieval_ms"] = elapsed_ms
        print(f"â±ï¸  [PostRetrieval] æ€»è€—æ—¶: {elapsed_ms:.2f}ms")
        print(f"{'=' * 80}\n")

        return data

    def _apply_tier_limits(self, items: list[MemoryItem]) -> list[MemoryItem]:
        """åº”ç”¨åˆ†å±‚æ£€ç´¢é™åˆ¶

        Args:
            items: åŸå§‹è®°å¿†åˆ—è¡¨

        Returns:
            é™åˆ¶åçš„è®°å¿†åˆ—è¡¨
        """
        if not self._tier_retrieval_limits:
            return items

        # æŒ‰ tier åˆ†ç»„
        tier_items = {}
        for item in items:
            tier = item.metadata.get("tier", "default")
            if tier not in tier_items:
                tier_items[tier] = []
            tier_items[tier].append(item)

        # åº”ç”¨æ¯å±‚çš„é™åˆ¶
        limited_items = []
        for tier, tier_limit in self._tier_retrieval_limits.items():
            if tier in tier_items:
                limited_items.extend(tier_items[tier][:tier_limit])

        # ä¿ç•™æœªé…ç½®é™åˆ¶çš„å±‚çº§
        for tier, items_list in tier_items.items():
            if tier not in self._tier_retrieval_limits:
                limited_items.extend(items_list)

        return limited_items

    def _format_conversation_history(self, items: list[MemoryItem]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²ï¼Œæ”¯æŒ {stm_memories}/{ltm_memories} å ä½ç¬¦

        Args:
            items: è®°å¿†åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        if not items:
            return ""

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†å±‚å ä½ç¬¦
        has_tier_placeholders = (
            "{stm_memories}" in self._conversation_format_prompt
            or "{ltm_memories}" in self._conversation_format_prompt
        )

        if has_tier_placeholders:
            # æŒ‰å±‚çº§åˆ†ç»„
            stm_items = [item for item in items if item.metadata.get("tier") == "stm"]
            ltm_items = [item for item in items if item.metadata.get("tier") == "ltm"]

            stm_text = "\n".join(item.text for item in stm_items) if stm_items else "None"
            ltm_text = "\n".join(item.text for item in ltm_items) if ltm_items else "None"

            result = self._conversation_format_prompt.replace("{stm_memories}", stm_text).replace(
                "{ltm_memories}", ltm_text
            )
        else:
            # ç®€å•æ ¼å¼åŒ–ï¼ˆå‘åå…¼å®¹ï¼‰
            formatted = self._conversation_format_prompt
            for item in items:
                formatted += f"{item.text}\n"
            result = formatted.rstrip()

        # [DEBUG] æ‰“å°post_retrievalç”Ÿæˆçš„å†å²å¯¹è¯éƒ¨åˆ†
        # print("\n" + "=" * 80)
        # print("[DEBUG] PostRetrieval - å†å²å¯¹è¯éƒ¨åˆ† (é˜¶æ®µä¸€):")
        # print("=" * 80)
        # print(result)
        # print("=" * 80 + "\n")

        return result
