"""PreRetrieval Operator - è®°å¿†æ£€ç´¢å‰é¢„å¤„ç†ç®—å­

Pipeline ä½ç½®: ç¬¬ 3 å±‚ï¼ˆæ£€ç´¢å‰ï¼‰
è®¿é—®æƒé™: ä»…å…è®¸æ£€ç´¢è®°å¿†æœåŠ¡ï¼ˆä¸å…è®¸æ’å…¥/åˆ é™¤ï¼‰

é‡‡ç”¨ç­–ç•¥æ¨¡å¼ï¼Œé€šè¿‡ Action æ³¨å†Œè¡¨åŠ¨æ€é€‰æ‹©å’Œæ‰§è¡Œé¢„å¤„ç†ç­–ç•¥ã€‚
"""

from __future__ import annotations

import time
from typing import Any

from sage.benchmark.benchmark_memory.experiment.utils import (
    EmbeddingGenerator,
    LLMGenerator,
    get_required_config,
)
from sage.common.core import MapFunction

from .base import BasePreRetrievalAction, PreRetrievalInput, PreRetrievalOutput
from .registry import PreRetrievalActionRegistry


class PreRetrieval(MapFunction):
    """è®°å¿†æ£€ç´¢å‰çš„é¢„å¤„ç†ç®—å­ï¼ˆé‡æ„ç‰ˆï¼‰"""

    def __init__(self, config):
        super().__init__()
        self.config = config
        self.service_name = config.get("services.retrieve_memory_service", "short_term_memory")

        # å…ˆåˆå§‹åŒ– LLM å’Œ Embeddingï¼Œä»¥ä¾¿è¾“å‡ºæ¨¡å‹ä¿¡æ¯
        self._llm_generator = LLMGenerator.from_config(self.config)
        self._embedding_generator = EmbeddingGenerator.from_config(self.config)

        # è¾“å‡ºæ¨¡å‹ä¿¡æ¯
        print("\n" + "=" * 80)
        print("ğŸ“‹ [PreRetrieval Init] æ¨¡å‹é…ç½®ä¿¡æ¯")
        print("=" * 80)
        print("ğŸ¤– LLM æ¨¡å‹:")
        print(f"   - Model: {self._llm_generator.model_name}")
        print(f"   - Base URL: {self.config.get('runtime.base_url')}")
        print(f"   - Max Tokens: {self._llm_generator.max_tokens}")
        print(f"   - Temperature: {self._llm_generator.temperature}")
        if self._llm_generator.seed is not None:
            print(f"   - Seed: {self._llm_generator.seed}")

        print("\nğŸ”¢ Embedding æ¨¡å‹:")
        if self._embedding_generator.is_available():
            print(f"   - Model: {self._embedding_generator.model_name}")
            print(f"   - Base URL: {self._embedding_generator.base_url}")
        else:
            print("   - Status: Disabled (no embedding_base_url configured)")
        print("=" * 80 + "\n")

        action_config = self.config.get("operators.pre_retrieval", {})
        self.action_name = get_required_config(self.config, "operators.pre_retrieval.action")
        self.action_type = None

        # æ”¯æŒ optimize.* å’Œ enhancement.* å­ç±»å‹
        if self.action_name == "optimize":
            self.action_type = get_required_config(
                self.config, "operators.pre_retrieval.optimize_type", "action=optimize"
            )
        elif self.action_name == "enhancement":
            self.action_type = get_required_config(
                self.config, "operators.pre_retrieval.enhancement_type", "action=enhancement"
            )

        action_key = (
            f"{self.action_name}.{self.action_type}" if self.action_type else self.action_name
        )
        action_class = PreRetrievalActionRegistry.get(action_key)
        self.action: BasePreRetrievalAction = action_class(action_config)

        # è®¾ç½®LLMç”Ÿæˆå™¨
        if hasattr(self.action, "set_llm_generator"):
            self.action.set_llm_generator(self._llm_generator)

        # è®¾ç½®Embeddingç”Ÿæˆå™¨
        if hasattr(self.action, "set_embedding_generator"):
            self.action.set_embedding_generator(self._embedding_generator)

    def execute(self, data: dict[str, Any]) -> dict[str, Any]:
        start_time = time.perf_counter()
        print(f"\n{'=' * 80}")
        print(f"ğŸ” [PreRetrieval] å¼€å§‹æ‰§è¡Œ action={self.action_name}")
        print(f"{'=' * 80}")

        # å‡†å¤‡runtimeé…ç½®ï¼ˆä¾›multi_embedç­‰actionä½¿ç”¨ï¼‰
        runtime_config = {
            "embedding_base_url": self.config.get("runtime.embedding_base_url"),
            "llm_base_url": self.config.get("runtime.llm_base_url"),
        }
        data["_runtime_config"] = runtime_config

        input_data = PreRetrievalInput(
            data=data, config=self.config.get("operators.pre_retrieval", {})
        )
        output: PreRetrievalOutput = self.action.execute(input_data)

        # æ¸…ç†ä¸´æ—¶runtimeé…ç½®
        data.pop("_runtime_config", None)

        if output.metadata.get("needs_embedding") and self._embedding_generator:
            query_embedding = self._embedding_generator.embed(output.query)
            output.query_embedding = query_embedding
        data["question"] = output.query
        if output.query_embedding:
            data["query_embedding"] = output.query_embedding
        if output.retrieve_mode:
            data["retrieve_mode"] = output.retrieve_mode
        if output.retrieve_params:
            data["retrieve_params"] = output.retrieve_params
        if output.metadata:
            data.setdefault("metadata", {}).update(output.metadata)
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        data.setdefault("stage_timings", {})["pre_retrieval_ms"] = elapsed_ms
        print(f"\nâ±ï¸  [PreRetrieval] æ€»è€—æ—¶: {elapsed_ms:.2f}ms")
        print(f"{'=' * 80}\n")
        return data
