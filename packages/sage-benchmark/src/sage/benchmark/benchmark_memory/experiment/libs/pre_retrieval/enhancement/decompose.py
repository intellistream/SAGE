"""DecomposeAction - æŸ¥è¯¢åˆ†è§£ç­–ç•¥

ä½¿ç”¨åœºæ™¯ï¼š
- å¤æ‚å¤šæ­¥æŸ¥è¯¢åˆ†è§£ä¸ºå­æŸ¥è¯¢
- æ”¯æŒLLMã€è§„åˆ™ã€æ··åˆä¸‰ç§åˆ†è§£ç­–ç•¥

ç‰¹ç‚¹ï¼š
- ç”Ÿæˆå¤šä¸ªç‹¬ç«‹çš„å­æŸ¥è¯¢
- æ¯ä¸ªå­æŸ¥è¯¢å¯å¹¶è¡Œæˆ–é¡ºåºæ£€ç´¢
- æ”¯æŒè‡ªå®šä¹‰åˆ†è§£è§„åˆ™
"""

import json
import re
from typing import Any

from sage.benchmark.benchmark_memory.experiment.utils import LLMGenerator

from ..base import BasePreRetrievalAction, PreRetrievalInput, PreRetrievalOutput


class DecomposeAction(BasePreRetrievalAction):
    """æŸ¥è¯¢åˆ†è§£Action

    å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªç®€å•å­æŸ¥è¯¢ï¼Œæ”¯æŒç‹¬ç«‹æ£€ç´¢ã€‚
    """

    def _init_action(self) -> None:
        """åˆå§‹åŒ–æŸ¥è¯¢åˆ†è§£é…ç½®"""
        self.decompose_strategy = self._get_config_value(
            "decompose_strategy", required=True, context="action=enhancement.decompose"
        )

        self.max_sub_queries = self._get_config_value(
            "max_sub_queries", default=5, context="action=enhancement.decompose"
        )

        self.sub_query_action = self._get_config_value("sub_query_action", default="parallel")

        self.embed_sub_queries = self._get_config_value("embed_sub_queries", default=False)

        # åˆå§‹åŒ– Embedding ç”Ÿæˆå™¨ï¼ˆç”¨äºå­æŸ¥è¯¢å‘é‡åŒ–ï¼‰
        from sage.benchmark.benchmark_memory.experiment.utils import EmbeddingGenerator

        self._embedding_generator = EmbeddingGenerator.from_config(self.config)

        # LLMåˆ†è§£é…ç½®
        if self.decompose_strategy in ["llm", "hybrid"]:
            self.decompose_prompt = self._get_config_value(
                "decompose_prompt",
                default="""Break down this complex question into simpler sub-questions that can be answered independently.
Each sub-question should be self-contained and searchable.

Question: {query}

Return a JSON array of sub-questions. Example: ["sub-question 1", "sub-question 2"]
Sub-questions:""",
            )

        # è§„åˆ™åˆ†è§£é…ç½®
        if self.decompose_strategy in ["rule", "hybrid"]:
            self.split_keywords = self._get_config_value(
                "split_keywords",
                default=["and", "or", "also", "additionally", "moreover", "furthermore", "besides"],
            )

        # LLMç”Ÿæˆå™¨å°†ç”±PreRetrievalä¸»ç±»æä¾›
        self._llm_generator = None

    def set_llm_generator(self, generator: LLMGenerator) -> None:
        """è®¾ç½®LLMç”Ÿæˆå™¨ï¼ˆç”±PreRetrievalä¸»ç±»è°ƒç”¨ï¼‰"""
        self._llm_generator = generator

    def execute(self, input_data: PreRetrievalInput) -> PreRetrievalOutput:
        """åˆ†è§£æŸ¥è¯¢

        Args:
            input_data: è¾“å…¥æ•°æ®

        Returns:
            åŒ…å«å­æŸ¥è¯¢åˆ—è¡¨çš„è¾“å‡ºæ•°æ®
        """
        question = input_data.question

        if not question:
            return PreRetrievalOutput(
                query=question,
                metadata={"sub_queries": [], "decompose_strategy": self.decompose_strategy},
            )

        # æ ¹æ®ç­–ç•¥åˆ†è§£æŸ¥è¯¢
        sub_queries = self._decompose(question)

        # é™åˆ¶å­æŸ¥è¯¢æ•°é‡
        sub_queries = sub_queries[: self.max_sub_queries]

        # å¦‚æœæ²¡æœ‰æˆåŠŸåˆ†è§£ï¼Œä½¿ç”¨åŸæŸ¥è¯¢
        if not sub_queries:
            sub_queries = [question]

        # ä¸ºå­æŸ¥è¯¢ç”Ÿæˆ embedding
        sub_query_embeddings = []
        if self._embedding_generator:
            print(f"\nğŸ”„ å¼€å§‹ä¸º {len(sub_queries)} ä¸ªå­æŸ¥è¯¢ç”Ÿæˆ embedding...")
            for idx, sq in enumerate(sub_queries, 1):
                try:
                    embedding = self._embedding_generator.embed(sq)
                    sub_query_embeddings.append(embedding)
                    print(f"  âœ“ å­æŸ¥è¯¢ {idx}: {sq[:50]}... (ç»´åº¦: {len(embedding)})")
                except Exception as e:
                    print(f"  âœ— å­æŸ¥è¯¢ {idx} embedding ç”Ÿæˆå¤±è´¥: {e}")
                    sub_query_embeddings.append(None)
        else:
            print("âš ï¸  æœªåˆå§‹åŒ– EmbeddingGeneratorï¼Œå­æŸ¥è¯¢å°†æ—  embedding")
            sub_query_embeddings = [None] * len(sub_queries)

        # ============ DEBUG: åˆ†è§£åæ‰“å° ============
        print("\n" + "=" * 80)
        print("ğŸ” [DecomposeAction] æŸ¥è¯¢åˆ†è§£ç»“æœ")
        print("=" * 80)
        print(f"åŸå§‹æŸ¥è¯¢: {question}")
        print(f"\nåˆ†è§£ç­–ç•¥: {self.decompose_strategy}")
        print(f"å­æŸ¥è¯¢æ•°é‡: {len(sub_queries)}")
        for idx, sq in enumerate(sub_queries, 1):
            emb_status = "âœ“" if sub_query_embeddings[idx - 1] is not None else "âœ—"
            print(f"  {idx}. {emb_status} {sq}")
        print("\n" + "=" * 80)
        # ============ DEBUG END ============

        # æ„å»ºå…ƒæ•°æ®
        metadata: dict[str, Any] = {
            "original_query": question,
            "sub_queries": sub_queries,
            "sub_query_embeddings": sub_query_embeddings,
            "sub_query_action": self.sub_query_action,
            "decompose_strategy": self.decompose_strategy,
            "needs_embedding": self.embed_sub_queries,
        }

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå­æŸ¥è¯¢ä½œä¸ºä¸»æŸ¥è¯¢ï¼Œå…¶ä»–ä½œä¸ºå…ƒæ•°æ®
        return PreRetrievalOutput(
            query=sub_queries[0] if len(sub_queries) == 1 else question,
            query_embedding=None,
            metadata=metadata,
            retrieve_mode="active",
            retrieve_params={
                "sub_queries": sub_queries,
                "sub_query_embeddings": sub_query_embeddings,
                "action": self.sub_query_action,
            },
        )

    def _decompose(self, question: str) -> list[str]:
        """æ‰§è¡ŒæŸ¥è¯¢åˆ†è§£"""
        if self.decompose_strategy == "llm":
            return self._decompose_llm(question)
        elif self.decompose_strategy == "rule":
            return self._decompose_rule(question)
        elif self.decompose_strategy == "hybrid":
            # å…ˆå°è¯•è§„åˆ™ï¼Œå¤±è´¥åˆ™ç”¨LLM
            sub_queries = self._decompose_rule(question)
            if len(sub_queries) <= 1:
                sub_queries = self._decompose_llm(question)
            return sub_queries
        else:
            return [question]

    def _decompose_llm(self, question: str) -> list[str]:
        """ä½¿ç”¨LLMåˆ†è§£æŸ¥è¯¢"""
        if self._llm_generator is None:
            return [question]

        prompt = self.decompose_prompt.format(query=question)

        try:
            result = self._llm_generator.generate(prompt, max_tokens=500, temperature=0.5)

            # å°è¯•è§£æJSONæ•°ç»„
            try:
                match = re.search(r"\[.*?\]", result, re.DOTALL)
                if match:
                    parsed_queries = json.loads(match.group())
                    if isinstance(parsed_queries, list):
                        return [q for q in parsed_queries if isinstance(q, str) and q.strip()]
            except json.JSONDecodeError:
                pass

            # è§£æå¤±è´¥ï¼Œå°è¯•æŒ‰è¡Œè§£æ
            lines = result.strip().split("\n")
            parsed_lines = []
            for line in lines:
                # ç§»é™¤åºå·
                line = line.strip().lstrip("0123456789.-) ")
                # è¿‡æ»¤æ¡ä»¶ï¼š
                # 1. éç©º
                # 2. ä¸æ˜¯JSONæ ‡è®°
                # 3. ä¸åŒ…å«'decompose', 'break down', 'following'ç­‰è¯´æ˜æ€§è¯æ±‡
                # 4. å¿…é¡»ä»¥ç–‘é—®è¯å¼€å¤´æˆ–ä»¥é—®å·ç»“å°¾ï¼ˆæ˜¯çœŸæ­£çš„é—®é¢˜ï¼‰
                if (
                    line
                    and not line.startswith("[")
                    and not line.endswith("]")
                    and not any(
                        word in line.lower()
                        for word in [
                            "to decompose",
                            "break down",
                            "can break",
                            "following",
                            "sub-questions:",
                        ]
                    )
                    and (
                        line.endswith("?")
                        or any(
                            line.lower().startswith(q)
                            for q in [
                                "who",
                                "what",
                                "when",
                                "where",
                                "why",
                                "how",
                                "is",
                                "are",
                                "was",
                                "were",
                                "did",
                                "does",
                                "do",
                                "can",
                                "could",
                                "will",
                                "would",
                            ]
                        )
                    )
                ):
                    parsed_lines.append(line)

            return parsed_lines if parsed_lines else [question]

        except Exception as e:
            print(f"[WARNING] LLM decompose failed: {e}")
            return [question]

    def _decompose_rule(self, question: str) -> list[str]:
        """ä½¿ç”¨è§„åˆ™åˆ†è§£æŸ¥è¯¢"""
        # æ„å»ºåˆ†è¯æ¨¡å¼
        pattern = r"\b(?:" + "|".join(re.escape(kw) for kw in self.split_keywords) + r")\b"

        # åˆ†å‰²æŸ¥è¯¢
        parts = re.split(pattern, question, flags=re.IGNORECASE)

        # æ¸…ç†å¹¶è¿‡æ»¤
        parsed_parts = [p.strip() for p in parts if p.strip()]

        # å¦‚æœæˆåŠŸåˆ†å‰²ï¼ˆè‡³å°‘2ä¸ªéƒ¨åˆ†ï¼‰ï¼Œè¿”å›ç»“æœ
        if len(parsed_parts) > 1:
            return parsed_parts

        # å¦åˆ™è¿”å›åŸæŸ¥è¯¢
        return [question]
