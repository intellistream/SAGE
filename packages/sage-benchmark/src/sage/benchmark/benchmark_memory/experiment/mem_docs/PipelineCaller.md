# PipelineCaller 核心处理文档

## 概述

`PipelineCaller` 是主 Pipeline 的核心 Map 算子，负责协调记忆存储和记忆测试两个子
Pipeline。它实现了**问题驱动的测试策略**，在数据流入的过程中智能地触发测试，避免每个数据包都测试带来的性能开销。

## 核心职责

1. **记忆存储**：将每个对话数据包发送到记忆存储服务（总是执行）
1. **问题驱动测试**：根据可见问题数的增长，智能触发记忆测试
1. **进度追踪**：实时显示数据处理进度和统计信息
1. **结果汇总**：收集测试答案，构造标准化输出格式

## 问题驱动测试策略

### 设计思想

传统方案每处理一个数据包就测试一次，导致：

- 测试频率过高，性能开销大
- 早期问题被重复测试多次
- 无法充分利用记忆积累的优势

**问题驱动策略**：只在可见问题数显著增加时才触发测试，实现：

- 减少测试次数，提高效率
- 每次测试覆盖从开始到当前的所有问题
- 充分利用已积累的记忆信息

### 触发条件

测试会在以下情况触发：

1. **增量达到阈值**：自上次测试以来，新增问题数 ≥ 总问题数的 1/10
1. **最后一个数据包**：确保所有问题都被测试到

**阈值计算**：

```python
test_threshold = max(1, total_questions // 10)
```

最小为 1，确保至少有 1 个新问题才测试。

### 测试范围

每次触发测试时：

- **不是**只测试新增的问题
- **而是**从第 1 个问题测试到当前可见的最后一个问题
- 这样可以验证记忆系统对所有历史问题的回答能力

## 工作流程

### 初始化阶段

1. **加载数据集信息**：

   - 根据 `dataset` 类型创建数据加载器
   - 获取任务的总问题数（排除无 evidence 的问题）

1. **初始化状态变量**：

   - `total_questions`：任务的总问题数
   - `last_tested_count`：上次测试时的问题数（初始为 0）
   - `test_threshold`：测试阈值（总问题数的 1/10）
   - `total_dialogs_inserted`：累计插入的对话数

1. **进度条**：将在第一个数据包到达时初始化

### 执行阶段（每个数据包）

```
┌─────────────────────────────────────────────────────────────┐
│ 1. 接收数据包（来自 MemorySource）                          │
│    - task_id, session_id, dialog_id, dialogs               │
│    - packet_idx, total_packets                             │
└─────────────────────────────────────────────────────────────┘
                         ↓
┌─────────────────────────────────────────────────────────────┐
│ 2. 更新进度条                                                │
│    - 显示当前进度：packet_idx/total_packets                 │
└─────────────────────────────────────────────────────────────┘
                         ↓
┌─────────────────────────────────────────────────────────────┐
│ 3. 打印数据包信息                                            │
│    - Session ID, Dialog ID                                 │
│    - 对话内容（speaker + text）                            │
└─────────────────────────────────────────────────────────────┘
                         ↓
┌─────────────────────────────────────────────────────────────┐
│ 4. 阶段1：记忆存储（总是执行）                              │
│    - 构造 insert_data                                       │
│    - 调用 memory_insert_service（阻塞等待）                │
│    - 累计插入的对话数                                       │
└─────────────────────────────────────────────────────────────┘
                         ↓
┌─────────────────────────────────────────────────────────────┐
│ 5. 检查测试触发条件                                          │
│    - 获取当前可见问题列表（排除无 evidence）                │
│    - 计算新增问题数：current_count - last_tested_count     │
│    - 判断是否为最后一个数据包                               │
└─────────────────────────────────────────────────────────────┘
                         ↓
                    条件判断
                         ↓
        ┌────────────────┴────────────────┐
        ↓                                  ↓
   未触发测试                          触发测试
  （增量 < 阈值                    （增量 ≥ 阈值
   且非最后包）                      或最后一个包）
        ↓                                  ↓
  打印统计信息                 ┌─────────────────────────┐
  返回 None                    │ 6. 阶段2：记忆测试       │
  （不发送给 Sink）            │   逐个测试所有问题       │
                              └─────────────────────────┘
                                         ↓
                         ┌───────────────────────────┐
                         │ 7. 构造测试结果            │
                         │    - question_range       │
                         │    - answers (所有问答)    │
                         │    - completed 标志        │
                         └───────────────────────────┘
                                         ↓
                         ┌───────────────────────────┐
                         │ 8. 更新测试状态            │
                         │    last_tested_count =    │
                         │    current_count          │
                         └───────────────────────────┘
                                         ↓
                                   返回测试结果
                                 （发送给 Sink）
```

## 服务调用机制

### 1. 记忆存储服务

**服务名称**：`memory_insert_service`

**调用时机**：每个数据包都会调用

**请求格式**：

```python
{
    "task_id": str,        # 任务ID
    "session_id": int,     # 会话ID
    "dialog_id": int,      # 对话索引
    "dialogs": [           # 对话列表
        {
            "speaker": str,
            "text": str
        },
        ...
    ]
}
```

**调用方式**：

```python
self.call_service(
    "memory_insert_service",
    insert_data,
    method="process",
    timeout=30.0,  # 30秒超时
)
```

**阻塞行为**：调用会阻塞等待服务完成，确保记忆存储成功后再继续。

### 2. 记忆测试服务

**服务名称**：`memory_test_service`

**调用时机**：触发测试时，对每个可见问题都调用一次

**请求格式**：

```python
{
    "task_id": str,             # 任务ID
    "session_id": int,          # 会话ID
    "dialog_id": int,           # 对话索引
    "dialogs": list,            # 当前对话列表
    "question": str,            # 问题文本
    "question_idx": int,        # 问题序号（1-based）
    "question_metadata": dict   # 完整的 QA 对象（包含 evidence, category 等）
}
```

**调用方式**：

```python
result = self.call_service(
    "memory_test_service",
    test_data,
    method="process",
    timeout=300.0,  # 5分钟超时（LLM调用可能较慢）
)
```

**返回格式**：

```python
{
    "answer": str,              # 生成的答案
    "question_metadata": dict   # 原始 metadata（透传）
}
```

**错误处理**：

- 如果服务调用失败（超时、服务关闭等），记录错误但继续处理下一个问题
- 失败的问题会在答案列表中标记为 `[ERROR]`，并包含错误信息

## 输出格式

### 触发测试时的输出

```python
{
    "dataset": str,           # 数据集类型
    "task_id": str,           # 任务ID
    "question_range": {       # 本次测试的问题范围
        "start": int,         # 起始问题序号（1-based）
        "end": int            # 结束问题序号（1-based）
    },
    "dialogs_inserted": int,  # 累计插入的对话数
    "answers": [              # 所有问题的答案列表
        {
            "question_index": int,        # 问题序号
            "question": str,              # 问题文本
            "predicted_answer": str,      # 预测答案
            "metadata": dict              # 问题元数据（evidence, category等）
        },
        ...
    ],
    "completed": bool         # 是否为最后一个数据包
}
```

### 未触发测试时的输出

返回 `None`，不发送数据给 Sink。

### 最后一个包但未触发测试

```python
{
    "dataset": str,
    "task_id": str,
    "completed": True
}
```

不包含测试结果，只标记完成状态。

## 统计信息输出

### 数据包信息

```
============================================================
【Memory Source】（1/10）
>> Session：0，Dialog 0 - 1
>> Dialog 0(User): ...
>> Dialog 1(Assistant): ...

============================================================
```

### 未触发测试

```
>> 当前可见问题数：3/30
>> 距上次测试新增：3，阈值：3（未触发测试）
============================================================
```

### 触发测试

```
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
【QA】：问题驱动测试触发
>> 当前可见问题数：10/30
>> 距上次测试新增：7，阈值：3
>> 测试范围：问题 1 到 10
>> Question 1：...
>> Answer：...
>> Question 2：...
>> Answer：...
...
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
```

## 性能优化

### 1. 问题过滤

只测试有 evidence 的问题：

```python
current_questions = self.loader.get_question_list(
    task_id,
    session_x=session_id,
    dialog_y=dialog_id + len(dialogs) - 1,
    include_no_evidence=False,  # 排除无 evidence 的问题
)
```

这样可以：

- 减少无意义的测试
- 提高测试准确率
- 加快处理速度

### 2. 阻塞等待

所有服务调用都使用阻塞等待，确保：

- 记忆存储完成后再继续处理
- 测试结果正确收集
- 避免并发问题

### 3. 进度追踪

使用进度条实时显示处理进度：

```python
self.progress_bar = ProgressBar(total=total_packets, desc="处理对话")
self.progress_bar.update(1)
```

## 配置说明

在配置文件中需要指定：

- `dataset`: 数据集类型（如 "locomo"）
- `task_id`: 任务/样本ID

无需额外配置测试阈值，自动按总问题数的 1/10 计算。

## 添加新数据集

如需支持新数据集，需要确保数据加载器实现以下方法：

1. **`get_total_valid_questions(task_id, include_no_evidence)`**

   - 返回任务的总问题数
   - `include_no_evidence=False` 时排除无 evidence 的问题

1. **`get_question_list(task_id, session_x, dialog_y, include_no_evidence)`**

   - 返回截止到指定位置的问题列表
   - 每个问题包含 `question` 字段和其他 metadata

1. **问题格式要求**：

   ```python
   {
       "question": str,          # 必需：问题文本
       "evidence": list,         # 可选：证据列表
       "category": str,          # 可选：问题分类
       # ... 其他数据集特定字段
   }
   ```

然后在 `__init__()` 中添加数据集判断分支即可。

## 注意事项

1. **修改代码时请同步更新本文档**
1. 测试范围是累积的（1 到 current_count），不是增量的
1. 服务调用失败不会中断整个流程，会继续处理下一个问题
1. 最后一个数据包必定触发测试，确保所有问题都被覆盖
1. 如果最后一个包但增量不足，会发送完成信号但不包含测试结果
1. 进度条会在最后一个包处理完毕后自动关闭

## 相关文件

- 实现文件：`libs/pipeline_caller.py`
- Pipeline 文档：`mem_docs/Pipeline_README.md`
- 数据源文档：`mem_docs/MemorySource.md`
- 进度条工具：`utils/progress_bar.py`
