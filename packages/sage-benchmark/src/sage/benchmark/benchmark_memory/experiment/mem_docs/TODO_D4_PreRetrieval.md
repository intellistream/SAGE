# D4: PreRetrieval å¼€å‘ TODO

## ğŸ“Œ ä»»åŠ¡äº¤æ¥è¯´æ˜

**è´Ÿè´£äºº**: å·²å®Œæˆ  
**é¢„ä¼°å·¥æ—¶**: 12 äººå¤©  
**ä¾èµ–**: æ— ï¼ˆå¯ç‹¬ç«‹å¼€å‘ï¼‰  
**äº¤ä»˜ç‰©**: `libs/pre_retrieval.py` ä¸­çš„æ–° action åˆ†æ”¯å®ç°

æœ¬ç»´åº¦è´Ÿè´£**è®°å¿†æ£€ç´¢å‰çš„æŸ¥è¯¢é¢„å¤„ç†**ï¼Œä¼˜åŒ–ç”¨æˆ·æŸ¥è¯¢ä»¥æé«˜æ£€ç´¢æ•ˆæœã€‚ä½ éœ€è¦å®ç° 5 ç§æ–°çš„ actionï¼šæŸ¥è¯¢ä¼˜åŒ–ã€å¤šç»´ç¼–ç ã€æŸ¥è¯¢åˆ†è§£ã€æ£€ç´¢è·¯ç”±ã€æŸ¥è¯¢éªŒè¯ã€‚è¿™äº›åŠŸèƒ½å¯ä»¥æ˜¾è‘—æå‡æ£€ç´¢çš„å‡†ç¡®ç‡å’Œå¬å›ç‡ã€‚

**å¼€å‘å‰è¯·é˜…è¯»**:
- ç°æœ‰å®ç°å‚è€ƒ: `pre_retrieval.py` ä¸­çš„ `embedding` action
- ä¸ D2 çš„å¯¹åº”å…³ç³»: `multi_embed` åº”ä¸ D2 çš„ `multi_embed` é…ç½®ä¿æŒä¸€è‡´
- è·¯ç”±åŠŸèƒ½: `route` action éœ€è¦ä¸å¤šä¸ª Memory Service åä½œ

**éªŒæ”¶æ ‡å‡†**:
- [x] `optimize` çš„å…³é”®è¯æå–èƒ½æ­£ç¡®å·¥ä½œ
- [x] `multi_embed` ä¸ D2 é…ç½®å¯¹é½
- [x] `route` èƒ½æ­£ç¡®è·¯ç”±åˆ°ä¸åŒå­˜å‚¨åç«¯
- [x] æŸ¥è¯¢å¤„ç†å»¶è¿Ÿåœ¨å¯æ¥å—èŒƒå›´å†…

---

> **ä»£ç ä½ç½®**: `libs/pre_retrieval.py`
> **é…ç½®é”®**: `operators.pre_retrieval.action`
> **èŒè´£**: è®°å¿†æ£€ç´¢å‰çš„æŸ¥è¯¢é¢„å¤„ç†ï¼ˆå‘é‡åŒ–ã€æ”¹å†™ã€ä¼˜åŒ–ï¼‰

---

## ğŸ“Š Action æ€»è§ˆ

| Action | çŠ¶æ€ | å°ç±»å‚æ•° | å‚è€ƒå·¥ä½œ |
|--------|------|----------|----------|
| `none` | âœ… å·²å®ç° | - | åŸºç¡€é€ä¼  |
| `embedding` | âœ… å·²å®ç° | `embedding_model` | é€šç”¨ |
| `optimize` | âœ… å·²å®ç° | è§ä¸‹æ–‡ | LD-Agent, HippoRAG |
| `multi_embed` | âœ… å·²å®ç° | è§ä¸‹æ–‡ | EmotionalRAG |
| `decompose` | âœ… å·²å®ç° | è§ä¸‹æ–‡ | å¤æ‚æŸ¥è¯¢ |
| `route` | âœ… å·²å®ç° | è§ä¸‹æ–‡ | å¤šæºæ£€ç´¢ |
| `validate` | âœ… å·²å®ç° | è§ä¸‹æ–‡ | é€šç”¨ |

---

## âœ… DONE-D4-1: `optimize`

### æ¦‚è¿°
å¯¹æŸ¥è¯¢è¿›è¡Œä¼˜åŒ–å¤„ç†ï¼ŒåŒ…æ‹¬å…³é”®è¯æå–ã€æŸ¥è¯¢æ‰©å±•ã€æŒ‡ä»¤å¢å¼ºç­‰ã€‚

### å°ç±»å‚æ•°

```yaml
operators:
  pre_retrieval:
    action: optimize
    
    # ä¼˜åŒ–ç±»å‹
    optimize_type: "keyword_extract" # keyword_extract | expand | rewrite | instruction
    
    # keyword_extract ä¸“ç”¨ (LD-Agent)
    extractor: "spacy"               # spacy | nltk | llm
    extract_types: ["NOUN", "PROPN"] # æå–çš„è¯æ€§
    max_keywords: 10
    keyword_prompt: |                # llm æ¨¡å¼ä¸“ç”¨
      Extract the key search terms from this query...
    
    # expand ä¸“ç”¨
    expand_prompt: |
      Generate 3 alternative phrasings of this query...
    expand_count: 3
    merge_strategy: "union"          # union | intersection
    
    # rewrite ä¸“ç”¨ (HippoRAG Query2Doc)
    rewrite_prompt: |
      Rewrite this query to be more specific and searchable...
    
    # instruction ä¸“ç”¨ (HippoRAG)
    instruction_prefix: |
      Retrieve passages that contain information about...
    instruction_suffix: ""
    
    # è¾“å‡ºé…ç½®
    replace_original: false          # æ˜¯å¦æ›¿æ¢åŸæŸ¥è¯¢
    store_optimized: true            # å­˜å‚¨ä¼˜åŒ–åçš„æŸ¥è¯¢
```

### å‚è€ƒå®ç°åˆ†æ

#### LD-Agent (keyword_extract)
- **ä»£ç ä½ç½®**: `/home/zrc/develop_item/LD-Agent/`
- **æ ¸å¿ƒé€»è¾‘**:
  ```python
  # spaCy åè¯æå–
  doc = nlp(query)
  keywords = [token.text for token in doc if token.pos_ in ["NOUN", "PROPN"]]
  
  # ç”¨å…³é”®è¯æ£€ç´¢
  results = retriever.search(" ".join(keywords))
  ```

#### HippoRAG (instruction prefix)
- **ä»£ç ä½ç½®**: `/home/zrc/develop_item/HippoRAG/src/`
- **æ ¸å¿ƒé€»è¾‘**:
  ```python
  # æ·»åŠ æ£€ç´¢æŒ‡ä»¤å‰ç¼€
  instruction = "Retrieve passages that help answer the question: "
  augmented_query = instruction + query
  
  # ç”Ÿæˆ embedding
  query_embedding = embed(augmented_query)
  ```

### å¼€å‘ä»»åŠ¡

- [x] å®ç° `keyword_extract` å­ç±»å‹
  - [x] spaCy åè¯æå–
  - [x] NLTK è¯æ€§æ ‡æ³¨
  - [x] LLM å…³é”®è¯æå–
- [x] å®ç° `expand` å­ç±»å‹
  - [x] LLM æŸ¥è¯¢æ‰©å±•
  - [x] å¤šæŸ¥è¯¢åˆå¹¶
- [x] å®ç° `rewrite` å­ç±»å‹
  - [x] Query2Doc æ”¹å†™
- [x] å®ç° `instruction` å­ç±»å‹
  - [x] æŒ‡ä»¤å‰ç¼€/åç¼€æ·»åŠ 

### é¢„ä¼°å·¥æ—¶: 3 å¤© âœ… å·²å®Œæˆ

---

## âœ… DONE-D4-2: `multi_embed`

### æ¦‚è¿°
ç”Ÿæˆå¤šç»´æŸ¥è¯¢å‘é‡ï¼Œç”¨äºå¤šè·¯æ£€ç´¢ã€‚

### å°ç±»å‚æ•°

```yaml
operators:
  pre_retrieval:
    action: multi_embed
    
    # å‘é‡é…ç½®
    embeddings:
      - name: "semantic"
        model: "text-embedding-3-small"
        weight: 0.6
      - name: "emotion"
        model: "emotion-roberta"
        weight: 0.4
    
    # è¾“å‡ºæ ¼å¼
    output_format: "dict"            # dict | list
    
    # ä¸ D2 multi_embed å¯¹åº”
    match_insert_config: true        # è‡ªåŠ¨åŒ¹é… pre_insert çš„é…ç½®
```

### å‚è€ƒå®ç°åˆ†æ

#### EmotionalRAG (dual embedding)
- **ä»£ç ä½ç½®**: `/home/zrc/develop_item/EmotionalRAG/`
- **æ ¸å¿ƒé€»è¾‘**:
  ```python
  # åŒå‘é‡æŸ¥è¯¢
  semantic_emb = semantic_model.encode(query)
  emotion_emb = emotion_model.encode(query)
  
  # å¤šè·¯æ£€ç´¢
  semantic_results = semantic_index.search(semantic_emb)
  emotion_results = emotion_index.search(emotion_emb)
  
  # èåˆç»“æœ
  results = fusion(semantic_results, emotion_results, weights)
  ```

### å¼€å‘ä»»åŠ¡

- [x] å¤šæ¨¡å‹ embedding ç”Ÿæˆ
- [x] ä¸ D2 multi_embed é…ç½®å¯¹é½
- [x] æƒé‡é…ç½®

### é¢„ä¼°å·¥æ—¶: 2 å¤© âœ… å·²å®Œæˆ

---

## âœ… DONE-D4-3: `decompose`

### æ¦‚è¿°
å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå­æŸ¥è¯¢ã€‚

### å°ç±»å‚æ•°

```yaml
operators:
  pre_retrieval:
    action: decompose
    
    # åˆ†è§£ç­–ç•¥
    decompose_strategy: "llm"        # llm | rule | hybrid
    
    # llm ç­–ç•¥
    decompose_prompt: |
      Break down this complex question into simpler sub-questions:
      Question: {query}
      Sub-questions:
    max_sub_queries: 5
    
    # rule ç­–ç•¥
    split_keywords: ["and", "or", "also", "additionally"]
    
    # å­æŸ¥è¯¢å¤„ç†
    sub_query_action: "parallel"     # parallel | sequential
    merge_strategy: "union"          # union | intersection | rerank
```

### å¼€å‘ä»»åŠ¡

- [x] å®ç° `llm` åˆ†è§£ç­–ç•¥
- [x] å®ç° `rule` åˆ†è§£ç­–ç•¥
- [x] å­æŸ¥è¯¢å¹¶è¡Œ/ä¸²è¡Œå¤„ç†
- [x] ç»“æœåˆå¹¶

### é¢„ä¼°å·¥æ—¶: 2 å¤© âœ… å·²å®Œæˆ

---

## âœ… DONE-D4-4: `route`

### æ¦‚è¿°
æ ¹æ®æŸ¥è¯¢å†…å®¹è·¯ç”±åˆ°ä¸åŒçš„æ£€ç´¢æºã€‚

### å°ç±»å‚æ•°

```yaml
operators:
  pre_retrieval:
    action: route
    
    # è·¯ç”±ç­–ç•¥
    route_strategy: "classifier"     # classifier | keyword | llm
    
    # classifier ç­–ç•¥
    classifier_model: "intent-classifier"
    route_mapping:
      factual: "knowledge_base"
      personal: "user_memory"
      recent: "short_term_memory"
    
    # keyword ç­–ç•¥
    keyword_rules:
      - keywords: ["remember", "recall", "last time"]
        target: "long_term_memory"
      - keywords: ["just", "now", "recently"]
        target: "short_term_memory"
    
    # llm ç­–ç•¥
    route_prompt: |
      Determine which memory source should be queried:
      - short_term: recent conversations
      - long_term: historical memories
      - knowledge: factual information
    
    # å¤šè·¯ç”±
    allow_multi_route: true
    max_routes: 2
```

### å‚è€ƒå®ç°åˆ†æ

#### MemoryOS (multi-tier routing)
- **ä»£ç ä½ç½®**: `/home/zrc/develop_item/MemoryOS/`
- **æ ¸å¿ƒé€»è¾‘**:
  - åŒæ—¶æŸ¥è¯¢ STM, MTM, LTM
  - ç»“æœåˆå¹¶

#### MemGPT (function-based routing)
- **ä»£ç ä½ç½®**: `/home/zrc/develop_item/MemGPT/memgpt/`
- **æ ¸å¿ƒé€»è¾‘**:
  - Function calling å†³å®šæŸ¥è¯¢å“ªä¸ªè®°å¿†æº
  - Core/Archival/Recall åˆ†åˆ«å¤„ç†

### å¼€å‘ä»»åŠ¡

- [x] å®ç° `classifier` è·¯ç”±ç­–ç•¥
- [x] å®ç° `keyword` è·¯ç”±ç­–ç•¥
- [x] å®ç° `llm` è·¯ç”±ç­–ç•¥
- [x] å¤šè·¯ç”±æ”¯æŒ
- [x] ä¸å¤šæºæ£€ç´¢è”åŠ¨

### é¢„ä¼°å·¥æ—¶: 3 å¤© âœ… å·²å®Œæˆ

---

## âœ… DONE-D4-5: `validate`

### æ¦‚è¿°
æŸ¥è¯¢éªŒè¯å’Œé¢„å¤„ç†ã€‚

### å°ç±»å‚æ•°

```yaml
operators:
  pre_retrieval:
    action: validate
    
    # éªŒè¯è§„åˆ™
    rules:
      - type: "length"
        min: 3
        max: 1000
      - type: "language"
        allowed: ["en", "zh"]
      - type: "safety"
        blocked_patterns: ["ignore previous", "system prompt"]
    
    # å¤±è´¥å¤„ç†
    on_fail: "default"               # default | error | skip
    default_query: "Hello"           # on_fail=default æ—¶ä½¿ç”¨
    
    # é¢„å¤„ç†
    preprocessing:
      - strip_whitespace: true
      - lowercase: false
      - remove_punctuation: false
```

### å¼€å‘ä»»åŠ¡

- [x] é•¿åº¦éªŒè¯
- [x] è¯­è¨€æ£€æµ‹
- [x] å®‰å…¨æ£€æŸ¥ (prompt injection é˜²æŠ¤)
- [x] é¢„å¤„ç†æµç¨‹
- [x] å¤±è´¥å¤„ç†

### é¢„ä¼°å·¥æ—¶: 2 å¤© âœ… å·²å®Œæˆ

---

## ğŸ“‹ å¼€å‘ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | Action | å°ç±» | å‚è€ƒå·¥ä½œ | é¢„ä¼°å·¥æ—¶ | çŠ¶æ€ |
|--------|--------|------|----------|----------|------|
| P0 | `optimize` | keyword_extract, expand, rewrite, instruction | LD-Agent, HippoRAG | 3å¤© | âœ… |
| P1 | `multi_embed` | semantic+emotion | EmotionalRAG | 2å¤© | âœ… |
| P1 | `route` | classifier, keyword, llm | MemoryOS, MemGPT | 3å¤© | âœ… |
| P2 | `decompose` | llm, rule | å¤æ‚æŸ¥è¯¢ | 2å¤© | âœ… |
| P2 | `validate` | length, language, safety | é€šç”¨ | 2å¤© | âœ… |

**æ€»è®¡**: 12 äººå¤© âœ… å·²å…¨éƒ¨å®Œæˆ

---

*æ–‡æ¡£åˆ›å»ºæ—¶é—´: 2025-01-27*  
*å®Œæˆæ—¶é—´: 2025-11-27*
