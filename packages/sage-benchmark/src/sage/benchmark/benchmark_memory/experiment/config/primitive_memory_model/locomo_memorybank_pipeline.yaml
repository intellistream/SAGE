# ============================================================
# MemoryBank Pipeline 配置
# 论文: MemoryBank: Enhancing Large Language Models with Long-Term Memory
# 特点: 分层记忆 + Ebbinghaus 遗忘 + 多层摘要
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10

  prompt_template: |
    Based on the above context, answer the following question concisely.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Based on the above context, answer the following question.

    Question: {question}
    Answer:

  # LLM 配置
  # 配置1（Llama-3.1-8B，用于对比）：
  api_key: "token-abc123"
  base_url: "http://sage2:8000/v1"
  model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  max_tokens: 256
  temperature: 0
  seed: 42

  # 新配置（PanGu Embedded 1B）：
  # api_key: "iloveshuhao"
  # base_url: "http://172.17.0.1:1040/v1"
  # model_name: "pangu_embedded_1b"
  # max_tokens: 256
  # temperature: 0
  # seed: 42
  memory_name: "MemoryBank"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置
# ============================================================
services:
  register_memory_service: "hierarchical_memory"
  hierarchical_memory:
    tier_mode: "three_tier"           # 三层: STM / MTM / LTM
    tier_names: ["stm", "mtm", "ltm"]
    tier_capacities:
      stm: 50
      mtm: 500
      ltm: -1                         # 无限
    migration_policy: "overflow"      # 迁移策略: overflow | importance | time
    migration_threshold: 0.7
    embedding_dim: 1024               # bge-m3 模型输出 1024 维向量
  memory_retrieval_adapter: "none"

# ============================================================
# Operator 配置
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 生成摘要 + 重要性评分
  #
  # 【差异说明】
  # - 原始 MemoryBank: 使用独立的 summarize_memory.py 批量生成三种摘要
  #   * Daily Summary: 每日事件摘要
  #   * Personality Analysis: 用户性格分析
  #   * Overall Summary: 全局记忆概览
  #   运行时机: 离线/定期执行,而非每次对话实时生成
  #
  # - SAGE 实现: 支持两种模式
  #   * only_on_session_end=false: 每次对话实时生成摘要 (默认)
  #   * only_on_session_end=true: 仅在 session 结束时生成 (对齐原版)
  # ----------------------------------------------------------
  pre_insert:
    action: "transform"
    transform_type: "summarize"
    only_on_session_end: true  # 仅在 session 结束时生成摘要 (对齐原版)
    summarize_prompt: |
      Summarize the key events and information from this conversation.
      Focus on: facts mentioned, preferences expressed, plans discussed.
      Keep the summary concise but informative.

      Conversation:
      {dialogue}

      Summary:

  # ----------------------------------------------------------
  # PostInsert: Ebbinghaus 遗忘 + 层间迁移
  # MemoryBank 使用遗忘曲线管理记忆强度
  # ----------------------------------------------------------
  post_insert:
    action: "forgetting"
    strategy: "ebbinghaus"            # 遗忘策略：ebbinghaus | heat_based | time_based
    forget_threshold: 0.1             # 遗忘阈值 (R < 0.1 时删除)
    only_on_session_end: true         # 仅在会话结束时执行遗忘

  # ----------------------------------------------------------
  # PreRetrieval: 基础 embedding
  # ----------------------------------------------------------
  pre_retrieval:
    action: "embedding"

  # ----------------------------------------------------------
  # PostRetrieval: 时间加权重排序
  #
  # 【差异说明】
  # - 原始 MemoryBank: 仅使用日期排序 (按 metadata["source"] 日期升序)
  #   检索结果直接按日期排序,无额外加权
  #   代码: sorted(related_docs, key=lambda x: x.metadata["source"])
  #
  # - SAGE 增强: 添加时间加权 rerank (time_weighted)
  #   公式: score = similarity * exp(-time_decay * elapsed_days)
  #   效果: 近期记忆权重更高,更符合记忆遗忘规律
  #   ⚠️ 这是 SAGE 的工程增强,原论文无此机制
  # ----------------------------------------------------------
  post_retrieval:
    action: "rerank"
    rerank_type: "time_weighted"      # [SAGE 增强] 原版仅用日期排序
    time_decay_rate: 0.1              # [SAGE 增强] 时间衰减系数
    time_field: "timestamp"
    top_k: 10
    # 记忆强化配置 (MemoryBank 核心机制)
    enable_reinforcement: true        # 启用检索后的记忆强化
    reinforcement_increment: 1.0      # 强度增量 (S += 1)
    reinforcement_reset_time: true    # 重置 last_recall_date

# ============================================================
# MemoryBank 复现说明
# ============================================================
# 论文核心特性：
#   1. 多层级存储：原始对话 + 事件摘要 + 用户画像
#   2. Ebbinghaus 遗忘曲线：基于记忆强度的衰减
#   3. 检索强化：被检索的记忆强度增加
#   4. 全局画像：每日人格分析 + 全局用户画像
#
# SAGE 实现方式：
# ┌─────────────────────────────────────────────────────────┐
# │ Pipeline 阶段      │ 对应 MemoryBank 操作 │ 实现组件     │
# ├─────────────────────────────────────────────────────────┤
# │ PreInsert          │ Event Summarization  │ transform    │
# │  - 对话摘要        │ Daily Event Summary  │ summarize    │
# │  - Embedding       │ 摘要向量化           │ BGE-M3       │
# │  - 主动插入标记    │ target_tier="ltm"    │ insert_mode  │
# ├─────────────────────────────────────────────────────────┤
# │ MemoryInsert       │ Multi-tier Insert    │ Hierarchical │
# │  - STM: 原始对话   │ 存入短期记忆         │ capacity=50  │
# │  - LTM: 摘要       │ 摘要主动写入 LTM     │ capacity=-1  │
# ├─────────────────────────────────────────────────────────┤
# │ PostInsert         │ Forgetting Mechanism │ forgetting   │
# │  - 计算记忆强度    │ S = 初始强度 + 检索次数 │ ebbinghaus │
# │  - 应用遗忘曲线    │ R = exp(-t/S)        │ exponential  │
# │  - 删除低强度记忆  │ R < threshold 时删除 │ retention_min│
# │  - 检索增强        │ 被检索时 +0.5        │ review_boost │
# ├─────────────────────────────────────────────────────────┤
# │ PreRetrieval       │ Query Embedding      │ embedding    │
# │  - 查询向量化      │ 用于向量检索         │ BGE-M3       │
# ├─────────────────────────────────────────────────────────┤
# │ MemoryRetrieval    │ Dense Retrieval      │ Hierarchical │
# │  - 多层检索        │ 同时搜索 STM/MTM/LTM │ FAISS        │
# │  - 相似度排序      │ Cosine Similarity    │ top_k        │
# ├─────────────────────────────────────────────────────────┤
# │ PostRetrieval      │ Context Integration  │ rerank       │
# │  - 时间加权        │ 近期记忆权重更高     │ time_decay   │
# │  - 重排序          │ 综合相似度+时间      │ top_k=10     │
# └─────────────────────────────────────────────────────────┘
#
# 关键配置参数：
#   - tier_mode="three_tier": 三层架构（STM/MTM/LTM）
#   - strategy="ebbinghaus": 艾宾浩斯遗忘曲线
#   - forget_threshold=0.1: 遗忘阈值 (R < 0.1 删除)
#   - increment=1.0: 检索时的强度增量 (S += 1)
#   - time_decay_rate=0.1: 时间衰减率
#
# 与论文的差异：
#   1. 【存储架构】
#      - 原版: 平铺字典 history[date]=[dialogs]
#      - SAGE: 三层架构 STM/MTM/LTM (工程增强,便于层级管理)
#
#   2. 【摘要生成】
#      - 原版: 离线批量生成 (summarize_memory.py 脚本)
#      - SAGE: 实时流式生成 (PreInsert 阶段)
#
#   3. 【检索重排序】
#      - 原版: 仅日期排序 sorted(docs, key=lambda x: x.metadata["source"])
#      - SAGE: 时间加权 rerank (工程增强,平衡相似度与时效性)
#
#   4. 【向量模型】
#      - 原版: MiniLM/Text2vec
#      - SAGE: BGE-M3 (1024维,性能更强)
#
#   5. 【可配置性】
#      - 原版: 固定摘要模板和遗忘参数
#      - SAGE: 支持可配置的 prompt、阈值、迁移策略
#
# 运行示例：
#   python packages/sage-benchmark/.../memory_test_pipeline.py \
#     --config .../locomo_memorybank_pipeline.yaml --task_id conv-26
