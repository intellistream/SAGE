# ============================================================
# PreRetrieval 实验: Mem0ᵍ + Baseline (G1)
# 记忆体结构: Hybrid Memory with Graph (图记忆版)
# PreRetrieval 策略: none (对照基线)
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10

  prompt_template: |
    Based on the above context, answer the following question concisely.

    Question: {question}
    Answer:

  prompt_template_category5: |
    Based on the above context, answer the following question.

    Question: {question}
    Answer:

  # LLM 配置 (统一)
  api_key: "token-abc123"
  base_url: "http://sage2:8000/v1"
  model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  max_tokens: 512
  temperature: 0.3
  seed: 42
  memory_name: "Mem0g_Baseline"

  # Embedding 配置 (统一)
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置: Hybrid Memory with Graph (图结构)
# ============================================================
services:
  register_memory_service: "hybrid_memory"
  hybrid_memory:
    # 启用图索引
    graph_enabled: true
    entity_extraction: true
    relation_extraction: true

    # 向量+图混合检索配置 (默认权重)
    vector_weight: 0.6
    graph_weight: 0.4

# ============================================================
# Operator 配置: 固定其他阶段为 baseline
# ============================================================
operators:
  # PreInsert: 固定为 none
  pre_insert:
    action: "none"

  # PostInsert: 固定为 none
  post_insert:
    action: "none"

  # PreRetrieval: 实验变量 - Baseline
  pre_retrieval:
    action: "none"  # 直接使用原始问题，不做任何优化

  # PostRetrieval: 固定为 none
  post_retrieval:
    action: "none"
