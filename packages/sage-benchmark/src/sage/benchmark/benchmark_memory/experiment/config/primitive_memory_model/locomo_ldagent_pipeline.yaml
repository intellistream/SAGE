# ============================================================
# LD-Agent Pipeline 配置
# 论文: LD-Agent for Long-term Dialogue
# 特点: STM 缓存 + 事件摘要 LTM + 话题重叠检索
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10

  prompt_template: |
    Based on the above context, answer the following question concisely.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Based on the above context, answer the following question.

    Question: {question}
    Answer:

  # LLM 配置
  # 配置1（Llama-3.1-8B，用于对比）：
  api_key: "token-abc123"
  base_url: "http://sage2:8000/v1"
  model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  max_tokens: 256
  temperature: 0
  seed: 42

  # 新配置（PanGu Embedded 1B）：
  # api_key: "iloveshuhao"
  # base_url: "http://172.17.0.1:1040/v1"
  # model_name: "pangu_embedded_1b"
  # max_tokens: 256
  # temperature: 0
  # seed: 42
  memory_name: "LD-Agent"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置
# ============================================================
services:
  register_memory_service: "hierarchical_memory"
  hierarchical_memory:
    tier_mode: "two_tier"             # 双层模式会自动使用 ["stm", "ltm"]
    tier_capacities:
      stm: 50                         # 当前会话缓存
      ltm: -1                         # 事件摘要库
    migration_policy: "time"          # 按时间迁移
    embedding_dim: 1024               # BAAI/bge-m3 输出 1024 维向量
  memory_retrieval_adapter: "none"

# ============================================================
# Operator 配置
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 事件摘要生成
  # LD-Agent 会对对话生成事件摘要
  # ----------------------------------------------------------
  pre_insert:
    action: "transform"
    transform_type: "summarize"
    summarize_prompt: |
      Summarize the key events from this dialogue as a brief event description.
      Focus on: What happened? Who was involved? What was decided/planned?

      Dialogue:
      {dialogue}

      Event summary:

  # ----------------------------------------------------------
  # PostInsert: 会话间隔触发迁移
  # LD-Agent 在会话间隔>1小时时触发 STM→LTM 迁移
  # ----------------------------------------------------------
  post_insert:
    action: "migrate"
    migrate_policy: "time"
    session_gap: 3600
    upgrade_transform: "summarize"
    downgrade_transform: "none"

  # ----------------------------------------------------------
  # PreRetrieval: 名词/关键词提取（用于话题重叠）
  # LD-Agent 使用 spaCy 提取名词集合
  # ----------------------------------------------------------
  pre_retrieval:
    action: "optimize"
    optimize_type: "keyword_extract"
    extractor: "spacy"
    spacy_model: "en_core_web_sm"     # spaCy 模型名称
    extract_types: ["NOUN", "PROPN"]
    max_keywords: 15

  # ----------------------------------------------------------
  # PostRetrieval: 多因子重排序（语义+话题+时间）
  # LD-Agent 使用综合得分排序
  # ----------------------------------------------------------
  post_retrieval:
    action: "rerank"
    rerank_type: "weighted"
    factors:
    - name: "relevance"
      weight: 0.4
      source: "embedding_similarity"
    - name: "recency"
      weight: 0.3
      decay_type: "exponential"
      decay_rate: 0.995
    - name: "topic_overlap"
      weight: 0.3
      source: "keyword_jaccard"
    top_k: 10
    conversation_format_prompt: |
      The following is relevant dialogue history.

# ============================================================
# LD-Agent 复现说明
# ============================================================
# 论文核心特性：
#   1. 双层记忆: STM 缓存 + LTM 事件摘要库
#   2. 事件摘要: 对对话生成事件描述
#   3. 话题重叠检索: 基于名词集合的 Jaccard 相似度
#   4. 多因子重排序: 语义 + 时间 + 话题
#
# SAGE 实现方式：
# ┌─────────────────────────────────────────────────────────┐
# │ Pipeline 阶段      │ 对应 LD-Agent 操作    │ 实现组件     │
# ├─────────────────────────────────────────────────────────┤
# │ PreInsert          │ Event Summarization   │ transform    │
# │  - 事件摘要        │ 提取事件描述          │ summarize    │
# │  - Embedding       │ 摘要向量化            │ BGE-M3       │
# ├─────────────────────────────────────────────────────────┤
# │ MemoryInsert       │ Dual-tier Insert      │ Hierarchical │
# │  - STM 插入        │ 当前会话缓存          │ stm=50       │
# │  - LTM 预留        │ 事件摘要库            │ ltm=-1       │
# ├─────────────────────────────────────────────────────────┤
# │ PostInsert         │ Session-gap Migrate   │ migrate      │
# │  - 时间间隔判断    │ >1小时触发迁移        │ gap=3600s    │
# │  - STM → LTM       │ 摘要迁移到长期记忆    │ time policy  │
# ├─────────────────────────────────────────────────────────┤
# │ PreRetrieval       │ Keyword Extraction    │ optimize     │
# │  - 名词提取        │ spaCy NOUN/PROPN      │ spacy        │
# │  - 话题集合        │ 用于 Jaccard 计算     │ max_kw=15    │
# ├─────────────────────────────────────────────────────────┤
# │ MemoryRetrieval    │ Multi-tier Search     │ Hierarchical │
# │  - 同时检索 STM/LTM│ 合并结果              │ FAISS        │
# ├─────────────────────────────────────────────────────────┤
# │ PostRetrieval      │ Multi-factor Rerank   │ rerank       │
# │  - 语义相似度      │ embedding similarity  │ weight=0.4   │
# │  - 时间衰减        │ exponential decay     │ weight=0.3   │
# │  - 话题重叠        │ keyword Jaccard       │ weight=0.3   │
# │  - 加权融合        │ 综合排序              │ top_k=10     │
# └─────────────────────────────────────────────────────────┘
#
# 关键配置参数：
#   - tier_mode="two_tier": 双层架构（STM/LTM）
#   - session_gap=3600: 会话间隔阈值（秒）
#   - extract_types=["NOUN", "PROPN"]: 名词和专有名词
#   - rerank factors: relevance(0.4) + recency(0.3) + topic(0.3)
#
# 与论文的差异：
#   1. 论文使用 jieba 分词（中文），SAGE 使用 spaCy（英文）
#   2. SAGE 支持配置化的权重和衰减率
#   3. SAGE 增加了 migration 算子处理 STM→LTM 迁移
#
# 运行示例：
#   python packages/sage-benchmark/.../memory_test_pipeline.py \
#     --config .../locomo_ldagent_pipeline.yaml --task_id conv-26
