# ============================================================
# Mem0 Pipeline 配置
# 论文: Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory
# 特点: 事实存储 + ADD/UPDATE/DELETE 操作 + 全局摘要
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10

  prompt_template: |
    Based on the context above, provide a brief, direct answer to the question. No explanation, no reasoning, no elaboration - just the answer.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Answer the multiple choice question based on the context. Provide ONLY the answer in format (a) or (b) without any explanation.

    Question: {question}
    Answer:

  # LLM 配置
  # 配置1（Llama-3.1-8B，用于对比）：
  # api_key: "token-abc123"
  # base_url: "http://sage2:8000/v1"
  # model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  # max_tokens: 256
  # temperature: 0
  # seed: 42

  # 新配置（PanGu Embedded 1B）：
  api_key: "iloveshuhao"
  base_url: "http://172.17.0.1:1040/v1"
  model_name: "pangu_embedded_1b"
  max_tokens: 256
  temperature: 0
  seed: 42
  memory_name: "Mem0"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置
# ============================================================
services:
  services_type: "partitional.inverted_vectorstore_combination"
  inverted_vectorstore_combination:
    vector_dim: 1024                  # BAAI/bge-m3 输出 1024 维向量
    fusion_strategy: "linear"         # linear 融合策略（对应 weighted）
    linear_alpha: 0.3                 # BM25 权重 0.3, Vector 权重 0.7 (semantic)
  memory_retrieval_adapter: "none"

# ============================================================
# Operator 配置
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 从对话中提取事实候选
  # Mem0 会提取 salient memories（显著事实）
  # ----------------------------------------------------------
  pre_insert:
    action: "extract"
    extract_type: "fact"              # Mem0 风格：抽取显著事实（salient facts）
    method: "mem0_llm"               # LLM 抽取，失败回退到 simple
    add_to_metadata: true             # 将抽取到的 facts 放入 metadata（便于后续 PostInsert 使用）
    keep_original: true               # 保留原始对话文本
    mem0_llm_prompt: |
      You are an assistant that extracts salient facts from the given conversation.
      Return ONLY a compact JSON with the schema:
      {
        "facts": ["..."]
      }
      Rules:
      - Each fact should be concise and self-contained.
      - Avoid duplicates; skip trivial greetings.
      - Do NOT include any explanation or extra keys.

  # ----------------------------------------------------------
  # PostInsert: ADD/UPDATE/DELETE 决策
  # Mem0 的核心：LLM 决定对已有记忆的操作
  # ----------------------------------------------------------
  post_insert:
    action: "crud"
    top_k: 10
    debug_summary_only: true
    decision_prompt: |
      You are a JSON decision API. Output ONLY a single minified JSON object, no prose, no markdown, no code fences.

      Schema:
      {
        "action": "ADD|UPDATE|DELETE|NOOP",
        "to_delete": ["<id>", ...],
        "reason": "<short explanation>"
      }

      Rules:
      - Use UPPERCASE for action exactly as one of ADD, UPDATE, DELETE, NOOP.
      - If uncertain, default to {"action":"ADD","to_delete":[],"reason":"insufficient evidence"}.
      - "to_delete" must contain only IDs present in the Existing facts list (the values inside square brackets []).
      - UPDATE or DELETE: put the affected existing fact IDs into to_delete.
      - NOOP: to_delete must be [].

      Inputs:
      New fact:
      {new_memory}

      Existing facts:
      {existing_memories}

      Now respond with ONLY the JSON object.

  # ----------------------------------------------------------
  # PreRetrieval: 基础 embedding
  # ----------------------------------------------------------
  pre_retrieval:
    action: "embedding"

  # ----------------------------------------------------------
  # PostRetrieval: 简单格式化（Mem0 基础版较简单）
  # ----------------------------------------------------------
  post_retrieval:
    action: "filter"
    filter_type: "threshold"
    threshold: 0.5              # 低于该分数的记忆将被过滤（与 Mem0 的阈值策略一致）
    score_field: "score"        # 从结果的 score 字段读取分数；若无则从 metadata[score] 读取
    conversation_format_prompt: |
      The following are relevant facts from memory.

# ============================================================
# Mem0 复现说明
# ============================================================
# 论文核心特性：
#   1. 事实存储: 提取并存储离散事实
#   2. ADD/UPDATE/DELETE: LLM 决策记忆操作
#   3. 混合检索: Vector + BM25 融合
#   4. 全局摘要: 用户画像和知识库概览
#
# SAGE 实现方式：
# ┌─────────────────────────────────────────────────────────┐
# │ Pipeline 阶段      │ 对应 Mem0 操作        │ 实现组件     │
# ├─────────────────────────────────────────────────────────┤
# │ PreInsert          │ Fact Extraction       │ extract      │
# │  - 事实/实体提取    │ 显著事实候选          │ mem0_llm     │
# │  - 回退策略        │ NER/名词短语          │ spaCy        │
# │  - 元数据标注      │ 实体类型标记          │ metadata     │
# ├─────────────────────────────────────────────────────────┤
# │ MemoryInsert       │ Hybrid Insert         │ HybridMemory │
# │  - 向量索引        │ 语义检索              │ vector       │
# │  - BM25 索引       │ 关键词检索            │ bm25         │
# │  - 融合权重        │ 0.7 semantic + 0.3 kw │ weighted     │
# ├─────────────────────────────────────────────────────────┤
# │ PostInsert         │ ADD/UPDATE/DELETE     │ distillation │
# │  - 检索相似事实    │ 查找已有事实          │ topk=10      │
# │  - LLM 决策        │ 判断操作类型          │ LLM Prompt   │
# │  - 执行操作        │ ADD: 新增             │ Service      │
# │                    │ UPDATE: 删旧加新      │              │
# │                    │ DELETE: 删除矛盾      │              │
# │                    │ NOOP: 已存在          │              │
# ├─────────────────────────────────────────────────────────┤
# │ PreRetrieval       │ Query Embedding       │ embedding    │
# │  - 查询向量化      │ 用于混合检索          │ BGE-M3       │
# ├─────────────────────────────────────────────────────────┤
# │ MemoryRetrieval    │ Hybrid Search         │ HybridMemory │
# │  - 向量检索        │ semantic top-k        │ FAISS        │
# │  - BM25 检索       │ keyword top-k         │ BM25         │
# │  - 加权融合        │ RRF / weighted sum    │ fusion       │
# ├─────────────────────────────────────────────────────────┤
# │ PostRetrieval      │ Basic Format          │ none         │
# │  - 基础格式化      │ 拼接事实列表          │ default      │
# └─────────────────────────────────────────────────────────┘
#
# 关键配置参数：
#   - fusion_strategy="weighted": 加权融合策略
#   - fusion_weights: {semantic: 0.7, keyword: 0.3}
#   - distillation_prompt: ADD/UPDATE/DELETE 决策 prompt
#
# 与论文的差异：
#   1. 原论文常用云端向量数据库（如 Qdrant/Weaviate）；SAGE 使用内置向量索引（可通过配置切换）
#   2. SAGE 的 distillation_prompt 参照论文逻辑进行简化与对齐
#   3. 融合权重（semantic/keyword）可在配置中调整

# 正确实现参考：
#   - 源码路径：Mem0-memory/main.py
#   - 相关模块：Mem0-memory/storage.py、Mem0-memory/utils.py
#   - 行为基线：提取显著事实（salient facts）、LLM 决策 CRUD、混合检索（vector+BM25）、全局摘要维护

# 与正确实现的差异：
#   - 向量库：Mem0 原仓常用 Qdrant/Weaviate；SAGE 采用 FAISS（本地快速原型）
#   - 检索融合：Mem0 支持 RRF/分数归一化等多策略；SAGE 当前为简单加权（weights: semantic 0.7, keyword 0.3）
#   - 抽取策略：Mem0 可灵活配置抽取流水线；SAGE 提供 mem0_llm + spaCy 回退的轻量实现
#   - 全局摘要：Mem0 维护用户画像/知识概要；SAGE 目前不在 pipeline 中自动维护（可通过自定义算子扩展）
#
# 运行示例：
#   python packages/sage-benchmark/.../memory_test_pipeline.py \
#     --config .../locomo_mem0_pipeline.yaml --task_id conv-26
