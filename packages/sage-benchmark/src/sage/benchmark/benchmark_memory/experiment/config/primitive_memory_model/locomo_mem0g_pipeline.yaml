# ============================================================
# Mem0ᵍ Pipeline 配置 (图记忆版)
# 论文: Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory
# 变体: Mem0ᵍ - 向量 + 知识图谱 + 实体链接
# 特点: 相比基础版 Mem0，增加了图索引支持，可以通过实体关系进行检索
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10

  prompt_template: |
    Based on the context above, provide a brief, direct answer to the question. No explanation, no reasoning, no elaboration - just the answer.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Answer the multiple choice question based on the context. Provide ONLY the answer in format (a) or (b) without any explanation.

    Question: {question}
    Answer:

  # LLM 配置
  # 配置1（Llama-3.1-8B，用于对比）：
  # api_key: "token-abc123"
  # base_url: "http://sage2:8000/v1"
  # model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  # max_tokens: 256
  # temperature: 0
  # seed: 42

  # 新配置（PanGu Embedded 1B）：
  api_key: "iloveshuhao"
  base_url: "http://172.17.0.1:1040/v1"
  model_name: "pangu_embedded_1b"
  max_tokens: 256
  temperature: 0
  seed: 42
  memory_name: "Mem0g"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置
# Mem0ᵍ 使用 SemanticInvertedKnowledgeGraphService (三层架构)
# ============================================================
services:
  services_type: "hierarchical.semantic_inverted_knowledge_graph"
  semantic_inverted_knowledge_graph:
    vector_dim: 1024                  # BAAI/bge-m3 输出 1024 维向量
    hierarchy_levels: 3               # 三层：Semantic + Inverted + KG
    routing_strategy: "parallel"      # parallel 并行检索三层并融合（对应原 weighted）
    enable_cross_layer_query: true    # 启用跨层查询
    max_hops: 3                       # KG 最大跳数
    default_index: "semantic_index"   # 默认语义索引
    # Note: 索引由服务自动创建
    #   - semantic_index: FAISS (dim=1024, BGE-M3)
    #   - inverted_index: BM25
    #   - kg_index: Segment (模拟图结构)
  memory_retrieval_adapter: "none"

# ============================================================
# Operator 配置
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 实体和关系抽取
  # Mem0ᵍ 会抽取实体和关系用于构建知识图谱
  # ----------------------------------------------------------
  pre_insert:
    action: "extract.triple"          # 使用三元组抽取（比 entity 更完整）
    extraction_method: "llm"           # 启用 LLM 路径以触发三元组抽取的真实大模型调用
    triple_extraction_prompt: |
      You are a knowledge graph builder. Extract factual triples from the dialogue.
      Focus on entities (people, organizations, locations) and their relationships.

      Rules:
      1. Output format: (Subject, Predicate, Object) - one triple per line
      2. Resolve ALL pronouns to actual entity names
      3. Extract relationships, attributes, and temporal information
      4. Be concise and factual

      Dialogue:
      {dialogue}

      Triples:

  # ----------------------------------------------------------
  # PostInsert: CRUD 决策 + 实体链接占位（图版）
  # Mem0ᵍ 的核心：LLM 决定对已有记忆的操作；图索引的链接在其他算子中维护
  # ----------------------------------------------------------
  post_insert:
    action: "crud"
    top_k: 10
    debug_summary_only: true        # 仅输出 LLM 调用汇总行（抑制其他 CRUD 调试输出）
    decision_prompt: |
      You are a JSON decision API. Output ONLY a single minified JSON object, no prose, no markdown, no code fences.

      Schema:
      {
        "action": "ADD|UPDATE|DELETE|NOOP",
        "to_delete": ["<id>", ...],
        "reason": "<short explanation>"
      }

      Rules:
      - Use UPPERCASE for action exactly as one of ADD, UPDATE, DELETE, NOOP.
      - If uncertain, default to {"action":"ADD","to_delete":[],"reason":"insufficient evidence"}.
      - "to_delete" must contain only IDs present in the Existing facts list (the values inside square brackets []).
      - UPDATE or DELETE: put the affected existing fact IDs into to_delete.
      - NOOP: to_delete must be [].

      Inputs:
      New fact:
      {new_memory}

      Existing facts:
      {existing_memories}

      Now respond with ONLY the JSON object.

  # ----------------------------------------------------------
  # PreRetrieval: 基础 embedding + 实体识别
  # ----------------------------------------------------------
  pre_retrieval:
    action: "embedding"

  # ----------------------------------------------------------
  # PostRetrieval: 混合检索结果融合
  # Mem0ᵍ 融合向量检索和图检索结果
  # ----------------------------------------------------------
  post_retrieval:
    action: "none"
    top_k: 10
    conversation_format_prompt: |
      The following is relevant context retrieved from memory.

# ============================================================
# Mem0ᵍ 复现说明（图记忆版）
# ============================================================
# 论文核心特性（图版）：
#   1. ADD/UPDATE/DELETE 决策（与基础版一致）
#   2. 图索引支持：实体关系与图结构用于检索
#   3. 三重索引：向量 + BM25 + 图
#   4. 三元组抽取：面向实体与关系的结构化表示
#   5. 混合检索：融合多索引结果
#
# SAGE 实现方式：
# ┌───────────────────────────────────────────────────────────┐
# │ Pipeline 阶段      │ 对应 Mem0ᵍ 操作        │ 实现组件     │
# ├───────────────────────────────────────────────────────────┤
# │ PreInsert          │ Triple Extraction      │ extract.triple│
# │  - 三元组抽取        │ (Subject, Predicate, Object) │ LLM Prompt │
# │  - 面向图结构        │ 为实体/关系提供结构化输入 │            │
# ├───────────────────────────────────────────────────────────┤
# │ MemoryInsert       │ Hybrid Insert          │ HybridMemory │
# │  - 向量索引          │ 语义相似度检索          │ vector       │
# │  - 关键词索引        │ 文本匹配                │ bm25         │
# │  - 图索引            │ 实体关系检索            │ graph        │
# ├───────────────────────────────────────────────────────────┤
# │ PostInsert         │ CRUD 决策               │ mem0_crud    │
# │  - 检索相似记忆      │ topk=10                 │ hybrid search│
# │  - LLM 决策          │ ADD/UPDATE/DELETE/NOOP  │ CRUD Prompt  │
# │  - 执行操作          │ 更新/删除/保留          │ Service      │
# ├───────────────────────────────────────────────────────────┤
# │ PreRetrieval       │ Query Embedding        │ embedding    │
# │  - 查询向量化        │ 用于混合检索            │ BGE-M3       │
# ├───────────────────────────────────────────────────────────┤
# │ MemoryRetrieval    │ Hybrid Retrieval       │ HybridMemory │
# │  - 向量检索          │ 语义相似度              │ vector       │
# │  - 关键词检索        │ BM25 匹配               │ bm25         │
# │  - 图检索            │ 实体关系检索            │ graph        │
# │  - 结果融合          │ 加权融合（semantic/keyword/entity_graph） │ weighted │
# ├───────────────────────────────────────────────────────────┤
# │ PostRetrieval      │ Context Integration    │ none         │
# │  - 基础格式化        │ 拼接为 prompt          │ 默认格式     │
# └───────────────────────────────────────────────────────────┘
#
# 关键配置参数：
#   graph_enabled: true             # 启用图索引（与基础版的核心区别）
#   entity_extraction: true         # 启用实体抽取
#   relation_extraction: true       # 启用关系抽取
#   indexes:                        # 三重索引配置
#     - semantic (vector, 权重 0.5)
#     - keyword (BM25, 权重 0.2)
#     - entity_graph (graph, 权重 0.3)  # 新增
#   fusion_strategy: "weighted"     # 加权融合策略
#   triple_extraction_prompt        # 三元组抽取 prompt
#
# 与 Mem0 基础版的差异：
#   1. 索引类型：基础版为 vector+BM25；图版增加 graph 索引
#   2. PreInsert：基础版常用实体/事实抽取；图版使用三元组抽取
#   3. 检索策略：图版融合三种检索结果；基础版为两种
#   4. 场景适配：图版更适合实体/关系密集的任务
#
# 实体关系检索示例：
#   查询: "Sarah 的妈妈喜欢什么？"
#   1. 向量检索：找到包含 "Sarah" 和 "妈妈" 的记忆
#   2. 关键词检索：匹配 "喜欢" 关键词
#   3. **图检索**：
#      - 识别实体: Sarah, 妈妈
#      - 遍历关系: Sarah -[has_mom]-> 妈妈 -[likes]-> ?
#      - 找到答案: 妈妈 -[likes]-> 绘画
#   4. 融合结果: 0.5*向量分数 + 0.2*BM25分数 + 0.3*图分数
#
# 与论文的差异：
#   - 原论文常用专业图数据库（如 Neo4j）；SAGE 使用自研的图索引实现（GraphMemoryCollection/简单图结构）
#   - 实体链接与消歧在原论文更复杂；SAGE 使用简化版（相似度 + Prompt 决策）
#   - 融合权重为经验值（semantic/keyword/entity_graph 可在配置中调整）

# 正确实现参考：
#   - 源码路径：Mem0-memory/graph_memory.py
#   - 相关模块：Mem0-memory/base.py、Mem0-memory/storage.py
#   - 行为基线：三元组抽取、实体链接、向量+BM25+图三重索引与融合

# 与正确实现的差异：
#   - 图数据库：Mem0ᵍ 原仓可接入 Neo4j/NetworkX；SAGE 使用轻量 igraph/自研结构以便快速验证
#   - 链接算法：Mem0ᵍ 实体链接更复杂（消歧/归一化）；SAGE 以相似度 + Prompt 决策为主，规则更简化
#   - 融合策略：Mem0ᵍ 支持学习/自适应权重；SAGE 当前使用经验权重 semantic:0.5, keyword:0.2, entity_graph:0.3（可在配置调整）
#
# 运行示例：
#   python packages/sage-benchmark/.../memory_test_pipeline.py \
#     --config .../locomo_mem0g_pipeline.yaml --task_id conv-26
