# ============================================================
# HippoRAG Pipeline 配置
# 论文: HippoRAG: Neurobiologically Inspired Long-Term Memory for LLMs
# 特点: Knowledge Graph + Synonym Edges + PPR 检索
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10

  prompt_template: |
    Based on the context above, provide a brief, direct answer to the question. No explanation, no reasoning, no elaboration - just the answer.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Answer the multiple choice question based on the context. Provide ONLY the answer in format (a) or (b) without any explanation.

    Question: {question}
    Answer:

  # LLM 配置
  # 配置1（Llama-3.1-8B，用于对比）：
  # api_key: "token-abc123"
  # base_url: "http://sage2:8000/v1"
  # model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  # max_tokens: 256
  # temperature: 0
  # seed: 42

  # 新配置（PanGu Embedded 1B）：
  api_key: "iloveshuhao"
  base_url: "http://172.17.0.1:1040/v1"
  model_name: "pangu_embedded_1b"
  max_tokens: 256
  temperature: 0
  seed: 42
  memory_name: "HippoRAG"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置 - 新架构 (neuromem)
# ============================================================
services:
  # ✅ 迁移到 hierarchical.semantic_inverted_knowledge_graph
  services_type: "hierarchical.semantic_inverted_knowledge_graph"

  # 三层架构配置（必须嵌套在 semantic_inverted_knowledge_graph 下）
  semantic_inverted_knowledge_graph:
    vector_dim: 1024                    # BGE-M3 向量维度
    hierarchy_levels: 3                 # 固定3层（语义+倒排+知识图谱）
    routing_strategy: "cascade"         # 级联检索策略
    enable_cross_layer_query: true      # 启用跨层查询（支持多跳推理）
    max_hops: 3                         # KG最大跳数（对应 max_depth）
    default_index: "semantic_index"     # 默认使用语义索引作为起始点

# ============================================================
# Operator 配置
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 三元组抽取（OpenIE 风格）
  # HippoRAG 的核心是从文本抽取 (S, P, O) 三元组
  # ----------------------------------------------------------
  pre_insert:
    action: "extract.triple"
    triple_extraction_prompt: |
      You are a knowledge graph builder. Extract ALL factual triples from the dialogue, focusing on information that could answer questions about WHO, WHAT, WHEN, WHERE, WHY, and HOW.

      CRITICAL Rules:
      1. Output format: (Subject, Predicate, Object) - one triple per line
      2. Resolve ALL pronouns (he, she, it, they, etc.) to actual entity names
      3. Extract TEMPORAL information as separate triples:
         - (Event, happened_on, time/date)
         - (Person, did_action_at, time)
      4. Extract LOCATION information:
         - (Event, took_place_at, location)
         - (Person, was_at, place)
      5. Extract ATTRIBUTES and PROPERTIES:
         - (Entity, has_property, value)
         - (Person, is_a, role/occupation)
      6. Extract RELATIONSHIPS between people:
         - (Person1, relationship_with, Person2)
      7. Extract REASONS and PURPOSES:
         - (Action, was_for, purpose)
         - (Person, supports, cause/group)
      8. Be EXHAUSTIVE - extract every fact, even implicit ones
      9. Use specific predicates (e.g., "painted_at_lake" not just "painted")

      Example:
      Dialogue: "Yesterday, Sarah told me she painted a sunrise at the lake for her mom's birthday."
      Triples:
      (Sarah, painted, sunrise)
      (Sarah, painted_at, lake)
      (painting, happened_on, yesterday)
      (painting, was_for, mom's birthday)
      (Sarah, has_mom, mentioned)

      Dialogue:
      {dialogue}

      Triples:

  # ----------------------------------------------------------
  # PostInsert: Synonym Edge 建立
  # HippoRAG 原版在 indexing 阶段结束后才一次性创建 synonym edges
  # 现在 PostInsert 会自动检测：仅在 session 结束或最后一个 packet 时执行
  # ----------------------------------------------------------
  post_insert:
    action: "link_evolution"
    link_policy: "synonym_edge"
    knn_k: 10
    similarity_threshold: 0.7
    edge_weight: 1.0

  # ----------------------------------------------------------
  # PreRetrieval: Query Embedding
  # HippoRAG 需要 embedding 来通过向量相似度找到图中的起始节点
  # ----------------------------------------------------------
  pre_retrieval:
    action: "embedding"
    # embedding 配置（使用默认的 embedding 模型）

  # ----------------------------------------------------------
  # PostRetrieval: PPR 重排序（暂时禁用）
  # HippoRAG 使用 Personalized PageRank 排序检索结果
  # 注意：PPR 在服务单线程下容易超时，暂时禁用
  # ----------------------------------------------------------
  post_retrieval:
    action: "none"
    # action: "rerank"
    # rerank_type: "ppr"
    # damping_factor: 0.5
    # max_iterations: 100
    # convergence_threshold: 1e-6
    # personalization_nodes: "query_entities"
    top_k: 10
    conversation_format_prompt: |
      The following is relevant knowledge from the graph.

# ============================================================
# HippoRAG 架构说明 - 新实现 (neuromem)
# ============================================================
# 论文核心特性：
#   1. 知识图谱存储：(Subject, Predicate, Object) 三元组
#   2. Synonym Edges: 连接语义相近的节点
#   3. PPR 检索：Personalized PageRank 图遍历
#   4. 两阶段检索：向量查找起始节点 + 图遍历扩展
#
# 新架构映射 (hierarchical.semantic_inverted_knowledge_graph):
# ┌──────────────────────────────────────────────────────────────┐
# │ Pipeline 阶段      │ HippoRAG 操作        │ 新架构实现      │
# ├──────────────────────────────────────────────────────────────┤
# │ PreInsert          │ OpenIE Triple Extract│ extract.triple  │
# │  - 三元组提取      │ (S, P, O) 抽取       │ LLM Prompt      │
# │  - 节点 Embedding    │ 为每个实体生成向量   │ BGE-M3          │
# ├──────────────────────────────────────────────────────────────┤
# │ MemoryInsert       │ Graph Insert         │ 3层索引自动插入 │
# │  - Layer 1 (Semantic) │ 向量索引           │ FAISS (1024维)  │
# │  - Layer 2 (Inverted) │ 关键词倒排         │ BM25            │
# │  - Layer 3 (KG)       │ 知识图谱          │ Segment (模拟)  │
# ├──────────────────────────────────────────────────────────────┤
# │ PostInsert         │ Synonym Edge Build   │ link_evolution  │
# │  - 语义相似计算    │ 找到相近节点        │ knn_k=10        │
# │  - 建立 synonym 边  │ 连接语义相近实体    │ threshold=0.7   │
# ├──────────────────────────────────────────────────────────────┤
# │ PreRetrieval       │ Query Embedding      │ embedding       │
# │  - 查询向量化      │ 用于找起始节点      │ BGE-M3          │
# ├──────────────────────────────────────────────────────────────┤
# │ MemoryRetrieval    │ Vector + Graph       │ cascade检索     │
# │  - 阶段1: 语义层   │ 向量相似度检索      │ semantic_index  │
# │  - 阶段2: 倒排层   │ BM25关键词匹配      │ inverted_index  │
# │  - 阶段3: KG层     │ 图遍历（max_hops=3）│ kg_index        │
# ├──────────────────────────────────────────────────────────────┤
# │ PostRetrieval      │ PPR Rerank (禁用)   │ none            │
# │  - PPR 重排序      │ PageRank 权重       │ 超时问题暂时禁用│
# └──────────────────────────────────────────────────────────────┘
#
# 关键配置参数：
#   - vector_dim=1024: BGE-M3 向量维度
#   - hierarchy_levels=3: 固定3层架构
#   - routing_strategy="cascade": 级联检索（语义→倒排→KG）
#   - max_hops=3: 知识图谱最大跳数（对应论文的 graph traversal depth）
#   - enable_cross_layer_query=true: 支持跨层查询和多跳推理
#
# 与论文的差异：
#   1. 论文使用 ColBERT，SAGE 使用 BGE-M3（更通用）
#   2. PPR 重排序暂时禁用（单线程易超时）
#   3. SAGE 使用三层架构增强检索能力（语义+倒排+KG）
#   4. 支持自动检测 session 结束才建立 synonym 边
#
# 运行示例：
#   packages/sage-benchmark/.../run_locomo_hipporag.sh
