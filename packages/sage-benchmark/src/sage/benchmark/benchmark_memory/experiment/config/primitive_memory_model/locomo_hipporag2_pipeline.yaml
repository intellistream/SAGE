# ============================================================
# HippoRAG2 Pipeline 配置 (改进版)
# 论文: HippoRAG: Neurobiologically Inspired Long-Term Memory for LLMs
# 变体: HippoRAG2 - 更深的 PPR + 更好的 Rerank
# 特点: 相比基础版 HippoRAG，增加了 PPR 深度和增强的重排序
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10

  prompt_template: |
    Based on the above context, answer the following question concisely.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Based on the above context, answer the following question.

    Question: {question}
    Answer:

  # LLM 配置
  api_key: "token-abc123"
  base_url: "http://sage2:8000/v1"
  model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  max_tokens: 512
  temperature: 0.3
  seed: 42
  memory_name: "HippoRAG2"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置
# HippoRAG2 使用增强的图检索参数
# ============================================================
services:
  register_memory_service: "graph_memory"
  graph_memory:
    graph_type: "knowledge_graph"     # HippoRAG 使用知识图谱
    triple_store: "igraph"
    node_embedding_dim: 1024
    edge_types: ["relation", "synonym", "temporal"]
    # 关键区别：HippoRAG2 使用更深的 PPR 和更多起始节点
    ppr_depth: 3                      # 更深的 PPR（HippoRAG 基础版为 2）
    ppr_damping: 0.9                  # 更高的 damping（HippoRAG 基础版为 0.85）
    enhanced_rerank: true             # 启用增强的重排序
    # 检索参数：进一步增加起始节点和遍历深度
    retrieval_top_k: 30               # 初始向量检索返回数量（基础版为 20）
    num_start_nodes: 15               # 使用更多种子节点启动图遍历（基础版为 10）
    max_depth: 4                      # 增加遍历深度（基础版为 3）
  memory_retrieval_adapter: "none"

# ============================================================
# Operator 配置
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 三元组抽取（与基础版相同）
  # HippoRAG 的核心是从文本抽取 (S, P, O) 三元组
  # ----------------------------------------------------------
  pre_insert:
    action: "extract.triple"
    triple_extraction_prompt: |
      You are a knowledge graph builder. Extract ALL factual triples from the dialogue, focusing on information that could answer questions about WHO, WHAT, WHEN, WHERE, WHY, and HOW.

      CRITICAL Rules:
      1. Output format: (Subject, Predicate, Object) - one triple per line
      2. Resolve ALL pronouns (he, she, it, they, etc.) to actual entity names
      3. Extract TEMPORAL information as separate triples:
         - (Event, happened_on, time/date)
         - (Person, did_action_at, time)
      4. Extract LOCATION information:
         - (Event, took_place_at, location)
         - (Person, was_at, place)
      5. Extract ATTRIBUTES and PROPERTIES:
         - (Entity, has_property, value)
         - (Person, is_a, role/occupation)
      6. Extract RELATIONSHIPS between people:
         - (Person1, relationship_with, Person2)
      7. Extract REASONS and PURPOSES:
         - (Action, was_for, purpose)
         - (Person, supports, cause/group)
      8. Be EXHAUSTIVE - extract every fact, even implicit ones
      9. Use specific predicates (e.g., "painted_at_lake" not just "painted")

      Example:
      Dialogue: "Yesterday, Sarah told me she painted a sunrise at the lake for her mom's birthday."
      Triples:
      (Sarah, painted, sunrise)
      (Sarah, painted_at, lake)
      (painting, happened_on, yesterday)
      (painting, was_for, mom's birthday)
      (Sarah, has_mom, mentioned)

      Dialogue:
      {dialogue}

      Triples:

  # ----------------------------------------------------------
  # PostInsert: Synonym Edge 建立（与基础版相同）
  # ----------------------------------------------------------
  post_insert:
    action: "link_evolution"
    link_policy: "synonym_edge"
    knn_k: 10
    similarity_threshold: 0.7
    edge_weight: 1.0

  # ----------------------------------------------------------
  # PreRetrieval: Query Embedding（与基础版相同）
  # ----------------------------------------------------------
  pre_retrieval:
    action: "embedding"

  # ----------------------------------------------------------
  # PostRetrieval: 增强的 PPR 重排序
  # HippoRAG2 使用更深的 PPR 和增强的 rerank
  # ----------------------------------------------------------
  post_retrieval:
    action: "rerank"
    rerank_type: "ppr"
    damping_factor: 0.9               # 更高的 damping（基础版为 0.5）
    max_iterations: 150               # 更多迭代次数（基础版为 100）
    convergence_threshold: 1e-7       # 更严格的收敛阈值
    personalization_nodes: "query_entities"
    # 增强的重排序：结合 PPR 分数和语义相似度
    enhanced_rerank: true
    rerank_weight_ppr: 0.6            # PPR 分数权重
    rerank_weight_semantic: 0.4       # 语义相似度权重
    top_k: 15                         # 返回更多结果（基础版为 10）
    conversation_format_prompt: |
      The following is relevant knowledge from the graph.

# ============================================================
# HippoRAG2 复现说明（改进版）
# ============================================================
# 论文核心特性（改进版）：
#   1. 知识图谱 + PPR 检索（与基础版相同）
#   2. **更深的 PPR 深度**：ppr_depth=3（基础版为 2）
#   3. **更多起始节点**：num_start_nodes=15（基础版为 10）
#   4. **增强的重排序**：结合 PPR 分数和语义相似度
#   5. **更严格的收敛**：convergence_threshold=1e-7
#
# SAGE 实现方式：
# ┌───────────────────────────────────────────────────────────┐
# │ Pipeline 阶段      │ 对应 HippoRAG2 操作    │ 实现组件     │
# ├───────────────────────────────────────────────────────────┤
# │ PreInsert          │ Triple Extraction      │ extract.triple│
# │  - 三元组抽取        │ (S, P, O) 形式         │ LLM Prompt   │
# │  - 时间/地点/属性    │ 包含 temporal 等边     │ multi-type   │
# ├───────────────────────────────────────────────────────────┤
# │ MemoryInsert       │ Insert (KG)            │ GraphMemory  │
# │  - 节点创建          │ 实体 → node            │ igraph       │
# │  - 边创建            │ relation → edge        │ triple_store │
# ├───────────────────────────────────────────────────────────┤
# │ PostInsert         │ Synonym Edge           │ link_evolution│
# │  - 同义实体链接      │ 相似节点连接            │ knn_k=10     │
# │  - 边权重            │ similarity_threshold   │ threshold=0.7│
# ├───────────────────────────────────────────────────────────┤
# │ PreRetrieval       │ Query Embedding        │ embedding    │
# │  - 查询向量化        │ 用于向量检索种子节点    │ BGE-M3       │
# ├───────────────────────────────────────────────────────────┤
# │ MemoryRetrieval    │ KG Retrieval           │ GraphMemory  │
# │  - 向量检索起始节点  │ top_k=30 (基础版 20)   │ retrieval    │
# │  - **深度图遍历**    │ max_depth=4 (基础版 3) │ igraph BFS   │
# │  - **更多种子**      │ num_start=15 (基础10)  │ subgraph     │
# ├───────────────────────────────────────────────────────────┤
# │ PostRetrieval      │ **Enhanced PPR Rerank**│ rerank       │
# │  - **更深的 PPR**    │ ppr_depth=3 (基础版 2) │ power_iter   │
# │  - **混合打分**      │ 0.6*PPR + 0.4*Semantic │ weighted     │
# │  - **更多迭代**      │ max_iter=150 (基础100) │ convergence  │
# │  - **更严格阈值**    │ threshold=1e-7         │ precision    │
# └───────────────────────────────────────────────────────────┘
#
# 关键配置参数：
#   ppr_depth: 3                    # 更深的 PPR（基础版为 2）
#   ppr_damping: 0.9                # 更高的 damping（基础版为 0.85）
#   enhanced_rerank: true           # 启用增强重排序（基础版无）
#   num_start_nodes: 15             # 更多种子节点（基础版为 10）
#   max_depth: 4                    # 更深的遍历（基础版为 3）
#   rerank_weight_ppr: 0.6          # PPR 分数权重
#   rerank_weight_semantic: 0.4     # 语义相似度权重
#   max_iterations: 150             # 更多迭代（基础版为 100）
#   convergence_threshold: 1e-7     # 更严格的收敛（基础版为 1e-6）
#
# 与 HippoRAG 基础版的差异：
#   1. **PPR 深度提升**：从 2 跳增加到 3 跳，捕获更长距离依赖
#   2. **起始节点增加**：从 10 个增加到 15 个，提高覆盖率
#   3. **遍历深度增加**：从 3 跳增加到 4 跳，探索更大子图
#   4. **增强重排序**：结合 PPR 和语义相似度，不仅依赖 PPR
#   5. **更严格收敛**：阈值从 1e-6 提升到 1e-7，提高精度
#   6. **返回结果更多**：top_k 从 10 增加到 15
#   → 代价：计算开销增加，延迟提升约 30-50%
#   → 收益：检索质量提升，适合需要高召回率的场景
#
# 适用场景：
#   - 需要高召回率的复杂问答（多跳推理）
#   - 对延迟不敏感的离线分析任务
#   - 知识图谱足够大时（>1000 节点）
#
# 运行示例：
#   python packages/sage-benchmark/.../memory_test_pipeline.py \
#     --config .../locomo_hipporag2_pipeline.yaml --task_id conv-26
