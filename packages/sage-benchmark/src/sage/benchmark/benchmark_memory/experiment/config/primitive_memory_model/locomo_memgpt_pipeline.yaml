# ============================================================
# MemGPT Agent Pipeline 配置 (Agent 版)
# 论文: MemGPT: Towards LLMs as Operating Systems
# 变体: MemGPT-agent - 带工具调用的 Agent 版本
# 特点: 相比基础版 MemGPT，启用工具调用模式，LLM 可以主动调用记忆操作
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10
  service_timeout: 180.0              # Agent 版需要更长超时（多轮工具调用）

  prompt_template: |
    Based on the above context, answer the following question concisely.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Based on the above context, answer the following question.

    Question: {question}
    Answer:

  # LLM 配置
  # 旧配置（已弃用）：
  # api_key: "token-abc123"
  # base_url: "http://sage2:8000/v1"
  # model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  # max_tokens: 512
  # temperature: 0.3
  # seed: 42

  # 新配置（PanGu Embedded 1B）：
  api_key: "iloveshuhao"
  base_url: "http://172.17.0.1:1040/v1"
  model_name: "pangu_embedded_1b"
  max_tokens: 256
  temperature: 0
  seed: 42
  memory_name: "MemGPT-Agent"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置
# MemGPT-Agent 使用工具调用模式
# ============================================================
services:
  register_memory_service: "hierarchical_memory"
  hierarchical_memory:
    tier_mode: "functional"           # 功能分层: core / archival / recall
    tier_names: ["core", "archival", "recall"]
    tier_capacities:
      core: 20                        # Working context 较小
      archival: -1                    # 无限
      recall: 100                     # FIFO 队列
    migration_policy: "overflow"      # 溢出时迁移
    embedding_dim: 1024               # bge-m3 输出 1024 维向量
    # 关键区别：启用工具调用模式
    tool_use: true                    # Agent 版启用工具调用
  memory_retrieval_adapter: "none"

# ============================================================
# 工具配置（Agent 版特有）
# MemGPT 论文定义的标准工具集
# ============================================================
tools:
  enabled: true                       # 启用工具调用
  tool_list:
  - name: "core_memory_append"
    description: "Append content to the core memory (working context)"
    parameters:
      content: "string"
      name: "string (optional)"
  - name: "core_memory_replace"
    description: "Replace content in core memory"
    parameters:
      old_content: "string"
      new_content: "string"
  - name: "archival_memory_insert"
    description: "Insert content into archival memory for long-term storage"
    parameters:
      content: "string"
      metadata: "object (optional)"
  - name: "archival_memory_search"
    description: "Search archival memory for relevant content"
    parameters:
      query: "string"
      top_k: "integer (default: 5)"
  - name: "recall_memory_search"
    description: "Search recent conversation history (recall memory)"
    parameters:
      query: "string"
      top_k: "integer (default: 5)"
  tool_choice: "auto"                 # LLM 自动决定是否调用工具

# ============================================================
# Operator 配置
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 实体/事实抽取（与基础版相同）
  # ----------------------------------------------------------
  pre_insert:
    action: "extract"
    extract_type: "entity"
    spacy_model: "en_core_web_sm"
    entity_types: ["PERSON", "ORG", "LOC", "EVENT", "DATE"]
    add_to_metadata: true

  # ----------------------------------------------------------
  # PostInsert: Replace 操作（与基础版相同）
  # Agent 版的 replace 可以通过工具调用触发
  # ----------------------------------------------------------
  post_insert:
    action: "distillation"
    distillation_topk: 5
    distillation_threshold:
    distillation_prompt: |
      You are updating a knowledge base. Given a new fact and existing facts,
      determine if any existing fact should be REPLACED by the new one.

      New fact: {new_entry}

      Existing facts:
      {memory_list}

      If the new fact updates/corrects an existing fact, respond:
      {"to_delete": ["exact old fact text"], "to_insert": []}

      If the new fact is entirely new information, respond:
      {"to_delete": [], "to_insert": []}

      Respond with JSON only:

  # ----------------------------------------------------------
  # PreRetrieval: 关键词提取 + embedding（与基础版相同）
  # ----------------------------------------------------------
  pre_retrieval:
    action: "optimize"
    optimize_type: "keyword_extract"
    extractor: "spacy"
    spacy_model: "en_core_web_sm"
    extract_types: ["NOUN", "PROPN"]
    max_keywords: 10

  # ----------------------------------------------------------
  # PostRetrieval: 多层查询合并 + 工具决策
  # Agent 版可以通过工具调用进行额外的检索
  # ----------------------------------------------------------
  post_retrieval:
    action: "merge"
    merge_type: "multi_query"
    # Agent 版特有：启用迭代式工具调用
    enable_tool_iteration: true       # 允许 LLM 迭代调用工具
    max_tool_iterations: 3            # 最多 3 次工具调用迭代
    secondary_queries:
    - query_template: "{question}"
      metadata: {tier: "core"}
    - query_template: "{question}"
      metadata: {tier: "recall"}
    conversation_format_prompt: |
      The following is the relevant context from memory.
      You can use tools to search for more information if needed.
