# ============================================================
# MemGPT Agent Pipeline 配置 (Agent 版)
# 论文: MemGPT: Towards LLMs as Operating Systems
# 变体: MemGPT-agent - 带工具调用的 Agent 版本
# 特点: 相比基础版 MemGPT，启用工具调用模式，LLM 可以主动调用记忆操作
# ============================================================

runtime:
  dataset: "locomo"
  memory_insert_verbose: false
  memory_test_verbose: true
  test_segments: 10
  service_timeout: 180.0              # Agent 版需要更长超时（多轮工具调用）

  # ============================================================
  # MemGPT Memory Management 配置
  # 论文原文: Section 2.2 - Memory hierarchy
  # ============================================================
  context_window_size: 8192           # LLM 的 context window (tokens)
  memory_pressure_threshold: 0.7      # 70% 时触发 Memory Pressure Warning
  queue_flush_threshold: 1.0          # 100% 时强制 flush FIFO queue

  prompt_template: |
    Based on the above context, answer the following question concisely.

    Question: {question}
    Answer:

  # 第五类问题专用 Prompt（选择题格式，更简洁）
  prompt_template_category5: |
    Based on the above context, answer the following question.

    Question: {question}
    Answer:

  # LLM 配置
  # 配置1（Llama-3.1-8B，用于对比）：
  api_key: "token-abc123"
  base_url: "http://sage2:8000/v1"
  model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  max_tokens: 256
  temperature: 0
  seed: 42

  # 新配置（PanGu Embedded 1B）：
  # api_key: "iloveshuhao"
  # base_url: "http://172.17.0.1:1040/v1"
  # model_name: "pangu_embedded_1b"
  # max_tokens: 256
  # temperature: 0
  # seed: 42
  memory_name: "MemGPT-Agent"

  # Embedding 配置
  embedding_base_url: "http://localhost:8091/v1"
  embedding_model: "BAAI/bge-m3"

# ============================================================
# 服务配置
# MemGPT 论文原文: Figure 3 - Memory Hierarchy
#
# 架构说明:
# - Working Context (Core Memory): 始终在 LLM context 中，通过函数读写
# - Archival Storage: 外部存储，向量检索，手动插入
# - Recall Storage: 外部存储，混合检索(向量+全文+RRF)，自动追加
# - FIFO Queue: 最近对话消息，满时自动flush到Recall
# ============================================================
services:
  register_memory_service: "hierarchical_memory"
  hierarchical_memory:
    tier_mode: "functional"           # 功能分层: core / archival / recall
    tier_names: ["core", "archival", "recall"]
    tier_capacities:
      core: 2000                      # ✅ 2000字符（Working Context 限制）
      archival: -1                    # ✅ 无限容量（Archival Storage）
      recall: -1                      # ✅ 无限容量（Recall Storage）
    migration_policy: "none"          # ✅ 禁用自动迁移（由Agent手动管理）
    embedding_dim: 1024               # bge-m3 输出 1024 维向量

    # MemGPT 核心特性（论文 Section 2.2）
    use_core_embedding: false         # ✅ Core不使用向量检索（始终在context）
    use_recall_hybrid: true           # ✅ Recall使用混合检索（向量+FTS+RRF）
    rrf_k: 60                         # ✅ RRF常数（论文实现）
    vector_weight: 0.5                # 向量检索权重
    fts_weight: 0.5                   # 全文检索权重
  memory_retrieval_adapter: "none"

# ============================================================
# 工具配置（Agent 版特有）
# 论文原文: Section 2.1 - LLM processor
#
# MemGPT 的核心工具（BASE_TOOLS + BASE_MEMORY_TOOLS）:
# - send_message: 发送消息给用户
# - conversation_search: 搜索对话历史(Recall Storage)
# - archival_memory_insert/search: 档案记忆操作
# - core_memory_append/replace: Core Memory编辑
# ============================================================
tools:
  enabled: true                       # 启用工具调用
  tool_list:
  # ==================== Core Memory Tools ====================
  - name: "core_memory_append"
    description: "Append content to the core memory (working context). Core memory is always visible to you."
    parameters:
      label: "string"                 # Block label (e.g., 'persona', 'human')
      content: "string"               # Content to append

  - name: "core_memory_replace"
    description: "Replace specific content in core memory with new content"
    parameters:
      label: "string"                 # Block label
      old_content: "string"           # Exact text to replace
      new_content: "string"           # New text

  # ==================== Archival Memory Tools ====================
  - name: "archival_memory_insert"
    description: "Insert content into archival memory for long-term storage. Use this to save important information that doesn't fit in core memory."
    parameters:
      content: "string"               # Content to insert
      tags: "list[string] (optional)" # Tags for categorization

  - name: "archival_memory_search"
    description: "Search archival memory using semantic similarity"
    parameters:
      query: "string"                 # Search query
      tags: "list[string] (optional)" # Filter by tags
      top_k: "integer (default: 5)"   # Number of results
      start_datetime: "string (optional)"  # Filter by date range
      end_datetime: "string (optional)"

  # ==================== Recall Memory Tools ====================
  - name: "conversation_search"
    description: "Search recent conversation history using hybrid retrieval (semantic + keyword matching)"
    parameters:
      query: "string"                 # Search query
      roles: "list[string] (optional)"  # Filter by role: 'user', 'assistant', 'tool'
      limit: "integer (default: 50)"  # Max results
      start_date: "string (optional)" # Filter by date range
      end_date: "string (optional)"

  # ==================== Communication Tool ====================
  - name: "send_message"
    description: "Send a message to the user. This is the ONLY way to communicate with the user."
    parameters:
      message: "string"               # Message content

  tool_choice: "auto"                 # LLM 自动决定是否调用工具

# ============================================================
# Operator 配置
# 论文原文: Figure 3 - MemGPT System Architecture
#
# MemGPT 的设计特点:
# - PreInsert/PostInsert: 无复杂预处理，Agent通过工具主动管理
# - PreRetrieval: 生成embedding用于向量检索
# - PostRetrieval: 三层融合(Core始终在context + Archival/Recall RRF融合)
# ============================================================
operators:
  # ----------------------------------------------------------
  # PreInsert: 无预处理（论文无提及）
  # 原因: Agent通过工具主动决定插入内容，无需自动实体抽取
  # ----------------------------------------------------------
  pre_insert:
    action: "none"                    # ✅ 忠于原文

  # ----------------------------------------------------------
  # PostInsert: 无自动优化（论文Section 2.1）
  # 原因: Core Memory编辑由Agent通过工具主动调用
  #       (core_memory_replace, memory_apply_patch等)
  # ----------------------------------------------------------
  post_insert:
    action: "none"                    # ✅ 忠于原文（replace是工具，非operator）

  # ----------------------------------------------------------
  # PreRetrieval: 生成embedding（论文Section 2.2）
  # 用途: 为Archival和Recall的向量检索提供query向量
  # ----------------------------------------------------------
  pre_retrieval:
    action: "embedding"               # ✅ 忠于原文

  # ----------------------------------------------------------
  # PostRetrieval: 多层融合（论文Figure 3 + Section 3）
  # 核心逻辑:
  # 1. Core Memory: 始终在context，完整返回
  # 2. Archival + Recall: RRF融合后返回Top-K
  # 3. 组装成最终prompt
  # ----------------------------------------------------------
  post_retrieval:
    action: "merge"
    merge_type: "multi_tier"          # ✅ 自实现的三层融合算子
    tiers_to_search: ["core", "archival", "recall"]
    fusion_strategy: "rrf"            # ✅ Reciprocal Rank Fusion
    rrf_k: 60                         # ✅ 论文实现的常数
    vector_weight: 0.5                # Archival权重
    fts_weight: 0.5                   # Recall权重
    top_k: 10                         # 返回Top-K融合结果

    # Memory Pressure Warning（论文Section 2.2核心创新）
    # 当context使用率超过阈值时，插入系统警告
    enable_memory_pressure_warning: true

    conversation_format_prompt: |
      The following is the relevant context from memory.
      You can use tools to search for more information if needed.
