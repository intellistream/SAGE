# Runtime parameters configuration
runtime:
  dataset: "conflict_resolution"  # Dataset name
  # task_id: "task_all"  # Task ID, can be overridden by --task_id command line argument
  memory_insert_verbose: false  # Whether to print memory insert details (Memory Source part)
  memory_test_verbose: true    # Whether to print memory test details (QA part)
  test_segments: 10             # Number of test segments, divide total questions into segments for testing

  # Prompt template configuration (Phase 2: MemoryTest)
  prompt_template: |
    Based on the above context, answer the following question concisely using exact words from the context whenever possible. If the information is not mentioned in the conversation, respond with "Not mentioned in the conversation".

    Question: {question}
    Answer:

  # LLM Generator configuration
  api_key: "token-abc123"
  base_url: "http://sage2:8000/v1"
  model_name: "/home/cyb/Llama-3.1-8B-Instruct"
  max_tokens: 80
  temperature: 0.3
  seed: 42
  memory_name: "stm"

# Service configuration
services:
  register_memory_service: "short_term_memory"  # Registered memory service name, can switch to other services
  short_term_memory:
    max_dialog: 5530  # Short-term memory window size (set to total facts so tests can access all facts)
  memory_insert_adapter: "to_dialogs"
  memory_retrieval_adapter: "none"



# Operator configuration
operators:
  pre_insert:
    action: "none"  # Pre-insert action: none, validate, transform
  pre_retrieval:
    action: "none"  # Pre-retrieval action: none, optimize, validate
  post_insert:
    action: "none"  # Post-insert action
  post_retrieval:
    action: "none"  # Post-retrieval action: none (default will format conversation history)
    # Phase 1: Conversation history formatting Prompt (PostRetrieval)
    conversation_format_prompt: |
      The following is some history information.
