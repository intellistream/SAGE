"""OpenAI embedding wrapper.

æ”¯æŒ OpenAI å®˜æ–¹ APIã€å…¼å®¹ API ä»¥åŠæœ¬åœ° sagellm æ¨ç†å¼•æ“ï¼ˆå ä½å®ç°ï¼‰ã€‚
"""

import logging
import os
from typing import TYPE_CHECKING, Any

from ..base import BaseEmbedding

if TYPE_CHECKING:
    pass  # Reserved for future type hints

# æŠ‘åˆ¶ httpx çš„ INFO æ—¥å¿—ï¼ˆæ¯æ¬¡ HTTP è¯·æ±‚éƒ½ä¼šæ‰“å°ï¼‰
logging.getLogger("httpx").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)


class OpenAIEmbedding(BaseEmbedding):
    """OpenAI Embedding API Wrapper

    æ”¯æŒ OpenAI å®˜æ–¹ APIã€å…¼å®¹çš„ç¬¬ä¸‰æ–¹ APIï¼ˆå¦‚ vLLMã€DeepSeek ç­‰ï¼‰
    ä»¥åŠæœ¬åœ° sagellm æ¨ç†å¼•æ“ã€‚

    ç‰¹ç‚¹:
        - âœ… é«˜è´¨é‡ embedding
        - âœ… æ”¯æŒå¤šç§æ¨¡å‹
        - âœ… å…¼å®¹ç¬¬ä¸‰æ–¹ API
        - âœ… æ”¯æŒæœ¬åœ° sagellm å¼•æ“ï¼ˆæ— éœ€ç½‘ç»œï¼‰
        - âŒ éœ€è¦ API Keyï¼ˆä»… openai providerï¼‰
        - âŒ éœ€è¦ç½‘ç»œè¿æ¥ï¼ˆä»… openai providerï¼‰
        - ğŸ’° æŒ‰ä½¿ç”¨é‡è®¡è´¹ï¼ˆä»… openai providerï¼‰

    æ”¯æŒçš„æ¨¡å‹:
        - text-embedding-3-small (1536ç»´ï¼Œæ€§ä»·æ¯”é«˜)
        - text-embedding-3-large (3072ç»´ï¼Œæœ€é«˜è´¨é‡)
        - text-embedding-ada-002 (1536ç»´ï¼Œæ—§ç‰ˆæœ¬)
        - ä»»æ„ HuggingFace æ¨¡å‹ï¼ˆé€šè¿‡ sagellm providerï¼‰

    Args:
        model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ 'text-embedding-3-small'ï¼‰
        api_key: API å¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡ OPENAI_API_KEY è¯»å–ï¼‰
        base_url: API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼Œç”¨äºå…¼å®¹ APIï¼‰
        provider: åç«¯æä¾›è€…ï¼Œ'openai'ï¼ˆé»˜è®¤ï¼‰æˆ– 'sagellm'ï¼ˆæœ¬åœ°æ¨ç†ï¼‰
        sagellm_config: sagellm æ¨ç†é…ç½®ï¼ˆä»… provider='sagellm' æ—¶æœ‰æ•ˆï¼‰

    Examples:
        >>> # OpenAI å®˜æ–¹ API
        >>> import os
        >>> emb = OpenAIEmbedding(
        ...     model="text-embedding-3-small",
        ...     api_key=os.getenv("OPENAI_API_KEY")
        ... )
        >>> vec = emb.embed("hello world")
        >>>
        >>> # å…¼å®¹ APIï¼ˆè‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
        >>> emb = OpenAIEmbedding(
        ...     model="text-embedding-v1",
        ...     api_key=os.getenv("OPENAI_API_KEY"),
        ...     base_url=os.getenv("OPENAI_BASE_URL", "http://localhost:8090/v1")
        ... )
        >>> vec = emb.embed("ä½ å¥½ä¸–ç•Œ")
        >>>
        >>> # vLLM éƒ¨ç½²çš„æ¨¡å‹
        >>> emb = OpenAIEmbedding(
        ...     model="BAAI/bge-base-en-v1.5",
        ...     base_url="http://localhost:8000/v1"
        ... )
        >>>
        >>> # æœ¬åœ° sagellm æ¨ç†ï¼ˆå½“å‰ä½¿ç”¨ sentence-transformers ä½œä¸ºå ä½å®ç°ï¼Œæ— éœ€ API Key å’Œç½‘ç»œï¼‰
        >>> emb = OpenAIEmbedding(
        ...     model="BAAI/bge-small-zh-v1.5",
        ...     provider="sagellm",
        ...     sagellm_config={"device": "cuda"}
        ... )
        >>> vec = emb.embed("ä½ å¥½ä¸–ç•Œ")
    """

    # å¸¸è§æ¨¡å‹çš„ç»´åº¦æ˜ å°„
    DIMENSION_MAP = {
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072,
        "text-embedding-ada-002": 1536,
        "text-embedding-v1": 1536,
        # Common HuggingFace models for sagellm
        "BAAI/bge-small-zh-v1.5": 512,
        "BAAI/bge-base-zh-v1.5": 768,
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-small-en-v1.5": 384,
        "BAAI/bge-base-en-v1.5": 768,
        "BAAI/bge-large-en-v1.5": 1024,
        "BAAI/bge-m3": 1024,
        "sentence-transformers/all-MiniLM-L6-v2": 384,
        "sentence-transformers/all-mpnet-base-v2": 768,
    }

    # æ”¯æŒçš„ provider
    SUPPORTED_PROVIDERS = ("openai", "sagellm")

    def __init__(
        self,
        model: str = "text-embedding-3-small",
        api_key: str | None = None,
        base_url: str | None = None,
        provider: str = "openai",
        sagellm_config: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> None:
        """åˆå§‹åŒ– OpenAI Embedding

        Args:
            model: æ¨¡å‹åç§°
            api_key: API å¯†é’¥ï¼ˆå¯é€‰ï¼Œä»… openai providerï¼‰
            base_url: API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼Œä»… openai providerï¼‰
            provider: åç«¯æä¾›è€…ï¼Œ'openai' æˆ– 'sagellm'
            sagellm_config: sagellm æ¨ç†é…ç½®ï¼ˆä»… provider='sagellm' æ—¶æœ‰æ•ˆï¼‰
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆä¿ç•™ç”¨äºæ‰©å±•ï¼‰

        Raises:
            RuntimeError: å¦‚æœ openai provider æœªæä¾› API Key
            ValueError: å¦‚æœ provider ä¸æ”¯æŒ
        """
        super().__init__(model=model, api_key=api_key, base_url=base_url, **kwargs)

        self._model = model
        self._provider = provider.lower()
        self._sagellm_config = sagellm_config or {}
        self._sagellm_engine: Any = None  # Lazy-loaded sagellm engine

        # éªŒè¯ provider
        if self._provider not in self.SUPPORTED_PROVIDERS:
            raise ValueError(
                f"ä¸æ”¯æŒçš„ provider: {self._provider}\n"
                f"æ”¯æŒçš„ provider: {', '.join(self.SUPPORTED_PROVIDERS)}"
            )

        if self._provider == "openai":
            # OpenAI API æ¨¡å¼
            self._api_key = api_key or os.getenv("OPENAI_API_KEY")
            self._base_url = base_url

            # æ£€æŸ¥ API Key
            if not self._api_key:
                raise RuntimeError(
                    "OpenAI embedding éœ€è¦ API Keyã€‚\n"
                    "è§£å†³æ–¹æ¡ˆ:\n"
                    "  1. è®¾ç½®ç¯å¢ƒå˜é‡: export OPENAI_API_KEY='your-key'\n"  # pragma: allowlist secret
                    "  2. ä¼ é€’å‚æ•°: OpenAIEmbedding(api_key='your-key', ...)\n"  # pragma: allowlist secret
                    "\n"
                    "å¦‚æœä½¿ç”¨å…¼å®¹ API:\n"
                    "  export OPENAI_API_KEY='your-api-key'\n"  # pragma: allowlist secret
                    "  å¹¶æŒ‡å®š base_url å‚æ•°\n"
                    "\n"
                    "æˆ–è€…ä½¿ç”¨æœ¬åœ°æ¨ç†:\n"
                    "  OpenAIEmbedding(model='BAAI/bge-small-zh-v1.5', provider='local')"
                )
        else:
            # æœ¬åœ°æ¨ç†æ¨¡å¼ï¼ˆå½“å‰å ä½å®ç°ï¼šsentence-transformersï¼‰
            self._api_key = None
            self._base_url = None
            logger.info(
                f"ä½¿ç”¨ sagellm æœ¬åœ°æ¨ç†å ä½å®ç°: model={model}, config={self._sagellm_config}"
            )

        # æ¨æ–­æˆ–è·å–ç»´åº¦
        self._dim = self._infer_dimension()

    def embed(self, text: str) -> list[float]:
        """å°†æ–‡æœ¬è½¬æ¢ä¸º embedding å‘é‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            embedding å‘é‡

        Raises:
            RuntimeError: å¦‚æœ API è°ƒç”¨æˆ–æœ¬åœ°æ¨ç†å¤±è´¥
        """
        if self._provider == "sagellm":
            return self._embed_with_sagellm(text)
        return self._embed_with_openai(text)

    def _embed_with_openai(self, text: str) -> list[float]:
        """ä½¿ç”¨ OpenAI API ç”Ÿæˆ embedding

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            embedding å‘é‡
        """
        try:
            from openai import OpenAI

            client = OpenAI(api_key=self._api_key, base_url=self._base_url)
            response = client.embeddings.create(
                model=self._model,
                input=text,
            )
            return response.data[0].embedding
        except Exception as e:
            raise RuntimeError(
                f"OpenAI embedding å¤±è´¥: {e}\n"
                f"æ¨¡å‹: {self._model}\n"
                f"æ–‡æœ¬: {text[:100]}...\n"
                f"æç¤º: æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆï¼Œç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸"
            ) from e

    def _embed_with_sagellm(self, text: str) -> list[float]:
        """ä½¿ç”¨ sagellmï¼ˆå ä½ï¼šsentence-transformersï¼‰ç”Ÿæˆ embedding

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            embedding å‘é‡
        """
        engine = self._get_sagellm_engine()
        try:
            # sentence-transformers è¿”å› numpy array
            result = engine.encode(text)
            # ç¡®ä¿è¿”å› list[float]
            if hasattr(result, "tolist"):
                return result.tolist()
            return list(result)
        except Exception as e:
            raise RuntimeError(
                f"sagellm embedding å¤±è´¥: {e}\n"
                f"æ¨¡å‹: {self._model}\n"
                f"æ–‡æœ¬: {text[:100]}...\n"
                f"æç¤º: æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½ï¼Œè®¾å¤‡æ˜¯å¦å¯ç”¨"
            ) from e

    def _get_sagellm_engine(self) -> Any:
        """è·å–æˆ–åˆ›å»º sagellm embedding å¼•æ“ï¼ˆæ‡’åŠ è½½ï¼‰

        æ³¨æ„ï¼šå½“å‰ sagellm ä»“åº“å°šæœªæä¾› embedding å¼•æ“ï¼Œè¿™é‡Œä»¥
        sentence-transformers ä½œä¸ºå ä½å®ç°ã€‚å®Œæˆ sagellm çš„ EmbeddingEngine
        å®ç°åï¼Œå¯ç›´æ¥æ›¿æ¢ä¸ºæ­£å¼å¼•æ“ã€‚

        Returns:
            å ä½çš„ sentence-transformers æ¨¡å‹å®ä¾‹

        Raises:
            RuntimeError: å¦‚æœæ— æ³•åŠ è½½ sentence-transformers
        """
        if self._sagellm_engine is not None:
            return self._sagellm_engine

        try:
            # ä½¿ç”¨ sentence-transformers ä½œä¸ºå ä½ï¼ˆå¾… sagellm åŸç”Ÿ EmbeddingEngine å®Œæˆåæ›¿æ¢ï¼‰
            from sentence_transformers import SentenceTransformer

            device = self._sagellm_config.get("device", "cpu")
            logger.info(
                f"ä½¿ç”¨ sentence-transformers å ä½æ¨ç†: model={self._model}, device={device}"
            )
            self._sagellm_engine = SentenceTransformer(
                self._model,
                device=device,
            )
            return self._sagellm_engine

        except ImportError as e:
            raise RuntimeError(
                "æœ¬åœ° embedding éœ€è¦ sentence-transformersã€‚\n"
                "è¯·å®‰è£…: pip install sentence-transformers"
            ) from e
        except Exception as e:
            raise RuntimeError(
                f"æ— æ³•åˆå§‹åŒ– sagellm embedding å ä½å¼•æ“: {e}\n"
                f"æ¨¡å‹: {self._model}\n"
                f"é…ç½®: {self._sagellm_config}"
            ) from e

    def embed_batch(self, texts: list[str]) -> list[list[float]]:
        """æ‰¹é‡å°†æ–‡æœ¬è½¬æ¢ä¸º embedding å‘é‡

        ä½¿ç”¨ OpenAI API çš„æ‰¹é‡æ¥å£æˆ– sagellm çš„æ‰¹é‡ç¼–ç ã€‚

        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨

        Returns:
            embedding å‘é‡åˆ—è¡¨

        Raises:
            RuntimeError: å¦‚æœ API è°ƒç”¨æˆ–æœ¬åœ°æ¨ç†å¤±è´¥
        """
        if not texts:
            return []

        if self._provider == "sagellm":
            return self._embed_batch_with_sagellm(texts)
        return self._embed_batch_with_openai(texts)

    def _embed_batch_with_openai(self, texts: list[str]) -> list[list[float]]:
        """ä½¿ç”¨ OpenAI API æ‰¹é‡ç”Ÿæˆ embedding

        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨

        Returns:
            embedding å‘é‡åˆ—è¡¨
        """
        try:
            from openai import OpenAI

            # è®¾ç½®ç¯å¢ƒå˜é‡
            if self._api_key:
                import os

                os.environ["OPENAI_API_KEY"] = self._api_key

            client = OpenAI(base_url=self._base_url)

            # OpenAI API æ”¯æŒæ‰¹é‡ï¼šinput å¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
            response = client.embeddings.create(
                model=self._model,
                input=texts,  # ç›´æ¥ä¼ å…¥åˆ—è¡¨
            )

            # æŒ‰ç…§åŸå§‹é¡ºåºè¿”å›ç»“æœ
            return [item.embedding for item in response.data]

        except Exception as e:
            raise RuntimeError(
                f"OpenAI æ‰¹é‡ embedding å¤±è´¥: {e}\n"
                f"æ¨¡å‹: {self._model}\n"
                f"æ‰¹é‡å¤§å°: {len(texts)}\n"
                f"æç¤º: æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆï¼Œç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸"
            ) from e

    def _embed_batch_with_sagellm(self, texts: list[str]) -> list[list[float]]:
        """ä½¿ç”¨ sagellmï¼ˆå ä½ï¼šsentence-transformersï¼‰æ‰¹é‡ç”Ÿæˆ embedding

        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨

        Returns:
            embedding å‘é‡åˆ—è¡¨
        """
        engine = self._get_sagellm_engine()
        try:
            # sentence-transformers æ”¯æŒæ‰¹é‡ç¼–ç 
            results = engine.encode(texts)
            # ç¡®ä¿è¿”å› list[list[float]]
            if hasattr(results, "tolist"):
                return results.tolist()
            return [list(r) if hasattr(r, "__iter__") else [r] for r in results]
        except Exception as e:
            raise RuntimeError(
                f"sagellm æ‰¹é‡ embedding å¤±è´¥: {e}\n"
                f"æ¨¡å‹: {self._model}\n"
                f"æ‰¹é‡å¤§å°: {len(texts)}\n"
                f"æç¤º: æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½ï¼Œè®¾å¤‡æ˜¯å¦å¯ç”¨"
            ) from e

    def get_dim(self) -> int:
        """è·å–å‘é‡ç»´åº¦

        Returns:
            ç»´åº¦å€¼
        """
        return self._dim

    @property
    def method_name(self) -> str:
        """è¿”å›æ–¹æ³•åç§°

        Returns:
            'openai' æˆ– 'sagellm'ï¼ˆå–å†³äº providerï¼‰
        """
        return self._provider

    @property
    def provider(self) -> str:
        """è¿”å›åç«¯æä¾›è€…

        Returns:
            'openai' æˆ– 'sagellm'
        """
        return self._provider

    def _infer_dimension(self) -> int:
        """æ¨æ–­æˆ–è·å–ç»´åº¦

        Returns:
            æ¨æ–­çš„ç»´åº¦å€¼
        """
        # ä¼˜å…ˆä½¿ç”¨å·²çŸ¥çš„ç»´åº¦æ˜ å°„
        if self._model in self.DIMENSION_MAP:
            return self.DIMENSION_MAP[self._model]

        # å¦‚æœæ˜¯æœªçŸ¥æ¨¡å‹ï¼Œå°è¯•é€šè¿‡å®é™…è°ƒç”¨æ¨æ–­
        try:
            sample = self.embed("test")
            return len(sample)
        except Exception:
            # å¦‚æœæ¨æ–­å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»´åº¦
            return 1536

    @classmethod
    def get_model_info(cls) -> dict[str, Any]:
        """è¿”å›æ¨¡å‹å…ƒä¿¡æ¯

        Returns:
            æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        return {
            "method": "openai",
            "requires_api_key": True,  # Only for openai provider
            "requires_model_download": True,  # sagellm éœ€è¦æœ¬åœ°æ¨¡å‹
            "default_dimension": 1536,
            "supported_providers": list(cls.SUPPORTED_PROVIDERS),
        }

    def __repr__(self) -> str:
        """è¿”å›å¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤º

        Returns:
            å­—ç¬¦ä¸²è¡¨ç¤º
        """
        base_info = f"OpenAIEmbedding(model='{self._model}', dim={self._dim}, provider='{self._provider}'"
        if self._provider == "openai" and self._base_url:
            base_info += f", base_url='{self._base_url}'"
        elif self._provider == "sagellm" and self._sagellm_config:
            config_str = ", ".join(f"{k}={v!r}" for k, v in self._sagellm_config.items())
            base_info += f", config={{{config_str}}}"
        return base_info + ")"

    def close(self) -> None:
        """é‡Šæ”¾èµ„æº

        æ¸…ç†æœ¬åœ°å¼•æ“å ç”¨çš„ GPU å†…å­˜ç­‰èµ„æºã€‚
        """
        if self._sagellm_engine is not None:
            # å°è¯•é‡Šæ”¾èµ„æº
            if hasattr(self._sagellm_engine, "close"):
                self._sagellm_engine.close()
            elif hasattr(self._sagellm_engine, "stop"):
                self._sagellm_engine.stop()
            self._sagellm_engine = None
            logger.debug("sagellm embedding å¼•æ“å ä½å·²é‡Šæ”¾")

    def __del__(self) -> None:
        """ææ„å‡½æ•°"""
        try:
            self.close()
        except Exception:
            pass  # å¿½ç•¥ææ„æ—¶çš„é”™è¯¯
