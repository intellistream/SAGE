import logging
import json
import tempfile
import threading
import time
from pathlib import Path
from typing import Any, Dict, List

from sage.core.api.function.filter_function import FilterFunction
from sage.core.api.function.flatmap_function import FlatMapFunction
from sage.core.api.function.join_function import BaseJoinFunction
from sage.core.api.function.keyby_function import KeyByFunction
from sage.core.api.function.sink_function import SinkFunction
from sage.core.api.function.source_function import SourceFunction
from sage.core.api.local_environment import LocalEnvironment

# =====================================================================
# Source Functions - ç”Ÿæˆæµ‹è¯•æ•°æ®
# =====================================================================


class OrderEventSource(SourceFunction):
    """ç”Ÿæˆè®¢å•äº‹ä»¶æ•°æ®"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.counter = 0
        self.order_events = [
            {
                "event_id": 1,
                "order_id": "order_001",
                "user_id": "user_1",
                "event": "created",
                "amount": 100.0,
                "timestamp": 1000,
            },
            {
                "event_id": 2,
                "order_id": "order_002",
                "user_id": "user_2",
                "event": "created",
                "amount": 250.0,
                "timestamp": 1100,
            },
            {
                "event_id": 3,
                "order_id": "order_001",
                "user_id": "user_1",
                "event": "paid",
                "amount": 100.0,
                "timestamp": 1200,
            },
            {
                "event_id": 4,
                "order_id": "order_003",
                "user_id": "user_1",
                "event": "created",
                "amount": 75.0,
                "timestamp": 1300,
            },
            {
                "event_id": 5,
                "order_id": "order_002",
                "user_id": "user_2",
                "event": "cancelled",
                "amount": 250.0,
                "timestamp": 1400,
            },
            {
                "event_id": 6,
                "order_id": "order_003",
                "user_id": "user_1",
                "event": "paid",
                "amount": 75.0,
                "timestamp": 1500,
            },
            {
                "event_id": 7,
                "order_id": "order_004",
                "user_id": "user_3",
                "event": "created",
                "amount": 300.0,
                "timestamp": 1600,
            },
            {
                "event_id": 8,
                "order_id": "order_004",
                "user_id": "user_3",
                "event": "paid",
                "amount": 300.0,
                "timestamp": 1700,
            },
        ]

    def execute(self):
        if self.counter >= len(self.order_events):
            return None

        data = self.order_events[self.counter]
        self.counter += 1
        self.logger.info(f"OrderEventSource generated: {data}")
        return data


class UserProfileSource(SourceFunction):
    """ç”Ÿæˆç”¨æˆ·æ¡£æ¡ˆæ•°æ®"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.counter = 0
        self.user_profiles = [
            {
                "profile_id": 1,
                "user_id": "user_1",
                "name": "Alice",
                "email": "alice@example.com",
                "tier": "gold",
                "region": "US",
            },
            {
                "profile_id": 2,
                "user_id": "user_2",
                "name": "Bob",
                "email": "bob@example.com",
                "tier": "silver",
                "region": "EU",
            },
            {
                "profile_id": 3,
                "user_id": "user_3",
                "name": "Charlie",
                "email": "charlie@example.com",
                "tier": "gold",
                "region": "US",
            },
            {
                "profile_id": 4,
                "user_id": "user_4",
                "name": "Diana",
                "email": "diana@example.com",
                "tier": "bronze",
                "region": "ASIA",
            },
        ]

    def execute(self):
        if self.counter >= len(self.user_profiles):
            return None

        data = self.user_profiles[self.counter]
        self.counter += 1
        self.logger.info(f"UserProfileSource generated: {data}")
        return data


# =====================================================================
# FlatMap Functions - åˆ†è§£æ•°æ®
# =====================================================================


class OrderEventFlatMap(FlatMapFunction):
    """å°†è®¢å•äº‹ä»¶åˆ†è§£ä¸ºè®¢å•ä¿¡æ¯å’Œäº‹ä»¶ä¿¡æ¯"""

    def execute(self, data: Any) -> List[Dict]:
        order_id = data.get("order_id")
        user_id = data.get("user_id")
        event_type = data.get("event")
        amount = data.get("amount")
        timestamp = data.get("timestamp")

        results = []

        # 1. æå–è®¢å•åŸºç¡€ä¿¡æ¯
        order_info = {
            "type": "order_info",
            "order_id": order_id,
            "user_id": user_id,
            "amount": amount,
            "timestamp": timestamp,
            "source": "order_event_flatmap",
        }
        results.append(order_info)

        # 2. æå–äº‹ä»¶ä¿¡æ¯
        event_info = {
            "type": "event_info",
            "order_id": order_id,
            "user_id": user_id,
            "event": event_type,
            "timestamp": timestamp,
            "source": "order_event_flatmap",
        }
        results.append(event_info)

        # 3. å¦‚æœæ˜¯æ”¯ä»˜äº‹ä»¶ï¼Œç”Ÿæˆé¢å¤–çš„æ”¯ä»˜è®°å½•
        if event_type == "paid":
            payment_info = {
                "type": "payment_info",
                "order_id": order_id,
                "user_id": user_id,
                "amount": amount,
                "payment_timestamp": timestamp,
                "source": "order_event_flatmap",
            }
            results.append(payment_info)

        self.logger.info(
            f"OrderEventFlatMap: flattened order {order_id} into {len(results)} items"
        )
        return results


class UserProfileFlatMap(FlatMapFunction):
    """å°†ç”¨æˆ·æ¡£æ¡ˆåˆ†è§£ä¸ºç”¨æˆ·ä¿¡æ¯å’Œåå¥½ä¿¡æ¯"""

    def execute(self, data: Any) -> List[Dict]:
        user_id = data.get("user_id")
        name = data.get("name")
        email = data.get("email")
        tier = data.get("tier")
        region = data.get("region")

        results = []

        # 1. æå–åŸºç¡€ç”¨æˆ·ä¿¡æ¯
        user_info = {
            "type": "user_info",
            "user_id": user_id,
            "name": name,
            "email": email,
            "source": "user_profile_flatmap",
        }
        results.append(user_info)

        # 2. æå–ç”¨æˆ·åå¥½ä¿¡æ¯
        preference_info = {
            "type": "preference_info",
            "user_id": user_id,
            "tier": tier,
            "region": region,
            "is_premium": tier in ["gold", "platinum"],
            "source": "user_profile_flatmap",
        }
        results.append(preference_info)

        # 3. å¦‚æœæ˜¯é‡‘ç‰Œç”¨æˆ·ï¼Œç”ŸæˆVIPä¿¡æ¯
        if tier == "gold":
            vip_info = {
                "type": "vip_info",
                "user_id": user_id,
                "vip_level": "gold",
                "benefits": ["free_shipping", "priority_support"],
                "source": "user_profile_flatmap",
            }
            results.append(vip_info)

        self.logger.info(
            f"UserProfileFlatMap: flattened user {user_id} into {len(results)} items"
        )
        return results


# =====================================================================
# Filter Functions - è¿‡æ»¤æ•°æ®
# =====================================================================


class OrderInfoFilter(FilterFunction):
    """è¿‡æ»¤è®¢å•ä¿¡æ¯ï¼Œåªä¿ç•™è®¢å•ç›¸å…³æ•°æ®"""

    def execute(self, data: Any) -> bool:
        data_type = data.get("type", "")
        is_order_related = data_type in ["order_info", "payment_info"]

        if is_order_related:
            self.logger.info(
                f"âœ… OrderInfoFilter: accepted {data_type} for order {data.get('order_id')}"
            )
        else:
            self.logger.info(f"âŒ OrderInfoFilter: rejected {data_type}")

        return is_order_related


class UserInfoFilter(FilterFunction):
    """è¿‡æ»¤ç”¨æˆ·ä¿¡æ¯ï¼Œåªä¿ç•™ç”¨æˆ·ç›¸å…³æ•°æ®"""

    def execute(self, data: Any) -> bool:
        data_type = data.get("type", "")
        is_user_related = data_type in ["user_info", "preference_info", "vip_info"]

        if is_user_related:
            self.logger.info(
                f"âœ… UserInfoFilter: accepted {data_type} for user {data.get('user_id')}"
            )
        else:
            self.logger.info(f"âŒ UserInfoFilter: rejected {data_type}")

        return is_user_related


class PremiumUserFilter(FilterFunction):
    """åªä¿ç•™é«˜çº§ç”¨æˆ·"""

    def execute(self, data: Any) -> bool:
        logging.info(f"ğŸ” PremiumUserFilter.execute called with data: {data}")
        self.logger.info(f"ğŸ” PremiumUserFilter.execute called with data: {data}")

        if data.get("type") == "preference_info":
            is_premium = data.get("is_premium", False)
            if is_premium:
                self.logger.info(
                    f"âœ… PremiumUserFilter: accepted premium user {data.get('user_id')}"
                )
                logging.info(
                    f"âœ… PremiumUserFilter: accepted premium user {data.get('user_id')}"
                )
                return True
            else:
                self.logger.info(
                    f"âŒ PremiumUserFilter: rejected non-premium user {data.get('user_id')}"
                )
                logging.info(
                    f"âŒ PremiumUserFilter: rejected non-premium user {data.get('user_id')}"
                )
                return False

        # å¯¹äºéåå¥½ä¿¡æ¯ï¼Œç›´æ¥é€šè¿‡
        self.logger.info(
            f"âœ… PremiumUserFilter: passed non-preference data {data.get('type')}"
        )
        logging.info(f"âœ… PremiumUserFilter: passed non-preference data {data.get('type')}")
        return data.get("type") != "preference_info"


# =====================================================================
# KeyBy Functions - æå–åˆ†åŒºé”®
# =====================================================================


class UserIdKeyBy(KeyByFunction):
    """æŒ‰ç”¨æˆ·IDåˆ†åŒº"""

    def execute(self, data: Any) -> str:
        user_id = data.get("user_id", "unknown")
        self.logger.debug(
            f"UserIdKeyBy: extracted key '{user_id}' from {data.get('type', 'unknown')}"
        )
        return user_id


class OrderIdKeyBy(KeyByFunction):
    """æŒ‰è®¢å•IDåˆ†åŒº"""

    def execute(self, data: Any) -> str:
        order_id = data.get("order_id", "unknown")
        self.logger.debug(
            f"OrderIdKeyBy: extracted key '{order_id}' from {data.get('type', 'unknown')}"
        )
        return order_id


# =====================================================================
# Join Functions - å…³è”é€»è¾‘
# =====================================================================


class UserOrderJoin(BaseJoinFunction):
    """ç”¨æˆ·å’Œè®¢å•çš„Inner Join"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.user_cache = {}  # {user_id: user_data}
        self.order_cache = {}  # {user_id: [order_data, ...]}
        self.join_count = 0

    def execute(self, payload: Any, key: Any, tag: int) -> List[Any]:
        results = []
        self.logger.debug(
            f"UserOrderJoin: processing key='{key}', tag={tag}, payload={payload}"
        )
        if tag == 0:  # ç”¨æˆ·æµ
            user_type = payload.get("type", "")
            if user_type == "user_info":
                # ç¼“å­˜ç”¨æˆ·åŸºç¡€ä¿¡æ¯
                self.user_cache[key] = payload

                # æ£€æŸ¥æ˜¯å¦æœ‰å¾…åŒ¹é…çš„è®¢å•
                if key in self.order_cache:
                    for order_data in self.order_cache[key]:
                        joined = self._create_user_order_join(payload, order_data, key)
                        results.append(joined)
                        self.join_count += 1
                    # æ¸…ç†å·²åŒ¹é…çš„è®¢å•
                    del self.order_cache[key]

        elif tag == 1:  # è®¢å•æµ
            order_type = payload.get("type", "")
            if order_type == "order_info":
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„ç”¨æˆ·
                if key in self.user_cache:
                    joined = self._create_user_order_join(
                        self.user_cache[key], payload, key
                    )
                    results.append(joined)
                    self.join_count += 1
                else:
                    # ç¼“å­˜è®¢å•ç­‰å¾…ç”¨æˆ·æ•°æ®
                    if key not in self.order_cache:
                        self.order_cache[key] = []
                    self.order_cache[key].append(payload)

        if results:
            self.logger.info(
                f"UserOrderJoin: generated {len(results)} joins for key '{key}', total joins: {self.join_count}"
            )

        return results

    def _create_user_order_join(
        self, user_data: Any, order_data: Any, user_id: str
    ) -> Dict:
        return {
            "join_type": "user_order",
            "user_id": user_id,
            "user_name": user_data.get("name"),
            "user_email": user_data.get("email"),
            "order_id": order_data.get("order_id"),
            "order_amount": order_data.get("amount"),
            "order_timestamp": order_data.get("timestamp"),
            "join_timestamp": time.time_ns() // 1_000_000,
            "source": "user_order_join",
        }


class UserPaymentJoin(BaseJoinFunction):
    """ç”¨æˆ·å’Œæ”¯ä»˜çš„Left Join"""

    def __init__(self, timeout_ms: int = 5000, **kwargs):
        super().__init__(**kwargs)
        self.user_cache = {}  # {user_id: (user_data, timestamp)}
        self.payment_cache = {}  # {user_id: [payment_data, ...]}
        self.timeout_ms = timeout_ms
        self.join_count = 0
        import time

        self.current_time = lambda: int(time.time() * 1000)

    def execute(self, payload: Any, key: Any, tag: int) -> List[Any]:
        results = []
        current_time = self.current_time()

        if tag == 0:  # ç”¨æˆ·æµ
            user_type = payload.get("type", "")
            if user_type in ["user_info", "preference_info"]:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æ”¯ä»˜
                if key in self.payment_cache:
                    for payment_data in self.payment_cache[key]:
                        joined = self._create_user_payment_join(
                            payload, payment_data, key
                        )
                        results.append(joined)
                        self.join_count += 1
                    del self.payment_cache[key]
                else:
                    # ç¼“å­˜ç”¨æˆ·æ•°æ®ï¼Œè®¾ç½®è¶…æ—¶
                    self.user_cache[key] = (payload, current_time)

        elif tag == 1:  # æ”¯ä»˜æµ
            payment_type = payload.get("type", "")
            if payment_type == "payment_info":
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„ç”¨æˆ·
                if key in self.user_cache:
                    user_data, _ = self.user_cache[key]
                    joined = self._create_user_payment_join(user_data, payload, key)
                    results.append(joined)
                    self.join_count += 1
                    del self.user_cache[key]
                else:
                    # ç¼“å­˜æ”¯ä»˜æ•°æ®
                    if key not in self.payment_cache:
                        self.payment_cache[key] = []
                    self.payment_cache[key].append(payload)

        # æ£€æŸ¥è¶…æ—¶çš„ç”¨æˆ·æ•°æ®ï¼ˆLeft Joinç‰¹æ€§ï¼‰
        expired_users = []
        for user_id, (user_data, timestamp) in self.user_cache.items():
            if current_time - timestamp > self.timeout_ms:
                # è¾“å‡ºæ²¡æœ‰æ”¯ä»˜çš„ç”¨æˆ·
                no_payment_result = self._create_user_payment_join(
                    user_data, None, user_id
                )
                results.append(no_payment_result)
                expired_users.append(user_id)
                self.join_count += 1

        # æ¸…ç†è¿‡æœŸç”¨æˆ·
        for user_id in expired_users:
            del self.user_cache[user_id]

        if results:
            self.logger.info(
                f"UserPaymentJoin: generated {len(results)} joins for key '{key}', total joins: {self.join_count}"
            )

        return results

    def _create_user_payment_join(
        self, user_data: Any, payment_data: Any, user_id: str
    ) -> Dict:
        return {
            "join_type": "user_payment",
            "user_id": user_id,
            "user_name": user_data.get("name") if user_data else None,
            "user_tier": user_data.get("tier") if user_data else None,
            "order_id": payment_data.get("order_id") if payment_data else None,
            "payment_amount": payment_data.get("amount") if payment_data else 0,
            "payment_timestamp": (
                payment_data.get("payment_timestamp") if payment_data else None
            ),
            "has_payment": payment_data is not None,
            "join_timestamp": time.time_ns() // 1_000_000,
            "source": "user_payment_join",
        }


class OrderEventJoin(BaseJoinFunction):
    """è®¢å•å’Œäº‹ä»¶çš„çª—å£Join"""

    def __init__(self, window_ms: int = 3000, **kwargs):
        super().__init__(**kwargs)
        self.window_ms = window_ms
        self.event_buffer = {}  # {order_id: [(data, timestamp, tag), ...]}
        self.join_count = 0
        import time

        self.current_time = lambda: int(time.time() * 1000)

    def execute(self, payload: Any, key: Any, tag: int) -> List[Any]:
        current_time = self.current_time()
        results = []

        # æ¸…ç†è¿‡æœŸäº‹ä»¶
        self._cleanup_expired_events(current_time)

        # è·å–æ•°æ®ç±»å‹
        data_type = payload.get("type", "")

        # åªå¤„ç†è®¢å•ä¿¡æ¯å’Œäº‹ä»¶ä¿¡æ¯
        if data_type not in ["order_info", "event_info"]:
            return results

        # æ·»åŠ å½“å‰äº‹ä»¶åˆ°ç¼“å†²åŒº
        if key not in self.event_buffer:
            self.event_buffer[key] = []
        self.event_buffer[key].append((payload, current_time, tag))

        # æ£€æŸ¥çª—å£å†…çš„äº‹ä»¶ç»„åˆ
        if key in self.event_buffer:
            window_events = self._get_window_events(key, current_time)
            combinations = self._find_order_event_combinations(window_events, key)
            results.extend(combinations)
            self.join_count += len(combinations)

        if results:
            self.logger.info(
                f"OrderEventJoin: generated {len(results)} joins for order '{key}', total joins: {self.join_count}"
            )

        return results

    def _cleanup_expired_events(self, current_time: int):
        cutoff_time = current_time - self.window_ms

        for key in list(self.event_buffer.keys()):
            valid_events = [
                (data, ts, tag)
                for data, ts, tag in self.event_buffer[key]
                if ts >= cutoff_time
            ]
            if valid_events:
                self.event_buffer[key] = valid_events
            else:
                del self.event_buffer[key]

    def _get_window_events(self, key: Any, current_time: int) -> List:
        cutoff_time = current_time - self.window_ms
        return [
            (data, ts, tag)
            for data, ts, tag in self.event_buffer[key]
            if ts >= cutoff_time
        ]

    def _find_order_event_combinations(self, events: List, order_id: str) -> List:
        combinations = []

        # æŒ‰tagåˆ†ç»„äº‹ä»¶
        order_infos = [
            (data, ts)
            for data, ts, tag in events
            if tag == 0 and data.get("type") == "order_info"
        ]
        event_infos = [
            (data, ts)
            for data, ts, tag in events
            if tag == 1 and data.get("type") == "event_info"
        ]

        # ç»„åˆè®¢å•ä¿¡æ¯å’Œäº‹ä»¶ä¿¡æ¯
        for order_data, order_ts in order_infos:
            for event_data, event_ts in event_infos:
                # äº‹ä»¶åº”è¯¥åœ¨è®¢å•ä¹‹åæˆ–åŒæ—¶å‘ç”Ÿ
                if event_ts >= order_ts:
                    combo_result = {
                        "join_type": "order_event",
                        "order_id": order_id,
                        "user_id": order_data.get("user_id"),
                        "order_amount": order_data.get("amount"),
                        "order_timestamp": order_data.get("timestamp"),
                        "event_type": event_data.get("event"),
                        "event_timestamp": event_data.get("timestamp"),
                        "time_diff": event_ts - order_ts,
                        "join_timestamp": time.time_ns() // 1_000_000,
                        "source": "order_event_join",
                    }
                    combinations.append(combo_result)

        return combinations


# =====================================================================
# Sink Functions - æ”¶é›†ç»“æœ
# =====================================================================


class JoinResultSink(SinkFunction):
    """æ”¶é›†Joinç»“æœçš„Sink"""

    def __init__(self, output_file=None, **kwargs):
        super().__init__(**kwargs)
        self.parallel_index = None
        self.received_count = 0

        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
        if output_file is None:
            self.output_file = Path(tempfile.gettempdir()) / "join_test_results.json"
        else:
            self.output_file = Path(output_file)

        if self.ctx:
            self.logger.info(
                f"JoinResultSink initialized, output file: {self.output_file}"
            )

    def execute(self, data: Any):
        if self.ctx:
            self.parallel_index = self.ctx.parallel_index

        self.received_count += 1

        join_type = data.get("join_type", "unknown")
        key_field = "user_id" if "user" in join_type else "order_id"
        key_value = data.get(key_field, "unknown")

        if self.ctx:
            self.logger.info(
                f"[Instance {self.parallel_index}] "
                f"Received join result #{self.received_count}: {join_type} for {key_field}={key_value}"
            )

        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        logging.info(
            f"ğŸ”— [Instance {self.parallel_index}] Join: {join_type} | {key_field}={key_value}"
        )

        # ä¿å­˜åˆ°æ–‡ä»¶
        self._append_record(
            {
                "parallel_index": self.parallel_index,
                "sequence": self.received_count,
                "data": data,
                "timestamp": time.time(),
            }
        )

        return data

    def _append_record(self, record):
        """åŸå­æ€§åœ°è¿½åŠ è®°å½•åˆ°æ–‡ä»¶"""
        try:
            # ä»¥è¿½åŠ æ¨¡å¼æ‰“å¼€æ–‡ä»¶
            with open(self.output_file, "a") as f:
                # å†™å…¥ä¸€è¡ŒJSON
                f.write(json.dumps(record) + "\n")
                f.flush()
        except Exception as e:
            if self.ctx:
                self.logger.error(f"Failed to write record: {e}")

    @classmethod
    def read_results(cls, output_file=None):
        """è¯»å–æµ‹è¯•ç»“æœ"""
        if output_file is None:
            output_file = Path(tempfile.gettempdir()) / "join_test_results.json"
        else:
            output_file = Path(output_file)

        results = {}

        if not output_file.exists():
            logging.info(f"ğŸ“‚ No results file found: {output_file}")
            return results

        try:
            with open(output_file, "r") as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue

                    try:
                        record = json.loads(line)
                        parallel_index = record.get("parallel_index", 0)
                        data = record.get("data")

                        if parallel_index not in results:
                            results[parallel_index] = []

                        results[parallel_index].append(data)

                    except json.JSONDecodeError as e:
                        logging.info(f"âš ï¸ Failed to parse line {line_num}: {e}")
                        continue

        except Exception as e:
            logging.info(f"âŒ Failed to read results file: {e}")

        logging.info(
            f"ğŸ“‚ Read {sum(len(data_list) for data_list in results.values())} records from {len(results)} parallel instances"
        )
        return results

    @classmethod
    def clear_results(cls, output_file=None):
        """æ¸…ç†ç»“æœ"""
        if output_file is None:
            output_file = Path(tempfile.gettempdir()) / "join_test_results.json"
        else:
            output_file = Path(output_file)

        if output_file.exists():
            output_file.unlink()
            logging.info(f"ğŸ—‘ï¸ Cleared results file: {output_file}")

    @classmethod
    def get_received_data(cls, output_file=None):
        """å…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨read_results"""
        return cls.read_results(output_file)


# =====================================================================
# æµ‹è¯•ç±»
# =====================================================================


class TestJoinFunctionality:
    """æµ‹è¯•JoinåŠŸèƒ½çš„å®Œæ•´æµ‹è¯•å¥—ä»¶"""

    def setup_method(self):
        JoinResultSink.clear_results()

    # def test_flatmap_filter_join_pipeline(self):
    #     """æµ‹è¯•å®Œæ•´çš„FlatMap -> Filter -> Joinç®¡é“"""
    #     logging.info("\nğŸš€ Testing Complete FlatMap -> Filter -> Join Pipeline")

    #     env = LocalEnvironment("flatmap_filter_join_test")

    #     # 1. åˆ›å»ºæºæ•°æ®æµ
    #     order_source = env.from_source(OrderEventSource, delay=0.2)
    #     user_source = env.from_source(UserProfileSource, delay=0.3)

    #     # 2. ä¸Šæ¸¸å¤„ç†ï¼šFlatMapåˆ†è§£æ•°æ®ï¼ŒFilterè¿‡æ»¤
    #     order_stream = (order_source
    #         .flatmap(OrderEventFlatMap)    # åˆ†è§£è®¢å•äº‹ä»¶
    #         .filter(OrderInfoFilter)       # åªä¿ç•™è®¢å•ç›¸å…³ä¿¡æ¯
    #         .keyby(UserIdKeyBy)             # æŒ‰ç”¨æˆ·IDåˆ†åŒº
    #     )

    #     user_stream = (user_source
    #         .flatmap(UserProfileFlatMap)    # åˆ†è§£ç”¨æˆ·æ¡£æ¡ˆ
    #         .filter(UserInfoFilter)         # åªä¿ç•™ç”¨æˆ·ç›¸å…³ä¿¡æ¯
    #         .keyby(UserIdKeyBy)             # æŒ‰ç”¨æˆ·IDåˆ†åŒº
    #     )

    #     # 3. ä¸‹æ¸¸å¤„ç†ï¼šConnectå’ŒJoin
    #     join_result = (user_stream
    #         .connect(order_stream)          # è¿æ¥ä¸¤ä¸ªæµ
    #         .join(UserOrderJoin)            # ç”¨æˆ·-è®¢å•Join
    #         .sink(JoinResultSink, parallelism=1)
    #     )

    #     logging.info("ğŸ“Š Pipeline: OrderSource -> flatmap -> filter -> keyby")
    #     logging.info("           UserSource -> flatmap -> filter -> keyby")
    #     logging.info("           user_stream.connect(order_stream).join(UserOrderJoin)")
    #     logging.info("ğŸ¯ Expected: User and order data joined on user_id\n")

    #     try:
    #         env.submit()

    #         time.sleep(6)
    #     finally:
    #         env.close()

    #     # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
    #     time.sleep(1)
    #     self._verify_user_order_join_results()

    def test_multi_stage_join_pipeline(self):
        """æµ‹è¯•å¤šé˜¶æ®µJoinç®¡é“"""
        logging.info("\nğŸš€ Testing Multi-Stage Join Pipeline")

        env = LocalEnvironment("multi_stage_join_test")

        # ç¬¬ä¸€é˜¶æ®µï¼šè®¢å•äº‹ä»¶æµå¤„ç†
        order_source = env.from_source(OrderEventSource, delay=0.2)

        # åˆ†ç¦»ä¸ºä¸¤ä¸ªæµï¼šè®¢å•ä¿¡æ¯æµå’Œæ”¯ä»˜ä¿¡æ¯æµ
        order_info_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "order_info")
            .keyby(UserIdKeyBy)
        )

        payment_info_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "payment_info")
            .keyby(UserIdKeyBy)
        )

        # ç¬¬äºŒé˜¶æ®µï¼šç”¨æˆ·ä¿¡æ¯æµå¤„ç†
        user_source = env.from_source(UserProfileSource, delay=0.3)

        # åªä¿ç•™é«˜çº§ç”¨æˆ·
        premium_user_stream = (
            user_source.flatmap(UserProfileFlatMap)
            .filter(PremiumUserFilter)
            .filter(lambda x: x.get("type") in ["user_info", "preference_info"])
            .keyby(UserIdKeyBy)
        )

        # ç¬¬ä¸‰é˜¶æ®µï¼šå¤šé‡Join
        # Join 1: é«˜çº§ç”¨æˆ· + æ”¯ä»˜ä¿¡æ¯
        user_payment_join = (
            premium_user_stream.connect(payment_info_stream)
            .join(UserPaymentJoin, timeout_ms=3000)
            .sink(JoinResultSink, parallelism=1)
        )

        logging.info("ğŸ“Š Multi-Stage Pipeline:")
        logging.info("   OrderSource -> flatmap -> filter(order_info) -> keyby")
        logging.info("   OrderSource -> flatmap -> filter(payment_info) -> keyby")
        logging.info("   UserSource -> flatmap -> filter(premium) -> keyby")
        logging.info("   premium_user.connect(payment).join(UserPaymentJoin)")
        logging.info("ğŸ¯ Expected: Premium users with their payment information\n")

        try:
            env.submit()

            time.sleep(6)
        finally:
            env.close()

        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
        time.sleep(1)
        self._verify_user_payment_join_results()

    def test_windowed_join_pipeline(self):
        """æµ‹è¯•åŸºäºæ—¶é—´çª—å£çš„Join"""
        logging.info("\nğŸš€ Testing Windowed Join Pipeline")

        env = LocalEnvironment("windowed_join_test")

        order_source = env.from_source(OrderEventSource, delay=0.15)

        # åˆ†ç¦»è®¢å•ä¿¡æ¯å’Œäº‹ä»¶ä¿¡æ¯ï¼ŒæŒ‰è®¢å•IDåˆ†åŒº
        order_info_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "order_info")
            .keyby(OrderIdKeyBy)
        )

        event_info_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "event_info")
            .keyby(OrderIdKeyBy)
        )

        # çª—å£Joinï¼šåœ¨æ—¶é—´çª—å£å†…å…³è”è®¢å•å’Œäº‹ä»¶
        windowed_join = (
            order_info_stream.connect(event_info_stream)
            .join(OrderEventJoin, window_ms=2000)
            .sink(JoinResultSink, parallelism=1)
        )

        logging.info("ğŸ“Š Windowed Join Pipeline:")
        logging.info("   OrderSource -> flatmap -> filter(order_info) -> keyby(order_id)")
        logging.info("   OrderSource -> flatmap -> filter(event_info) -> keyby(order_id)")
        logging.info("   order_info.connect(event_info).join(OrderEventJoin, window=2s)")
        logging.info("ğŸ¯ Expected: Orders matched with their events within time window\n")

        try:
            env.submit()

            time.sleep(5)
        finally:
            env.close()

        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
        time.sleep(1)
        self._verify_order_event_join_results()

    def test_complex_pipeline_with_multiple_joins(self):
        """æµ‹è¯•åŒ…å«å¤šä¸ªJoinçš„å¤æ‚ç®¡é“"""
        logging.info("\nğŸš€ Testing Complex Pipeline with Multiple Joins")

        env = LocalEnvironment("complex_multi_join_test")

        # æ•°æ®æº
        order_source = env.from_source(OrderEventSource, delay=0.2)
        user_source = env.from_source(UserProfileSource, delay=0.3)

        # å¤æ‚çš„æ•°æ®åˆ†æµå’Œè¿‡æ»¤
        # æµ1ï¼šç”¨æˆ·åŸºç¡€ä¿¡æ¯
        user_basic_stream = (
            user_source.flatmap(UserProfileFlatMap)
            .filter(lambda x: x.get("type") == "user_info")
            .keyby(UserIdKeyBy)
        )

        # æµ2ï¼šè®¢å•æ”¯ä»˜ä¿¡æ¯
        payment_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "payment_info")
            .keyby(UserIdKeyBy)
        )

        # æµ3ï¼šè®¢å•åŸºç¡€ä¿¡æ¯
        order_basic_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "order_info")
            .keyby(UserIdKeyBy)
        )

        # Join 1: ç”¨æˆ· + æ”¯ä»˜ä¿¡æ¯
        user_payment = user_basic_stream.connect(payment_stream).join(
            UserPaymentJoin, timeout_ms=2000
        )

        # Join 2: ç”¨æˆ· + è®¢å•ä¿¡æ¯
        user_order = user_basic_stream.connect(order_basic_stream).join(UserOrderJoin)

        # æ”¶é›†æ‰€æœ‰Joinç»“æœ
        user_payment.sink(JoinResultSink, parallelism=1)
        user_order.sink(JoinResultSink, parallelism=1)

        logging.info("ğŸ“Š Complex Multi-Join Pipeline:")
        logging.info("   UserSource -> flatmap -> filter(user_info) -> keyby")
        logging.info("   OrderSource -> flatmap -> filter(payment_info) -> keyby")
        logging.info("   OrderSource -> flatmap -> filter(order_info) -> keyby")
        logging.info("   user.connect(payment).join() + user.connect(order).join()")
        logging.info("ğŸ¯ Expected: Both user-payment and user-order joins\n")

        try:
            env.submit()

            time.sleep(6)
        finally:
            env.close()

        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
        time.sleep(1)
        self._verify_complex_multi_join_results()

    def test_join_with_empty_streams(self):
        """æµ‹è¯•ç©ºæµçš„Joinå¤„ç†"""
        logging.info("\nğŸš€ Testing Join with Empty/Filtered Streams")

        env = LocalEnvironment("empty_stream_join_test")

        order_source = env.from_source(OrderEventSource, delay=0.2)
        user_source = env.from_source(UserProfileSource, delay=0.3)

        # åˆ›å»ºä¸€ä¸ªä¼šè¿‡æ»¤æ‰æ‰€æœ‰æ•°æ®çš„æµ
        empty_user_stream = (
            user_source.flatmap(UserProfileFlatMap)
            .filter(lambda x: False)  # è¿‡æ»¤æ‰æ‰€æœ‰æ•°æ®
            .keyby(UserIdKeyBy)
        )

        order_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "order_info")
            .keyby(UserIdKeyBy)
        )

        # Joinç©ºæµå’Œæ­£å¸¸æµ
        empty_join = (
            empty_user_stream.connect(order_stream)
            .join(UserOrderJoin)
            .sink(JoinResultSink, parallelism=1)
        )

        logging.info("ğŸ“Š Empty Stream Join Pipeline:")
        logging.info("   UserSource -> flatmap -> filter(False) -> keyby")
        logging.info("   OrderSource -> flatmap -> filter(order_info) -> keyby")
        logging.info("   empty_user.connect(order).join()")
        logging.info("ğŸ¯ Expected: No join results due to empty user stream\n")

        try:
            env.submit()

            time.sleep(4)
        finally:
            env.close()

        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
        time.sleep(1)
        self._verify_empty_stream_join_results()

    def test_windowed_join_pipeline(self):
        """æµ‹è¯•åŸºäºæ—¶é—´çª—å£çš„Join"""
        logging.info("\nğŸš€ Testing Windowed Join Pipeline")

        env = LocalEnvironment("windowed_join_test")

        order_source = env.from_source(OrderEventSource, delay=0.15)

        # åˆ†ç¦»è®¢å•ä¿¡æ¯å’Œäº‹ä»¶ä¿¡æ¯ï¼ŒæŒ‰è®¢å•IDåˆ†åŒº
        order_info_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "order_info")
            .keyby(OrderIdKeyBy)
        )

        event_info_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "event_info")
            .keyby(OrderIdKeyBy)
        )

        # çª—å£Joinï¼šåœ¨æ—¶é—´çª—å£å†…å…³è”è®¢å•å’Œäº‹ä»¶
        windowed_join = (
            order_info_stream.connect(event_info_stream)
            .join(OrderEventJoin, window_ms=2000)
            .sink(JoinResultSink, parallelism=1)
        )

        logging.info("ğŸ“Š Windowed Join Pipeline:")
        logging.info("   OrderSource -> flatmap -> filter(order_info) -> keyby(order_id)")
        logging.info("   OrderSource -> flatmap -> filter(event_info) -> keyby(order_id)")
        logging.info("   order_info.connect(event_info).join(OrderEventJoin, window=2s)")
        logging.info("ğŸ¯ Expected: Orders matched with their events within time window\n")

        try:
            env.submit()

            time.sleep(5)
        finally:
            env.close()

        self._verify_order_event_join_results()

    def test_complex_pipeline_with_multiple_joins(self):
        """æµ‹è¯•åŒ…å«å¤šä¸ªJoinçš„å¤æ‚ç®¡é“"""
        logging.info("\nğŸš€ Testing Complex Pipeline with Multiple Joins")

        env = LocalEnvironment("complex_multi_join_test")

        # æ•°æ®æº
        order_source = env.from_source(OrderEventSource, delay=0.2)
        user_source = env.from_source(UserProfileSource, delay=0.3)

        # å¤æ‚çš„æ•°æ®åˆ†æµå’Œè¿‡æ»¤
        # æµ1ï¼šç”¨æˆ·åŸºç¡€ä¿¡æ¯
        user_basic_stream = (
            user_source.flatmap(UserProfileFlatMap)
            .filter(lambda x: x.get("type") == "user_info")
            .keyby(UserIdKeyBy)
        )

        # æµ2ï¼šè®¢å•æ”¯ä»˜ä¿¡æ¯
        payment_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "payment_info")
            .keyby(UserIdKeyBy)
        )

        # æµ3ï¼šè®¢å•åŸºç¡€ä¿¡æ¯
        order_basic_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "order_info")
            .keyby(UserIdKeyBy)
        )

        # Join 1: ç”¨æˆ· + æ”¯ä»˜ä¿¡æ¯
        user_payment = user_basic_stream.connect(payment_stream).join(
            UserPaymentJoin, timeout_ms=2000
        )

        # Join 2: ç”¨æˆ· + è®¢å•ä¿¡æ¯
        user_order = user_basic_stream.connect(order_basic_stream).join(UserOrderJoin)

        # æ”¶é›†æ‰€æœ‰Joinç»“æœ
        user_payment.sink(JoinResultSink, parallelism=1)
        user_order.sink(JoinResultSink, parallelism=1)

        logging.info("ğŸ“Š Complex Multi-Join Pipeline:")
        logging.info("   UserSource -> flatmap -> filter(user_info) -> keyby")
        logging.info("   OrderSource -> flatmap -> filter(payment_info) -> keyby")
        logging.info("   OrderSource -> flatmap -> filter(order_info) -> keyby")
        logging.info("   user.connect(payment).join() + user.connect(order).join()")
        logging.info("ğŸ¯ Expected: Both user-payment and user-order joins\n")

        try:
            env.submit()

            time.sleep(7)
        finally:
            env.close()

        self._verify_complex_multi_join_results()

    def test_join_with_empty_streams(self):
        """æµ‹è¯•ç©ºæµçš„Joinå¤„ç†"""
        logging.info("\nğŸš€ Testing Join with Empty/Filtered Streams")

        env = LocalEnvironment("empty_stream_join_test")

        order_source = env.from_source(OrderEventSource, delay=0.2)
        user_source = env.from_source(UserProfileSource, delay=0.3)

        # åˆ›å»ºä¸€ä¸ªä¼šè¿‡æ»¤æ‰æ‰€æœ‰æ•°æ®çš„æµ
        empty_user_stream = (
            user_source.flatmap(UserProfileFlatMap)
            .filter(lambda x: False)  # è¿‡æ»¤æ‰æ‰€æœ‰æ•°æ®
            .keyby(UserIdKeyBy)
        )

        order_stream = (
            order_source.flatmap(OrderEventFlatMap)
            .filter(lambda x: x.get("type") == "order_info")
            .keyby(UserIdKeyBy)
        )

        # Joinç©ºæµå’Œæ­£å¸¸æµ
        empty_join = (
            empty_user_stream.connect(order_stream)
            .join(UserOrderJoin)
            .sink(JoinResultSink, parallelism=1)
        )

        logging.info("ğŸ“Š Empty Stream Join Pipeline:")
        logging.info("   UserSource -> flatmap -> filter(False) -> keyby")
        logging.info("   OrderSource -> flatmap -> filter(order_info) -> keyby")
        logging.info("   empty_user.connect(order).join()")
        logging.info("ğŸ¯ Expected: No join results due to empty user stream\n")

        try:
            env.submit()

            time.sleep(4)
        finally:
            env.close()

        self._verify_empty_stream_join_results()

    # =====================================================================
    # éªŒè¯æ–¹æ³•
    # =====================================================================

    def _verify_user_order_join_results(self):
        """éªŒè¯ç”¨æˆ·-è®¢å•Joinç»“æœ"""
        received_data = JoinResultSink.get_received_data()

        logging.info("\nğŸ“‹ User-Order Join Results:")
        logging.info("=" * 50)

        all_joins = []
        for instance_id, data_list in received_data.items():
            for data in data_list:
                if data.get("join_type") == "user_order":
                    all_joins.append(data)
                    user_id = data.get("user_id")
                    user_name = data.get("user_name")
                    order_id = data.get("order_id")
                    amount = data.get("order_amount")
                    logging.info(
                        f"   - User: {user_name} ({user_id}) -> Order: {order_id} (${amount})"
                    )

        logging.info(f"\nğŸ¯ User-Order Join Summary:")
        logging.info(f"   - Total user-order joins: {len(all_joins)}")

        # éªŒè¯Joinç»“æœ
        assert len(all_joins) > 0, "âŒ No user-order joins found"

        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        for join_data in all_joins:
            assert join_data.get("user_id"), f"âŒ Missing user_id: {join_data}"
            assert join_data.get("order_id"), f"âŒ Missing order_id: {join_data}"
            assert (
                join_data.get("source") == "user_order_join"
            ), f"âŒ Wrong source: {join_data}"

        logging.info("âœ… User-Order join test passed: Users successfully joined with orders")

    def _verify_user_payment_join_results(self):
        """éªŒè¯ç”¨æˆ·-æ”¯ä»˜Joinç»“æœ"""
        received_data = JoinResultSink.get_received_data()

        logging.info("\nğŸ“‹ User-Payment Join Results:")
        logging.info("=" * 50)

        all_joins = []
        with_payment = 0
        without_payment = 0

        for instance_id, data_list in received_data.items():
            for data in data_list:
                if data.get("join_type") == "user_payment":
                    all_joins.append(data)
                    user_name = data.get("user_name")
                    has_payment = data.get("has_payment", False)
                    payment_amount = data.get("payment_amount", 0)

                    if has_payment:
                        with_payment += 1
                        logging.info(f"   - User: {user_name} -> Payment: ${payment_amount}")
                    else:
                        without_payment += 1
                        logging.info(f"   - User: {user_name} -> No payment")

        logging.info(f"\nğŸ¯ User-Payment Join Summary:")
        logging.info(f"   - Total user-payment joins: {len(all_joins)}")
        logging.info(f"   - With payments: {with_payment}")
        logging.info(f"   - Without payments: {without_payment}")

        # éªŒè¯Joinç»“æœ
        assert len(all_joins) > 0, "âŒ No user-payment joins found"

        logging.info("âœ… User-Payment join test passed: Users joined with payment status")

    def _verify_order_event_join_results(self):
        """éªŒè¯è®¢å•-äº‹ä»¶Joinç»“æœ"""
        received_data = JoinResultSink.get_received_data()

        logging.info("\nğŸ“‹ Order-Event Join Results:")
        logging.info("=" * 50)

        all_joins = []
        for instance_id, data_list in received_data.items():
            for data in data_list:
                if data.get("join_type") == "order_event":
                    all_joins.append(data)
                    order_id = data.get("order_id")
                    event_type = data.get("event_type")
                    time_diff = data.get("time_diff", 0)
                    logging.info(
                        f"   - Order: {order_id} -> Event: {event_type} (time_diff: {time_diff}ms)"
                    )

        logging.info(f"\nğŸ¯ Order-Event Join Summary:")
        logging.info(f"   - Total order-event joins: {len(all_joins)}")

        # éªŒè¯çª—å£Joinç»“æœ
        assert len(all_joins) > 0, "âŒ No order-event joins found"

        # éªŒè¯æ—¶é—´çª—å£
        for join_data in all_joins:
            time_diff = join_data.get("time_diff", 0)
            assert time_diff >= 0, f"âŒ Invalid time diff: {time_diff}"

        logging.info(
            "âœ… Order-Event join test passed: Orders joined with events in time window"
        )

    def _verify_complex_multi_join_results(self):
        """éªŒè¯å¤æ‚å¤šJoinç»“æœ"""
        received_data = JoinResultSink.get_received_data()

        logging.info("\nğŸ“‹ Complex Multi-Join Results:")
        logging.info("=" * 50)

        user_payment_joins = []
        user_order_joins = []

        for instance_id, data_list in received_data.items():
            for data in data_list:
                join_type = data.get("join_type")
                if join_type == "user_payment":
                    user_payment_joins.append(data)
                elif join_type == "user_order":
                    user_order_joins.append(data)

                user_id = data.get("user_id", "unknown")
                logging.info(f"   - {join_type}: user {user_id}")

        logging.info(f"\nğŸ¯ Complex Multi-Join Summary:")
        logging.info(f"   - User-payment joins: {len(user_payment_joins)}")
        logging.info(f"   - User-order joins: {len(user_order_joins)}")
        logging.info(f"   - Total joins: {len(user_payment_joins) + len(user_order_joins)}")

        # éªŒè¯ä¸¤ç§Joinéƒ½æœ‰ç»“æœ
        assert (
            len(user_payment_joins) > 0 or len(user_order_joins) > 0
        ), "âŒ No joins found"

        logging.info("âœ… Complex multi-join test passed: Multiple join types working")

    def _verify_empty_stream_join_results(self):
        """éªŒè¯ç©ºæµJoinç»“æœ"""
        received_data = JoinResultSink.get_received_data()

        logging.info("\nğŸ“‹ Empty Stream Join Results:")
        logging.info("=" * 50)

        total_joins = sum(len(data_list) for data_list in received_data.values())
        logging.info(f"ğŸ”¹ Total join results: {total_joins}")

        # ç©ºæµJoinåº”è¯¥æ²¡æœ‰ç»“æœ
        assert (
            total_joins == 0
        ), f"âŒ Expected no joins with empty stream, got {total_joins}"

        logging.info("âœ… Empty stream join test passed: No results as expected")


if __name__ == "__main__":
    # å¯ä»¥ç›´æ¥è¿è¡Œå•ä¸ªæµ‹è¯•
    test = TestJoinFunctionality()
    test.setup_method()
    test.test_flatmap_filter_join_pipeline()

"""
# è¿è¡Œæ‰€æœ‰Joinæµ‹è¯•
pytest sage_tests/core_tests/join_test.py -v -s

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest sage_tests/core_tests/join_test.py::TestJoinFunctionality::test_flatmap_filter_join_pipeline -v -s
pytest sage_tests/core_tests/join_test.py::TestJoinFunctionality::test_multi_stage_join_pipeline -v -s
pytest sage_tests/core_tests/join_test.py::TestJoinFunctionality::test_windowed_join_pipeline -v -s
"""
