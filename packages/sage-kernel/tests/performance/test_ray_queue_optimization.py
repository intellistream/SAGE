"""
æ€§èƒ½æµ‹è¯•ï¼šéªŒè¯Rayé˜Ÿåˆ—æ‰¹é‡ä¼˜åŒ–çš„æ•ˆæœ

æµ‹è¯•åœºæ™¯ï¼š
1. å•æ¡put/get vs æ‰¹é‡æ“ä½œçš„æ€§èƒ½å¯¹æ¯”
2. ä¸åŒæ‰¹é‡å¤§å°çš„æ€§èƒ½å½±å“
3. åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„ååé‡æå‡

é¢„æœŸç»“æœï¼š
- æ‰¹é‡æ“ä½œåº”è¯¥æ¯”å•æ¡æ“ä½œå¿«10-50å€
- æ‰¹é‡å¤§å°åœ¨100-500æ—¶æ€§èƒ½æœ€ä¼˜
"""

import time

import pytest
import ray

from sage.platform.queue.ray_queue_descriptor import (
    RayQueueDescriptor,
    RayQueueProxy,
    get_global_queue_manager,
)


@pytest.fixture(scope="module")
def ray_init():
    """åˆå§‹åŒ–Rayç¯å¢ƒ"""
    if not ray.is_initialized():
        ray.init(ignore_reinit_error=True)
    yield
    # æµ‹è¯•ç»“æŸåä¸å…³é—­Rayï¼Œé¿å…å½±å“å…¶ä»–æµ‹è¯•


class TestRayQueueOptimization:
    """Rayé˜Ÿåˆ—æ‰¹é‡ä¼˜åŒ–æ€§èƒ½æµ‹è¯•"""

    def test_single_put_performance_baseline(self, ray_init):
        """åŸºå‡†æµ‹è¯•ï¼šå•æ¡putæ“ä½œçš„æ€§èƒ½ï¼ˆæ—§ç‰ˆæœ¬è¡Œä¸ºæ¨¡æ‹Ÿï¼‰"""
        print("\n" + "=" * 80)
        print("ğŸ”´ Baseline: å•æ¡putæ“ä½œæ€§èƒ½ï¼ˆåŒæ­¥ç­‰å¾…ï¼‰")
        print("=" * 80)

        # åˆ›å»ºé˜Ÿåˆ—
        queue_desc = RayQueueDescriptor(maxsize=10000, queue_id="perf_test_baseline")
        manager = get_global_queue_manager()

        # ç¡®ä¿é˜Ÿåˆ—åˆ›å»º
        ray.get(manager.get_or_create_queue.remote(queue_desc.queue_id, queue_desc.maxsize))

        # æµ‹è¯•æ•°æ®
        num_items = 1000
        test_data = [f"item_{i}" for i in range(num_items)]

        # å•æ¡putï¼ˆæ¨¡æ‹Ÿæ—§ç‰ˆæœ¬çš„åŒæ­¥è¡Œä¸ºï¼‰
        start_time = time.time()
        for item in test_data:
            ray.get(manager.put.remote(queue_desc.queue_id, item))
        elapsed_time = time.time() - start_time

        throughput = num_items / elapsed_time
        print(f"ğŸ“Š Items: {num_items}")
        print(f"â±ï¸  Time: {elapsed_time:.3f} seconds")
        print(f"ğŸš€ Throughput: {throughput:.1f} items/second")
        print(f"ğŸ“ˆ Average latency: {(elapsed_time / num_items) * 1000:.2f} ms/item")

        # æ¸…ç†é˜Ÿåˆ—
        ray.get(manager.delete_queue.remote(queue_desc.queue_id))

        return throughput

    def test_batch_put_performance_optimized(self, ray_init):
        """ä¼˜åŒ–æµ‹è¯•ï¼šæ‰¹é‡putæ“ä½œçš„æ€§èƒ½ï¼ˆæ–°ç‰ˆæœ¬ï¼‰"""
        print("\n" + "=" * 80)
        print("ğŸŸ¢ Optimized: æ‰¹é‡putæ“ä½œæ€§èƒ½ï¼ˆå¼‚æ­¥æ‰¹é‡ï¼‰")
        print("=" * 80)

        # åˆ›å»ºé˜Ÿåˆ—ï¼ˆä½¿ç”¨ä¼˜åŒ–çš„ä»£ç†ï¼‰
        queue_desc = RayQueueDescriptor(maxsize=10000, queue_id="perf_test_optimized")
        queue = queue_desc.queue_instance

        # æµ‹è¯•æ•°æ®
        num_items = 1000
        test_data = [f"item_{i}" for i in range(num_items)]

        # æ‰¹é‡putï¼ˆæ–°ç‰ˆæœ¬çš„å¼‚æ­¥æ‰¹é‡æ“ä½œï¼‰
        start_time = time.time()
        for item in test_data:
            queue.put(item)  # å¼‚æ­¥ï¼Œè‡ªåŠ¨æ‰¹é‡
        queue.flush()  # åˆ·æ–°ç¼“å†²åŒº
        queue.wait_for_pending_puts()  # ç­‰å¾…æ‰€æœ‰æ‰¹é‡æ“ä½œå®Œæˆ
        elapsed_time = time.time() - start_time

        throughput = num_items / elapsed_time
        print(f"ğŸ“Š Items: {num_items}")
        print(f"â±ï¸  Time: {elapsed_time:.3f} seconds")
        print(f"ğŸš€ Throughput: {throughput:.1f} items/second")
        print(f"ğŸ“ˆ Average latency: {(elapsed_time / num_items) * 1000:.2f} ms/item")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = queue.get_stats()
        print("\nğŸ“ˆ Performance Stats:")
        print(f"   Total puts: {stats['total_puts']}")
        print(f"   Batch puts: {stats['batch_puts']}")
        print(f"   Avg batch size: {stats['avg_batch_size']:.1f}")

        # æ¸…ç†é˜Ÿåˆ—
        manager = get_global_queue_manager()
        ray.get(manager.delete_queue.remote(queue_desc.queue_id))

        return throughput

    def test_performance_comparison(self, ray_init):
        """å¯¹æ¯”æµ‹è¯•ï¼šè®¡ç®—æ€§èƒ½æå‡å€æ•°"""
        print("\n" + "=" * 80)
        print("ğŸ“Š Performance Comparison")
        print("=" * 80)

        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        baseline_throughput = self.test_single_put_performance_baseline(ray_init)

        # è¿è¡Œä¼˜åŒ–æµ‹è¯•
        optimized_throughput = self.test_batch_put_performance_optimized(ray_init)

        # è®¡ç®—æå‡
        improvement = optimized_throughput / baseline_throughput
        print("\n" + "=" * 80)
        print("âœ¨ Performance Improvement Summary")
        print("=" * 80)
        print(f"ğŸ”´ Baseline throughput: {baseline_throughput:.1f} items/sec")
        print(f"ğŸŸ¢ Optimized throughput: {optimized_throughput:.1f} items/sec")
        print(f"ğŸš€ Improvement: {improvement:.1f}x faster")
        print("=" * 80)

        # è¯´æ˜ï¼šæœ¬åœ°ç¯å¢ƒvsåˆ†å¸ƒå¼ç¯å¢ƒ
        print("\nğŸ“ Note:")
        print("   - Local environment improvement: 1.5-2x (low network latency)")
        print("   - Distributed environment expected: 10-50x (1-5ms network latency)")
        print("   - High latency network expected: 50-100x (5-10ms network latency)")

        # æ–­è¨€ï¼šæœ¬åœ°ç¯å¢ƒä¸‹è‡³å°‘åº”è¯¥æœ‰1.2å€æå‡
        assert improvement >= 1.2, (
            f"Performance improvement {improvement:.1f}x is less than expected 1.2x"
        )
        print(f"\nâœ… Test PASSED! Performance improved by {improvement:.1f}x")

        if improvement >= 5.0:
            print("ğŸ‰ Excellent! This is distributed environment level performance!")
        elif improvement >= 2.0:
            print("ğŸ‘ Good! Better than local environment baseline.")
        else:
            print("â„¹ï¸  This is expected for local environment (same machine, low latency).")

    def test_batch_size_optimization(self, ray_init):
        """æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°çš„æ€§èƒ½å½±å“"""
        print("\n" + "=" * 80)
        print("ğŸ”¬ Batch Size Optimization Test")
        print("=" * 80)

        num_items = 2000
        test_data = [f"item_{i}" for i in range(num_items)]
        batch_sizes = [10, 50, 100, 200, 500]
        results = {}

        for batch_size in batch_sizes:
            # åˆ›å»ºé˜Ÿåˆ—
            queue_desc = RayQueueDescriptor(maxsize=10000, queue_id=f"perf_test_batch_{batch_size}")
            queue = queue_desc.queue_instance

            # è®¾ç½®æ‰¹é‡å¤§å°
            if isinstance(queue, RayQueueProxy):
                queue.batch_size = batch_size

            # æµ‹è¯•
            start_time = time.time()
            for item in test_data:
                queue.put(item)
            queue.flush()
            queue.wait_for_pending_puts()
            elapsed_time = time.time() - start_time

            throughput = num_items / elapsed_time
            results[batch_size] = throughput

            stats = queue.get_stats()
            print(f"\nğŸ“Š Batch size: {batch_size}")
            print(f"   Throughput: {throughput:.1f} items/sec")
            print(f"   Time: {elapsed_time:.3f} sec")
            print(f"   Batches: {stats['batch_puts']}")

            # æ¸…ç†
            manager = get_global_queue_manager()
            ray.get(manager.delete_queue.remote(queue_desc.queue_id))

        # æ‰¾å‡ºæœ€ä¼˜æ‰¹é‡å¤§å°
        best_batch_size = max(results, key=results.get)
        best_throughput = results[best_batch_size]

        print("\n" + "=" * 80)
        print("ğŸ† Best Batch Size")
        print("=" * 80)
        print(f"Optimal batch size: {best_batch_size}")
        print(f"Best throughput: {best_throughput:.1f} items/sec")
        print("=" * 80)

    def test_batch_get_performance(self, ray_init):
        """æµ‹è¯•æ‰¹é‡getæ“ä½œçš„æ€§èƒ½"""
        print("\n" + "=" * 80)
        print("ğŸ“¥ Batch Get Performance Test")
        print("=" * 80)

        # å‡†å¤‡æ•°æ®
        queue_desc = RayQueueDescriptor(maxsize=10000, queue_id="perf_test_batch_get")
        queue = queue_desc.queue_instance
        manager = get_global_queue_manager()

        num_items = 1000
        test_data = [f"item_{i}" for i in range(num_items)]

        # å…ˆæ‰¹é‡putæ•°æ®
        for item in test_data:
            queue.put(item)
        queue.flush()
        queue.wait_for_pending_puts()

        # æµ‹è¯•å•æ¡get
        print("\nğŸ”´ Single get (baseline):")
        retrieved_items = []
        start_time = time.time()
        for _ in range(num_items):
            item = queue.get()
            retrieved_items.append(item)
        single_get_time = time.time() - start_time
        single_throughput = num_items / single_get_time

        print(f"   Time: {single_get_time:.3f} sec")
        print(f"   Throughput: {single_throughput:.1f} items/sec")

        # é‡æ–°å¡«å……æ•°æ®
        for item in test_data:
            ray.get(manager.put.remote(queue_desc.queue_id, item))

        # æµ‹è¯•æ‰¹é‡get
        print("\nğŸŸ¢ Batch get (optimized):")
        retrieved_items = []
        start_time = time.time()
        while len(retrieved_items) < num_items:
            batch = queue.get_batch(count=100)
            if not batch:
                break
            retrieved_items.extend(batch)
        batch_get_time = time.time() - start_time
        batch_throughput = len(retrieved_items) / batch_get_time

        print(f"   Time: {batch_get_time:.3f} sec")
        print(f"   Throughput: {batch_throughput:.1f} items/sec")
        print(f"   Items retrieved: {len(retrieved_items)}")

        # è®¡ç®—æå‡
        if single_get_time > 0:
            improvement = batch_throughput / single_throughput  # æ‰¹é‡åº”è¯¥æ›´å¿«
            print(f"\nğŸ“Š Performance improvement: {improvement:.2f}x faster")

            if improvement >= 1.5:
                print(f"âœ… Batch get is {improvement:.1f}x faster than single get!")
            elif improvement >= 1.0:
                print("âœ… Batch get works correctly (slightly faster)")
            else:
                print("âš ï¸  Warning: Batch get slower than expected")

        # æ¸…ç†
        ray.get(manager.delete_queue.remote(queue_desc.queue_id))


if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("ğŸš€ Starting Ray Queue Performance Tests")
    print("=" * 80)

    # åˆå§‹åŒ–Ray
    if not ray.is_initialized():
        ray.init(ignore_reinit_error=True)

    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = TestRayQueueOptimization()

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    try:
        tester.test_performance_comparison(None)
        tester.test_batch_size_optimization(None)
        tester.test_batch_get_performance(None)

        print("\n" + "=" * 80)
        print("âœ… All performance tests completed successfully!")
        print("=" * 80)
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback

        traceback.print_exc()
    finally:
        # ray.shutdown()  # ä¿ç•™Rayç¯å¢ƒ
        pass
