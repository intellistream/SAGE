#!/usr/bin/env python3
"""
é˜Ÿåˆ—æè¿°ç¬¦æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•ä¸åŒé˜Ÿåˆ—ç±»å‹åœ¨å„ç§åœºæ™¯ä¸‹çš„æ€§èƒ½ï¼š
1. å•çº¿ç¨‹ååé‡æµ‹è¯•
2. å¤šçº¿ç¨‹å¹¶å‘æ€§èƒ½æµ‹è¯•
3. å¤šè¿›ç¨‹å¹¶å‘æ€§èƒ½æµ‹è¯•ï¼ˆæ”¯æŒçš„é˜Ÿåˆ—ç±»å‹ï¼‰
4. å†…å­˜ä½¿ç”¨æƒ…å†µæµ‹è¯•
5. å»¶è¿Ÿæµ‹è¯•
"""

import sys
import os
import time
import threading
import multiprocessing
import psutil
import statistics
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Tuple
import gc
import pytest

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/api-rework')

try:
    from sage.runtime.communication.queue_descriptor import (
        PythonQueueDescriptor,
        RayQueueDescriptor,  
        SageQueueDescriptor
    )
    print("âœ“ æˆåŠŸå¯¼å…¥é˜Ÿåˆ—æè¿°ç¬¦")
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.results = {}
        self.process = psutil.Process()
    
    def measure_memory_usage(self) -> Dict[str, float]:
        """æµ‹é‡å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory_info = self.process.memory_info()
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,  # ç‰©ç†å†…å­˜
            'vms_mb': memory_info.vms / 1024 / 1024,  # è™šæ‹Ÿå†…å­˜
            'percent': self.process.memory_percent()   # å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”
        }
    
    def single_thread_throughput_test(self, queue_desc, num_items: int = 10000) -> Dict[str, Any]:
        """å•çº¿ç¨‹ååé‡æµ‹è¯•"""
        print(f"\n--- å•çº¿ç¨‹ååé‡æµ‹è¯• ({queue_desc.queue_type}) ---")
        
        # å†…å­˜åŸºçº¿
        gc.collect()
        memory_before = self.measure_memory_usage()
        
        # å†™å…¥æµ‹è¯• - ä½¿ç”¨è¾ƒå°çš„æµ‹è¯•æ•°æ®é¿å…å†…å­˜é—®é¢˜
        start_time = time.time()
        for i in range(num_items):
            # ä½¿ç”¨è¾ƒçŸ­çš„å­—ç¬¦ä¸²é¿å…å…±äº«å†…å­˜æº¢å‡º
            test_data = f"item_{i}"
            queue_desc.put(test_data)
        write_end_time = time.time()
        
        write_duration = write_end_time - start_time
        write_throughput = num_items / write_duration
        
        # è¯»å–æµ‹è¯•
        read_start_time = time.time()
        items = []
        for i in range(num_items):
            items.append(queue_desc.get())
        read_end_time = time.time()
        
        read_duration = read_end_time - read_start_time
        read_throughput = num_items / read_duration
        
        # å†…å­˜æµ‹é‡
        memory_after = self.measure_memory_usage()
        memory_delta = memory_after['rss_mb'] - memory_before['rss_mb']
        
        result = {
            'queue_type': queue_desc.queue_type,
            'num_items': num_items,
            'write_duration': write_duration,
            'read_duration': read_duration,
            'write_throughput': write_throughput,
            'read_throughput': read_throughput,
            'total_duration': write_duration + read_duration,
            'memory_delta_mb': memory_delta,
            'memory_before': memory_before,
            'memory_after': memory_after
        }
        
        print(f"å†™å…¥: {write_throughput:.0f} items/sec, è¯»å–: {read_throughput:.0f} items/sec")
        print(f"å†…å­˜å˜åŒ–: {memory_delta:.2f} MB")
        
        return result
    
    def multi_thread_throughput_test(self, queue_desc, num_threads: int = 4, 
                                   items_per_thread: int = 2500) -> Dict[str, Any]:
        """å¤šçº¿ç¨‹ååé‡æµ‹è¯•"""
        print(f"\n--- å¤šçº¿ç¨‹ååé‡æµ‹è¯• ({queue_desc.queue_type}) ---")
        print(f"é…ç½®: {num_threads}ä¸ªçº¿ç¨‹, æ¯ä¸ªå¤„ç†{items_per_thread}ä¸ªé¡¹ç›®")
        
        gc.collect()
        memory_before = self.measure_memory_usage()
        
        # ç”Ÿäº§è€…çº¿ç¨‹å‡½æ•°
        def producer_worker(thread_id: int, items: int):
            start_time = time.time()
            for i in range(items):
                # ä½¿ç”¨è¾ƒçŸ­çš„å­—ç¬¦ä¸²
                test_data = f"t{thread_id}_i{i}"
                queue_desc.put(test_data)
            end_time = time.time()
            return {
                'thread_id': thread_id,
                'duration': end_time - start_time,
                'throughput': items / (end_time - start_time)
            }
        
        # æ¶ˆè´¹è€…çº¿ç¨‹å‡½æ•°
        def consumer_worker(thread_id: int, items: int):
            start_time = time.time()
            consumed = []
            for i in range(items):
                try:
                    item = queue_desc.get(timeout=5.0)
                    consumed.append(item)
                except:
                    break
            end_time = time.time()
            return {
                'thread_id': thread_id,
                'duration': end_time - start_time,
                'consumed': len(consumed),
                'throughput': len(consumed) / (end_time - start_time) if end_time > start_time else 0
            }
        
        # è¿è¡Œç”Ÿäº§è€…çº¿ç¨‹
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            producer_futures = []
            for i in range(num_threads):
                future = executor.submit(producer_worker, i, items_per_thread)
                producer_futures.append(future)
            
            producer_results = []
            for future in as_completed(producer_futures):
                result = future.result()
                producer_results.append(result)
        
        producer_end_time = time.time()
        
        # è¿è¡Œæ¶ˆè´¹è€…çº¿ç¨‹
        consumer_start_time = time.time()
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            consumer_futures = []
            for i in range(num_threads):
                future = executor.submit(consumer_worker, i, items_per_thread)
                consumer_futures.append(future)
            
            consumer_results = []
            for future in as_completed(consumer_futures):
                result = future.result()
                consumer_results.append(result)
        
        consumer_end_time = time.time()
        
        memory_after = self.measure_memory_usage()
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_items = num_threads * items_per_thread
        producer_throughputs = [r['throughput'] for r in producer_results]
        consumer_throughputs = [r['throughput'] for r in consumer_results]
        total_consumed = sum(r['consumed'] for r in consumer_results)
        
        result = {
            'queue_type': queue_desc.queue_type,
            'num_threads': num_threads,
            'items_per_thread': items_per_thread,
            'total_items': total_items,
            'producer_duration': producer_end_time - start_time,
            'consumer_duration': consumer_end_time - consumer_start_time,
            'total_consumed': total_consumed,
            'avg_producer_throughput': statistics.mean(producer_throughputs),
            'max_producer_throughput': max(producer_throughputs),
            'avg_consumer_throughput': statistics.mean(consumer_throughputs),
            'max_consumer_throughput': max(consumer_throughputs),
            'memory_delta_mb': memory_after['rss_mb'] - memory_before['rss_mb'],
            'producer_results': producer_results,
            'consumer_results': consumer_results
        }
        
        print(f"ç”Ÿäº§è€…å¹³å‡ååé‡: {result['avg_producer_throughput']:.0f} items/sec")
        print(f"æ¶ˆè´¹è€…å¹³å‡ååé‡: {result['avg_consumer_throughput']:.0f} items/sec")
        print(f"æ€»æ¶ˆè´¹é¡¹ç›®: {total_consumed}/{total_items}")
        
        return result
    
    def latency_test(self, queue_desc, num_samples: int = 1000) -> Dict[str, Any]:
        """å»¶è¿Ÿæµ‹è¯•"""
        print(f"\n--- å»¶è¿Ÿæµ‹è¯• ({queue_desc.queue_type}) ---")
        
        latencies = []
        
        for i in range(num_samples):
            # æµ‹é‡å•æ¬¡put-getå¾ªç¯çš„å»¶è¿Ÿ
            start_time = time.perf_counter()
            queue_desc.put(f"latency_test_{i}")
            item = queue_desc.get()
            end_time = time.perf_counter()
            
            latency_ms = (end_time - start_time) * 1000
            latencies.append(latency_ms)
        
        result = {
            'queue_type': queue_desc.queue_type,
            'num_samples': num_samples,
            'avg_latency_ms': statistics.mean(latencies),
            'median_latency_ms': statistics.median(latencies),
            'min_latency_ms': min(latencies),
            'max_latency_ms': max(latencies),
            'p95_latency_ms': statistics.quantiles(latencies, n=20)[18],  # 95th percentile
            'p99_latency_ms': statistics.quantiles(latencies, n=100)[98],  # 99th percentile
            'stddev_latency_ms': statistics.stdev(latencies)
        }
        
        print(f"å¹³å‡å»¶è¿Ÿ: {result['avg_latency_ms']:.3f}ms")
        print(f"ä¸­ä½å»¶è¿Ÿ: {result['median_latency_ms']:.3f}ms")
        print(f"P95å»¶è¿Ÿ: {result['p95_latency_ms']:.3f}ms")
        print(f"P99å»¶è¿Ÿ: {result['p99_latency_ms']:.3f}ms")
        
        return result
    
    def queue_size_performance_test(self, queue_desc, max_size: int = 100000, 
                                   step_size: int = 10000) -> Dict[str, Any]:
        """é˜Ÿåˆ—å¤§å°å¯¹æ€§èƒ½çš„å½±å“æµ‹è¯•"""
        print(f"\n--- é˜Ÿåˆ—å¤§å°æ€§èƒ½æµ‹è¯• ({queue_desc.queue_type}) ---")
        
        size_results = []
        
        for current_size in range(step_size, max_size + 1, step_size):
            print(f"æµ‹è¯•é˜Ÿåˆ—å¤§å°: {current_size}")
            
            # å¡«å……é˜Ÿåˆ—åˆ°æŒ‡å®šå¤§å°
            start_fill_time = time.time()
            for i in range(current_size):
                queue_desc.put(f"size_test_{i}")
            fill_duration = time.time() - start_fill_time
            
            # æµ‹é‡è¯»å–æ€§èƒ½
            start_read_time = time.time()
            for i in range(min(1000, current_size)):  # è¯»å–æœ€å¤š1000ä¸ªé¡¹ç›®
                queue_desc.get()
            read_duration = time.time() - start_read_time
            
            # æ¸…ç©ºå‰©ä½™é¡¹ç›®
            while not queue_desc.empty():
                try:
                    queue_desc.get_nowait()
                except:
                    break
            
            memory_usage = self.measure_memory_usage()
            
            size_results.append({
                'queue_size': current_size,
                'fill_duration': fill_duration,
                'fill_throughput': current_size / fill_duration,
                'read_duration': read_duration,
                'read_throughput': min(1000, current_size) / read_duration,
                'memory_mb': memory_usage['rss_mb']
            })
        
        result = {
            'queue_type': queue_desc.queue_type,
            'max_size': max_size,
            'step_size': step_size,
            'size_results': size_results
        }
        
        return result
    
    def run_all_benchmarks(self):
        """è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡Œé˜Ÿåˆ—æ€§èƒ½åŸºå‡†æµ‹è¯•")
        
        # æµ‹è¯•é˜Ÿåˆ—ç±»å‹é…ç½®
        queue_configs = [
            {
                'name': 'Pythonçº¿ç¨‹é˜Ÿåˆ—',
                'creator': lambda: PythonQueueDescriptor(maxsize=50000, use_multiprocessing=False, queue_id="perf_python_thread")
            },
            {
                'name': 'Pythonå¤šè¿›ç¨‹é˜Ÿåˆ—',
                'creator': lambda: PythonQueueDescriptor(maxsize=50000, use_multiprocessing=True, queue_id="perf_python_mp")
            }
        ]
        
        # æ·»åŠ å¯é€‰é˜Ÿåˆ—ç±»å‹
        # Rayé˜Ÿåˆ—ç”±äºæ€§èƒ½é—®é¢˜æš‚æ—¶è·³è¿‡
        print("âš ï¸ Rayé˜Ÿåˆ—æ€§èƒ½æµ‹è¯•å¤ªæ…¢ï¼Œå·²è·³è¿‡ä»¥æé«˜æµ‹è¯•æ•ˆç‡")
        
        try:
            # æš‚æ—¶è·³è¿‡SAGEé˜Ÿåˆ—ï¼Œå› ä¸ºå­˜åœ¨å…±äº«å†…å­˜åˆ†é…é—®é¢˜
            print("âš ï¸ SAGEé˜Ÿåˆ—å­˜åœ¨å…±äº«å†…å­˜åˆ†é…é—®é¢˜ï¼Œè·³è¿‡SAGEé˜Ÿåˆ—æµ‹è¯•")
            # queue_configs.append({
            #     'name': 'SAGEé˜Ÿåˆ—',
            #     'creator': lambda: SageQueueDescriptor(maxsize=1024*1024, queue_id="perf_sage")
            # })
        except Exception:
            print("âš ï¸ SAGEé˜Ÿåˆ—ä¸å¯ç”¨ï¼Œè·³è¿‡SAGEé˜Ÿåˆ—æµ‹è¯•")
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        for config in queue_configs:
            queue_name = config['name']
            print(f"\n{'='*60}")
            print(f"æµ‹è¯•é˜Ÿåˆ—ç±»å‹: {queue_name}")
            print(f"{'='*60}")
            
            try:
                queue_desc = config['creator']()
                
                # è¿è¡Œå„ç§åŸºå‡†æµ‹è¯•
                self.results[queue_name] = {
                    'single_thread': self.single_thread_throughput_test(queue_desc, 5000),
                    'multi_thread': self.multi_thread_throughput_test(queue_desc, 4, 1250),
                    'latency': self.latency_test(queue_desc, 500),
                    'queue_size': self.queue_size_performance_test(queue_desc, 50000, 10000)
                }
                
                print(f"âœ… {queue_name} åŸºå‡†æµ‹è¯•å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ {queue_name} åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    def generate_benchmark_report(self):
        """ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print("åŸºå‡†æµ‹è¯•ç»“æœæŠ¥å‘Š")
        print(f"{'='*60}")
        
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        # ç”Ÿæˆæ±‡æ€»è¡¨
        print("\nğŸ“Š æ€§èƒ½æ±‡æ€»è¡¨:")
        print(f"{'é˜Ÿåˆ—ç±»å‹':<15} {'å•çº¿ç¨‹å†™å…¥':<12} {'å•çº¿ç¨‹è¯»å–':<12} {'å¤šçº¿ç¨‹å†™å…¥':<12} {'å¤šçº¿ç¨‹è¯»å–':<12} {'å¹³å‡å»¶è¿Ÿ':<10}")
        print("-" * 80)
        
        for queue_name, results in self.results.items():
            single_thread = results.get('single_thread', {})
            multi_thread = results.get('multi_thread', {})
            latency = results.get('latency', {})
            
            write_throughput = f"{single_thread.get('write_throughput', 0):.0f}"
            read_throughput = f"{single_thread.get('read_throughput', 0):.0f}"
            mt_write_throughput = f"{multi_thread.get('avg_producer_throughput', 0):.0f}"
            mt_read_throughput = f"{multi_thread.get('avg_consumer_throughput', 0):.0f}"
            avg_latency = f"{latency.get('avg_latency_ms', 0):.2f}ms"
            
            print(f"{queue_name:<15} {write_throughput:<12} {read_throughput:<12} {mt_write_throughput:<12} {mt_read_throughput:<12} {avg_latency:<10}")
        
        # è¯¦ç»†æŠ¥å‘Š
        print(f"\nğŸ“ è¯¦ç»†æ€§èƒ½æŠ¥å‘Š:")
        for queue_name, results in self.results.items():
            print(f"\n--- {queue_name} ---")
            
            if 'single_thread' in results:
                st = results['single_thread']
                print(f"å•çº¿ç¨‹: å†™å…¥ {st['write_throughput']:.0f} items/sec, è¯»å– {st['read_throughput']:.0f} items/sec")
                print(f"         å†…å­˜ä½¿ç”¨ {st['memory_delta_mb']:.2f} MB")
            
            if 'multi_thread' in results:
                mt = results['multi_thread']
                print(f"å¤šçº¿ç¨‹: ç”Ÿäº§è€…å¹³å‡ {mt['avg_producer_throughput']:.0f} items/sec")
                print(f"        æ¶ˆè´¹è€…å¹³å‡ {mt['avg_consumer_throughput']:.0f} items/sec")
                print(f"        æ¶ˆè´¹æˆåŠŸç‡ {mt['total_consumed']/mt['total_items']*100:.1f}%")
            
            if 'latency' in results:
                lat = results['latency']
                print(f"å»¶è¿Ÿ: å¹³å‡ {lat['avg_latency_ms']:.3f}ms, P95 {lat['p95_latency_ms']:.3f}ms, P99 {lat['p99_latency_ms']:.3f}ms")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        self._save_detailed_report()
    
    def _save_detailed_report(self):
        """ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        import json
        from pathlib import Path
        
        report_file = Path("benchmark_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†åŸºå‡†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file.absolute()}")


# ================================
# pytest æµ‹è¯•å‡½æ•°
# ================================

@pytest.fixture
def benchmark_instance():
    """åˆ›å»ºæ€§èƒ½åŸºå‡†æµ‹è¯•å®ä¾‹"""
    return PerformanceBenchmark()


@pytest.fixture
def python_thread_queue():
    """åˆ›å»ºPythonçº¿ç¨‹é˜Ÿåˆ—"""
    return PythonQueueDescriptor(maxsize=10000, use_multiprocessing=False, queue_id="test_python_thread")


@pytest.fixture
def python_mp_queue():
    """åˆ›å»ºPythonå¤šè¿›ç¨‹é˜Ÿåˆ—"""
    return PythonQueueDescriptor(maxsize=10000, use_multiprocessing=True, queue_id="test_python_mp")


@pytest.fixture
def ray_queue():
    """åˆ›å»ºRayé˜Ÿåˆ—ï¼ˆç”±äºæ€§èƒ½é—®é¢˜ï¼Œè·³è¿‡å¤§ååé‡æµ‹è¯•ï¼‰"""
    pytest.skip("Rayé˜Ÿåˆ—æ€§èƒ½æµ‹è¯•å¤ªæ…¢ï¼Œè·³è¿‡ä»¥æé«˜æµ‹è¯•æ•ˆç‡")


@pytest.fixture
def sage_queue():
    """åˆ›å»ºSAGEé˜Ÿåˆ—ï¼ˆä¼˜åŒ–å…±äº«å†…å­˜ä½¿ç”¨ï¼‰"""
    try:
        # å…ˆæ£€æŸ¥å…±äº«å†…å­˜å¯ç”¨ç©ºé—´
        import os
        import subprocess
        
        # æ£€æŸ¥ /dev/shm çš„å¯ç”¨ç©ºé—´
        result = subprocess.run(['df', '/dev/shm'], capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if len(lines) >= 2:
                # è§£æå¯ç”¨ç©ºé—´ (å•ä½é€šå¸¸æ˜¯KB)
                fields = lines[1].split()
                if len(fields) >= 4:
                    avail_kb = int(fields[3])
                    avail_mb = avail_kb / 1024
                    
                    # å¦‚æœå¯ç”¨ç©ºé—´å°‘äº5MBï¼Œè·³è¿‡æµ‹è¯•
                    if avail_mb < 5:
                        pytest.skip(f"å…±äº«å†…å­˜ç©ºé—´ä¸è¶³: åªæœ‰ {avail_mb:.1f}MB å¯ç”¨ï¼Œéœ€è¦è‡³å°‘ 5MB")
        
        # ä½¿ç”¨è¾ƒå°çš„é˜Ÿåˆ—å¤§å°ä»¥é¿å…å…±äº«å†…å­˜è€—å°½
        from sage_ext.sage_queue.python.sage_queue import SageQueue
        
        # ä½¿ç”¨1MBè€Œä¸æ˜¯10MBï¼Œå‡å°‘å…±äº«å†…å­˜ä½¿ç”¨
        queue_desc = SageQueueDescriptor(maxsize=1024*1024, queue_id="test_sage_small")
        
        # æµ‹è¯•é˜Ÿåˆ—æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
        queue_instance = queue_desc.queue_instance
        
        # ç®€å•çš„åŠŸèƒ½æµ‹è¯•
        test_data = "test_message"
        queue_instance.put(test_data)
        retrieved_data = queue_instance.get()
        
        if retrieved_data != test_data:
            pytest.skip("SAGEé˜Ÿåˆ—åŠŸèƒ½æµ‹è¯•å¤±è´¥")
            
        return queue_desc
        
    except ImportError:
        pytest.skip("SAGEé˜Ÿåˆ—æ¨¡å—ä¸å¯ç”¨")
    except Exception as e:
        if "bad_alloc" in str(e) or "shared memory" in str(e).lower():
            pytest.skip(f"SAGEé˜Ÿåˆ—å…±äº«å†…å­˜åˆ†é…å¤±è´¥: {e}")
        else:
            pytest.skip(f"SAGEé˜Ÿåˆ—åˆå§‹åŒ–å¤±è´¥: {e}")


def test_python_thread_queue_single_thread_performance(benchmark_instance, python_thread_queue):
    """æµ‹è¯•Pythonçº¿ç¨‹é˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½"""
    result = benchmark_instance.single_thread_throughput_test(python_thread_queue, 1000)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'python'
    assert result['num_items'] == 1000
    assert result['write_throughput'] > 0
    assert result['read_throughput'] > 0
    assert result['write_duration'] > 0
    assert result['read_duration'] > 0
    
    print(f"Pythonçº¿ç¨‹é˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½: å†™å…¥ {result['write_throughput']:.0f} items/sec, è¯»å– {result['read_throughput']:.0f} items/sec")


def test_python_thread_queue_multi_thread_performance(benchmark_instance, python_thread_queue):
    """æµ‹è¯•Pythonçº¿ç¨‹é˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½"""
    result = benchmark_instance.multi_thread_throughput_test(python_thread_queue, 2, 500)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'python'
    assert result['num_threads'] == 2
    assert result['items_per_thread'] == 500
    assert result['total_items'] == 1000
    assert result['avg_producer_throughput'] > 0
    assert result['avg_consumer_throughput'] > 0
    
    print(f"Pythonçº¿ç¨‹é˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½: ç”Ÿäº§è€… {result['avg_producer_throughput']:.0f} items/sec, æ¶ˆè´¹è€… {result['avg_consumer_throughput']:.0f} items/sec")


def test_python_thread_queue_latency(benchmark_instance, python_thread_queue):
    """æµ‹è¯•Pythonçº¿ç¨‹é˜Ÿåˆ—å»¶è¿Ÿ"""
    result = benchmark_instance.latency_test(python_thread_queue, 100)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'python'
    assert result['num_samples'] == 100
    assert result['avg_latency_ms'] > 0
    assert result['median_latency_ms'] > 0
    assert result['min_latency_ms'] >= 0
    assert result['max_latency_ms'] >= result['avg_latency_ms']
    assert result['p95_latency_ms'] >= result['median_latency_ms']
    assert result['p99_latency_ms'] >= result['p95_latency_ms']
    
    print(f"Pythonçº¿ç¨‹é˜Ÿåˆ—å»¶è¿Ÿ: å¹³å‡ {result['avg_latency_ms']:.3f}ms, P95 {result['p95_latency_ms']:.3f}ms")


def test_python_mp_queue_single_thread_performance(benchmark_instance, python_mp_queue):
    """æµ‹è¯•Pythonå¤šè¿›ç¨‹é˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½"""
    result = benchmark_instance.single_thread_throughput_test(python_mp_queue, 1000)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'python'
    assert result['num_items'] == 1000
    assert result['write_throughput'] > 0
    assert result['read_throughput'] > 0
    
    print(f"Pythonå¤šè¿›ç¨‹é˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½: å†™å…¥ {result['write_throughput']:.0f} items/sec, è¯»å– {result['read_throughput']:.0f} items/sec")


def test_python_mp_queue_multi_thread_performance(benchmark_instance, python_mp_queue):
    """æµ‹è¯•Pythonå¤šè¿›ç¨‹é˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½"""
    result = benchmark_instance.multi_thread_throughput_test(python_mp_queue, 2, 500)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'python'
    assert result['num_threads'] == 2
    assert result['avg_producer_throughput'] > 0
    assert result['avg_consumer_throughput'] > 0
    
    print(f"Pythonå¤šè¿›ç¨‹é˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½: ç”Ÿäº§è€… {result['avg_producer_throughput']:.0f} items/sec, æ¶ˆè´¹è€… {result['avg_consumer_throughput']:.0f} items/sec")


def test_ray_queue_single_thread_performance(benchmark_instance, ray_queue):
    """æµ‹è¯•Rayé˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½"""
    result = benchmark_instance.single_thread_throughput_test(ray_queue, 1000)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'ray_queue'
    assert result['num_items'] == 1000
    assert result['write_throughput'] > 0
    assert result['read_throughput'] > 0
    
    print(f"Rayé˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½: å†™å…¥ {result['write_throughput']:.0f} items/sec, è¯»å– {result['read_throughput']:.0f} items/sec")


def test_ray_queue_multi_thread_performance(benchmark_instance, ray_queue):
    """æµ‹è¯•Rayé˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½"""
    result = benchmark_instance.multi_thread_throughput_test(ray_queue, 2, 500)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'ray_queue'
    assert result['num_threads'] == 2
    assert result['avg_producer_throughput'] > 0
    assert result['avg_consumer_throughput'] > 0
    
    print(f"Rayé˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½: ç”Ÿäº§è€… {result['avg_producer_throughput']:.0f} items/sec, æ¶ˆè´¹è€… {result['avg_consumer_throughput']:.0f} items/sec")


def test_sage_queue_single_thread_performance(benchmark_instance, sage_queue):
    """æµ‹è¯•SAGEé˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½"""
    try:
        result = benchmark_instance.single_thread_throughput_test(sage_queue, 500)  # å‡å°‘æµ‹è¯•æ•°æ®é‡
        
        # åŸºæœ¬æ–­è¨€
        assert result['queue_type'] == 'sage_queue'
        assert result['num_items'] == 500
        assert result['write_throughput'] > 0
        assert result['read_throughput'] > 0
        
        print(f"SAGEé˜Ÿåˆ—å•çº¿ç¨‹æ€§èƒ½: å†™å…¥ {result['write_throughput']:.0f} items/sec, è¯»å– {result['read_throughput']:.0f} items/sec")
    finally:
        # æ¸…ç†é˜Ÿåˆ—ä»¥é‡Šæ”¾å…±äº«å†…å­˜
        if hasattr(sage_queue, 'queue_instance') and hasattr(sage_queue.queue_instance, 'close'):
            sage_queue.queue_instance.close()


def test_sage_queue_multi_thread_performance(benchmark_instance, sage_queue):
    """æµ‹è¯•SAGEé˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½"""
    try:
        result = benchmark_instance.multi_thread_throughput_test(sage_queue, 2, 250)  # å‡å°‘æµ‹è¯•æ•°æ®é‡
        
        # åŸºæœ¬æ–­è¨€
        assert result['queue_type'] == 'sage_queue'
        assert result['num_threads'] == 2
        assert result['avg_producer_throughput'] > 0
        assert result['avg_consumer_throughput'] > 0
        
        print(f"SAGEé˜Ÿåˆ—å¤šçº¿ç¨‹æ€§èƒ½: ç”Ÿäº§è€… {result['avg_producer_throughput']:.0f} items/sec, æ¶ˆè´¹è€… {result['avg_consumer_throughput']:.0f} items/sec")
    finally:
        # æ¸…ç†é˜Ÿåˆ—ä»¥é‡Šæ”¾å…±äº«å†…å­˜
        if hasattr(sage_queue, 'queue_instance') and hasattr(sage_queue.queue_instance, 'close'):
            sage_queue.queue_instance.close()


def test_queue_size_impact_on_performance(benchmark_instance, python_thread_queue):
    """æµ‹è¯•é˜Ÿåˆ—å¤§å°å¯¹æ€§èƒ½çš„å½±å“"""
    result = benchmark_instance.queue_size_performance_test(python_thread_queue, 10000, 2500)
    
    # åŸºæœ¬æ–­è¨€
    assert result['queue_type'] == 'python'
    assert result['max_size'] == 10000
    assert len(result['size_results']) > 0
    
    # æ£€æŸ¥æ¯ä¸ªå¤§å°çš„ç»“æœ
    for size_result in result['size_results']:
        assert size_result['queue_size'] > 0
        assert size_result['fill_throughput'] > 0
        assert size_result['read_throughput'] > 0
        assert size_result['memory_mb'] > 0
    
    print(f"é˜Ÿåˆ—å¤§å°æ€§èƒ½æµ‹è¯•å®Œæˆ: æµ‹è¯•äº† {len(result['size_results'])} ä¸ªä¸åŒå¤§å°")


@pytest.mark.slow
def test_comprehensive_performance_benchmark():
    """ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆæ ‡è®°ä¸ºæ…¢é€Ÿæµ‹è¯•ï¼‰"""
    benchmark = PerformanceBenchmark()
    
    # è¿è¡Œç»¼åˆåŸºå‡†æµ‹è¯•
    benchmark.run_all_benchmarks()
    benchmark.generate_benchmark_report()
    
    # éªŒè¯ç»“æœ
    assert len(benchmark.results) > 0
    print("âœ… ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ")


def run_performance_benchmarks():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆä¿ç•™åŸå§‹å‡½æ•°ç”¨äºç‹¬ç«‹è¿è¡Œï¼‰"""
    benchmark = PerformanceBenchmark()
    
    try:
        benchmark.run_all_benchmarks()
        benchmark.generate_benchmark_report()
        return True
    except Exception as e:
        print(f"âŒ æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œè„šæœ¬ï¼Œæ‰§è¡Œç»¼åˆåŸºå‡†æµ‹è¯•
    success = run_performance_benchmarks()
    sys.exit(0 if success else 1)
