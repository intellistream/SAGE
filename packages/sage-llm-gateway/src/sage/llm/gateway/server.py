"""
SAGE Gateway FastAPI Server

æä¾› OpenAI/Anthropic å…¼å®¹çš„ REST APIï¼Œå¹¶é›†æˆ Control Plane ç®¡ç†åŠŸèƒ½ã€‚

Key Features:
- OpenAI å…¼å®¹çš„ /v1/chat/completions ç«¯ç‚¹
- ä¼šè¯ç®¡ç† (Session Management)
- RAG ç´¢å¼•ç®¡ç†
- Control Plane å¼•æ“ç®¡ç† (/v1/management/*)
"""

# pyright: reportMissingImports=false

import logging
import os
import time
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

from sage.common.config.ports import SagePorts
from sage.llm.gateway.adapters import ChatCompletionRequest, OpenAIAdapter
from sage.llm.gateway.routes.engine_control_plane import (
    control_plane_router as engine_control_plane_router,
)
from sage.llm.gateway.routes.engine_control_plane import (
    get_control_plane_manager,
    init_control_plane,
    start_control_plane,
    stop_control_plane,
)
from sage.llm.gateway.routes.studio import studio_router
from sage.llm.gateway.session import get_session_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("sage.llm.gateway")


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ SAGE Gateway starting...")

    # Initialize and start Control Plane if enabled
    enable_control_plane = os.getenv("SAGE_GATEWAY_ENABLE_CONTROL_PLANE", "true").lower() == "true"
    if enable_control_plane:
        scheduling_policy = os.getenv("SAGE_GATEWAY_SCHEDULING_POLICY", "adaptive")
        if init_control_plane(scheduling_policy=scheduling_policy):
            await start_control_plane()
            logger.info("âœ… Control Plane enabled")
        else:
            logger.warning("âš ï¸ Control Plane initialization failed, continuing without it")

    yield

    # Stop Control Plane on shutdown
    if enable_control_plane:
        await stop_control_plane()

    logger.info("ğŸ‘‹ SAGE Gateway shutting down...")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="SAGE Gateway",
    description="OpenAI/Anthropic compatible API gateway for SAGE framework",
    version="0.1.0",
    lifespan=lifespan,
)


@app.middleware("http")
async def api_prefix_middleware(request: Request, call_next):
    """
    Middleware to handle /api prefix for Gateway routes.

    In some deployment scenarios (e.g. production without Vite proxy),
    requests might reach the Gateway with /api prefix (e.g. /api/v1/chat/completions).
    We strip this prefix for specific Gateway routes to ensure they match.
    """
    path = request.url.path
    if path.startswith("/api/v1/") or path.startswith("/api/sessions") or path == "/api/health":
        request.scope["path"] = path.replace("/api", "", 1)

    response = await call_next(request)
    return response


# CORS é…ç½®ï¼ˆå…è®¸ sage-studio è°ƒç”¨ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # NOTE: ç”Ÿäº§ç¯å¢ƒåº”é…ç½®å…·ä½“çš„å…è®¸åŸŸååˆ—è¡¨
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–é€‚é…å™¨
openai_adapter = OpenAIAdapter()
session_manager = get_session_manager()

# æŒ‚è½½ Control Plane ç®¡ç†è·¯ç”±
app.include_router(engine_control_plane_router)
# æŒ‚è½½ Studio Backend è·¯ç”±ï¼ˆåŸ Studio Backend æœåŠ¡ç°åˆå¹¶åˆ° Gatewayï¼‰
app.include_router(studio_router)


class SessionCreatePayload(BaseModel):
    title: str | None = None


class SessionTitlePayload(BaseModel):
    title: str


class MemoryConfigPayload(BaseModel):
    """è®°å¿†é…ç½®"""

    backend: str  # short_term, vdb, kv, graph
    max_dialogs: int | None = None  # çŸ­æœŸè®°å¿†çª—å£å¤§å°
    embedding_model: str | None = None  # VDB åµŒå…¥æ¨¡å‹
    embedding_dim: int | None = None  # VDB å‘é‡ç»´åº¦
    index_type: str | None = None  # KV ç´¢å¼•ç±»å‹


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "SAGE Gateway",
        "version": "0.1.0",
        "endpoints": {
            "chat": "/v1/chat/completions",
            "embeddings": "/v1/embeddings",
            "health": "/health",
            "sessions": "/sessions",
            "index": {
                "status": "/admin/index/status",
                "build": "/admin/index/build",
            },
            "control_plane": {
                "engines": "/v1/management/engines",
                "start_engine": "POST /v1/management/engines",
                "register_engine": "POST /v1/management/engines/register",
                "stop_engine": "DELETE /v1/management/engines/{engine_id}",
                "status": "/v1/management/status",
                "backends": "/v1/management/backends",
                "gpu": "/v1/management/gpu",
            },
        },
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    stats = session_manager.get_stats()
    return {
        "status": "healthy",
        "sessions": stats,
    }


@app.get("/v1/models")
async def list_models():
    """
    OpenAI-compatible models endpoint.
    Returns list of available models from Control Plane.
    """
    manager = get_control_plane_manager()
    models = []

    if manager:
        # Get status which includes engines
        status = manager.get_cluster_status()
        engines = status.get("engines", []) or status.get("engine_instances", [])

        seen_models = set()
        for engine in engines:
            # Support both dict and object access if needed, though usually dict here
            if isinstance(engine, dict):
                model_id = engine.get("model_id") or engine.get("model_name")
            else:
                model_id = getattr(engine, "model_id", None)

            if model_id and model_id not in seen_models:
                # Filter out embedding models
                runtime = (
                    engine.get("runtime")
                    if isinstance(engine, dict)
                    else getattr(engine, "runtime", None)
                )
                if runtime == "embedding":
                    continue

                seen_models.add(model_id)
                models.append(
                    {
                        "id": model_id,
                        "object": "model",
                        "created": int(time.time()),
                        "owned_by": "sage",
                    }
                )

    return {"object": "list", "data": models}


@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest):
    """
    OpenAI å…¼å®¹çš„ chat completions ç«¯ç‚¹

    æ”¯æŒï¼š
    - éæµå¼å“åº” (stream=false)
    - æµå¼å“åº” (stream=true, SSE)
    - ä¼šè¯ç®¡ç† (session_id)
    """
    try:
        logger.info(f"Chat request: model={request.model}, stream={request.stream}")

        response = await openai_adapter.chat_completions(request)

        if request.stream:
            # æµå¼å“åº”ï¼ˆSSEï¼‰
            return StreamingResponse(
                response,
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                },
            )
        else:
            # éæµå¼å“åº”
            return response

    except Exception as e:
        logger.error(f"Error processing chat request: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


class EmbeddingRequest(BaseModel):
    """OpenAI å…¼å®¹çš„ Embedding è¯·æ±‚"""

    input: str | list[str]
    model: str | None = None
    encoding_format: str = "float"


@app.post("/v1/embeddings")
async def create_embeddings(request: EmbeddingRequest):
    """
    OpenAI å…¼å®¹çš„ embeddings ç«¯ç‚¹

    é€šè¿‡ Control Plane å°†è¯·æ±‚è·¯ç”±åˆ°å¯ç”¨çš„ Embedding åç«¯ã€‚
    """
    import httpx

    try:
        # è·å– Control Plane manager
        manager = get_control_plane_manager()
        if manager is None:
            raise HTTPException(
                status_code=503,
                detail="Control Plane not initialized. Start Gateway with --control-plane",
            )

        # è·å–å¯ç”¨çš„ embedding åç«¯
        backends_info = manager.get_registered_backends()
        embedding_backends = backends_info.get("embedding_backends", [])

        if not embedding_backends:
            raise HTTPException(
                status_code=503,
                detail="No embedding backend available",
            )

        # é€‰æ‹©ç¬¬ä¸€ä¸ªå¥åº·çš„åç«¯
        backend = None
        for b in embedding_backends:
            if b.get("healthy", False):
                backend = b
                break

        if not backend:
            # å¦‚æœæ²¡æœ‰å¥åº·çš„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
            backend = embedding_backends[0]

        # æ„å»ºåç«¯ URL
        host = backend.get("host", "localhost")
        port = backend.get("port", 8090)
        backend_url = f"http://{host}:{port}/v1/embeddings"

        logger.info(f"Proxying embedding request to {backend_url}")

        # ä»£ç†è¯·æ±‚åˆ°åç«¯
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                backend_url,
                json={
                    "input": request.input,
                    "model": request.model or backend.get("model_id", "default"),
                    "encoding_format": request.encoding_format,
                },
            )
            response.raise_for_status()
            return response.json()

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error processing embedding request: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/sessions")
async def list_sessions():
    """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
    return {
        "sessions": session_manager.list_sessions(),
        "stats": session_manager.get_stats(),
    }


@app.post("/sessions")
async def create_session(payload: SessionCreatePayload):
    """åˆ›å»ºæ–°çš„ä¼šè¯"""
    session = session_manager.create_session(title=payload.title)
    return session.to_dict()


@app.get("/sessions/{session_id}")
async def get_session(session_id: str):
    """è·å–ä¼šè¯è¯¦æƒ…"""
    session = session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    return session.to_dict()


@app.post("/sessions/{session_id}/clear")
async def clear_session(session_id: str):
    """æ¸…ç©ºä¼šè¯å†å²"""
    if not session_manager.clear_session(session_id):
        raise HTTPException(status_code=404, detail="Session not found")
    return {"status": "cleared", "session_id": session_id}


@app.patch("/sessions/{session_id}/title")
async def update_session_title(session_id: str, payload: SessionTitlePayload):
    """æ›´æ–°ä¼šè¯æ ‡é¢˜"""
    if not session_manager.rename_session(session_id, payload.title):
        raise HTTPException(status_code=404, detail="Session not found")
    return {"status": "updated", "session_id": session_id, "title": payload.title}


@app.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    """åˆ é™¤ä¼šè¯"""
    success = session_manager.delete(session_id)
    if not success:
        raise HTTPException(status_code=404, detail="Session not found")
    return {"status": "deleted", "session_id": session_id}


@app.post("/sessions/cleanup")
async def cleanup_sessions(max_age_minutes: int = 30):
    """æ¸…ç†è¿‡æœŸä¼šè¯"""
    count = session_manager.cleanup_expired(max_age_minutes)
    return {
        "status": "cleaned",
        "removed_sessions": count,
    }


# ==================== Memory Configuration APIs ====================


@app.get("/memory/config")
async def get_memory_config():
    """è·å–å½“å‰è®°å¿†é…ç½®

    Returns:
        å½“å‰çš„è®°å¿†åç«¯ç±»å‹å’Œé…ç½®
    """
    return {
        "backend": session_manager._memory_backend,
        "max_dialogs": session_manager._max_memory_dialogs,
        "config": session_manager._memory_config,
        "available_backends": ["short_term", "vdb", "kv", "graph"],
    }


@app.get("/memory/stats")
async def get_memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯

    Returns:
        å„ä¼šè¯çš„è®°å¿†ä½¿ç”¨æƒ…å†µ
    """
    stats = {}
    for session_id, memory_service in session_manager._memory_services.items():
        if session_manager._memory_backend == "short_term":
            # çŸ­æœŸè®°å¿†ç»Ÿè®¡
            stats[session_id] = {
                "backend": "short_term",
                "dialog_count": len(memory_service.dialog_queue),
                "max_dialogs": memory_service.max_dialog,
                "usage_percent": (
                    len(memory_service.dialog_queue) / memory_service.max_dialog * 100
                    if memory_service.max_dialog > 0
                    else 0
                ),
            }
        else:
            # neuromem collection ç»Ÿè®¡
            stats[session_id] = {
                "backend": session_manager._memory_backend,
                "collection_name": getattr(memory_service, "name", "unknown"),
                "has_index": hasattr(memory_service, "_gateway_index_name"),
            }

    return {
        "total_sessions": len(stats),
        "sessions": stats,
    }


# ==================== Index Management APIs ====================


class IndexBuildPayload(BaseModel):
    """ç´¢å¼•æ„å»ºè¯·æ±‚"""

    source_dir: str | None = None  # æºæ–‡æ¡£ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ docs-public/docs_src
    force_rebuild: bool = False  # å¼ºåˆ¶é‡å»ºï¼ˆå³ä½¿å·²å­˜åœ¨ï¼‰


@app.get("/admin/index/status")
async def get_index_status():
    """è·å–ç´¢å¼•çŠ¶æ€

    Returns:
        ç´¢å¼•çš„å…ƒæ•°æ®ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡æ¡£æ•°ã€chunkæ•°ã€åˆ›å»ºæ—¶é—´ç­‰
    """
    import json
    from pathlib import Path

    index_dir = Path.home() / ".sage" / "vector_db"
    manifest_path = index_dir / "manifest.json"

    if not manifest_path.exists():
        return {
            "status": "not_found",
            "message": "RAG index has not been built yet",
        }

    try:
        with open(manifest_path) as f:
            manifest = json.load(f)

        return {
            "status": "ready",
            "index": manifest,
        }
    except Exception as e:
        logger.error(f"Failed to load index manifest: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to load index: {str(e)}")


@app.post("/admin/index/build")
async def build_index(payload: IndexBuildPayload):
    """è§¦å‘ç´¢å¼•æ„å»º

    Args:
        payload: åŒ…å« source_dir å’Œ force_rebuild é€‰é¡¹

    Returns:
        æ„å»ºç»“æœå’Œç´¢å¼•å…ƒæ•°æ®
    """
    import json
    from pathlib import Path

    index_dir = Path.home() / ".sage" / "vector_db"
    manifest_path = index_dir / "manifest.json"

    # Check if index exists and force_rebuild is False
    if manifest_path.exists() and not payload.force_rebuild:
        with open(manifest_path) as f:
            existing_manifest = json.load(f)

        return {
            "status": "already_exists",
            "message": "Index already exists. Use force_rebuild=true to rebuild.",
            "index": existing_manifest,
        }

    # Determine source directory
    if payload.source_dir:
        source_dir = Path(payload.source_dir)
    else:
        # Auto-detect
        from sage.common.config.output_paths import find_sage_project_root

        project_root = find_sage_project_root()
        if project_root:
            source_dir = project_root / "docs-public" / "docs_src"
        else:
            source_dir = Path.cwd() / "docs-public" / "docs_src"
            if not source_dir.exists():
                source_dir = Path.home() / "SAGE" / "docs-public" / "docs_src"

    if not source_dir.exists():
        raise HTTPException(
            status_code=400,
            detail=f"Source directory not found: {source_dir}",
        )

    try:
        # Clear existing index if force_rebuild
        if payload.force_rebuild and index_dir.exists():
            import shutil

            shutil.rmtree(index_dir)
            logger.info(f"Removed existing index at {index_dir}")

        # Build index (reuse adapter's method)
        openai_adapter._build_index_from_docs(source_dir, index_dir)

        # Load manifest
        with open(manifest_path) as f:
            manifest = json.load(f)

        return {
            "status": "built",
            "message": "Index built successfully",
            "index": manifest,
        }

    except Exception as e:
        logger.error(f"Failed to build index: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to build index: {str(e)}")


@app.delete("/admin/index")
async def delete_index():
    """åˆ é™¤ç´¢å¼•

    Returns:
        åˆ é™¤ç»“æœ
    """
    import shutil
    from pathlib import Path

    index_dir = Path.home() / ".sage" / "vector_db"

    if not index_dir.exists():
        return {
            "status": "not_found",
            "message": "No index to delete",
        }

    try:
        shutil.rmtree(index_dir)
        logger.info(f"Deleted index at {index_dir}")

        return {
            "status": "deleted",
            "message": f"Index deleted: {index_dir}",
        }

    except Exception as e:
        logger.error(f"Failed to delete index: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to delete index: {str(e)}")


# ==================== Main Entry Point ====================


def main():
    """ä¸»å…¥å£"""
    import uvicorn

    # Support environment variable configuration
    host = os.getenv("SAGE_GATEWAY_HOST", "0.0.0.0")
    port = int(os.getenv("SAGE_GATEWAY_PORT", str(SagePorts.GATEWAY_DEFAULT)))

    logger.info(f"Starting SAGE Gateway server on {host}:{port}...")
    uvicorn.run(
        "sage.llm.gateway.server:app",
        host=host,
        port=port,
        reload=False,
        log_level="info",
    )


if __name__ == "__main__":
    main()
