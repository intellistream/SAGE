# sage-gateway

**SAGE API Gateway** - OpenAI/Anthropic compatible protocol adapter for SAGE framework.

## Overview

`sage-gateway` provides familiar API interfaces (OpenAI, Anthropic) that translate requests into
SAGE's DataStream execution model. This allows users to interact with SAGE using APIs they already
know, without learning new protocols.

## Features

- âœ… **OpenAI Compatible API** - `/v1/chat/completions` endpoint
- âœ… **Streaming Support** - Server-Sent Events (SSE) for real-time responses
- âœ… **Session Management** - Conversation history and context handling
- ğŸš§ **Anthropic Compatible API** - `/v1/messages` endpoint (coming soon)
- ğŸš§ **WebSocket Support** - Real-time bidirectional streaming (coming soon)

## Installation

```bash
# From PyPI (when published)
pip install sage-gateway

# From source (development)
cd packages/sage-gateway
pip install -e .
```

## Quick Start

### Start the Gateway Server

```bash
# Using the CLI
sage-gateway --host 0.0.0.0 --port 8000

# Or with Python
python -m sage.gateway.server
```

### Call with OpenAI SDK

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="sage-token",  # pragma: allowlist secret  # Any non-empty string
)

response = client.chat.completions.create(
    model="sage-default",
    messages=[
        {"role": "user", "content": "Hello, how are you?"}
    ],
    stream=True
)

for chunk in response:
    print(chunk.choices[0].delta.content, end="")
```

### Call with cURL

```bash
# Non-streaming
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sage-token" \
  -d '{
    "model": "sage-default",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'

# Streaming
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sage-token" \
  -d '{
    "model": "sage-default",
    "messages": [{"role": "user", "content": "Hello!"}],
    "stream": true
  }'
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          sage-gateway (L6)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  FastAPI Server                                 â”‚
â”‚  â”œâ”€ /v1/chat/completions (OpenAI compat)       â”‚
â”‚  â”œâ”€ /v1/messages (Anthropic compat)            â”‚
â”‚  â””â”€ /health, /metrics                          â”‚
â”‚                                                  â”‚
â”‚  Adapters                                       â”‚
â”‚  â”œâ”€ OpenAI Protocol â†’ SAGE Kernel              â”‚
â”‚  â””â”€ Anthropic Protocol â†’ SAGE Kernel           â”‚
â”‚                                                  â”‚
â”‚  Session Manager                                â”‚
â”‚  â””â”€ Conversation history, context tracking     â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          sage-kernel (L3)                       â”‚
â”‚  DataStream API â†’ Execution Engine              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Configuration

Create a `.env` file or set environment variables:

```bash
# Server
SAGE_GATEWAY_HOST=0.0.0.0
SAGE_GATEWAY_PORT=8000
SAGE_GATEWAY_WORKERS=4

# Authentication (optional)
SAGE_GATEWAY_API_KEY=your-secret-key

# Session storage (optional)
SAGE_GATEWAY_SESSION_BACKEND=memory  # or redis
SAGE_GATEWAY_REDIS_URL=redis://localhost:6379

# LLM Backend Configuration (REQUIRED for real LLM responses)
# Option 1: Alibaba DashScope (Qwen models)
SAGE_CHAT_MODEL=qwen-max
SAGE_CHAT_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
ALIBABA_API_KEY=your-dashscope-api-key

# Option 2: OpenAI
SAGE_CHAT_MODEL=gpt-4o-mini
SAGE_CHAT_BASE_URL=https://api.openai.com/v1
SAGE_CHAT_API_KEY=sk-your-openai-api-key

# Option 3: Local vLLM server
SAGE_CHAT_MODEL=meta-llama/Llama-2-13b-chat-hf
SAGE_CHAT_BASE_URL=http://localhost:8000/v1
SAGE_CHAT_API_KEY=empty  # pragma: allowlist secret

# Option 4: Ollama
SAGE_CHAT_MODEL=llama3.1:8b
SAGE_CHAT_BASE_URL=http://localhost:11434/v1
SAGE_CHAT_API_KEY=empty  # pragma: allowlist secret

# Logging
SAGE_GATEWAY_LOG_LEVEL=INFO
```

**Note:** If no API key is configured, the gateway will run in **development mode** and echo back
user messages with a warning. Set `SAGE_CHAT_API_KEY` or `ALIBABA_API_KEY` to enable real LLM
responses.

## Development

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/

# Start in development mode
uvicorn sage.gateway.server:app --reload --port 8000
```

## API Reference

### POST /v1/chat/completions

OpenAI-compatible chat completion endpoint.

**Request Body:**

```json
{
  "model": "sage-default",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
  ],
  "stream": false,
  "temperature": 1.0,
  "max_tokens": null
}
```

**Response (non-streaming):**

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1677858242,
  "model": "sage-default",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you today?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

## License

MIT License - see LICENSE file for details.
