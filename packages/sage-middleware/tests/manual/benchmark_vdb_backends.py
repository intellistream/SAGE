#!/usr/bin/env python
"""Performance benchmark: SageDB vs FAISS

Compares the performance of two VDB backends:
- SageDB: Self-developed C++ vector database (NOT FAISS-based)
- FAISS: Third-party Python wrapper (Facebook AI Research)

Benchmarks:
- Vector insertion (single & batch)
- Vector search (various k values)
- Memory usage
- Index building time

Note: SageDB is a fully custom C++ implementation. ANNS algorithms
will be migrated to sage-libs in the future for better modularity.
"""

import sys
import time
from pathlib import Path
from typing import Any, Callable

import numpy as np
import psutil

# Add SAGE to path
sage_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(sage_root / "packages/sage-middleware/src"))


class BenchmarkResult:
    """å­˜å‚¨åŸºå‡†æµ‹è¯•ç»“æœ"""

    def __init__(self, name: str):
        self.name = name
        self.times: list[float] = []
        self.memory_usage: list[float] = []

    def add_measurement(self, time_ms: float, memory_mb: float):
        self.times.append(time_ms)
        self.memory_usage.append(memory_mb)

    @property
    def avg_time(self) -> float:
        return np.mean(self.times) if self.times else 0.0

    @property
    def std_time(self) -> float:
        return np.std(self.times) if self.times else 0.0

    @property
    def avg_memory(self) -> float:
        return np.mean(self.memory_usage) if self.memory_usage else 0.0


def measure_memory() -> float:
    """è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰"""
    process = psutil.Process()
    return process.memory_info().rss / 1024 / 1024


def benchmark_operation(
    operation: Callable[[], Any], name: str, warmup: int = 1, iterations: int = 5
) -> BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ä¸€ä¸ªæ“ä½œ"""
    result = BenchmarkResult(name)

    # Warmup
    for _ in range(warmup):
        operation()

    # Benchmark
    for _ in range(iterations):
        mem_before = measure_memory()
        start = time.perf_counter()

        operation()

        end = time.perf_counter()
        mem_after = measure_memory()

        time_ms = (end - start) * 1000
        memory_mb = mem_after - mem_before

        result.add_measurement(time_ms, memory_mb)

    return result


def create_test_vectors(n: int, dim: int) -> list[np.ndarray]:
    """åˆ›å»ºæµ‹è¯•å‘é‡"""
    return [np.random.randn(dim).astype(np.float32) for _ in range(n)]


def benchmark_backend(backend_name: str, dim: int = 128, n_vectors: int = 10000):
    """åŸºå‡†æµ‹è¯•ä¸€ä¸ªåç«¯"""
    from sage.middleware.components.sage_mem.neuromem.search_engine.vdb_index import create_index

    print(f"\n{'=' * 60}")
    print(f"Benchmarking {backend_name} backend")
    print(f"{'=' * 60}")
    print(f"Dimension: {dim}, Vectors: {n_vectors}")

    # åˆ›å»ºç´¢å¼•
    config = {"name": f"test_{backend_name.lower()}", "dim": dim, "backend_type": backend_name}

    index = create_index(config)

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    vectors = create_test_vectors(n_vectors, dim)
    vector_ids = [f"vec_{i}" for i in range(n_vectors)]
    query_vectors = create_test_vectors(100, dim)  # 100 queries

    results = {}

    # 1. å•ä¸ªæ’å…¥åŸºå‡†
    print("\n1ï¸âƒ£  Single insert benchmark...")
    test_vectors = vectors[:100]  # åªæµ‹è¯•å‰100ä¸ª
    test_ids = vector_ids[:100]

    def single_insert():
        for vec, vid in zip(test_vectors, test_ids):
            index.insert(vec, f"{vid}_single")

    results["single_insert"] = benchmark_operation(
        single_insert, "Single Insert (100 vectors)", warmup=0, iterations=1
    )

    # 2. æ‰¹é‡æ’å…¥åŸºå‡†
    print("2ï¸âƒ£  Batch insert benchmark...")
    batch_vectors = vectors
    batch_ids = vector_ids

    def batch_insert():
        index.batch_insert(batch_vectors, batch_ids)

    results["batch_insert"] = benchmark_operation(
        batch_insert, f"Batch Insert ({n_vectors} vectors)", warmup=0, iterations=1
    )

    # 3. æœç´¢åŸºå‡† (ä¸åŒ k å€¼)
    for k in [1, 5, 10, 50]:
        print(f"3ï¸âƒ£  Search benchmark (k={k})...")

        def search_k():
            for query in query_vectors:
                index.search(query, topk=k)

        results[f"search_k{k}"] = benchmark_operation(
            search_k, f"Search (k={k}, 100 queries)", warmup=1, iterations=3
        )

    # 4. å†…å­˜å ç”¨
    mem_usage = measure_memory()
    print(f"\n4ï¸âƒ£  Memory usage: {mem_usage:.2f} MB")

    return results


def print_comparison_table(faiss_results: dict, sagedb_results: dict):
    """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
    print("\n" + "=" * 80)
    print("Performance Comparison: FAISS vs SageDB")
    print("=" * 80)

    # è¡¨å¤´
    print(f"\n{'Operation':<30} {'FAISS (ms)':<15} {'SageDB (ms)':<15} {'Speedup':<10}")
    print("-" * 80)

    # å¯¹æ¯”æ¯ä¸ªæ“ä½œ
    for op_name in faiss_results.keys():
        faiss_result = faiss_results[op_name]
        sagedb_result = sagedb_results.get(op_name)

        if sagedb_result:
            faiss_time = faiss_result.avg_time
            sagedb_time = sagedb_result.avg_time
            speedup = faiss_time / sagedb_time if sagedb_time > 0 else 0.0

            speedup_str = f"{speedup:.2f}x" if speedup > 0 else "N/A"
            if speedup > 1.0:
                speedup_str = f"ğŸš€ {speedup_str}"
            elif speedup < 1.0 and speedup > 0:
                speedup_str = f"ğŸ¢ {speedup_str}"

            print(
                f"{faiss_result.name:<30} "
                f"{faiss_time:>12.2f} Â±{faiss_result.std_time:>5.2f}  "
                f"{sagedb_time:>12.2f} Â±{sagedb_result.std_time:>5.2f}  "
                f"{speedup_str:<10}"
            )


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("VDB Backend Performance Benchmark")
    print("=" * 80)
    print("\nComparing FAISS vs SageDB performance...")
    print("This may take a few minutes...\n")

    # æµ‹è¯•å‚æ•°
    dim = 128
    n_vectors = 5000  # å‡å°‘åˆ° 5000 ä»¥åŠ å¿«æµ‹è¯•

    try:
        # åŸºå‡†æµ‹è¯• FAISS
        faiss_results = benchmark_backend("FAISS", dim, n_vectors)

        # åŸºå‡†æµ‹è¯• SageDB
        sagedb_results = benchmark_backend("SageDB", dim, n_vectors)

        # æ‰“å°å¯¹æ¯”
        print_comparison_table(faiss_results, sagedb_results)

        # æ€»ç»“
        print("\n" + "=" * 80)
        print("Summary")
        print("=" * 80)

        # è®¡ç®—å¹³å‡åŠ é€Ÿæ¯”
        speedups = []
        for op_name in faiss_results.keys():
            faiss_time = faiss_results[op_name].avg_time
            sagedb_time = sagedb_results[op_name].avg_time
            if sagedb_time > 0:
                speedups.append(faiss_time / sagedb_time)

        avg_speedup = np.mean(speedups) if speedups else 0.0

        print(f"\nAverage speedup: {avg_speedup:.2f}x")

        if avg_speedup > 1.1:
            print("âœ… SageDB is faster overall")
            print("ğŸ’¡ Recommendation: Use SageDB for production workloads")
        elif avg_speedup < 0.9:
            print("âœ… FAISS is faster overall")
            print("ğŸ’¡ Recommendation: FAISS may be better for your workload")
        else:
            print("âš–ï¸  Performance is similar")
            print("ğŸ’¡ Recommendation: Choose based on other factors (ease of use, features)")

        print("\nâœ… Benchmark completed successfully!")

    except Exception as e:
        print(f"\nâŒ Benchmark failed: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
