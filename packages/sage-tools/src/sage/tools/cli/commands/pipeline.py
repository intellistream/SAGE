#!/usr/bin/env python3
"""Interactive pipeline builder powered by LLMs."""

from __future__ import annotations

import json
import os
import re
import textwrap
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import typer
import yaml
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.table import Table

from sage.common.config.output_paths import get_sage_paths
from sage.tools.cli.commands.pipeline_domain import (
    load_custom_contexts,
    load_domain_contexts,
)
from sage.tools.cli.commands.pipeline_knowledge import (
    build_query_payload,
    get_default_knowledge_base,
    PipelineKnowledgeBase,
)

try:  # pragma: no cover - optional dependency at runtime only
    from sage.libs.utils.openaiclient import OpenAIClient

    OPENAI_AVAILABLE = True
    OPENAI_IMPORT_ERROR: Optional[Exception] = None
except Exception as exc:  # pragma: no cover - runtime check
    OPENAI_AVAILABLE = False
    OPENAI_IMPORT_ERROR = exc
    OpenAIClient = object  # type: ignore


DEFAULT_BACKEND = os.getenv("SAGE_PIPELINE_BUILDER_BACKEND", "openai")
DEFAULT_MODEL = os.getenv("SAGE_PIPELINE_BUILDER_MODEL") or os.getenv(
    "SAGE_CHAT_MODEL",
    "qwen-turbo-2025-02-11",
)
DEFAULT_BASE_URL = os.getenv("SAGE_PIPELINE_BUILDER_BASE_URL") or os.getenv(
    "SAGE_CHAT_BASE_URL"
)
DEFAULT_API_KEY = os.getenv("SAGE_PIPELINE_BUILDER_API_KEY") or os.getenv(
    "SAGE_CHAT_API_KEY"
)


SYSTEM_PROMPT = textwrap.dedent(
    """
    You are SAGE Pipeline Builder, an expert in configuring Streaming-Augmented Generative Execution pipelines.
    Produce a *single* JSON object that can be saved as a YAML config for the SAGE CLI.

    Required JSON structure:
    {
      "pipeline": {
        "name": str,
        "description": str,
        "version": "1.0.0",
        "type": "local" | "remote"
      },
      "source": { ... },
      "stages": [
        {
          "id": str,
          "kind": "map" | "batch" | "service",
          "class": str,  # Python class path within SAGE
          "params": { ... },
          "summary": str
        }
      ],
      "sink": { ... },
      "services": [
        {
          "name": str,
          "class": str,
          "params": { ... }
        }
      ],
      "monitors": [ ... ],
      "notes": [str]
    }

    Rules:
    - Populate concrete SAGE component class paths (e.g. "sage.libs.rag.retriever.Wiki18FAISSRetriever").
    - When unsure, choose sensible defaults that work out-of-the-box.
    - Always include at least one stage and a sink.
    - Ensure identifiers are slugified (lowercase, hyphen-separated).
    - Parameters must be JSON-serializable and concise.
    - Never wrap the JSON in markdown fences or add commentary outside the JSON.
    """
).strip()


console = Console()
app = typer.Typer(help="ğŸ§  ä½¿ç”¨å¤§æ¨¡å‹äº¤äº’å¼åˆ›å»º SAGE pipeline é…ç½®")


class PipelineBuilderError(RuntimeError):
    """Raised when the builder cannot produce a valid plan."""


def _slugify(value: str) -> str:
    slug = re.sub(r"[^a-zA-Z0-9]+", "-", value.lower()).strip("-")
    return slug or "pipeline"


def _extract_json_object(text: str) -> Dict[str, Any]:
    candidate = text.strip()
    if candidate.startswith("```"):
        candidate = re.sub(r"^```(?:json)?", "", candidate, count=1).strip()
        candidate = re.sub(r"```$", "", candidate, count=1).strip()

    try:
        return json.loads(candidate)
    except json.JSONDecodeError:
        pass

    brace_match = re.search(r"\{.*\}", candidate, re.DOTALL)
    if brace_match:
        try:
            return json.loads(brace_match.group())
        except json.JSONDecodeError as exc:  # pragma: no cover - defensive
            raise PipelineBuilderError(f"LLM returned invalid JSON: {exc}") from exc

    raise PipelineBuilderError("æ— æ³•è§£æå¤§æ¨¡å‹è¿”å›çš„ JSONï¼Œè¯·é‡è¯•æˆ–è°ƒæ•´æè¿°ã€‚")


def _validate_plan(plan: Dict[str, Any]) -> None:
    if "pipeline" not in plan or "stages" not in plan or "sink" not in plan:
        raise PipelineBuilderError(
            "ç”Ÿæˆçš„é…ç½®ç¼ºå°‘å¿…è¦å­—æ®µ (pipeline/stages/sink)ã€‚è¯·å°è¯•æä¾›æ›´å¤šéœ€æ±‚ç»†èŠ‚ã€‚"
        )

    if not isinstance(plan["stages"], list) or not plan["stages"]:
        raise PipelineBuilderError("stages å­—æ®µå¿…é¡»æ˜¯éç©ºåˆ—è¡¨ã€‚")

    if not isinstance(plan.get("sink"), dict) or not plan["sink"].get("class"):
        raise PipelineBuilderError("sink å­—æ®µå¿…é¡»æ˜¯åŒ…å« class çš„å¯¹è±¡ã€‚")

    source = plan.get("source")
    if source is not None and not isinstance(source, dict):
        raise PipelineBuilderError("source å­—æ®µå¿…é¡»æ˜¯å¯¹è±¡ã€‚")

    pipeline_block = plan["pipeline"]
    if "name" not in pipeline_block:
        pipeline_block["name"] = "untitled-pipeline"
    if "type" not in pipeline_block:
        pipeline_block["type"] = "local"
    if "version" not in pipeline_block:
        pipeline_block["version"] = "1.0.0"

    for stage in plan["stages"]:
        if not isinstance(stage, dict):
            raise PipelineBuilderError("stages åˆ—è¡¨ä¸­çš„å…ƒç´ å¿…é¡»æ˜¯å¯¹è±¡ã€‚")
        stage_id = stage.get("id")
        stage["id"] = _slugify(str(stage_id)) if stage_id else _slugify(stage.get("class", "stage"))
        if not stage.get("class"):
            raise PipelineBuilderError("æ¯ä¸ª stage å¿…é¡»åŒ…å« class å­—æ®µã€‚")
        params = stage.get("params", {})
        if params is None:
            stage["params"] = {}
        elif not isinstance(params, dict):
            raise PipelineBuilderError("stage çš„ params å¿…é¡»æ˜¯å¯¹è±¡ (key/value)ã€‚")


@dataclass
class BuilderConfig:
    backend: str
    model: str
    base_url: Optional[str]
    api_key: Optional[str]
    domain_contexts: Tuple[str, ...] = ()
    knowledge_base: Optional[PipelineKnowledgeBase] = None
    knowledge_top_k: int = 6
    show_knowledge: bool = False


class PipelinePlanGenerator:
    def __init__(self, config: BuilderConfig) -> None:
        self.config = config
        self._client = None  # type: Optional[Any]
        self._last_knowledge_contexts: Tuple[str, ...] = ()

        if self.config.backend != "mock":
            if not OPENAI_AVAILABLE:
                message = "æœªèƒ½å¯¼å…¥ OpenAIClientï¼š{}".format(OPENAI_IMPORT_ERROR)
                raise PipelineBuilderError(message)
            self._client = OpenAIClient(
                model_name=self.config.model,
                base_url=self.config.base_url,
                api_key=self.config.api_key,
                seed=42,
            )

    def generate(
        self,
        requirements: Dict[str, Any],
        previous_plan: Optional[Dict[str, Any]] = None,
        feedback: Optional[str] = None,
    ) -> Dict[str, Any]:
        knowledge_contexts: Tuple[str, ...] = ()
        if self.config.knowledge_base is not None:
            try:
                query_payload = build_query_payload(
                    requirements, previous_plan, feedback
                )
                results = self.config.knowledge_base.search(
                    query_payload,
                    top_k=self.config.knowledge_top_k,
                )
                knowledge_contexts = tuple(item.text for item in results)
                self._last_knowledge_contexts = knowledge_contexts
            except Exception as exc:  # pragma: no cover - defensive
                console.print(
                    f"[yellow]æ£€ç´¢çŸ¥è¯†åº“æ—¶å‡ºé”™ï¼Œå°†ç»§ç»­ä½¿ç”¨å†…å»ºä¸Šä¸‹æ–‡: {exc}[/yellow]"
                )
                self._last_knowledge_contexts = ()

            self._last_knowledge_contexts = ()

        if self.config.show_knowledge and knowledge_contexts:
            console.print(
                Panel(
                    "\n\n".join(knowledge_contexts),
                    title="çŸ¥è¯†åº“æ£€ç´¢ç»“æœ",
                    style="blue",
                )
            )

        if self.config.backend == "mock":
            return self._mock_plan(requirements, previous_plan, feedback)

        assert self._client is not None  # for type checker
        user_prompt = self._build_prompt(
            requirements,
            previous_plan,
            feedback,
            knowledge_contexts,
        )
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ]

        console.print("ğŸ¤– æ­£åœ¨è¯·æ±‚å¤§æ¨¡å‹ç”Ÿæˆé…ç½®...", style="cyan")
        response = self._client.generate(messages, max_tokens=1200, temperature=0.2)
        plan = _extract_json_object(response)
        _validate_plan(plan)
        return plan

    def _build_prompt(
        self,
        requirements: Dict[str, Any],
        previous_plan: Optional[Dict[str, Any]],
        feedback: Optional[str],
        knowledge_contexts: Tuple[str, ...],
    ) -> str:
        blocks = [
            "è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚ç”Ÿæˆç¬¦åˆ SAGE æ¡†æ¶çš„ pipeline é…ç½® JSONï¼š",
            json.dumps(requirements, ensure_ascii=False, indent=2),
        ]

        if knowledge_contexts:
            blocks.append("ä»¥ä¸‹æ˜¯ä» SAGE çŸ¥è¯†åº“æ£€ç´¢åˆ°çš„å‚è€ƒä¿¡æ¯ï¼š")
            for idx, snippet in enumerate(knowledge_contexts, start=1):
                blocks.append(f"çŸ¥è¯†[{idx}]:\n{snippet.strip()}")

        if self.config.domain_contexts:
            blocks.append("ä»¥ä¸‹æ˜¯ä¸ SAGE ç®¡é“æ„å»ºç›¸å…³çš„å‚è€ƒèµ„æ–™ï¼š")
            for idx, snippet in enumerate(self.config.domain_contexts, start=1):
                blocks.append(f"å‚è€ƒ[{idx}]:\n{snippet.strip()}")

        if previous_plan:
            blocks.append("è¿™æ˜¯ä¸Šä¸€ç‰ˆé…ç½®ä¾›å‚è€ƒï¼š")
            blocks.append(json.dumps(previous_plan, ensure_ascii=False, indent=2))

        if feedback:
            blocks.append("è¯·éµå¾ªä»¥ä¸‹ä¿®æ”¹æ„è§æ›´æ–°é…ç½®ï¼š")
            blocks.append(feedback.strip())

        blocks.append(
            "ä¸¥æ ¼è¾“å‡ºå•ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å« markdownã€æ³¨é‡Šæˆ–å¤šä½™æ–‡å­—ã€‚"
        )
        return "\n\n".join(blocks)

    @staticmethod
    def _mock_plan(
        requirements: Dict[str, Any],
        previous_plan: Optional[Dict[str, Any]],
        feedback: Optional[str],
    ) -> Dict[str, Any]:
        name = _slugify(requirements.get("name") or "demo-pipeline")
        description = requirements.get("goal", "Auto-generated pipeline")
        plan = {
            "pipeline": {
                "name": name,
                "description": description,
                "version": "1.0.0",
                "type": "local",
            },
            "source": {
                "class": "examples.rag.rag_simple.SimpleQuestionSource",
                "params": {"questions": ["ç¤ºä¾‹é—®é¢˜"]},
                "summary": "Sample in-memory question list",
            },
            "stages": [
                {
                    "id": "retriever",
                    "kind": "map",
                    "class": "examples.rag.rag_simple.SimpleRetriever",
                    "params": {},
                    "summary": "Keyword-based retriever for demo",
                },
                {
                    "id": "promptor",
                    "kind": "map",
                    "class": "examples.rag.rag_simple.SimplePromptor",
                    "params": {},
                    "summary": "Builds prompts for generator",
                },
                {
                    "id": "generator",
                    "kind": "map",
                    "class": "sage.libs.rag.generator.OpenAIGenerator",
                    "params": {
                        "method": "openai",
                        "model_name": DEFAULT_MODEL,
                        "base_url": DEFAULT_BASE_URL,
                        "api_key": "${OPENAI_API_KEY}",
                    },
                    "summary": "LLM generator via OpenAI-compatible endpoint",
                },
            ],
            "sink": {
                "class": "examples.rag.rag_simple.SimpleTerminalSink",
                "params": {},
                "summary": "Print answers to console",
            },
            "services": [],
            "monitors": [],
            "notes": [
                "Mock backendç”Ÿæˆï¼Œä»…ç”¨äºç¦»çº¿æµ‹è¯•ã€‚",
                "éƒ¨ç½²æ—¶è¯·å®Œå–„æ•°æ®æºä¸ç”Ÿæˆæ¨¡å‹å‚æ•°ã€‚",
            ],
        }

        if feedback and "file" in feedback.lower():
            plan["sink"] = {
                "class": "sage.libs.io_utils.file.FileSink",
                "params": {"path": "output/pipeline_results.txt"},
                "summary": "Persist results to local file",
            }

        return plan


def _render_plan(plan: Dict[str, Any]) -> None:
    pipeline_meta = plan.get("pipeline", {})
    console.print(
        Panel.fit(
            f"åç§°: [cyan]{pipeline_meta.get('name', '-') }[/cyan]\n"
            f"æè¿°: {pipeline_meta.get('description', '-') }\n"
            f"ç±»å‹: {pipeline_meta.get('type', '-') }",
            title="Pipeline å…ƒä¿¡æ¯",
            style="green",
        )
    )

    table = Table(title="é˜¶æ®µæ¦‚è§ˆ", show_header=True, header_style="bold blue")
    table.add_column("ID", style="cyan")
    table.add_column("ç±»å‹")
    table.add_column("ç±»è·¯å¾„")
    table.add_column("æ‘˜è¦")

    for stage in plan.get("stages", []):
        table.add_row(
            stage.get("id", "-"),
            stage.get("kind", "-"),
            stage.get("class", "-"),
            stage.get("summary", ""),
        )
    console.print(table)

    notes = plan.get("notes") or []
    if notes:
        console.print(Panel("\n".join(f"â€¢ {note}" for note in notes), title="Notes"))


def _plan_to_yaml(plan: Dict[str, Any]) -> str:
    data = dict(plan)
    stages = data.pop("stages", [])

    # Flatten stages into numbered keys for readability in YAML
    data["stages"] = stages
    return yaml.safe_dump(data, allow_unicode=True, sort_keys=False)


def _save_plan(plan: Dict[str, Any], output: Optional[Path], overwrite: bool) -> Path:
    yaml_text = _plan_to_yaml(plan)
    if output is None:
        default_name = _slugify(plan.get("pipeline", {}).get("name", "pipeline"))
        output_dir = get_sage_paths().output_dir / "pipelines"
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / f"{default_name}.yaml"
    else:
        output_path = Path(output).expanduser().resolve()
        if output_path.is_dir():
            default_name = _slugify(plan.get("pipeline", {}).get("name", "pipeline"))
            output_path = output_path / f"{default_name}.yaml"
        output_path.parent.mkdir(parents=True, exist_ok=True)

    if output_path.exists() and not overwrite:
        raise PipelineBuilderError(f"æ–‡ä»¶å·²å­˜åœ¨: {output_path}ã€‚ä½¿ç”¨ --overwrite å¼ºåˆ¶è¦†ç›–ã€‚")

    output_path.write_text(yaml_text, encoding="utf-8")
    return output_path


def _preview_yaml(yaml_text: str) -> None:
    syntax = Syntax(yaml_text, "yaml", theme="monokai", line_numbers=False)
    console.print(Panel(syntax, title="YAML é¢„è§ˆ"))


def _collect_requirements(
    name: Optional[str],
    goal: Optional[str],
    requirements_path: Optional[Path],
    interactive: bool,
) -> Dict[str, Any]:
    requirements: Dict[str, Any] = {}

    if requirements_path:
        path = Path(requirements_path).expanduser().resolve()
        if not path.exists():
            raise PipelineBuilderError(f"æ‰¾ä¸åˆ°éœ€æ±‚æ–‡ä»¶: {path}")
        requirements = json.loads(path.read_text(encoding="utf-8"))

    if name:
        requirements["name"] = name
    if goal:
        requirements["goal"] = goal

    if not interactive:
        missing = [key for key in ("name", "goal") if key not in requirements]
        if missing:
            raise PipelineBuilderError(
                f"éäº¤äº’æ¨¡å¼ä¸‹å¿…é¡»æä¾›: {', '.join(missing)}"
            )
        return requirements

    if "name" not in requirements:
        requirements["name"] = typer.prompt("Pipeline åç§°", default="My Pipeline")
    if "goal" not in requirements:
        requirements["goal"] = typer.prompt(
            "ä¸»è¦ç›®æ ‡", default="æ„å»ºä¸€ä¸ªé—®ç­”å‹ RAG pipeline"
        )

    if "data_sources" not in requirements:
        requirements["data_sources"] = typer.prompt(
            "æ•°æ®æ¥æº (å¯ç•™ç©º)", default="æ–‡æ¡£çŸ¥è¯†åº“"
        )
    if "latency_budget" not in requirements:
        requirements["latency_budget"] = typer.prompt(
            "å»¶è¿Ÿ/ååéœ€æ±‚ (å¯ç•™ç©º)", default="å®æ—¶ä½“éªŒä¼˜å…ˆ"
        )
    if "constraints" not in requirements:
        requirements["constraints"] = typer.prompt(
            "ç‰¹æ®Šçº¦æŸ (å¯ç•™ç©º)", default=""
        )

    return requirements


@app.command("build")
def build_pipeline(  # noqa: D401 - Typer handles CLI docs
    name: Optional[str] = typer.Option(None, help="Pipeline åç§°"),
    goal: Optional[str] = typer.Option(None, help="Pipeline ç›®æ ‡æè¿°"),
    backend: str = typer.Option(
        DEFAULT_BACKEND,
        help="LLM åç«¯ (openai/compatible/mock)",
    ),
    model: Optional[str] = typer.Option(None, help="LLM æ¨¡å‹åç§°"),
    base_url: Optional[str] = typer.Option(None, help="LLM Base URL"),
    api_key: Optional[str] = typer.Option(None, help="LLM API Key"),
    requirements_path: Optional[Path] = typer.Option(
        None,
        exists=False,
        help="éœ€æ±‚ JSON æ–‡ä»¶è·¯å¾„ï¼Œæä¾›å·²æœ‰è¾“å…¥ä»¥è·³è¿‡äº¤äº’",
    ),
    output: Optional[Path] = typer.Option(
        None,
        help="è¾“å‡º YAML æ–‡ä»¶è·¯å¾„ (å¯ä¸ºç›®å½•)",
    ),
    overwrite: bool = typer.Option(False, help="å…è®¸è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶"),
    non_interactive: bool = typer.Option(
        False, help="éäº¤äº’æ¨¡å¼ (éœ€è¦åŒæ—¶æä¾›åç§°å’Œç›®æ ‡)"
    ),
    context_limit: int = typer.Option(
        4,
        "--context-limit",
        min=0,
        max=12,
        help="æç¤ºä¸­åŒ…å«çš„ç¤ºä¾‹é…ç½®æ•°é‡",
    ),
    context_file: List[Path] = typer.Option(
        [],
        "--context-file",
        "-c",
        help="é¢å¤–ä¸Šä¸‹æ–‡æ–‡ä»¶ (çº¯æ–‡æœ¬)ï¼Œå¯é‡å¤æŒ‡å®š",
        exists=True,
        file_okay=True,
        dir_okay=False,
        resolve_path=True,
    ),
    show_contexts: bool = typer.Option(
        False, "--show-contexts", help="æ‰“å°ç”¨äºæç¤ºçš„å¤§æ¨¡å‹ä¸Šä¸‹æ–‡"
    ),
    disable_knowledge: bool = typer.Option(
        False,
        "--no-knowledge",
        help="ç¦ç”¨ä»æœ¬åœ°çŸ¥è¯†åº“è‡ªåŠ¨æ£€ç´¢ä¸Šä¸‹æ–‡",
    ),
    knowledge_top_k: int = typer.Option(
        5,
        "--knowledge-top-k",
        min=1,
        max=12,
        help="æ¯æ¬¡æ£€ç´¢è¿”å›çš„çŸ¥è¯†ç‰‡æ®µæ•°é‡",
    ),
    show_knowledge: bool = typer.Option(
        False,
        "--show-knowledge",
        help="æ‰“å°çŸ¥è¯†åº“æ£€ç´¢ç»“æœ",
    ),
) -> None:
    """ä½¿ç”¨å¤§æ¨¡å‹äº¤äº’å¼ç”Ÿæˆ SAGE pipeline é…ç½®ã€‚"""

    resolved_model = model or DEFAULT_MODEL
    resolved_base_url = base_url or DEFAULT_BASE_URL
    resolved_api_key = api_key or DEFAULT_API_KEY

    if backend != "mock" and not resolved_api_key:
        raise PipelineBuilderError(
            "æœªæä¾› API Keyã€‚è¯·é€šè¿‡ --api-key æˆ–ç¯å¢ƒå˜é‡ SAGE_PIPELINE_BUILDER_API_KEY/SAGE_CHAT_API_KEY è®¾ç½®ã€‚"
        )

    requirements = _collect_requirements(
        name,
        goal,
        requirements_path,
        interactive=not non_interactive,
    )

    try:
        domain_contexts = list(load_domain_contexts(limit=context_limit))
    except Exception as exc:  # pragma: no cover - defensive
        raise PipelineBuilderError(f"åŠ è½½é»˜è®¤ä¸Šä¸‹æ–‡å¤±è´¥: {exc}") from exc

    if context_file:
        try:
            custom_contexts = load_custom_contexts(tuple(context_file))
            domain_contexts.extend(custom_contexts)
        except RuntimeError as exc:
            raise PipelineBuilderError(str(exc)) from exc

    if show_contexts and domain_contexts:
        console.print(
            Panel(
                "\n\n".join(domain_contexts),
                title="LLM æç¤ºä¸Šä¸‹æ–‡",
                style="magenta",
            )
        )

    knowledge_base: Optional[PipelineKnowledgeBase] = None
    if not disable_knowledge:
        try:
            knowledge_base = get_default_knowledge_base()
        except Exception as exc:
            console.print(
                f"[yellow]åˆå§‹åŒ–çŸ¥è¯†åº“å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨é™æ€ä¸Šä¸‹æ–‡: {exc}[/yellow]"
            )

    config = BuilderConfig(
        backend=backend,
        model=resolved_model,
        base_url=resolved_base_url,
        api_key=resolved_api_key,
        domain_contexts=tuple(domain_contexts),
        knowledge_base=knowledge_base,
        knowledge_top_k=knowledge_top_k,
        show_knowledge=show_knowledge,
    )

    generator = PipelinePlanGenerator(config)

    plan: Optional[Dict[str, Any]] = None
    feedback: Optional[str] = None

    for iteration in range(1, 6):
        try:
            plan = generator.generate(requirements, plan, feedback)
        except PipelineBuilderError as exc:
            console.print(f"[red]ç”Ÿæˆå¤±è´¥: {exc}[/red]")
            if non_interactive:
                raise
            if not typer.confirm("æ˜¯å¦é‡æ–°å°è¯•ç”Ÿæˆï¼Ÿ", default=True):
                raise
            feedback = typer.prompt("è¯·æä¾›æ›´è¯¦ç»†çš„éœ€æ±‚æˆ–ä¿®æ”¹å»ºè®®")
            continue

        _render_plan(plan)

        if non_interactive:
            break

        if typer.confirm("å¯¹é…ç½®æ»¡æ„å—ï¼Ÿ", default=True):
            break

        feedback = typer.prompt(
            "è¯·è¾“å…¥éœ€è¦è°ƒæ•´çš„ç‚¹ï¼ˆä¾‹å¦‚ä¿®æ”¹æŸä¸€é˜¶æ®µ/æ›¿æ¢ç»„ä»¶ï¼‰",
            default="",
        )
        if not feedback.strip():
            console.print("æœªæä¾›ä¿®æ”¹æ„è§ï¼Œä¿æŒå½“å‰ç‰ˆæœ¬ã€‚", style="yellow")
            break

    if plan is None:
        raise PipelineBuilderError("æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ pipeline é…ç½®ã€‚")

    yaml_text = _plan_to_yaml(plan)
    _preview_yaml(yaml_text)

    if not non_interactive and not typer.confirm("æ˜¯å¦ä¿å­˜è¯¥é…ç½®?", default=True):
        console.print("æ“ä½œå·²å–æ¶ˆï¼Œæœªå†™å…¥æ–‡ä»¶ã€‚", style="yellow")
        return

    output_path = _save_plan(plan, output, overwrite)
    console.print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: [green]{output_path}[/green]")


__all__ = ["app"]
