#!/usr/bin/env python3
"""Interactive pipeline builder powered by LLMs."""

from __future__ import annotations

import importlib
import json
import os
import re
import textwrap
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import typer
import yaml
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.table import Table

from sage.common.config.output_paths import get_sage_paths
from sage.core.api.base_environment import BaseEnvironment
from sage.core.api.local_environment import LocalEnvironment
from sage.tools.cli.commands.pipeline_domain import (
    load_custom_contexts,
    load_domain_contexts,
)
from sage.tools.cli.commands.pipeline_knowledge import (
    build_query_payload,
    get_default_knowledge_base,
    PipelineKnowledgeBase,
)
from sage.tools.cli.core.exceptions import CLIException

try:  # pragma: no cover - optional dependency at runtime only
    from sage.libs.utils.openaiclient import OpenAIClient

    OPENAI_AVAILABLE = True
    OPENAI_IMPORT_ERROR: Optional[Exception] = None
except Exception as exc:  # pragma: no cover - runtime check
    OPENAI_AVAILABLE = False
    OPENAI_IMPORT_ERROR = exc
    OpenAIClient = object  # type: ignore


DEFAULT_BACKEND = os.getenv("SAGE_PIPELINE_BUILDER_BACKEND", "openai")
DEFAULT_MODEL = os.getenv("SAGE_PIPELINE_BUILDER_MODEL") or os.getenv(
    "SAGE_CHAT_MODEL",
    "qwen-turbo-2025-02-11",
)
DEFAULT_BASE_URL = os.getenv("SAGE_PIPELINE_BUILDER_BASE_URL") or os.getenv(
    "SAGE_CHAT_BASE_URL"
)
DEFAULT_API_KEY = os.getenv("SAGE_PIPELINE_BUILDER_API_KEY") or os.getenv(
    "SAGE_CHAT_API_KEY"
)


SYSTEM_PROMPT = textwrap.dedent(
    """
    You are SAGE Pipeline Builder, an expert in configuring Streaming-Augmented Generative Execution pipelines.
    Produce a *single* JSON object that can be saved as a YAML config for the SAGE CLI.

    Required JSON structure:
    {
      "pipeline": {
        "name": str,
        "description": str,
        "version": "1.0.0",
        "type": "local" | "remote"
      },
      "source": { ... },
      "stages": [
        {
          "id": str,
          "kind": "map" | "batch" | "service",
          "class": str,  # Python class path within SAGE
          "params": { ... },
          "summary": str
        }
      ],
      "sink": { ... },
      "services": [
        {
          "name": str,
          "class": str,
          "params": { ... }
        }
      ],
      "monitors": [ ... ],
      "notes": [str]
    }

    Rules:
    - Populate concrete SAGE component class paths (e.g. "sage.libs.rag.retriever.Wiki18FAISSRetriever").
    - When unsure, choose sensible defaults that work out-of-the-box.
    - Always include at least one stage and a sink.
    - Ensure identifiers are slugified (lowercase, hyphen-separated).
    - Parameters must be JSON-serializable and concise.
    - Never wrap the JSON in markdown fences or add commentary outside the JSON.
    """
).strip()


console = Console()
app = typer.Typer(help="ğŸ§  ä½¿ç”¨å¤§æ¨¡å‹äº¤äº’å¼åˆ›å»º SAGE pipeline é…ç½®")


class PipelineBuilderError(RuntimeError):
    """Raised when the builder cannot produce a valid plan."""


def _slugify(value: str) -> str:
    slug = re.sub(r"[^a-zA-Z0-9]+", "-", value.lower()).strip("-")
    return slug or "pipeline"


def _extract_json_object(text: str) -> Dict[str, Any]:
    candidate = text.strip()
    if candidate.startswith("```"):
        candidate = re.sub(r"^```(?:json)?", "", candidate, count=1).strip()
        candidate = re.sub(r"```$", "", candidate, count=1).strip()

    try:
        return json.loads(candidate)
    except json.JSONDecodeError:
        pass

    brace_match = re.search(r"\{.*\}", candidate, re.DOTALL)
    if brace_match:
        try:
            return json.loads(brace_match.group())
        except json.JSONDecodeError as exc:  # pragma: no cover - defensive
            raise PipelineBuilderError(f"LLM returned invalid JSON: {exc}") from exc

    raise PipelineBuilderError("æ— æ³•è§£æå¤§æ¨¡å‹è¿”å›çš„ JSONï¼Œè¯·é‡è¯•æˆ–è°ƒæ•´æè¿°ã€‚")


def _validate_plan(plan: Dict[str, Any]) -> None:
    if "pipeline" not in plan or "stages" not in plan or "sink" not in plan:
        raise PipelineBuilderError(
            "ç”Ÿæˆçš„é…ç½®ç¼ºå°‘å¿…è¦å­—æ®µ (pipeline/stages/sink)ã€‚è¯·å°è¯•æä¾›æ›´å¤šéœ€æ±‚ç»†èŠ‚ã€‚"
        )

    if not isinstance(plan["stages"], list) or not plan["stages"]:
        raise PipelineBuilderError("stages å­—æ®µå¿…é¡»æ˜¯éç©ºåˆ—è¡¨ã€‚")

    if not isinstance(plan.get("sink"), dict) or not plan["sink"].get("class"):
        raise PipelineBuilderError("sink å­—æ®µå¿…é¡»æ˜¯åŒ…å« class çš„å¯¹è±¡ã€‚")

    source = plan.get("source")
    if source is not None and not isinstance(source, dict):
        raise PipelineBuilderError("source å­—æ®µå¿…é¡»æ˜¯å¯¹è±¡ã€‚")

    pipeline_block = plan["pipeline"]
    if "name" not in pipeline_block:
        pipeline_block["name"] = "untitled-pipeline"
    if "type" not in pipeline_block:
        pipeline_block["type"] = "local"
    if "version" not in pipeline_block:
        pipeline_block["version"] = "1.0.0"

    for stage in plan["stages"]:
        if not isinstance(stage, dict):
            raise PipelineBuilderError("stages åˆ—è¡¨ä¸­çš„å…ƒç´ å¿…é¡»æ˜¯å¯¹è±¡ã€‚")
        stage_id = stage.get("id")
        stage["id"] = _slugify(str(stage_id)) if stage_id else _slugify(stage.get("class", "stage"))
        if not stage.get("class"):
            raise PipelineBuilderError("æ¯ä¸ª stage å¿…é¡»åŒ…å« class å­—æ®µã€‚")
        params = stage.get("params", {})
        if params is None:
            stage["params"] = {}
        elif not isinstance(params, dict):
            raise PipelineBuilderError("stage çš„ params å¿…é¡»æ˜¯å¯¹è±¡ (key/value)ã€‚")


def _expand_params(value: Any) -> Any:
    if isinstance(value, dict):
        return {key: _expand_params(val) for key, val in value.items()}
    if isinstance(value, list):
        return [_expand_params(item) for item in value]
    if isinstance(value, str):
        return os.path.expandvars(os.path.expanduser(value))
    return value


def _import_attr(path: str) -> Any:
    try:
        module_name, attr_name = path.rsplit(".", 1)
    except ValueError as exc:  # pragma: no cover - defensive
        raise CLIException(f"Invalid class path: {path}") from exc

    try:
        module = importlib.import_module(module_name)
    except ImportError as exc:
        raise CLIException(f"æ— æ³•å¯¼å…¥æ¨¡å— {module_name}: {exc}") from exc

    try:
        return getattr(module, attr_name)
    except AttributeError as exc:
        raise CLIException(f"æ¨¡å— {module_name} ä¸åŒ…å« {attr_name}") from exc


def _ensure_pipeline_dict(data: Dict[str, Any]) -> Dict[str, Any]:
    if not isinstance(data, dict):
        raise CLIException("Pipeline é…ç½®å¿…é¡»æ˜¯å­—å…¸ç»“æ„ã€‚")
    return data


def _create_environment(
    plan: Dict[str, Any], host: Optional[str], port: Optional[int]
) -> BaseEnvironment:
    pipeline_meta = plan.get("pipeline") or {}
    pipeline_name = pipeline_meta.get("name", "sage-pipeline")
    env_settings = plan.get("environment") or {}
    env_config = _expand_params(env_settings.get("config") or {})

    env_type = (pipeline_meta.get("type") or "local").lower()
    if env_type == "remote":
        from sage.core.api.remote_environment import RemoteEnvironment  # import lazily

        resolved_host = host or env_settings.get("host") or "127.0.0.1"
        resolved_port = port or env_settings.get("port") or 19001
        return RemoteEnvironment(
            name=pipeline_name,
            config=env_config,
            host=resolved_host,
            port=int(resolved_port),
        )

    return LocalEnvironment(name=pipeline_name, config=env_config)


def _register_services(env: BaseEnvironment, services: List[Dict[str, Any]]) -> None:
    for service in services or []:
        name = service.get("name")
        class_path = service.get("class")
        if not name or not class_path:
            raise CLIException("æ¯ä¸ª service éœ€è¦ name å’Œ class å­—æ®µã€‚")

        service_class = _import_attr(class_path)
        args = service.get("args") or []
        if not isinstance(args, list):
            raise CLIException(f"Service {name} çš„ args å¿…é¡»æ˜¯æ•°ç»„ã€‚")
        params = _expand_params(service.get("params") or {})
        env.register_service(name, service_class, *args, **params)


def _apply_source(env: BaseEnvironment, source: Dict[str, Any]):
    if not source:
        raise CLIException("Pipeline ç¼ºå°‘ source å®šä¹‰ã€‚")

    class_path = source.get("class")
    if not class_path:
        raise CLIException("source éœ€è¦æä¾› class å­—æ®µã€‚")

    function_class = _import_attr(class_path)
    args = source.get("args") or []
    if not isinstance(args, list):
        raise CLIException("source çš„ args å¿…é¡»æ˜¯æ•°ç»„ã€‚")
    params = _expand_params(source.get("params") or {})
    kind = (source.get("kind") or "batch").lower()

    if kind in {"batch", "collection"}:
        return env.from_batch(function_class, *args, **params)
    if kind in {"source", "stream"}:
        return env.from_source(function_class, *args, **params)
    if kind == "future":
        future_name = params.get("name") or source.get("id") or "future"
        return env.from_future(future_name)

    # Default to from_source for unknown kinds
    return env.from_source(function_class, *args, **params)


def _apply_stage(stream, stage: Dict[str, Any]):
    class_path = stage.get("class")
    if not class_path:
        raise CLIException("stage ç¼ºå°‘ class å­—æ®µã€‚")

    function_class = _import_attr(class_path)
    args = stage.get("args") or []
    if not isinstance(args, list):
        raise CLIException(f"stage {stage.get('id')} çš„ args å¿…é¡»æ˜¯æ•°ç»„ã€‚")
    params = _expand_params(stage.get("params") or {})
    kind = (stage.get("kind") or "map").lower()

    if kind in {"map", "service", "batch"}:
        return stream.map(function_class, *args, **params)
    if kind == "flatmap":
        return stream.flatmap(function_class, *args, **params)
    if kind == "filter":
        return stream.filter(function_class, *args, **params)
    if kind == "keyby":
        strategy = params.pop("strategy", "hash")
        return stream.keyby(function_class, strategy=strategy, *args, **params)
    if kind == "sink":
        stream.sink(function_class, *args, **params)
        return stream

    console.print(
        f"[yellow]âš ï¸ æœªçŸ¥çš„ stage ç±»å‹ {kind}ï¼Œé»˜è®¤ä½¿ç”¨ mapã€‚[/yellow]"
    )
    return stream.map(function_class, *args, **params)


def _apply_sink(stream, sink: Dict[str, Any]):
    if not sink:
        raise CLIException("Pipeline ç¼ºå°‘ sink å®šä¹‰ã€‚")

    class_path = sink.get("class")
    if not class_path:
        raise CLIException("sink éœ€è¦æä¾› class å­—æ®µã€‚")

    function_class = _import_attr(class_path)
    args = sink.get("args") or []
    if not isinstance(args, list):
        raise CLIException("sink çš„ args å¿…é¡»æ˜¯æ•°ç»„ã€‚")
    params = _expand_params(sink.get("params") or {})
    stream.sink(function_class, *args, **params)


def _load_pipeline_file(path: Path) -> Dict[str, Any]:
    try:
        content = path.read_text(encoding="utf-8")
    except FileNotFoundError as exc:
        raise CLIException(f"æ‰¾ä¸åˆ° pipeline é…ç½®æ–‡ä»¶: {path}") from exc
    except OSError as exc:
        raise CLIException(f"è¯»å– pipeline æ–‡ä»¶å¤±è´¥: {exc}") from exc

    try:
        data = yaml.safe_load(content) or {}
    except yaml.YAMLError as exc:
        raise CLIException(f"è§£æ YAML å¤±è´¥: {exc}") from exc

    return _ensure_pipeline_dict(data)


@dataclass
class BuilderConfig:
    backend: str
    model: str
    base_url: Optional[str]
    api_key: Optional[str]
    domain_contexts: Tuple[str, ...] = ()
    knowledge_base: Optional[PipelineKnowledgeBase] = None
    knowledge_top_k: int = 6
    show_knowledge: bool = False


class PipelinePlanGenerator:
    def __init__(self, config: BuilderConfig) -> None:
        self.config = config
        self._client = None  # type: Optional[Any]
        self._last_knowledge_contexts: Tuple[str, ...] = ()

        if self.config.backend != "mock":
            if not OPENAI_AVAILABLE:
                message = "æœªèƒ½å¯¼å…¥ OpenAIClientï¼š{}".format(OPENAI_IMPORT_ERROR)
                raise PipelineBuilderError(message)
            self._client = OpenAIClient(
                model_name=self.config.model,
                base_url=self.config.base_url,
                api_key=self.config.api_key,
                seed=42,
            )

    def generate(
        self,
        requirements: Dict[str, Any],
        previous_plan: Optional[Dict[str, Any]] = None,
        feedback: Optional[str] = None,
    ) -> Dict[str, Any]:
        knowledge_contexts: Tuple[str, ...] = ()
        if self.config.knowledge_base is not None:
            try:
                query_payload = build_query_payload(
                    requirements, previous_plan, feedback
                )
                results = self.config.knowledge_base.search(
                    query_payload,
                    top_k=self.config.knowledge_top_k,
                )
                knowledge_contexts = tuple(item.text for item in results)
                self._last_knowledge_contexts = knowledge_contexts
            except Exception as exc:  # pragma: no cover - defensive
                console.print(
                    f"[yellow]æ£€ç´¢çŸ¥è¯†åº“æ—¶å‡ºé”™ï¼Œå°†ç»§ç»­ä½¿ç”¨å†…å»ºä¸Šä¸‹æ–‡: {exc}[/yellow]"
                )
                self._last_knowledge_contexts = ()

            self._last_knowledge_contexts = ()

        if self.config.show_knowledge and knowledge_contexts:
            console.print(
                Panel(
                    "\n\n".join(knowledge_contexts),
                    title="çŸ¥è¯†åº“æ£€ç´¢ç»“æœ",
                    style="blue",
                )
            )

        if self.config.backend == "mock":
            return self._mock_plan(requirements, previous_plan, feedback)

        assert self._client is not None  # for type checker
        user_prompt = self._build_prompt(
            requirements,
            previous_plan,
            feedback,
            knowledge_contexts,
        )
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ]

        console.print("ğŸ¤– æ­£åœ¨è¯·æ±‚å¤§æ¨¡å‹ç”Ÿæˆé…ç½®...", style="cyan")
        response = self._client.generate(messages, max_tokens=1200, temperature=0.2)
        plan = _extract_json_object(response)
        _validate_plan(plan)
        return plan

    def _build_prompt(
        self,
        requirements: Dict[str, Any],
        previous_plan: Optional[Dict[str, Any]],
        feedback: Optional[str],
        knowledge_contexts: Tuple[str, ...],
    ) -> str:
        blocks = [
            "è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚ç”Ÿæˆç¬¦åˆ SAGE æ¡†æ¶çš„ pipeline é…ç½® JSONï¼š",
            json.dumps(requirements, ensure_ascii=False, indent=2),
        ]

        if knowledge_contexts:
            blocks.append("ä»¥ä¸‹æ˜¯ä» SAGE çŸ¥è¯†åº“æ£€ç´¢åˆ°çš„å‚è€ƒä¿¡æ¯ï¼š")
            for idx, snippet in enumerate(knowledge_contexts, start=1):
                blocks.append(f"çŸ¥è¯†[{idx}]:\n{snippet.strip()}")

        if self.config.domain_contexts:
            blocks.append("ä»¥ä¸‹æ˜¯ä¸ SAGE ç®¡é“æ„å»ºç›¸å…³çš„å‚è€ƒèµ„æ–™ï¼š")
            for idx, snippet in enumerate(self.config.domain_contexts, start=1):
                blocks.append(f"å‚è€ƒ[{idx}]:\n{snippet.strip()}")

        if previous_plan:
            blocks.append("è¿™æ˜¯ä¸Šä¸€ç‰ˆé…ç½®ä¾›å‚è€ƒï¼š")
            blocks.append(json.dumps(previous_plan, ensure_ascii=False, indent=2))

        if feedback:
            blocks.append("è¯·éµå¾ªä»¥ä¸‹ä¿®æ”¹æ„è§æ›´æ–°é…ç½®ï¼š")
            blocks.append(feedback.strip())

        blocks.append(
            "ä¸¥æ ¼è¾“å‡ºå•ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å« markdownã€æ³¨é‡Šæˆ–å¤šä½™æ–‡å­—ã€‚"
        )
        return "\n\n".join(blocks)

    @staticmethod
    def _mock_plan(
        requirements: Dict[str, Any],
        previous_plan: Optional[Dict[str, Any]],
        feedback: Optional[str],
    ) -> Dict[str, Any]:
        name = _slugify(requirements.get("name") or "demo-pipeline")
        description = requirements.get("goal", "Auto-generated pipeline")
        plan = {
            "pipeline": {
                "name": name,
                "description": description,
                "version": "1.0.0",
                "type": "local",
            },
            "source": {
                "class": "examples.rag.rag_simple.SimpleQuestionSource",
                "params": {"questions": ["ç¤ºä¾‹é—®é¢˜"]},
                "summary": "Sample in-memory question list",
            },
            "stages": [
                {
                    "id": "retriever",
                    "kind": "map",
                    "class": "examples.rag.rag_simple.SimpleRetriever",
                    "params": {},
                    "summary": "Keyword-based retriever for demo",
                },
                {
                    "id": "promptor",
                    "kind": "map",
                    "class": "examples.rag.rag_simple.SimplePromptor",
                    "params": {},
                    "summary": "Builds prompts for generator",
                },
                {
                    "id": "generator",
                    "kind": "map",
                    "class": "sage.libs.rag.generator.OpenAIGenerator",
                    "params": {
                        "method": "openai",
                        "model_name": DEFAULT_MODEL,
                        "base_url": DEFAULT_BASE_URL,
                        "api_key": "${OPENAI_API_KEY}",
                    },
                    "summary": "LLM generator via OpenAI-compatible endpoint",
                },
            ],
            "sink": {
                "class": "examples.rag.rag_simple.SimpleTerminalSink",
                "params": {},
                "summary": "Print answers to console",
            },
            "services": [],
            "monitors": [],
            "notes": [
                "Mock backendç”Ÿæˆï¼Œä»…ç”¨äºç¦»çº¿æµ‹è¯•ã€‚",
                "éƒ¨ç½²æ—¶è¯·å®Œå–„æ•°æ®æºä¸ç”Ÿæˆæ¨¡å‹å‚æ•°ã€‚",
            ],
        }

        if feedback and "file" in feedback.lower():
            plan["sink"] = {
                "class": "sage.libs.io_utils.file.FileSink",
                "params": {"path": "output/pipeline_results.txt"},
                "summary": "Persist results to local file",
            }

        return plan


def _render_plan(plan: Dict[str, Any]) -> None:
    pipeline_meta = plan.get("pipeline", {})
    console.print(
        Panel.fit(
            f"åç§°: [cyan]{pipeline_meta.get('name', '-') }[/cyan]\n"
            f"æè¿°: {pipeline_meta.get('description', '-') }\n"
            f"ç±»å‹: {pipeline_meta.get('type', '-') }",
            title="Pipeline å…ƒä¿¡æ¯",
            style="green",
        )
    )

    table = Table(title="é˜¶æ®µæ¦‚è§ˆ", show_header=True, header_style="bold blue")
    table.add_column("ID", style="cyan")
    table.add_column("ç±»å‹")
    table.add_column("ç±»è·¯å¾„")
    table.add_column("æ‘˜è¦")

    for stage in plan.get("stages", []):
        table.add_row(
            stage.get("id", "-"),
            stage.get("kind", "-"),
            stage.get("class", "-"),
            stage.get("summary", ""),
        )
    console.print(table)

    notes = plan.get("notes") or []
    if notes:
        console.print(Panel("\n".join(f"â€¢ {note}" for note in notes), title="Notes"))


def _plan_to_yaml(plan: Dict[str, Any]) -> str:
    data = dict(plan)
    stages = data.pop("stages", [])

    # Flatten stages into numbered keys for readability in YAML
    data["stages"] = stages
    return yaml.safe_dump(data, allow_unicode=True, sort_keys=False)


def _save_plan(plan: Dict[str, Any], output: Optional[Path], overwrite: bool) -> Path:
    yaml_text = _plan_to_yaml(plan)
    if output is None:
        default_name = _slugify(plan.get("pipeline", {}).get("name", "pipeline"))
        output_dir = get_sage_paths().output_dir / "pipelines"
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / f"{default_name}.yaml"
    else:
        output_path = Path(output).expanduser().resolve()
        if output_path.is_dir():
            default_name = _slugify(plan.get("pipeline", {}).get("name", "pipeline"))
            output_path = output_path / f"{default_name}.yaml"
        output_path.parent.mkdir(parents=True, exist_ok=True)

    if output_path.exists() and not overwrite:
        raise PipelineBuilderError(f"æ–‡ä»¶å·²å­˜åœ¨: {output_path}ã€‚ä½¿ç”¨ --overwrite å¼ºåˆ¶è¦†ç›–ã€‚")

    output_path.write_text(yaml_text, encoding="utf-8")
    return output_path


def _preview_yaml(yaml_text: str) -> None:
    syntax = Syntax(yaml_text, "yaml", theme="monokai", line_numbers=False)
    console.print(Panel(syntax, title="YAML é¢„è§ˆ"))


def _collect_requirements(
    name: Optional[str],
    goal: Optional[str],
    requirements_path: Optional[Path],
    interactive: bool,
) -> Dict[str, Any]:
    requirements: Dict[str, Any] = {}

    if requirements_path:
        path = Path(requirements_path).expanduser().resolve()
        if not path.exists():
            raise PipelineBuilderError(f"æ‰¾ä¸åˆ°éœ€æ±‚æ–‡ä»¶: {path}")
        requirements = json.loads(path.read_text(encoding="utf-8"))

    if name:
        requirements["name"] = name
    if goal:
        requirements["goal"] = goal

    if not interactive:
        missing = [key for key in ("name", "goal") if key not in requirements]
        if missing:
            raise PipelineBuilderError(
                f"éäº¤äº’æ¨¡å¼ä¸‹å¿…é¡»æä¾›: {', '.join(missing)}"
            )
        return requirements

    if "name" not in requirements:
        requirements["name"] = typer.prompt("Pipeline åç§°", default="My Pipeline")
    if "goal" not in requirements:
        requirements["goal"] = typer.prompt(
            "ä¸»è¦ç›®æ ‡", default="æ„å»ºä¸€ä¸ªé—®ç­”å‹ RAG pipeline"
        )

    if "data_sources" not in requirements:
        requirements["data_sources"] = typer.prompt(
            "æ•°æ®æ¥æº (å¯ç•™ç©º)", default="æ–‡æ¡£çŸ¥è¯†åº“"
        )
    if "latency_budget" not in requirements:
        requirements["latency_budget"] = typer.prompt(
            "å»¶è¿Ÿ/ååéœ€æ±‚ (å¯ç•™ç©º)", default="å®æ—¶ä½“éªŒä¼˜å…ˆ"
        )
    if "constraints" not in requirements:
        requirements["constraints"] = typer.prompt(
            "ç‰¹æ®Šçº¦æŸ (å¯ç•™ç©º)", default=""
        )

    return requirements


@app.command("build")
def build_pipeline(  # noqa: D401 - Typer handles CLI docs
    name: Optional[str] = typer.Option(None, help="Pipeline åç§°"),
    goal: Optional[str] = typer.Option(None, help="Pipeline ç›®æ ‡æè¿°"),
    backend: str = typer.Option(
        DEFAULT_BACKEND,
        help="LLM åç«¯ (openai/compatible/mock)",
    ),
    model: Optional[str] = typer.Option(None, help="LLM æ¨¡å‹åç§°"),
    base_url: Optional[str] = typer.Option(None, help="LLM Base URL"),
    api_key: Optional[str] = typer.Option(None, help="LLM API Key"),
    requirements_path: Optional[Path] = typer.Option(
        None,
        exists=False,
        help="éœ€æ±‚ JSON æ–‡ä»¶è·¯å¾„ï¼Œæä¾›å·²æœ‰è¾“å…¥ä»¥è·³è¿‡äº¤äº’",
    ),
    output: Optional[Path] = typer.Option(
        None,
        help="è¾“å‡º YAML æ–‡ä»¶è·¯å¾„ (å¯ä¸ºç›®å½•)",
    ),
    overwrite: bool = typer.Option(False, help="å…è®¸è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶"),
    non_interactive: bool = typer.Option(
        False, help="éäº¤äº’æ¨¡å¼ (éœ€è¦åŒæ—¶æä¾›åç§°å’Œç›®æ ‡)"
    ),
    context_limit: int = typer.Option(
        4,
        "--context-limit",
        min=0,
        max=12,
        help="æç¤ºä¸­åŒ…å«çš„ç¤ºä¾‹é…ç½®æ•°é‡",
    ),
    context_file: List[Path] = typer.Option(
        [],
        "--context-file",
        "-c",
        help="é¢å¤–ä¸Šä¸‹æ–‡æ–‡ä»¶ (çº¯æ–‡æœ¬)ï¼Œå¯é‡å¤æŒ‡å®š",
        exists=True,
        file_okay=True,
        dir_okay=False,
        resolve_path=True,
    ),
    show_contexts: bool = typer.Option(
        False, "--show-contexts", help="æ‰“å°ç”¨äºæç¤ºçš„å¤§æ¨¡å‹ä¸Šä¸‹æ–‡"
    ),
    disable_knowledge: bool = typer.Option(
        False,
        "--no-knowledge",
        help="ç¦ç”¨ä»æœ¬åœ°çŸ¥è¯†åº“è‡ªåŠ¨æ£€ç´¢ä¸Šä¸‹æ–‡",
    ),
    knowledge_top_k: int = typer.Option(
        5,
        "--knowledge-top-k",
        min=1,
        max=12,
        help="æ¯æ¬¡æ£€ç´¢è¿”å›çš„çŸ¥è¯†ç‰‡æ®µæ•°é‡",
    ),
    show_knowledge: bool = typer.Option(
        False,
        "--show-knowledge",
        help="æ‰“å°çŸ¥è¯†åº“æ£€ç´¢ç»“æœ",
    ),
) -> None:
    """ä½¿ç”¨å¤§æ¨¡å‹äº¤äº’å¼ç”Ÿæˆ SAGE pipeline é…ç½®ã€‚"""

    resolved_model = model or DEFAULT_MODEL
    resolved_base_url = base_url or DEFAULT_BASE_URL
    resolved_api_key = api_key or DEFAULT_API_KEY

    if backend != "mock" and not resolved_api_key:
        raise PipelineBuilderError(
            "æœªæä¾› API Keyã€‚è¯·é€šè¿‡ --api-key æˆ–ç¯å¢ƒå˜é‡ SAGE_PIPELINE_BUILDER_API_KEY/SAGE_CHAT_API_KEY è®¾ç½®ã€‚"
        )

    requirements = _collect_requirements(
        name,
        goal,
        requirements_path,
        interactive=not non_interactive,
    )

    try:
        domain_contexts = list(load_domain_contexts(limit=context_limit))
    except Exception as exc:  # pragma: no cover - defensive
        raise PipelineBuilderError(f"åŠ è½½é»˜è®¤ä¸Šä¸‹æ–‡å¤±è´¥: {exc}") from exc

    if context_file:
        try:
            custom_contexts = load_custom_contexts(tuple(context_file))
            domain_contexts.extend(custom_contexts)
        except RuntimeError as exc:
            raise PipelineBuilderError(str(exc)) from exc

    if show_contexts and domain_contexts:
        console.print(
            Panel(
                "\n\n".join(domain_contexts),
                title="LLM æç¤ºä¸Šä¸‹æ–‡",
                style="magenta",
            )
        )

    knowledge_base: Optional[PipelineKnowledgeBase] = None
    if not disable_knowledge:
        try:
            knowledge_base = get_default_knowledge_base()
        except Exception as exc:
            console.print(
                f"[yellow]åˆå§‹åŒ–çŸ¥è¯†åº“å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨é™æ€ä¸Šä¸‹æ–‡: {exc}[/yellow]"
            )

    config = BuilderConfig(
        backend=backend,
        model=resolved_model,
        base_url=resolved_base_url,
        api_key=resolved_api_key,
        domain_contexts=tuple(domain_contexts),
        knowledge_base=knowledge_base,
        knowledge_top_k=knowledge_top_k,
        show_knowledge=show_knowledge,
    )

    generator = PipelinePlanGenerator(config)

    plan: Optional[Dict[str, Any]] = None
    feedback: Optional[str] = None

    for iteration in range(1, 6):
        try:
            plan = generator.generate(requirements, plan, feedback)
        except PipelineBuilderError as exc:
            console.print(f"[red]ç”Ÿæˆå¤±è´¥: {exc}[/red]")
            if non_interactive:
                raise
            if not typer.confirm("æ˜¯å¦é‡æ–°å°è¯•ç”Ÿæˆï¼Ÿ", default=True):
                raise
            feedback = typer.prompt("è¯·æä¾›æ›´è¯¦ç»†çš„éœ€æ±‚æˆ–ä¿®æ”¹å»ºè®®")
            continue

        _render_plan(plan)

        if non_interactive:
            break

        if typer.confirm("å¯¹é…ç½®æ»¡æ„å—ï¼Ÿ", default=True):
            break

        feedback = typer.prompt(
            "è¯·è¾“å…¥éœ€è¦è°ƒæ•´çš„ç‚¹ï¼ˆä¾‹å¦‚ä¿®æ”¹æŸä¸€é˜¶æ®µ/æ›¿æ¢ç»„ä»¶ï¼‰",
            default="",
        )
        if not feedback.strip():
            console.print("æœªæä¾›ä¿®æ”¹æ„è§ï¼Œä¿æŒå½“å‰ç‰ˆæœ¬ã€‚", style="yellow")
            break

    if plan is None:
        raise PipelineBuilderError("æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ pipeline é…ç½®ã€‚")

    yaml_text = _plan_to_yaml(plan)
    _preview_yaml(yaml_text)

    if not non_interactive and not typer.confirm("æ˜¯å¦ä¿å­˜è¯¥é…ç½®?", default=True):
        console.print("æ“ä½œå·²å–æ¶ˆï¼Œæœªå†™å…¥æ–‡ä»¶ã€‚", style="yellow")
        return

    output_path = _save_plan(plan, output, overwrite)
    console.print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: [green]{output_path}[/green]")


@app.command("run")
def run_pipeline(
    config: Path = typer.Argument(..., exists=False, help="Pipeline YAML é…ç½®æ–‡ä»¶"),
    autostop: bool = typer.Option(
        True, "--autostop/--no-autostop", help="æäº¤åæ˜¯å¦ç­‰å¾…æ‰¹å¤„ç†å®Œæˆ"
    ),
    host: Optional[str] = typer.Option(
        None,
        "--host",
        help="è¿œç¨‹ç¯å¢ƒ JobManager ä¸»æœº (ä»…å½“ pipeline.type=remote æ—¶ç”Ÿæ•ˆ)",
    ),
    port: Optional[int] = typer.Option(
        None,
        "--port",
        min=1,
        max=65535,
        help="è¿œç¨‹ç¯å¢ƒ JobManager ç«¯å£ (ä»…å½“ pipeline.type=remote æ—¶ç”Ÿæ•ˆ)",
    ),
) -> None:
    """åŠ è½½ YAML é…ç½®å¹¶è¿è¡Œ SAGE pipelineã€‚"""

    try:
        config_path = Path(config).expanduser().resolve()
        plan = _load_pipeline_file(config_path)

        pipeline_meta = plan.get("pipeline") or {}
        pipeline_name = pipeline_meta.get("name", config_path.stem)

        console.print(
            Panel.fit(
                f"åç§°: [cyan]{pipeline_name}[/cyan]\nç±»å‹: {pipeline_meta.get('type', 'local')}\næ¥æº: {config_path}",
                title="è¿è¡Œ Pipeline",
                style="blue",
            )
        )

        env = _create_environment(plan, host, port)

        services = plan.get("services") or []
        if services:
            console.print(f"ğŸ”§ æ³¨å†Œ {len(services)} ä¸ªæœåŠ¡...")
            _register_services(env, services)

        source = plan.get("source")
        stream = _apply_source(env, source)

        stages = plan.get("stages") or []
        for stage in stages:
            stage_id = stage.get("id", "stage")
            console.print(f"â¡ï¸  åº”ç”¨é˜¶æ®µ: {stage_id}")
            stream = _apply_stage(stream, stage)

        sink = plan.get("sink")
        console.print("ğŸ›¬ é…ç½®ç»ˆç«¯ sink")
        _apply_sink(stream, sink)

        if plan.get("monitors"):
            console.print("[yellow]ğŸ“ˆ å½“å‰ç‰ˆæœ¬æš‚æœªè‡ªåŠ¨é…ç½® monitorsï¼Œéœ€æ‰‹åŠ¨é›†æˆã€‚[/yellow]")

        console.print("ğŸš€ æäº¤ pipeline...")
        job_uuid = env.submit(autostop=autostop)

        if job_uuid:
            console.print(f"âœ… Pipeline å·²æäº¤ï¼Œä½œä¸š UUID: [green]{job_uuid}[/green]")
        else:
            console.print("âœ… Pipeline å·²æäº¤ã€‚")

        if autostop:
            console.print("ğŸ‰ æ‰¹å¤„ç†å®Œæˆå¹¶è‡ªåŠ¨æ¸…ç†ã€‚")
        else:
            console.print("â³ Pipeline æ­£åœ¨è¿è¡Œï¼Œå¯ä½¿ç”¨ 'sage job list' æŸ¥çœ‹çŠ¶æ€ã€‚")

    except CLIException as exc:
        console.print(f"[red]âŒ {exc}[/red]")
        raise typer.Exit(1) from exc


__all__ = ["app"]
