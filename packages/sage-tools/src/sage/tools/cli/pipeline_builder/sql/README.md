# SQL-based Pipeline Builder

## æ¦‚è¿°

SQL-based Pipeline Builder æ˜¯ SAGE é¡¹ç›®çš„æ–°ä¸€ä»£ç®¡é“æ„å»ºç³»ç»Ÿï¼Œè§£å†³äº†æ¨¡æ¿æ–¹æ³•çš„åˆšæ€§é™åˆ¶ï¼Œæä¾›æ›´çµæ´»ã€æ•°æ®é©±åŠ¨çš„ç®¡é“å®šä¹‰å’Œç®¡ç†èƒ½åŠ›ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ çµæ´»çš„è¯­æ³•æ”¯æŒ
- **CREATE PIPELINEå†…è”è¯­æ³•**: ç®€æ´çš„ç®¡é“å®šä¹‰æ–¹å¼
- **ä¼ ç»ŸINSERTè¯­å¥**: è¯¦ç»†çš„è¡¨æ ¼åŒ–ç®¡é“å®šä¹‰
- **æ··åˆæ¨¡å¼**: ä¸¤ç§è¯­æ³•å¯ä»¥ç»„åˆä½¿ç”¨

### ğŸ—„ï¸ æ•°æ®é©±åŠ¨å­˜å‚¨
- SQLiteæ•°æ®åº“æŒä¹…åŒ–ç®¡é“å®šä¹‰
- æ”¯æŒç®¡é“çš„CRUDæ“ä½œ
- ç‰ˆæœ¬åŒ–ç®¡é“ç®¡ç†

### ğŸ”§ è‡ªåŠ¨ä»£ç ç”Ÿæˆ
- è‡ªåŠ¨ç”ŸæˆYAMLé…ç½®æ–‡ä»¶
- è‡ªåŠ¨ç”ŸæˆPythonè¿è¡Œå™¨
- æ”¯æŒæ‰¹å¤„ç†å’Œæµå¼æ¨¡å¼

### ğŸ§ª å®Œæ•´æµ‹è¯•è¦†ç›–
- 9ä¸ªæµ‹è¯•ç”¨ä¾‹å…¨éƒ¨é€šè¿‡
- è¦†ç›–è§£æã€å­˜å‚¨ã€ç¼–è¯‘å…¨æµç¨‹
- é›†æˆæµ‹è¯•ç¡®ä¿ç«¯åˆ°ç«¯åŠŸèƒ½

## å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨

```bash
# æŸ¥çœ‹å¸®åŠ©
sage pipeline sql --help

# åŠ è½½SQLç®¡é“å®šä¹‰
sage pipeline sql load examples.sql

# åˆ—å‡ºæ‰€æœ‰ç®¡é“
sage pipeline sql list

# æŸ¥çœ‹ç®¡é“è¯¦æƒ…
sage pipeline sql show simple_qa

# ç¼–è¯‘ç®¡é“ä¸ºYAMLå’ŒPython
sage pipeline sql compile simple_qa --output-dir ./output
```

### 2. SQLè¯­æ³•ç¤ºä¾‹

#### CREATE PIPELINEè¯­æ³• (æ¨è)

```sql
-- ç®€å•QAç®¡é“
CREATE PIPELINE simple_qa (
  source = FileSource { data_path: "data/questions.txt", chunk_size: 1000 },
  retriever = ChromaRetriever { top_k: 5 },
  promptor = QAPromptor { template: "Answer: {context}" },
  generator = OpenAIGenerator { model: "gpt-3.5-turbo" },
  sink = TerminalSink { format: "json" },
  source -> retriever -> promptor -> generator -> sink
);
```

#### ä¼ ç»ŸINSERTè¯­æ³•

```sql
-- ç®¡é“åŸºæœ¬ä¿¡æ¯
INSERT INTO pipeline VALUES 
  ('advanced_rag', 'Advanced RAG', 'Multi-step RAG pipeline', 'streaming');

-- æ“ä½œç¬¦å®šä¹‰
INSERT INTO operator VALUES
  ('advanced_rag', 'source', 'FileSource', 1, '{"data_path": "corpus/"}'),
  ('advanced_rag', 'retriever', 'ChromaRetriever', 2, '{"top_k": 10}'),
  ('advanced_rag', 'reranker', 'CrossEncoderReranker', 3, '{"model": "ms-marco"}'),
  ('advanced_rag', 'generator', 'OpenAIGenerator', 4, '{"model": "gpt-4"}');

-- è¿æ¥å®šä¹‰
INSERT INTO pipeline_edge VALUES
  ('advanced_rag', 'source', 'retriever'),
  ('advanced_rag', 'retriever', 'reranker'),
  ('advanced_rag', 'reranker', 'generator');
```

## æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```
SQL DSL Input
      â†“
SQLPipelineDSLParser  â†’  PipelineDefinition
      â†“                        â†“
SQLPipelineStore            SQLPipelineCompiler
      â†“                        â†“
SQLite Database            YAML + Python Output
```

### ç±»å±‚æ¬¡ç»“æ„

- **SQLPipelineStore**: ç®¡é“çš„æŒä¹…åŒ–å­˜å‚¨
- **SQLPipelineCompiler**: ç®¡é“å®šä¹‰åˆ°ä»£ç çš„ç¼–è¯‘å™¨
- **SQLPipelineDSLParser**: SQL DSLåˆ°ç®¡é“å®šä¹‰çš„è§£æå™¨
- **OperatorNode**: ç®¡é“æ“ä½œç¬¦çš„æ•°æ®ç»“æ„
- **PipelineDefinition**: å®Œæ•´ç®¡é“å®šä¹‰çš„æ•°æ®ç»“æ„

## ä½¿ç”¨åœºæ™¯

### 1. å¿«é€ŸåŸå‹å¼€å‘
```sql
CREATE PIPELINE prototype (
  source = FileSource { data_path: "test.txt" },
  sink = TerminalSink {},
  source -> sink
);
```

### 2. å¤æ‚RAGç³»ç»Ÿ
```sql
CREATE PIPELINE advanced_rag (
  -- æ•°æ®æº
  source = FileSource { data_path: "corpus/", file_pattern: "*.md" },
  
  -- å¤šè·¯å¬å›
  dense_retriever = ChromaRetriever { top_k: 20, collection_name: "dense" },
  sparse_retriever = BM25Retriever { top_k: 20, index_path: "bm25/" },
  
  -- é‡æ’åº
  reranker = CrossEncoderReranker { model: "cross-encoder/ms-marco", top_k: 5 },
  
  -- ç”Ÿæˆ
  promptor = QAPromptor { template: "Context: {context}\nQ: {question}\nA:" },
  generator = OpenAIGenerator { model: "gpt-4", temperature: 0.2 },
  
  -- è¾“å‡º
  sink = StreamingSink { format: "markdown" },
  
  -- è¿æ¥å…³ç³»
  source -> dense_retriever -> reranker,
  source -> sparse_retriever -> reranker,
  reranker -> promptor -> generator -> sink
);
```

### 3. å¤šæ¨¡æ€åˆ†æ
```sql
CREATE PIPELINE multimodal (
  image_source = ImageSource { data_path: "images/", formats: ["jpg", "png"] },
  text_source = FileSource { data_path: "descriptions.txt" },
  
  image_processor = VisionProcessor { model: "clip-vit-base" },
  text_processor = TextEmbedder { model: "sentence-transformers/all-MiniLM" },
  
  fusion = MultiModalFusion { strategy: "concatenate" },
  classifier = MLClassifier { model_path: "models/classifier.pkl" },
  
  sink = CSVSink { output_path: "results.csv" },
  
  image_source -> image_processor -> fusion,
  text_source -> text_processor -> fusion,
  fusion -> classifier -> sink
);
```

## é…ç½®æ˜ å°„

ç³»ç»Ÿè‡ªåŠ¨å°†æ“ä½œç¬¦ç±»å‹æ˜ å°„åˆ°é…ç½®èŠ‚ï¼š

- `FileSource` â†’ `source`
- `ChromaRetriever` â†’ `retriever`  
- `QAPromptor` â†’ `promptor`
- `OpenAIGenerator` â†’ `generator`
- `TerminalSink` â†’ `sink`

## ç”Ÿæˆçš„ä»£ç ç»“æ„

### YAMLé…ç½®
```yaml
pipeline:
  name: Simple QA
  description: Question answering pipeline
  mode: batch
  type: local
  version: 1.0.0

source:
  data_path: data/questions.txt
  chunk_size: 1000

retriever:
  top_k: 5
  collection_name: documents

generator:
  model: gpt-3.5-turbo
  temperature: 0.1
```

### Pythonè¿è¡Œå™¨
```python
"""Auto-generated SAGE pipeline from SQL definition."""

from sage.core.api.local_environment import LocalEnvironment
from sage.libs.io_utils.source import FileSource
from sage.libs.rag.retriever import ChromaRetriever
# ... other imports

def build_pipeline(config: dict) -> Tuple[LocalEnvironment, object]:
    env = LocalEnvironment(config["pipeline"]["name"])
    
    pipeline = (
        env.from_source(FileSource, config["source"])
        .map(ChromaRetriever, config["retriever"])
        .map(QAPromptor, config["promptor"])
        .map(OpenAIGenerator, config["generator"])
        .sink(TerminalSink, config["sink"])
    )
    
    return env, pipeline

def main():
    # CLI argument parsing and pipeline execution
    # ...
```

## æµ‹è¯•è¦†ç›–

- **TestSQLPipelineStore**: æ•°æ®åº“å­˜å‚¨å’Œæ£€ç´¢
- **TestSQLPipelineCompiler**: YAMLå’ŒPythonä»£ç ç”Ÿæˆ
- **TestSQLPipelineDSLParser**: SQLè¯­æ³•è§£æ
- **TestSQLIntegration**: ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

## ç›¸æ¯”Templateæ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | Templateæ–¹æ³• | SQLæ–¹æ³• |
|------|-------------|---------|
| çµæ´»æ€§ | âŒ å›ºå®šæ¨¡æ¿ | âœ… è‡ªç”±ç»„åˆ |
| å¯æ‰©å±•æ€§ | âŒ éœ€è¦ç¼–ç¨‹ | âœ… å£°æ˜å¼å®šä¹‰ |
| é‡ç”¨æ€§ | âŒ æ¨¡æ¿ç»‘å®š | âœ… ç»„ä»¶åŒ–è®¾è®¡ |
| ç‰ˆæœ¬ç®¡ç† | âŒ æ–‡ä»¶çº§åˆ« | âœ… æ•°æ®åº“çº§åˆ« |
| æŸ¥è¯¢èƒ½åŠ› | âŒ æ–‡ä»¶æœç´¢ | âœ… SQLæŸ¥è¯¢ |
| æ‰¹é‡æ“ä½œ | âŒ å•ä¸ªå¤„ç† | âœ… æ‰¹é‡ç®¡ç† |

## æœªæ¥æ‰©å±•

1. **å¯è§†åŒ–ç¼–è¾‘å™¨**: åŸºäºSQLå®šä¹‰çš„å›¾å½¢åŒ–ç®¡é“ç¼–è¾‘
2. **ç®¡é“è°ƒè¯•**: SQLå®šä¹‰çš„è¿è¡Œæ—¶è°ƒè¯•æ”¯æŒ
3. **æ€§èƒ½ä¼˜åŒ–**: åŸºäºä½¿ç”¨æ¨¡å¼çš„ç®¡é“ä¼˜åŒ–å»ºè®®
4. **ç‰ˆæœ¬æ§åˆ¶**: ç®¡é“å®šä¹‰çš„Gité›†æˆ
5. **æ¨¡æ¿ç”Ÿæˆ**: ä»SQLå®šä¹‰è‡ªåŠ¨ç”Ÿæˆæ¨¡æ¿

## ç»“è®º

SQL-based Pipeline Builder ä¸ºSAGEé¡¹ç›®æä¾›äº†å¼ºå¤§ã€çµæ´»çš„ç®¡é“æ„å»ºèƒ½åŠ›ï¼Œå®Œå…¨è§£å†³äº†issue #220ä¸­æå‡ºçš„éœ€æ±‚ï¼Œå¹¶ä¸ºæœªæ¥çš„æ™ºèƒ½æç¤ºå’ŒIDEé›†æˆå¥ å®šäº†åšå®åŸºç¡€ã€‚