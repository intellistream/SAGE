"""
SAGE Bench CLI - ç»Ÿä¸€ Benchmark å‘½ä»¤å…¥å£

æä¾›æ‰€æœ‰ Benchmark çš„ç»Ÿä¸€å­å‘½ä»¤ï¼š

å‘½ä»¤ç»“æ„:
    sage bench agent paper1 run --quick    # Paper 1 Agent Benchmark
    sage bench agent paper2                # Paper 2 (Coming Soon)
    sage bench control-plane run ...       # Control Plane Benchmark

å¿«æ·æ–¹å¼ (å‘åå…¼å®¹):
    sage bench run --quick                 # ç­‰åŒäº sage bench agent paper1 run
    sage bench eval --dataset sage         # ç­‰åŒäº sage bench agent paper1 eval

Benchmark ç±»å‹:
    - agent: Agent èƒ½åŠ›è¯„æµ‹ (å·¥å…·é€‰æ‹©/è§„åˆ’/æ—¶æœºåˆ¤æ–­)
    - control-plane: è°ƒåº¦ç­–ç•¥è¯„æµ‹ (LLM/Hybrid)
    - rag: RAG è¯„æµ‹ (é¢„ç•™)
    - memory: å†…å­˜ç®¡ç†è¯„æµ‹ (é¢„ç•™)
"""

from __future__ import annotations

import sys
from enum import Enum
from typing import Optional

import typer
from rich.console import Console
from rich.table import Table

console = Console()

# =========================================================================
# ä¸‰å±‚ Typer åº”ç”¨ç»“æ„
# =========================================================================

# é¡¶å±‚: sage bench
app = typer.Typer(
    name="bench",
    help="ğŸ§ª Benchmark - ç»Ÿä¸€è¯„æµ‹å…¥å£ (Agent, Control Plane, RAG, ...)",
    no_args_is_help=True,
)

# Agent å±‚: sage bench agent
agent_app = typer.Typer(
    name="agent",
    help="ğŸ¤ Agent Benchmarks - å¤šç¯‡è®ºæ–‡çš„ Agent èƒ½åŠ›è¯„æµ‹",
    no_args_is_help=True,
)

# Paper 1 å±‚: sage bench agent paper1
paper1_app = typer.Typer(
    name="paper1",
    help="ğŸ“Š Paper 1: SAGE-Bench - å·¥å…·é€‰æ‹©/è§„åˆ’/æ—¶æœºåˆ¤æ–­è¯„æµ‹æ¡†æ¶",
    no_args_is_help=True,
)

# Paper 2 å±‚ (é¢„ç•™): sage bench agent paper2
paper2_app = typer.Typer(
    name="paper2",
    help="ğŸ“ Paper 2: SAGE-Agent - Streaming Adaptive Learning",
    no_args_is_help=False,
)


@paper2_app.callback(invoke_without_command=True)
def paper2_placeholder(ctx: typer.Context):
    """Paper 2: SAGE-Agent (Coming Soon)"""
    if ctx.invoked_subcommand is None:
        console.print("[yellow]ğŸ“ Paper 2: SAGE-Agent å³å°†æ¨å‡º...[/yellow]")
        console.print("[dim]æ•¬è¯·æœŸå¾…æ›´å¤š Agent è¯„æµ‹å®éªŒã€‚[/dim]")


@paper2_app.command("status")
def paper2_status():
    """æŸ¥çœ‹ Paper 2 å®ç°çŠ¶æ€"""
    table = Table(title="ğŸ“Š Paper 2: SAGE-Agent å®ç°çŠ¶æ€", show_header=True)
    table.add_column("æ¨¡å—", style="cyan", width=25)
    table.add_column("çŠ¶æ€", width=10)
    table.add_column("å¤‡æ³¨", width=30)

    modules = [
        ("æµå¼æ•°æ®å¤„ç†", "ğŸš§ å¼€å‘ä¸­", "Streaming data pipeline"),
        ("è‡ªé€‚åº”å­¦ä¹ ç­–ç•¥", "ğŸ“‹ è§„åˆ’ä¸­", "Adaptive learning policy"),
        ("Agent è¯„æµ‹æ¡†æ¶", "ğŸ“‹ è§„åˆ’ä¸­", "Evaluation framework"),
        ("è®­ç»ƒè„šæœ¬", "ğŸ“‹ è§„åˆ’ä¸­", "Training scripts"),
    ]

    for module, status, note in modules:
        table.add_row(module, status, note)

    console.print(table)
    console.print("\n[dim]é¢„è®¡å®Œæˆæ—¶é—´: TBD[/dim]")


# æ³¨å†Œå±‚çº§å…³ç³»
agent_app.add_typer(paper1_app, name="paper1", rich_help_panel="Papers")
agent_app.add_typer(paper2_app, name="paper2", rich_help_panel="Papers")
app.add_typer(agent_app, name="agent", rich_help_panel="Benchmarks")

# Control Plane Benchmark (è°ƒåº¦ç­–ç•¥è¯„æµ‹)
try:
    from sage.benchmark.benchmark_control_plane.cli import create_app as create_cp_cli

    _cp_app = create_cp_cli()
except ImportError as e:  # pragma: no cover - optional dependency
    _cp_app = None
    console.print(f"[yellow]âš ï¸  æœªå®‰è£… control-plane benchmark ä¾èµ–: {e}[/yellow]")
else:
    if _cp_app is not None:
        app.add_typer(
            _cp_app,
            name="control-plane",
            help="ğŸ§  Control Plane Benchmark - è°ƒåº¦ç­–ç•¥/æ··åˆæ¨¡å¼è¯„æµ‹",
            rich_help_panel="Benchmarks",
        )
        app.add_typer(
            _cp_app,
            name="cp",
            help="Control Plane Benchmark (åˆ«å)",
            hidden=True,
        )


# =========================================================================
# Agent list å‘½ä»¤ - åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ papers
# =========================================================================


@agent_app.command("list")
def list_agent_papers():
    """åˆ—å‡ºæ‰€æœ‰ Agent Benchmark papers"""
    table = Table(title="ğŸ“š Available Agent Benchmarks", show_header=True)
    table.add_column("Paper", style="cyan", width=10)
    table.add_column("Description", width=45)
    table.add_column("Status", style="green", width=8)

    papers = [
        ("paper1", "SAGE-Bench - Agent èƒ½åŠ›è¯„æµ‹æ¡†æ¶\nå·¥å…·é€‰æ‹©/ä»»åŠ¡è§„åˆ’/æ—¶æœºåˆ¤æ–­è¯„æµ‹", "âœ… Ready"),
        ("paper2", "SAGE-Agent - Streaming Adaptive Learning\næµå¼è‡ªé€‚åº”å­¦ä¹ æ–¹æ³•", "ğŸš§ WIP"),
    ]

    for paper, desc, status in papers:
        table.add_row(paper, desc, status)

    console.print(table)
    console.print("\n[dim]Usage:[/dim]")
    console.print("  sage bench agent paper1 run --quick")
    console.print("  sage bench agent paper2")


# =========================================================================
# Paper 1 Agent Benchmark å®ç° (SAGE-Bench è¯„æµ‹æ¡†æ¶)
# =========================================================================


class Section(str, Enum):
    """è®ºæ–‡ç« èŠ‚"""

    ALL = "all"
    SEC_5_2 = "5.2"
    SEC_5_3 = "5.3"
    SEC_5_4 = "5.4"
    SEC_5_5 = "5.5"


class Experiment(str, Enum):
    """å•ä¸ªå®éªŒ"""

    TIMING = "timing"
    PLANNING = "planning"
    SELECTION = "selection"
    ERROR = "error"
    SCALING = "scaling"
    ROBUSTNESS = "robustness"
    ABLATION = "ablation"
    CROSS_DATASET = "cross-dataset"
    TRAINING = "training"


# ============================================================================
# Run Command
# ============================================================================


def _run_agent_experiments(
    section: Optional[Section],
    exp: Optional[Experiment],
    quick: bool,
    skip_llm: bool,
    skip_llm_scaling: bool,
    generate_paper: bool,
    output_dir: Optional[str],
):
    """
    è¿è¡Œ Paper 1 Benchmark å®éªŒ

    ç¤ºä¾‹:
        sage bench agent paper1 run --quick         # å¿«é€Ÿæµ‹è¯•
        sage bench agent paper1 run --section 5.2   # ä¸»è¦è¯„æµ‹
        sage bench run --quick                      # å¿«æ·æ–¹å¼
    """
    try:
        # æ·»åŠ å®éªŒè„šæœ¬**çˆ¶ç›®å½•**åˆ° sys.pathï¼Œä½¿å¾— run_paper1_experiments.py
        # ä¸­çš„ "from experiments.xxx" å¯¼å…¥èƒ½æ­£å¸¸å·¥ä½œ
        # æ³¨æ„ï¼šå¿…é¡»æ˜¯çˆ¶ç›®å½•ï¼Œå› ä¸º Python éœ€è¦ä» sys.path ä¸‹æŸ¥æ‰¾ "experiments" æ¨¡å—
        from pathlib import Path

        import sage.benchmark.benchmark_agent.scripts.experiments as exp_module

        exp_dir = Path(exp_module.__file__).parent
        scripts_dir = exp_dir.parent  # .../scripts/ ç›®å½•
        if str(scripts_dir) not in sys.path:
            sys.path.insert(0, str(scripts_dir))

        from sage.benchmark.benchmark_agent.scripts.experiments.run_paper1_experiments import (
            main as run_main,
        )

        # æ„å»ºå‚æ•°
        sys.argv = ["run_paper1_experiments.py"]

        if section:
            sys.argv.extend(["--section", section.value])
        if exp:
            sys.argv.extend(["--exp", exp.value])
        if quick:
            sys.argv.append("--quick")
        if skip_llm:
            sys.argv.append("--skip-llm")
        if skip_llm_scaling:
            sys.argv.append("--skip-llm-scaling")
        if generate_paper:
            sys.argv.append("--generate-paper")
        if output_dir:
            sys.argv.extend(["--output-dir", output_dir])

        run_main()

    except ImportError as e:
        console.print("[red]é”™è¯¯: æ— æ³•å¯¼å…¥ benchmark æ¨¡å—[/red]")
        console.print("[yellow]è¯·ç¡®ä¿å·²å®‰è£… sage-benchmark: pip install isage-benchmark[/yellow]")
        console.print(f"[dim]è¯¦ç»†é”™è¯¯: {e}[/dim]")
        raise typer.Exit(1)


@paper1_app.command("run")
@app.command("run", rich_help_panel="Quick Access (Paper 1)")
def run_experiments(
    section: Optional[Section] = typer.Option(
        None, "--section", "-s", help="è¿è¡Œç‰¹å®šç« èŠ‚ (5.2/5.3/5.4/5.5/all)"
    ),
    exp: Optional[Experiment] = typer.Option(
        None, "--exp", "-e", help="è¿è¡Œå•ä¸ªå®éªŒ (timing/planning/selection/...)"
    ),
    quick: bool = typer.Option(False, "--quick", "-q", help="å¿«é€Ÿæ¨¡å¼ (å‡å°‘æ ·æœ¬é‡)"),
    skip_llm: bool = typer.Option(False, "--skip-llm", help="è·³è¿‡ LLM-based æ–¹æ³•"),
    skip_llm_scaling: bool = typer.Option(
        False, "--skip-llm-scaling", help="è·³è¿‡ LLM Scaling æµ‹è¯•"
    ),
    generate_paper: bool = typer.Option(False, "--generate-paper", help="ç”Ÿæˆè®ºæ–‡å›¾è¡¨å’Œè¡¨æ ¼"),
    output_dir: Optional[str] = typer.Option(
        None, "--output", "-o", help="è¾“å‡ºç›®å½• (é»˜è®¤ .sage/benchmark/paper1/)"
    ),
):
    """Paper 1 Agent Benchmark - è¿è¡Œå®éªŒ (å¿«æ·æ–¹å¼: `sage bench run`)"""

    _run_agent_experiments(
        section,
        exp,
        quick,
        skip_llm,
        skip_llm_scaling,
        generate_paper,
        output_dir,
    )


# ============================================================================
# Eval Command
# ============================================================================


def _run_agent_evaluation(dataset: str, samples: int, top_k: int) -> None:
    """
    å·¥å…·é€‰æ‹©è¯„æµ‹

    ç¤ºä¾‹:
        sage bench agent paper1 eval --dataset sage --samples 100
        sage bench agent paper1 eval --dataset all  # è·¨æ•°æ®é›†
        sage bench eval --dataset sage              # å¿«æ·æ–¹å¼
    """
    try:
        # æ·»åŠ å®éªŒè„šæœ¬çˆ¶ç›®å½•åˆ° sys.path
        from pathlib import Path

        import sage.benchmark.benchmark_agent.scripts.experiments as exp_module

        exp_dir = Path(exp_module.__file__).parent
        scripts_dir = exp_dir.parent
        if str(scripts_dir) not in sys.path:
            sys.path.insert(0, str(scripts_dir))

        from sage.benchmark.benchmark_agent.scripts.experiments.exp_utils import (
            setup_experiment_env,
        )

        setup_experiment_env()

        if dataset == "all":
            from sage.benchmark.benchmark_agent.scripts.experiments.exp_cross_dataset import (
                run_cross_dataset_evaluation,
            )

            run_cross_dataset_evaluation(
                datasets=["sage", "acebench"],
                max_samples=samples,
                verbose=True,
            )
        else:
            from sage.benchmark.benchmark_agent.scripts.experiments.exp_main_selection import (
                run_selection_experiment,
            )

            run_selection_experiment(
                max_samples=samples,
                top_k=top_k,
                skip_llm=False,
                verbose=True,
            )

    except ImportError as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•å¯¼å…¥ benchmark æ¨¡å—: {e}[/red]")
        raise typer.Exit(1)


@paper1_app.command("eval")
@app.command("eval", rich_help_panel="Quick Access (Paper 1)")
def eval_agent(
    dataset: str = typer.Option("sage", "--dataset", "-d", help="æ•°æ®é›† (sage/acebench/all)"),
    samples: int = typer.Option(100, "--samples", "-n", help="æ ·æœ¬æ•°é‡"),
    top_k: int = typer.Option(5, "--top-k", "-k", help="Top-K å·¥å…·æ•°"),
):
    """Paper 1 Agent Benchmark - å·¥å…·é€‰æ‹©è¯„æµ‹ (å¿«æ·æ–¹å¼: `sage bench eval`)"""

    _run_agent_evaluation(dataset, samples, top_k)


# ============================================================================
# Train Command
# ============================================================================


def _run_agent_training(
    methods: str,
    model: str,
    quick: bool,
    dry_run: bool,
):
    """
    è®­ç»ƒæ–¹æ³•å¯¹æ¯” (Section 5.5)

    ç¤ºä¾‹:
        sage bench agent paper1 train --dry-run          # æ¨¡æ‹Ÿè¿è¡Œ
        sage bench agent paper1 train --methods A_baseline  # å•ä¸ªæ–¹æ³•
        sage bench train --quick                         # å¿«æ·æ–¹å¼
    """
    try:
        # æ·»åŠ å®éªŒè„šæœ¬çˆ¶ç›®å½•åˆ° sys.path
        from pathlib import Path

        import sage.benchmark.benchmark_agent.scripts.experiments as exp_module

        exp_dir = Path(exp_module.__file__).parent
        scripts_dir = exp_dir.parent
        if str(scripts_dir) not in sys.path:
            sys.path.insert(0, str(scripts_dir))

        from sage.benchmark.benchmark_agent.scripts.experiments.exp_training_comparison import (
            run_training_comparison,
        )

        method_list = methods.split(",")
        run_training_comparison(
            methods=method_list,
            base_model=model,
            quick=quick,
            dry_run=dry_run,
            verbose=True,
        )

    except ImportError as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•å¯¼å…¥è®­ç»ƒæ¨¡å—: {e}[/red]")
        raise typer.Exit(1)


@paper1_app.command("train")
@app.command("train", rich_help_panel="Quick Access (Paper 1)")
def train_agent(
    methods: str = typer.Option(
        "A_baseline,D_combined", "--methods", "-m", help="è®­ç»ƒæ–¹æ³• (é€—å·åˆ†éš”)"
    ),
    model: str = typer.Option("Qwen/Qwen2.5-1.5B-Instruct", "--model", help="åŸºç¡€æ¨¡å‹"),
    quick: bool = typer.Option(False, "--quick", "-q", help="å¿«é€Ÿæ¨¡å¼"),
    dry_run: bool = typer.Option(False, "--dry-run", help="æ¨¡æ‹Ÿè¿è¡Œ (ä¸å®é™…è®­ç»ƒ)"),
):
    """Paper 1 Agent Benchmark - è®­ç»ƒæ–¹æ³•å¯¹æ¯” (å¿«æ·æ–¹å¼: `sage bench train`)"""

    _run_agent_training(methods, model, quick, dry_run)


# ============================================================================
# LLM Subcommand
# ============================================================================

llm_app = typer.Typer(help="Paper 1 LLM æœåŠ¡ç®¡ç†")
paper1_app.add_typer(llm_app, name="llm")
app.add_typer(llm_app, name="llm", hidden=True)


@llm_app.command("status")
def llm_status():
    """æŸ¥çœ‹ LLM æœåŠ¡çŠ¶æ€"""
    try:
        # æ·»åŠ å®éªŒè„šæœ¬çˆ¶ç›®å½•åˆ° sys.path
        from pathlib import Path

        import sage.benchmark.benchmark_agent.scripts.experiments as exp_module

        exp_dir = Path(exp_module.__file__).parent
        scripts_dir = exp_dir.parent
        if str(scripts_dir) not in sys.path:
            sys.path.insert(0, str(scripts_dir))

        from sage.benchmark.benchmark_agent.scripts.experiments.llm_service import (
            print_llm_status,
        )

        print_llm_status()

    except ImportError as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•å¯¼å…¥ LLM æœåŠ¡æ¨¡å—: {e}[/red]")
        raise typer.Exit(1)


@llm_app.command("start")
def llm_start(
    model: str = typer.Option("Qwen/Qwen2.5-1.5B-Instruct", "--model", "-m", help="æ¨¡å‹åç§°"),
    port: int = typer.Option(8901, "--port", "-p", help="æœåŠ¡ç«¯å£"),
    gpu_memory: float = typer.Option(0.9, "--gpu-memory", help="GPU æ˜¾å­˜å ç”¨æ¯”ä¾‹"),
):
    """å¯åŠ¨ LLM æœåŠ¡"""
    try:
        # æ·»åŠ å®éªŒè„šæœ¬çˆ¶ç›®å½•åˆ° sys.path
        from pathlib import Path

        import sage.benchmark.benchmark_agent.scripts.experiments as exp_module

        exp_dir = Path(exp_module.__file__).parent
        scripts_dir = exp_dir.parent
        if str(scripts_dir) not in sys.path:
            sys.path.insert(0, str(scripts_dir))

        from sage.benchmark.benchmark_agent.scripts.experiments.llm_service import (
            start_llm_service,
        )

        success = start_llm_service(
            model=model,
            port=port,
            gpu_memory=gpu_memory,
        )
        if not success:
            raise typer.Exit(1)

    except ImportError as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•å¯¼å…¥ LLM æœåŠ¡æ¨¡å—: {e}[/red]")
        raise typer.Exit(1)


@llm_app.command("stop")
def llm_stop():
    """åœæ­¢ LLM æœåŠ¡"""
    try:
        # æ·»åŠ å®éªŒè„šæœ¬çˆ¶ç›®å½•åˆ° sys.path
        from pathlib import Path

        import sage.benchmark.benchmark_agent.scripts.experiments as exp_module

        exp_dir = Path(exp_module.__file__).parent
        scripts_dir = exp_dir.parent
        if str(scripts_dir) not in sys.path:
            sys.path.insert(0, str(scripts_dir))

        from sage.benchmark.benchmark_agent.scripts.experiments.llm_service import (
            stop_llm_service,
        )

        success = stop_llm_service()
        if not success:
            raise typer.Exit(1)

    except ImportError as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•å¯¼å…¥ LLM æœåŠ¡æ¨¡å—: {e}[/red]")
        raise typer.Exit(1)


# ============================================================================
# List Command
# ============================================================================


def _list_resources(resource: str) -> None:
    if resource == "experiments":
        _list_experiments()
    elif resource == "datasets":
        _list_datasets()
    elif resource == "methods":
        _list_methods()
    else:
        console.print(f"[red]æœªçŸ¥èµ„æºç±»å‹: {resource}[/red]")
        console.print("å¯ç”¨: experiments, datasets, methods")
        raise typer.Exit(1)


@paper1_app.command("list")
def list_resources(
    resource: str = typer.Argument("experiments", help="èµ„æºç±»å‹ (experiments/datasets/methods)"),
):
    """åˆ—å‡º Paper 1 å¯ç”¨èµ„æº"""

    _list_resources(resource)


def _list_experiments():
    """åˆ—å‡ºå¯ç”¨å®éªŒ"""
    table = Table(title="ğŸ“‹ å¯ç”¨å®éªŒ", show_header=True)
    table.add_column("ç« èŠ‚", style="cyan")
    table.add_column("å®éªŒ", style="green")
    table.add_column("æè¿°")

    experiments = [
        ("5.2", "timing", "å·¥å…·è°ƒç”¨æ—¶æœºè¯„æµ‹"),
        ("5.2", "planning", "ä»»åŠ¡è§„åˆ’èƒ½åŠ›è¯„æµ‹"),
        ("5.2", "selection", "å·¥å…·é€‰æ‹©å‡†ç¡®ç‡è¯„æµ‹"),
        ("5.3", "error", "é”™è¯¯ç±»å‹åˆ†å¸ƒåˆ†æ"),
        ("5.3", "scaling", "å·¥å…·æ•°é‡æ‰©å±•æ€§åˆ†æ"),
        ("5.3", "robustness", "é²æ£’æ€§åˆ†æ"),
        ("5.3", "ablation", "æ¶ˆèå®éªŒ"),
        ("5.4", "cross-dataset", "è·¨æ•°æ®é›†æ³›åŒ–è¯„æµ‹"),
        ("5.5", "training", "è®­ç»ƒæ–¹æ³•å¯¹æ¯”"),
    ]

    for section, exp, desc in experiments:
        table.add_row(section, exp, desc)

    console.print(table)


def _list_datasets():
    """åˆ—å‡ºå¯ç”¨æ•°æ®é›†"""
    table = Table(title="ğŸ“Š å¯ç”¨æ•°æ®é›†", show_header=True)
    table.add_column("åç§°", style="cyan")
    table.add_column("æè¿°")
    table.add_column("æ ·æœ¬æ•°", style="green")

    datasets = [
        ("sage", "SAGE å†…ç½®å·¥å…·é€‰æ‹©æ•°æ®é›†", "~1000"),
        ("acebench", "ACEBench å¤–éƒ¨æ•°æ®é›†", "~500"),
    ]

    for name, desc, samples in datasets:
        table.add_row(name, desc, samples)

    console.print(table)


def _list_methods():
    """åˆ—å‡ºå¯ç”¨æ–¹æ³•"""
    table = Table(title="ğŸ”§ å¯ç”¨æ–¹æ³•", show_header=True)
    table.add_column("ç±»å‹", style="cyan")
    table.add_column("æ–¹æ³• ID", style="green")
    table.add_column("æè¿°")

    methods = [
        ("Timing", "rule_based", "å…³é”®è¯åŒ¹é… + æ­£åˆ™æ¨¡å¼"),
        ("Timing", "llm_based", "ç›´æ¥ç”¨ LLM åˆ¤æ–­"),
        ("Timing", "hybrid", "Rule åˆç­› + LLM ç²¾åˆ¤"),
        ("Planning", "simple", "ç®€å•è´ªå¿ƒè§„åˆ’"),
        ("Planning", "react", "ReAct æ–¹æ³•"),
        ("Planning", "tot", "Tree-of-Thoughts"),
        ("Selection", "keyword", "å…³é”®è¯åŒ¹é…"),
        ("Selection", "embedding", "è¯­ä¹‰ç›¸ä¼¼åº¦"),
        ("Selection", "gorilla", "Gorilla æ–¹æ³•"),
        ("Selection", "dfsdt", "DFSDT æ–¹æ³•"),
        ("Training", "A_baseline", "åŸºç¡€ SFT"),
        ("Training", "D_combined", "ç»„åˆæ–¹æ³• (Coreset + Continual)"),
    ]

    for typ, method_id, desc in methods:
        table.add_row(typ, method_id, desc)

    console.print(table)


# ============================================================================
# Figures & Tables
# ============================================================================


def _generate_figures(output_dir: Optional[str]) -> None:
    try:
        from sage.benchmark.benchmark_agent.scripts.experiments.figure_generator import (
            generate_all_figures,
        )

        generate_all_figures(output_dir=output_dir)
        console.print("[green]âœ… å›¾è¡¨ç”Ÿæˆå®Œæˆ[/green]")

    except ImportError as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•å¯¼å…¥å›¾è¡¨ç”Ÿæˆæ¨¡å—: {e}[/red]")
        raise typer.Exit(1)


@paper1_app.command("figures")
def generate_figures(
    output_dir: Optional[str] = typer.Option(None, "--output", "-o", help="è¾“å‡ºç›®å½•"),
):
    """ç”Ÿæˆ Paper 1 å›¾è¡¨"""

    _generate_figures(output_dir)


def _generate_tables(output_dir: Optional[str]) -> None:
    try:
        from sage.benchmark.benchmark_agent.scripts.experiments.table_generator import (
            generate_all_tables,
        )

        generate_all_tables(output_dir=output_dir)
        console.print("[green]âœ… è¡¨æ ¼ç”Ÿæˆå®Œæˆ[/green]")

    except ImportError as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•å¯¼å…¥è¡¨æ ¼ç”Ÿæˆæ¨¡å—: {e}[/red]")
        raise typer.Exit(1)


@paper1_app.command("tables")
def generate_tables(
    output_dir: Optional[str] = typer.Option(None, "--output", "-o", help="è¾“å‡ºç›®å½•"),
):
    """ç”Ÿæˆ Paper 1 LaTeX è¡¨æ ¼"""

    _generate_tables(output_dir)


@app.command("list", rich_help_panel="Quick Access (Paper 1)")
def list_default(
    resource: str = typer.Argument("experiments", help="èµ„æºç±»å‹ (experiments/datasets/methods)"),
):
    """Paper 1 - åˆ—å‡ºèµ„æº (å…¼å®¹ `sage bench list`)"""

    _list_resources(resource)


@app.command("figures", rich_help_panel="Quick Access (Paper 1)")
def figures_default(
    output_dir: Optional[str] = typer.Option(None, "--output", "-o", help="è¾“å‡ºç›®å½•"),
):
    """Paper 1 - ç”Ÿæˆå›¾è¡¨ (å…¼å®¹ `sage bench figures`)"""

    _generate_figures(output_dir)


@app.command("tables", rich_help_panel="Quick Access (Paper 1)")
def tables_default(
    output_dir: Optional[str] = typer.Option(None, "--output", "-o", help="è¾“å‡ºç›®å½•"),
):
    """Paper 1 - ç”Ÿæˆè¡¨æ ¼ (å…¼å®¹ `sage bench tables`)"""

    _generate_tables(output_dir)
