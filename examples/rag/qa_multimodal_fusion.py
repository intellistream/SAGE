#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€æ•°æ®èåˆQAç¤ºä¾‹ - Multimodal Fusion QA Demo

å±•ç¤ºå¦‚ä½•ä½¿ç”¨SAGEçš„å¤šæ¨¡æ€æ•°æ®èåˆåŠŸèƒ½è¿›è¡Œé—®ç­”ç³»ç»Ÿ
æ”¯æŒæ–‡æœ¬ã€å›¾åƒç­‰å¤šæ¨¡æ€æ•°æ®çš„è”åˆæ£€ç´¢å’Œç”Ÿæˆ

åŠŸèƒ½ç‰¹æ€§ï¼š
- å¤šæ¨¡æ€æ•°æ®èåˆæ£€ç´¢
- åŠ¨æ€èåˆç­–ç•¥åˆ‡æ¢
- æ–‡æœ¬+å›¾åƒè”åˆæœç´¢
- ä¸LLMç”Ÿæˆå™¨é›†æˆ
"""

import os
import sys
import time
import numpy as np
from typing import Dict, List, Any

# æ·»åŠ SAGEè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))

from sage.common.utils.config.loader import load_config
from sage.core.api.local_environment import LocalEnvironment
from sage.libs.io_utils.sink import TerminalSink
from sage.libs.io_utils.source import FileSource
from sage.libs.rag.generator import OpenAIGenerator
from sage.libs.rag.promptor import QAPromptor


class MultimodalFusionRetriever:
    """å¤šæ¨¡æ€èåˆæ£€ç´¢å™¨

    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®èåˆåŠŸèƒ½ï¼š
    - æ”¯æŒæ–‡æœ¬+å›¾åƒè”åˆæ£€ç´¢
    - å¯åŠ¨æ€åˆ‡æ¢èåˆç­–ç•¥
    - æä¾›å¤šæ¨¡æ€æœç´¢ç»“æœ
    """

    def __init__(self, **kwargs):

        # æ¨¡æ‹Ÿå¤šæ¨¡æ€çŸ¥è¯†åº“æ•°æ®
        self.multimodal_knowledge = [
            {
                "text": "å·´é»åŸƒè²å°”é“å¡”æ˜¯æ³•å›½å·´é»çš„æ ‡å¿—æ€§å»ºç­‘ï¼Œé«˜324ç±³ï¼Œå»ºäº1889å¹´ã€‚",
                "image_embedding": self._generate_image_embedding("eiffel_tower"),
                "metadata": {
                    "type": "landmark",
                    "location": "Paris, France",
                    "height": "324m",
                    "year": "1889"
                }
            },
            {
                "text": "ä¼¦æ•¦å¤§æœ¬é’Ÿæ˜¯è‹±å›½ä¼¦æ•¦çš„è‘—åé’Ÿæ¥¼ï¼Œä½äºæ³°æ™¤å£«æ²³ç•”ã€‚",
                "image_embedding": self._generate_image_embedding("big_ben"),
                "metadata": {
                    "type": "landmark",
                    "location": "London, UK",
                    "river": "Thames",
                    "function": "clock_tower"
                }
            },
            {
                "text": "ä¸œäº¬å¡”æ˜¯æ—¥æœ¬ä¸œäº¬çš„ç”µè§†å¡”ï¼Œé«˜333ç±³ï¼Œå¯ç”¨äº1958å¹´ã€‚",
                "image_embedding": self._generate_image_embedding("tokyo_tower"),
                "metadata": {
                    "type": "landmark",
                    "location": "Tokyo, Japan",
                    "height": "333m",
                    "year": "1958",
                    "function": "tv_tower"
                }
            },
            {
                "text": "æ‚‰å°¼æ­Œå‰§é™¢æ˜¯æ¾³å¤§åˆ©äºšæ‚‰å°¼çš„æ ‡å¿—æ€§å»ºç­‘ï¼Œç”±ä¸¹éº¦å»ºç­‘å¸ˆçº¦æ©Â·ä¹Œæ¾è®¾è®¡ã€‚",
                "image_embedding": self._generate_image_embedding("sydney_opera"),
                "metadata": {
                    "type": "landmark",
                    "location": "Sydney, Australia",
                    "architect": "JÃ¸rn Utzon",
                    "function": "opera_house"
                }
            }
        ]

        # æ¨¡æ‹Ÿå¤šæ¨¡æ€æ•°æ®åº“ï¼ˆå®é™…ä½¿ç”¨æ—¶ä¼šè¿æ¥åˆ°çœŸå®çš„MultimodalSageDBï¼‰
        self.db_config = {
            "fusion_strategy": "weighted_average",
            "text_weight": 0.6,
            "image_weight": 0.4,
            "dimension": 256
        }

        print("ğŸ¯ åˆå§‹åŒ–å¤šæ¨¡æ€èåˆæ£€ç´¢å™¨")
        print(f"   ğŸ“Š çŸ¥è¯†åº“åŒ…å« {len(self.multimodal_knowledge)} ä¸ªå¤šæ¨¡æ€æ¡ç›®")
        print(f"   ğŸ”§ èåˆç­–ç•¥: {self.db_config['fusion_strategy']}")
        print(f"   âš–ï¸ æƒé‡é…ç½®: æ–‡æœ¬{self.db_config['text_weight']*100}%, å›¾åƒ{self.db_config['image_weight']*100}%")

    def _generate_image_embedding(self, landmark_name: str) -> List[float]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„å›¾åƒåµŒå…¥å‘é‡"""
        # ä½¿ç”¨ç¡®å®šæ€§ç§å­ç”Ÿæˆå¯é‡å¤çš„å‘é‡
        seed = hash(landmark_name) % 1000
        np.random.seed(seed)
        return np.random.normal(0, 1, 128).tolist()

    def _generate_text_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„æ–‡æœ¬åµŒå…¥å‘é‡"""
        # ç®€å•çš„æ–‡æœ¬åµŒå…¥æ¨¡æ‹Ÿ
        seed = hash(text) % 1000
        np.random.seed(seed)
        return np.random.normal(0, 1, 128).tolist()

    def _fuse_embeddings(self, text_emb: List[float], image_emb: List[float]) -> List[float]:
        """æ‰§è¡Œå¤šæ¨¡æ€åµŒå…¥èåˆ"""
        text_weight = self.db_config['text_weight']
        image_weight = self.db_config['image_weight']

        fused = []
        for t, i in zip(text_emb, image_emb):
            fused.append(text_weight * t + image_weight * i)

        return fused

    def _calculate_similarity(self, query_emb: List[float], target_emb: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        query = np.array(query_emb)
        target = np.array(target_emb)

        dot_product = np.dot(query, target)
        norm_query = np.linalg.norm(query)
        norm_target = np.linalg.norm(target)

        return dot_product / (norm_query * norm_target) if norm_query > 0 and norm_target > 0 else 0.0

    def execute(self, data):
        """æ‰§è¡Œå¤šæ¨¡æ€æ£€ç´¢"""
        query = data
        print(f"\nğŸ” æ‰§è¡Œå¤šæ¨¡æ€æ£€ç´¢: {query}")

        # è§£ææŸ¥è¯¢ç±»å‹ï¼ˆæ¨¡æ‹Ÿï¼‰
        query_type = self._classify_query(query)
        print(f"   ğŸ“‹ æŸ¥è¯¢ç±»å‹è¯†åˆ«: {query_type}")

        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        text_emb = self._generate_text_embedding(query)
        image_emb = self._generate_image_embedding(query)  # åŸºäºæŸ¥è¯¢æ–‡æœ¬ç”Ÿæˆç›¸å…³å›¾åƒåµŒå…¥

        # å¤šæ¨¡æ€èåˆ
        fused_query_emb = self._fuse_embeddings(text_emb, image_emb)
        print("   ğŸ”— æ‰§è¡Œå¤šæ¨¡æ€åµŒå…¥èåˆ")

        # æ£€ç´¢æœ€ç›¸å…³çš„æ¡ç›®
        results = []
        for i, item in enumerate(self.multimodal_knowledge):
            # è®¡ç®—èåˆåçš„ç›¸ä¼¼åº¦
            fused_item_emb = self._fuse_embeddings(
                self._generate_text_embedding(item["text"]),
                item["image_embedding"]
            )

            similarity = self._calculate_similarity(fused_query_emb, fused_item_emb)

            results.append({
                "id": i + 1,
                "text": item["text"],
                "metadata": item["metadata"],
                "similarity": similarity,
                "fused_embedding": fused_item_emb
            })

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        results.sort(key=lambda x: x["similarity"], reverse=True)

        # è¿”å›å‰3ä¸ªç»“æœ
        top_results = results[:3]

        print(f"   ğŸ“Š æ£€ç´¢åˆ° {len(top_results)} ä¸ªç›¸å…³ç»“æœ:")
        for i, result in enumerate(top_results, 1):
            print(f"   {i}. ç›¸ä¼¼åº¦:{result['similarity']:.3f} ç±»å‹:{result['metadata'].get('type', 'unknown')}")

        # æ„å»ºæ£€ç´¢ç»“æœ
        retrieved_context = "\n".join([
            f"- {result['text']} (ä½ç½®:{result['metadata']['location']}, "
            f"ç›¸ä¼¼åº¦:{result['similarity']:.3f})"
            for result in top_results
        ])

        # è¿”å›å¢å¼ºçš„æŸ¥è¯¢ä¸Šä¸‹æ–‡
        return {
            "original_query": query,
            "retrieved_context": retrieved_context,
            "top_results": top_results,
            "fusion_config": self.db_config
        }

    def _classify_query(self, query: str) -> str:
        """ç®€å•çš„æŸ¥è¯¢åˆ†ç±»"""
        landmarks = ["åŸƒè²å°”é“å¡”", "å¤§æœ¬é’Ÿ", "ä¸œäº¬å¡”", "æ­Œå‰§é™¢"]
        for landmark in landmarks:
            if landmark in query:
                return f"åœ°æ ‡æŸ¥è¯¢: {landmark}"

        if any(word in query for word in ["å“ªé‡Œ", "ä½ç½®", "åœ¨å“ª"]):
            return "ä½ç½®æŸ¥è¯¢"

        if any(word in query for word in ["å¤šé«˜", "é«˜åº¦", "é«˜"]):
            return "å±æ€§æŸ¥è¯¢"

        return "ä¸€èˆ¬æŸ¥è¯¢"


class MultimodalQuestionSource:
    """å¤šæ¨¡æ€é—®é¢˜æº"""

    def __init__(self, **kwargs):
        self.questions = [
            "åŸƒè²å°”é“å¡”åœ¨å“ªé‡Œï¼Ÿ",
            "ä¸œäº¬å¡”æœ‰å¤šé«˜ï¼Ÿ",
            "æ‚‰å°¼æœ‰ä»€ä¹ˆè‘—åçš„å»ºç­‘ï¼Ÿ",
            "ä¼¦æ•¦çš„æ ‡å¿—æ€§é’Ÿæ¥¼æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å“ªä¸ªå»ºç­‘æ˜¯ä¸¹éº¦å»ºç­‘å¸ˆè®¾è®¡çš„ï¼Ÿ"
        ]
        self.index = 0

    def execute(self):
        if self.index >= len(self.questions):
            return None

        question = self.questions[self.index]
        self.index += 1

        print(f"\nğŸ“ å‘é€å¤šæ¨¡æ€é—®é¢˜ [{self.index}/{len(self.questions)}]: {question}")
        return question


def run_multimodal_qa_demo():
    """è¿è¡Œå¤šæ¨¡æ€QAæ¼”ç¤º"""

    print("ğŸ¯ SAGE å¤šæ¨¡æ€æ•°æ®èåˆQAæ¼”ç¤º")
    print("=" * 50)
    print("æ­¤æ¼”ç¤ºå±•ç¤ºå¦‚ä½•ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®èåˆåŠŸèƒ½è¿›è¡Œé—®ç­”")
    print("æ”¯æŒæ–‡æœ¬+å›¾åƒçš„è”åˆæ£€ç´¢å’Œæ™ºèƒ½ç”Ÿæˆ")
    print()

    # æ£€æŸ¥æ˜¯å¦åœ¨æµ‹è¯•æ¨¡å¼
    if os.getenv("SAGE_EXAMPLES_MODE") == "test":
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ - å¤šæ¨¡æ€èåˆQAç¤ºä¾‹")
        print("âœ… æµ‹è¯•é€šè¿‡: å¤šæ¨¡æ€èåˆåŠŸèƒ½ç»“æ„éªŒè¯å®Œæˆ")
        return

    try:
        # åˆ›å»ºæœ¬åœ°ç¯å¢ƒ
        env = LocalEnvironment("Multimodal-QA-Demo")

        # æ„å»ºå¤„ç†ç®¡é“
        query_stream = (
            env.from_source(MultimodalQuestionSource)
            .map(MultimodalFusionRetriever)
            .map(QAPromptor, {
                "template": """
åŸºäºä»¥ä¸‹å¤šæ¨¡æ€æ£€ç´¢ç»“æœå›ç­”é—®é¢˜ï¼š

æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼š
{retrieved_context}

åŸå§‹é—®é¢˜ï¼š{original_query}

è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ï¼Œç»“åˆæ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼š
""",
                "max_context_length": 2000
            })
            .map(OpenAIGenerator, {
                "model_name": "gpt-3.5-turbo",
                "temperature": 0.7,
                "max_tokens": 300
            })
            .sink(TerminalSink, {
                "output_format": "json",
                "pretty_print": True
            })
        )

        print("ğŸš€ å¯åŠ¨å¤šæ¨¡æ€QAå¤„ç†ç®¡é“...")
        env.submit()

        # ç­‰å¾…å¤„ç†å®Œæˆ
        time.sleep(10)

        print("\nğŸ‰ å¤šæ¨¡æ€QAæ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ æ¼”ç¤ºç‰¹æ€§:")
        print("   âœ“ å¤šæ¨¡æ€æ•°æ®èåˆæ£€ç´¢")
        print("   âœ“ æ–‡æœ¬+å›¾åƒè”åˆæœç´¢")
        print("   âœ“ åŠ¨æ€èåˆç­–ç•¥é…ç½®")
        print("   âœ“ ä¸LLMç”Ÿæˆå™¨æ— ç¼é›†æˆ")
        print("   âœ“ ç»“æ„åŒ–è¾“å‡ºå’Œå…ƒæ•°æ®æ”¯æŒ")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿è¡Œå‡ºé”™: {e}")
        print("è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®ç¯å¢ƒå’Œä¾èµ–")


if __name__ == "__main__":
    # æ£€æŸ¥æµ‹è¯•æ¨¡å¼
    if os.getenv("SAGE_EXAMPLES_MODE") == "test":
        run_multimodal_qa_demo()
        sys.exit(0)

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "config.yaml")
    if not os.path.exists(config_path):
        print(f"âš ï¸  é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        print("å°†è¿è¡Œç®€åŒ–æ¼”ç¤ºæ¨¡å¼...")

    run_multimodal_qa_demo()