#!/usr/bin/env python3
"""
MemoryService ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åœ¨SAGEä¸­è®¾ç½®å’Œä½¿ç”¨MemoryServiceè¿›è¡Œé«˜çº§è®°å¿†ç®¡ç†

MemoryService æ˜¯ SAGE middleware ä¸­çš„é«˜çº§ç¼–æ’æœåŠ¡ï¼Œ
å®ƒåè°ƒ KVã€VDB å’Œ Graph å¾®æœåŠ¡ï¼Œæä¾›ç»Ÿä¸€çš„è®°å¿†ç®¡ç†æ¥å£ã€‚
"""

import os
import time
from typing import Any, Dict, List

from sage.common.utils.logging.custom_logger import CustomLogger
from sage.core.api.function.batch_function import BatchFunction
from sage.core.api.function.map_function import MapFunction
from sage.core.api.function.sink_function import SinkFunction
from sage.core.api.local_environment import LocalEnvironment
from sage.middleware.services.memory.memory_service import MemoryService


# æ¨¡æ‹Ÿçš„embeddingå‡½æ•°ï¼ˆå®é™…ä½¿ç”¨ä¸­åº”è¯¥è°ƒç”¨çœŸå®çš„embeddingæœåŠ¡ï¼‰
def mock_embedding(text: str) -> List[float]:
    """ç®€å•çš„æ¨¡æ‹Ÿembeddingå‡½æ•°"""
    import hashlib
    import numpy as np

    # ä½¿ç”¨æ–‡æœ¬çš„hashæ¥ç”Ÿæˆç¡®å®šæ€§çš„å‘é‡ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
    hash_obj = hashlib.md5(text.encode())
    hash_int = int(hash_obj.hexdigest(), 16)
    np.random.seed(hash_int % 2**32)
    return np.random.random(384).tolist()


class ConversationDataSource(BatchFunction):
    """ç”Ÿæˆå¯¹è¯æ•°æ®çš„æ‰¹å¤„ç†æº"""

    def __init__(self, conversations: List[Dict[str, Any]]):
        super().__init__()
        self.conversations = conversations
        self.index = 0

    def execute(self):
        if self.index >= len(self.conversations):
            return None
        conversation = self.conversations[self.index]
        self.index += 1
        return conversation


class MemoryProcessor(MapFunction):
    """ä½¿ç”¨MemoryServiceå¤„ç†è®°å¿†çš„æ˜ å°„å‡½æ•°"""

    def __init__(self, session_id: str):
        super().__init__()
        self.session_id = session_id

    def execute(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å¯¹è¯æ•°æ®å¹¶å­˜å‚¨åˆ°è®°å¿†ä¸­"""
        memory_service = self.call_service["memory_service"]

        user_message = data["user_message"]
        ai_response = data["ai_response"]
        topic = data.get("topic", "general")

        try:
            # å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯
            user_memory_id = memory_service.store_memory(
                content=user_message,
                vector=mock_embedding(user_message),
                session_id=self.session_id,
                memory_type="conversation",
                metadata={
                    "speaker": "user",
                    "topic": topic,
                    "timestamp": time.time()
                }
            )

            # å­˜å‚¨AIå›å¤
            ai_memory_id = memory_service.store_memory(
                content=ai_response,
                vector=mock_embedding(ai_response),
                session_id=self.session_id,
                memory_type="conversation",
                metadata={
                    "speaker": "ai",
                    "topic": topic,
                    "timestamp": time.time()
                }
            )

            # å¦‚æœæ˜¯ç¼–ç¨‹ç›¸å…³ï¼Œå­˜å‚¨è¯­ä¹‰è®°å¿†
            if "python" in user_message.lower() or "ç¼–ç¨‹" in user_message:
                semantic_content = f"ç”¨æˆ·å¯¹ç¼–ç¨‹æ„Ÿå…´è¶£ï¼š{user_message[:50]}..."
                memory_service.store_memory(
                    content=semantic_content,
                    vector=mock_embedding(semantic_content),
                    session_id=self.session_id,
                    memory_type="knowledge",
                    metadata={
                        "topic": "programming",
                        "importance": "medium",
                        "timestamp": time.time()
                    }
                )

            return {
                "session_id": self.session_id,
                "user_memory_id": user_memory_id,
                "ai_memory_id": ai_memory_id,
                "topic": topic,
                "processed": True
            }

        except Exception as e:
            return {
                "error": f"å­˜å‚¨è®°å¿†å¤±è´¥: {str(e)}",
                "session_id": self.session_id
            }


class MemoryRetriever(MapFunction):
    """ä»è®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯çš„æ˜ å°„å‡½æ•°"""

    def __init__(self, session_id: str):
        super().__init__()
        self.session_id = session_id

    def execute(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºæŸ¥è¯¢æ£€ç´¢ç›¸å…³è®°å¿†"""
        memory_service = self.call_service["memory_service"]

        query = data.get("query", "")
        if not query:
            return {"error": "No query provided"}

        try:
            # æœç´¢ç›¸å…³è®°å¿†
            query_vector = mock_embedding(query)
            relevant_memories = memory_service.search_memories(
                query_vector=query_vector,
                session_id=self.session_id,
                limit=3
            )

            # è·å–ä¼šè¯è®°å¿†å†å²
            session_memories = memory_service.get_session_memories(self.session_id)

            # æ ¼å¼åŒ–ç»“æœ
            formatted_memories = []
            for mem in relevant_memories:
                formatted_memories.append({
                    "text": mem.get("content", ""),
                    "type": mem.get("memory_type", "unknown"),
                    "meta": mem.get("metadata", {})
                })

            # ç”Ÿæˆç®€åŒ–çš„ä¸Šä¸‹æ–‡
            context_parts = []
            for mem in session_memories[-5:]:  # æœ€è¿‘5æ¡è®°å¿†
                speaker = mem.get("metadata", {}).get("speaker", "unknown")
                content = mem.get("content", "")[:100]
                context_parts.append(f"[{speaker}] {content}")

            context = "\n".join(context_parts)

            return {
                "query": query,
                "relevant_memories": formatted_memories,
                "session_memories_count": len(session_memories),
                "context": context,
                "session_id": self.session_id
            }

        except Exception as e:
            return {
                "error": f"æ£€ç´¢è®°å¿†å¤±è´¥: {str(e)}",
                "query": query,
                "session_id": self.session_id
            }


class ResultPrinter(SinkFunction):
    """æ‰“å°ç»“æœçš„æ¥æ”¶å™¨å‡½æ•°"""

    def execute(self, data: Dict[str, Any]):
        """æ‰“å°å¤„ç†ç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ§  MemoryService å¤„ç†ç»“æœ")
        print("="*60)

        if "error" in data:
            print(f"âŒ é”™è¯¯: {data['error']}")
            return

        if "processed" in data:
            # å­˜å‚¨ç»“æœ
            print("âœ… è®°å¿†å­˜å‚¨æˆåŠŸ")
            print(f"   ä¼šè¯ID: {data['session_id']}")
            print(f"   ç”¨æˆ·è®°å¿†ID: {data['user_memory_id']}")
            print(f"   AIè®°å¿†ID: {data['ai_memory_id']}")
            print(f"   ä¸»é¢˜: {data['topic']}")

        elif "query" in data:
            # æ£€ç´¢ç»“æœ
            print(f"ğŸ” æŸ¥è¯¢: {data['query']}")
            print(f"   ä¼šè¯ID: {data['session_id']}")

            print(f"\nğŸ“š ç›¸å…³è®°å¿† ({len(data['relevant_memories'])} æ¡):")
            for i, mem in enumerate(data['relevant_memories'], 1):
                print(f"   {i}. [{mem['type']}] {mem['text'][:60]}...")
                if mem['meta']:
                    print(f"      å…ƒæ•°æ®: {mem['meta']}")

            print(f"\nï¿½ ä¼šè¯ç»Ÿè®¡:")
            print(f"   æ€»è®°å¿†æ•°: {data.get('session_memories_count', 0)}")

            print(f"\nğŸ“ ç”Ÿæˆçš„ä¸Šä¸‹æ–‡:")
            context = data.get('context', '')
            print(f"   {context[:200]}{'...' if len(context) > 200 else ''}")


def create_sample_conversations() -> List[Dict[str, Any]]:
    """åˆ›å»ºç¤ºä¾‹å¯¹è¯æ•°æ®"""
    # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½æ•°æ®
    try:
        import yaml
        config_path = os.path.join(
            os.path.dirname(__file__), "..", "config", "config_memory_service_demo.yaml"
        )
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config["demo_data"]["conversations"]
    except Exception as e:
        print(f"âš ï¸  æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨å†…ç½®æ•°æ®")

    # é»˜è®¤çš„å†…ç½®å¯¹è¯æ•°æ®
    return [
        {
            "user_message": "ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹ï¼Œåº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ",
            "ai_response": "ä½ å¥½ï¼å­¦ä¹ Pythonç¼–ç¨‹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ã€‚è¦å¼€å§‹å­¦ä¹ ï¼Œæˆ‘å»ºè®®ï¼š1. å®‰è£…Pythonç¯å¢ƒ 2. å­¦ä¹ åŸºç¡€è¯­æ³• 3. ç»ƒä¹ ç¼–å†™ç®€å•ç¨‹åº",
            "topic": "programming"
        },
        {
            "user_message": "Pythonä¸­å˜é‡å’Œæ•°æ®ç±»å‹æœ‰å“ªäº›ï¼Ÿ",
            "ai_response": "Pythonæœ‰ä»¥ä¸‹åŸºæœ¬æ•°æ®ç±»å‹ï¼š1. æ•´æ•°(int) 2. æµ®ç‚¹æ•°(float) 3. å­—ç¬¦ä¸²(str) 4. å¸ƒå°”å€¼(bool) 5. åˆ—è¡¨(list) 6. å…ƒç»„(tuple) 7. å­—å…¸(dict)",
            "topic": "programming"
        },
        {
            "user_message": "æˆ‘å¯¹æœºå™¨å­¦ä¹ å¾ˆæ„Ÿå…´è¶£ï¼Œæœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ",
            "ai_response": "æœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªå¾ˆæœ‰å‰æ™¯çš„é¢†åŸŸï¼å»ºè®®ä»ä»¥ä¸‹æ–¹é¢å¼€å§‹ï¼š1. å­¦ä¹ PythonåŸºç¡€ 2. æŒæ¡æ•°å­¦åŸºç¡€ï¼ˆçº¿æ€§ä»£æ•°ã€æ¦‚ç‡è®ºï¼‰3. å­¦ä¹ scikit-learnç­‰åº“ 4. å®è·µé¡¹ç›®",
            "topic": "ai"
        },
        {
            "user_message": "å‘¨æœ«æˆ‘æƒ³æ”¾æ¾ä¸€ä¸‹ï¼Œæœ‰ä»€ä¹ˆæ¨èï¼Ÿ",
            "ai_response": "å‘¨æœ«æ”¾æ¾å¾ˆé‡è¦ï¼å¯ä»¥è€ƒè™‘ï¼š1. æˆ·å¤–æ´»åŠ¨å¦‚æ•£æ­¥æˆ–éª‘è¡Œ 2. é˜…è¯»ä¹¦ç± 3. å­¦ä¹ æ–°æŠ€èƒ½ 4. å’Œæœ‹å‹èšé¤ è®°ä½ä¿æŒå·¥ä½œç”Ÿæ´»å¹³è¡¡ï¼",
            "topic": "lifestyle"
        },
        {
            "user_message": "æˆ‘æœ€è¿‘æ€»æ˜¯æ„Ÿè§‰ç–²æƒ«ï¼Œæœ‰ä»€ä¹ˆæ”¹å–„æ–¹æ³•ï¼Ÿ",
            "ai_response": "æ„Ÿè§‰ç–²æƒ«å¯èƒ½æ˜¯å¤šç§åŸå› é€ æˆçš„ã€‚å»ºè®®ï¼š1. ä¿è¯å……è¶³ç¡çœ ï¼ˆ7-9å°æ—¶ï¼‰2. è§„å¾‹é¥®é£Ÿï¼Œæ‘„å…¥å‡è¡¡è¥å…» 3. é€‚é‡è¿åŠ¨ 4. ç®¡ç†å‹åŠ› 5. å¦‚æŒç»­ä¸¥é‡ï¼Œå»ºè®®å’¨è¯¢åŒ»ç”Ÿ",
            "topic": "health"
        }
    ]


class MockMemoryService:
    """æ¨¡æ‹ŸMemoryServiceï¼Œç”¨äºæ¼”ç¤ºAPIä½¿ç”¨æ–¹å¼"""

    def __init__(self):
        self.memories = {}
        self.session_memories = {}
        self.memory_counter = 0

    def store_memory(self, content, vector, session_id, memory_type="conversation", metadata=None):
        """æ¨¡æ‹Ÿå­˜å‚¨è®°å¿†"""
        memory_id = f"mem_{self.memory_counter}"
        self.memory_counter += 1

        memory = {
            "id": memory_id,
            "content": content,
            "vector": vector,
            "session_id": session_id,
            "memory_type": memory_type,
            "metadata": metadata or {},
            "timestamp": time.time()
        }

        # å­˜å‚¨åˆ°å…¨å±€è®°å¿†åº“
        self.memories[memory_id] = memory

        # æ·»åŠ åˆ°ä¼šè¯è®°å¿†
        if session_id not in self.session_memories:
            self.session_memories[session_id] = []
        self.session_memories[session_id].append(memory_id)

        return memory_id

    def search_memories(self, query_vector, session_id=None, limit=5, memory_type=None):
        """æ¨¡æ‹Ÿæœç´¢è®°å¿†"""
        candidates = []

        # ç¡®å®šæœç´¢èŒƒå›´
        if session_id:
            memory_ids = self.session_memories.get(session_id, [])
        else:
            memory_ids = list(self.memories.keys())

        # è¿‡æ»¤è®°å¿†ç±»å‹
        for mem_id in memory_ids:
            memory = self.memories[mem_id]
            if memory_type and memory["memory_type"] != memory_type:
                continue
            candidates.append(memory)

        # è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ’åºï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        results = []
        for memory in candidates:
            similarity = self._cosine_similarity(query_vector, memory["vector"])
            results.append({
                "id": memory["id"],
                "content": memory["content"],
                "memory_type": memory["memory_type"],
                "metadata": memory["metadata"],
                "similarity": similarity
            })

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        results.sort(key=lambda x: x["similarity"], reverse=True)
        return results[:limit]

    def get_session_memories(self, session_id, memory_type=None):
        """è·å–ä¼šè¯è®°å¿†"""
        memory_ids = self.session_memories.get(session_id, [])
        memories = []

        for mem_id in memory_ids:
            memory = self.memories[mem_id]
            if memory_type and memory["memory_type"] != memory_type:
                continue
            memories.append(memory)

        return memories

    def generate_context(self, query, session_id, max_tokens=1000):
        """ç”Ÿæˆä¸Šä¸‹æ–‡"""
        query_vector = mock_embedding(query)
        relevant_memories = self.search_memories(query_vector, session_id, limit=5)

        context_parts = []
        total_length = 0

        for memory in relevant_memories:
            content = memory["content"]
            if total_length + len(content) > max_tokens:
                break
            context_parts.append(f"[{memory['memory_type']}] {content}")
            total_length += len(content)

        return "\n".join(context_parts)

    def _cosine_similarity(self, vec1, vec2):
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        import numpy as np
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)

        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)

        if norm1 == 0 or norm2 == 0:
            return 0.0

        return dot_product / (norm1 * norm2)


def demonstrate_api_usage():
    """æ¼”ç¤ºMemoryServiceçš„APIä½¿ç”¨æ–¹å¼ï¼ˆä¸ä¾èµ–å®é™…æœåŠ¡ï¼‰"""
    print("\nğŸ“– MemoryService API ä½¿ç”¨æ¼”ç¤º")
    print("-"*50)

    print("\nğŸ”§ æ ¸å¿ƒAPIæ–¹æ³•:")
    print("   1. store_memory(content, vector, session_id, memory_type, metadata)")
    print("      - å­˜å‚¨è®°å¿†å†…å®¹åˆ°è®°å¿†ç³»ç»Ÿ")
    print("      - å‚æ•°:")
    print("        * content: è®°å¿†å†…å®¹æ–‡æœ¬")
    print("        * vector: å†…å®¹çš„å‘é‡è¡¨ç¤ºï¼ˆç”¨äºè¯­ä¹‰æœç´¢ï¼‰")
    print("        * session_id: ä¼šè¯æ ‡è¯†ç¬¦")
    print("        * memory_type: è®°å¿†ç±»å‹ ('conversation', 'knowledge', 'working')")
    print("        * metadata: é™„åŠ å…ƒæ•°æ®å­—å…¸")

    print("\n   2. search_memories(query_vector, session_id, limit, memory_type)")
    print("      - åŸºäºå‘é‡ç›¸ä¼¼åº¦æœç´¢ç›¸å…³è®°å¿†")
    print("      - å‚æ•°:")
    print("        * query_vector: æŸ¥è¯¢çš„å‘é‡è¡¨ç¤º")
    print("        * session_id: ä¼šè¯æ ‡è¯†ç¬¦ï¼ˆå¯é€‰ï¼‰")
    print("        * limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶")
    print("        * memory_type: è®°å¿†ç±»å‹è¿‡æ»¤å™¨ï¼ˆå¯é€‰ï¼‰")

    print("\n   3. get_session_memories(session_id, memory_type)")
    print("      - è·å–æŒ‡å®šä¼šè¯çš„æ‰€æœ‰è®°å¿†")
    print("      - å‚æ•°:")
    print("        * session_id: ä¼šè¯æ ‡è¯†ç¬¦")
    print("        * memory_type: è®°å¿†ç±»å‹è¿‡æ»¤å™¨ï¼ˆå¯é€‰ï¼‰")

    print("\n   4. generate_context(query, session_id, max_tokens)")
    print("      - ç”Ÿæˆç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯")
    print("      - å‚æ•°:")
    print("        * query: æŸ¥è¯¢æ–‡æœ¬")
    print("        * session_id: ä¼šè¯æ ‡è¯†ç¬¦")
    print("        * max_tokens: ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦")

    print("\n   5. update_memory(memory_id, content, vector, metadata)")
    print("      - æ›´æ–°ç°æœ‰è®°å¿†")
    print("      - å‚æ•°:")
    print("        * memory_id: è®°å¿†ID")
    print("        * content: æ–°å†…å®¹ï¼ˆå¯é€‰ï¼‰")
    print("        * vector: æ–°å‘é‡ï¼ˆå¯é€‰ï¼‰")
    print("        * metadata: æ–°å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰")

    print("\n   6. delete_memory(memory_id)")
    print("      - åˆ é™¤æŒ‡å®šè®°å¿†")
    print("      - å‚æ•°:")
    print("        * memory_id: è¦åˆ é™¤çš„è®°å¿†ID")

    print("\nğŸ”„ å…¸å‹ä½¿ç”¨æµç¨‹:")
    print("   1. åˆå§‹åŒ– MemoryService å®ä¾‹")
    print("   2. ä¸ºæ¯ä¸ªå¯¹è¯è½®æ¬¡è°ƒç”¨ store_memory() å­˜å‚¨è®°å¿†")
    print("   3. ä½¿ç”¨ search_memories() æ£€ç´¢ç›¸å…³å†å²ä¿¡æ¯")
    print("   4. è°ƒç”¨ generate_context() è·å–ä¸Šä¸‹æ–‡æ‘˜è¦")
    print("   5. æ ¹æ®éœ€è¦æ›´æ–°æˆ–åˆ é™¤è®°å¿†")

    print("\nğŸ“Š è®°å¿†ç±»å‹è¯´æ˜:")
    print("   â€¢ conversation: å¯¹è¯å†å²è®°å½•")
    print("   â€¢ knowledge: äº‹å®æ€§çŸ¥è¯†å’Œå­¦ä¹ å†…å®¹")
    print("   â€¢ working: ä¸´æ—¶å·¥ä½œè®°å¿†ï¼ˆçŸ­æœŸå­˜å‚¨ï¼‰")

    print("\nâš™ï¸ é…ç½®å‚æ•°:")
    print("   â€¢ kv_service_name: KVå­˜å‚¨æœåŠ¡åç§°")
    print("   â€¢ vdb_service_name: å‘é‡æ•°æ®åº“æœåŠ¡åç§°")
    print("   â€¢ graph_service_name: å›¾æ•°æ®åº“æœåŠ¡åç§°")
    print("   â€¢ default_vector_dimension: é»˜è®¤å‘é‡ç»´åº¦")
    print("   â€¢ max_search_results: æœ€å¤§æœç´¢ç»“æœæ•°")
    print("   â€¢ enable_caching: æ˜¯å¦å¯ç”¨ç¼“å­˜")
    print("   â€¢ enable_knowledge_graph: æ˜¯å¦å¯ç”¨çŸ¥è¯†å›¾è°±")

    print("\nğŸ’¡ æœ€ä½³å®è·µ:")
    print("   â€¢ ä¸ºæ¯ä¸ªç”¨æˆ·ä¼šè¯ä½¿ç”¨å”¯ä¸€çš„ session_id")
    print("   â€¢ é€‰æ‹©åˆé€‚çš„å‘é‡åµŒå…¥æ¨¡å‹ï¼ˆæ¨è384ç»´ï¼‰")
    print("   â€¢ ä¸ºé‡è¦è®°å¿†æ·»åŠ ä¸°å¯Œçš„å…ƒæ•°æ®")
    print("   â€¢ å®šæœŸæ¸…ç†è¿‡æœŸçš„å·¥ä½œè®°å¿†")
    print("   â€¢ ç›‘æ§å‘é‡æœç´¢çš„æ€§èƒ½å’Œå‡†ç¡®æ€§")


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºMemoryServiceçš„ä½¿ç”¨"""
    print("ğŸš€ MemoryService ä½¿ç”¨ç¤ºä¾‹")
    print("="*60)

    # æ£€æŸ¥æ˜¯å¦åœ¨æµ‹è¯•æ¨¡å¼
    if os.getenv("SAGE_EXAMPLES_MODE") == "test":
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡ MemoryService ç¤ºä¾‹ï¼ˆéœ€è¦å®Œæ•´æœåŠ¡è®¾ç½®ï¼‰")
        return

    print("ğŸ“‹ åˆå§‹åŒ– MemoryService...")

    # å¼ºåˆ¶ä½¿ç”¨MockMemoryServiceè¿›è¡Œæ¼”ç¤ºï¼ˆé¿å…ä¾èµ–å¤æ‚çš„SAGEæœåŠ¡åŸºç¡€è®¾æ–½ï¼‰
    try:
        memory_service = MockMemoryService()
        print("âœ… MockMemoryService åˆå§‹åŒ–æˆåŠŸ")
        print("   ğŸ’¡ ä½¿ç”¨æ¨¡æ‹ŸæœåŠ¡å±•ç¤ºMemoryServiceåŠŸèƒ½")
    except Exception as e:
        print(f"âŒ æ¨¡æ‹ŸæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # åˆ›å»ºç¤ºä¾‹å¯¹è¯æ•°æ®
    conversations = create_sample_conversations()

    # æ¼”ç¤ºè®°å¿†å­˜å‚¨
    print("\nğŸ”„ é˜¶æ®µ1: å­˜å‚¨å¯¹è¯è®°å¿†")
    session_id = "demo_session_001"

    for i, conversation in enumerate(conversations, 1):
        print(f"\n   å¤„ç†å¯¹è¯ {i}/{len(conversations)}...")

        user_message = conversation["user_message"]
        ai_response = conversation["ai_response"]
        topic = conversation.get("topic", "general")

        try:
            # å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯
            user_memory_id = memory_service.store_memory(
                content=user_message,
                vector=mock_embedding(user_message),
                session_id=session_id,
                memory_type="conversation",
                metadata={
                    "speaker": "user",
                    "topic": topic,
                    "timestamp": time.time()
                }
            )
            print(f"     âœ… ç”¨æˆ·æ¶ˆæ¯å·²å­˜å‚¨: {user_memory_id}")

            # å­˜å‚¨AIå›å¤
            ai_memory_id = memory_service.store_memory(
                content=ai_response,
                vector=mock_embedding(ai_response),
                session_id=session_id,
                memory_type="conversation",
                metadata={
                    "speaker": "ai",
                    "topic": topic,
                    "timestamp": time.time()
                }
            )
            print(f"     âœ… AIå›å¤å·²å­˜å‚¨: {ai_memory_id}")

            # å¦‚æœæ˜¯ç¼–ç¨‹ç›¸å…³ï¼Œå­˜å‚¨è¯­ä¹‰è®°å¿†
            if "python" in user_message.lower() or "ç¼–ç¨‹" in user_message:
                semantic_content = f"ç”¨æˆ·å¯¹ç¼–ç¨‹æ„Ÿå…´è¶£ï¼š{user_message[:50]}..."
                semantic_id = memory_service.store_memory(
                    content=semantic_content,
                    vector=mock_embedding(semantic_content),
                    session_id=session_id,
                    memory_type="knowledge",
                    metadata={
                        "topic": "programming",
                        "importance": "medium",
                        "timestamp": time.time()
                    }
                )
                print(f"     âœ… è¯­ä¹‰è®°å¿†å·²å­˜å‚¨: {semantic_id}")

        except Exception as e:
            print(f"     âŒ å­˜å‚¨å¤±è´¥: {str(e)}")

    # æ¼”ç¤ºè®°å¿†æ£€ç´¢
    print("\nğŸ”„ é˜¶æ®µ2: è®°å¿†æ£€ç´¢æ¼”ç¤º")

    # åˆ›å»ºæ£€ç´¢æŸ¥è¯¢
    retrieval_queries = [
        "Pythonç¼–ç¨‹å­¦ä¹ ",
        "å¥åº·å’Œç–²æƒ«",
        "æœºå™¨å­¦ä¹ å»ºè®®"
    ]

    for query in retrieval_queries:
        print(f"\n   ğŸ” æŸ¥è¯¢: {query}")

        try:
            # æœç´¢ç›¸å…³è®°å¿†
            query_vector = mock_embedding(query)
            relevant_memories = memory_service.search_memories(
                query_vector=query_vector,
                session_id=session_id,
                limit=3
            )

            print(f"     ğŸ“š æ‰¾åˆ° {len(relevant_memories)} æ¡ç›¸å…³è®°å¿†:")
            for i, mem in enumerate(relevant_memories, 1):
                content = mem.get("content", "")[:60]
                mem_type = mem.get("memory_type", "unknown")
                print(f"       {i}. [{mem_type}] {content}...")

            # è·å–ä¼šè¯è®°å¿†ç»Ÿè®¡
            session_memories = memory_service.get_session_memories(session_id)
            print(f"     ğŸ“Š ä¼šè¯æ€»è®°å¿†æ•°: {len(session_memories)}")

        except Exception as e:
            print(f"     âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")

    print("\n" + "="*60)
    print("ğŸ‰ MemoryService ç¤ºä¾‹å®Œæˆï¼")
    print("="*60)
    print("\nğŸ“š å…³é”®ç‰¹æ€§å±•ç¤º:")
    print("   âœ… è®°å¿†å­˜å‚¨å’Œæ£€ç´¢")
    print("   âœ… ä¼šè¯ç®¡ç†å’Œéš”ç¦»")
    print("   âœ… è¯­ä¹‰æœç´¢åŠŸèƒ½")
    print("   âœ… å·¥ä½œè®°å¿†å’Œä¸Šä¸‹æ–‡ç”Ÿæˆ")
    print("   âœ… çŸ¥è¯†å›¾è°±é›†æˆ")
    print("\nğŸ’¡ å®é™…ä½¿ç”¨å»ºè®®:")
    print("   1. ç¡®ä¿å·²å¯åŠ¨ KVã€VDBã€Graph åº•å±‚æœåŠ¡")
    print("   2. é…ç½®åˆé€‚çš„å‘é‡ç»´åº¦å’ŒåµŒå…¥æ¨¡å‹")
    print("   3. æ ¹æ®åº”ç”¨åœºæ™¯è°ƒæ•´è®°å¿†ç±»å‹å’Œå…ƒæ•°æ®")
    print("   4. ç›‘æ§è®°å¿†ç³»ç»Ÿçš„æ€§èƒ½å’Œå­˜å‚¨ä½¿ç”¨æƒ…å†µ")


if __name__ == "__main__":
    # ç¦ç”¨æ§åˆ¶å°è°ƒè¯•æ—¥å¿—
    CustomLogger.disable_global_console_debug()

    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¤ºä¾‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
