from __future__ import annotations

import importlib
import json
import os
import sys
from typing import Any, Dict, Iterable

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° sys.path
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, "..", "..")
project_root = os.path.abspath(project_root)  # è§„èŒƒåŒ–è·¯å¾„
sys.path.insert(0, project_root)

# åŠ è½½ç¯å¢ƒé…ç½®
try:
    from tools.env_config import (get_api_key, load_sage_env,
                                  should_use_real_api)

    load_sage_env()  # ç«‹å³åŠ è½½ç¯å¢ƒå˜é‡
except ImportError:
    # Fallback if env_config is not available
    def get_api_key(service: str, required: bool = True):
        mapping = {"openai": "OPENAI_API_KEY"}
        key = os.getenv(mapping.get(service, f"{service.upper()}_API_KEY"))
        if required and not key:
            raise ValueError(f"Missing API key for {service}")
        return key

    def should_use_real_api():
        return False


from sage.common.utils.config.loader import load_config
from sage.libs.agents.action.mcp_registry import MCPRegistry
from sage.libs.agents.planning.llm_planner import LLMPlanner
from sage.libs.agents.profile.profile import BaseProfile
from sage.libs.agents.runtime.agent import AgentRuntime
from sage.libs.rag.generator import OpenAIGenerator


# ====== è¯»å– source ======
def iter_queries(source_cfg: Dict[str, Any]) -> Iterable[str]:
    stype = source_cfg.get("type", "local")
    if stype == "local":
        path = source_cfg["data_path"]
        field = source_cfg.get("field_query", "query")
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                obj = json.loads(line)
                q = obj.get(field, "")
                if isinstance(q, str) and q.strip():
                    yield q
    elif stype == "hf":
        from datasets import load_dataset

        name = source_cfg["hf_dataset_name"]
        config = source_cfg.get("hf_dataset_config")
        split = source_cfg.get("hf_split", "dev")
        field = source_cfg.get("field_query", "query")
        ds = load_dataset(name, config, split=split)
        for row in ds:
            q = row.get(field, "")
            if isinstance(q, str) and q.strip():
                yield q
    else:
        raise ValueError(f"Unsupported source.type: {stype}")


def main():
    # ====== è¯»å–é…ç½® ======
    cfg_path = os.path.join(
        os.path.dirname(__file__), "..", "config", "config_agent_min.yaml"
    )
    if not os.path.exists(cfg_path):
        print(f"âŒ Configuration file not found: {cfg_path}")
        sys.exit(1)
    config: Dict[str, Any] = load_config(cfg_path)

    # ====== Profile ======
    profile = BaseProfile.from_dict(config["profile"])

    # æ£€æŸ¥æ˜¯å¦åœ¨æµ‹è¯•æ¨¡å¼
    use_real_api = should_use_real_api()
    test_mode = (
        os.getenv("SAGE_EXAMPLES_MODE") == "test"
        or os.getenv("SAGE_TEST_MODE") == "true"
    ) and not use_real_api  # å¦‚æœæ˜ç¡®è¦æ±‚ä½¿ç”¨çœŸå®APIï¼Œåˆ™ä¸è¿›å…¥æµ‹è¯•æ¨¡å¼

    # åœ¨çœŸå®APIæ¨¡å¼ä¸‹ï¼Œä½¿ç”¨ç®€åŒ–çš„æŸ¥è¯¢æ•°æ®ä»¥é¿å…è¶…æ—¶
    if use_real_api:
        config["source"]["data_path"] = "examples/data/agent_queries_test.jsonl"

    # ====== Generator======
    gen_cfg = config["generator"]["remote"]  # å¯æ”¹ä¸º "local"/"remote"

    # éªŒè¯ API key é…ç½®ï¼ˆåœ¨æµ‹è¯•å’Œéæµ‹è¯•æ¨¡å¼ä¸‹éƒ½éœ€è¦æ£€æŸ¥ï¼‰
    try:
        api_key = get_api_key("openai", required=True)
        gen_cfg["api_key"] = api_key
        if use_real_api:
            print("ğŸŒ Real API mode: API key configuration validated")
        else:
            print("âœ… API key configuration validated")
    except ValueError as e:
        if test_mode:
            print(f"âš ï¸ Test mode: {e}")
            print("ğŸ’¡ Tip: Copy .env.template to .env and fill in your API keys")
            print(
                "âœ… Test mode: API key validation completed (missing key is OK in test)"
            )
        else:
            print(f"âŒ {e}")
            print("ğŸ’¡ Tip: Copy .env.template to .env and fill in your API keys")
            sys.exit(1)

    if test_mode:
        # åœ¨æµ‹è¯•æ¨¡å¼ä¸‹ï¼ŒéªŒè¯é…ç½®åŠ è½½å’Œæ¨¡å—å¯¼å…¥ï¼Œä½†ä¸å®é™…åˆå§‹åŒ–ç»„ä»¶
        print(
            "ğŸ§ª Test mode: Configuration loaded successfully (add --use-real-api to use real API)"
        )
        print("âœ… Test mode: Profile created successfully")

        # éªŒè¯é…ç½®æ–‡ä»¶ç»“æ„
        required_sections = ["generator", "planner", "tools", "runtime"]
        for section in required_sections:
            if section in config:
                print(f"âœ… Test mode: {section} config found")
            else:
                print(f"âŒ Test mode: {section} config missing")

        # éªŒè¯å·¥å…·æ¨¡å—å¯ä»¥å¯¼å…¥ï¼ˆä½†ä¸å®é™…åˆå§‹åŒ–ï¼‰
        try:
            for item in config.get("tools", []):
                mod = importlib.import_module(item["module"])
                cls = getattr(mod, item["class"])
                print(f"âœ… Test mode: Tool {item['class']} import successful")
        except Exception as e:
            print(f"âš ï¸ Test mode: Tool import failed (this is OK in test): {e}")

        print("âœ… Test mode: Agent pipeline structure validated")
        return

    if use_real_api:
        print("ğŸŒ Real API mode: Will make actual API calls with qwen-turbo")

    generator = OpenAIGenerator(gen_cfg)  # ====== Planner ======
    planner_cfg = config["planner"]
    planner = LLMPlanner(
        generator=generator,
        max_steps=planner_cfg.get("max_steps", 6),
        enable_repair=planner_cfg.get("enable_repair", True),
        topk_tools=planner_cfg.get("topk_tools", 6),
    )

    # ====== MCP å·¥å…·æ³¨å†Œï¼šæŒ‰é…ç½®åŠ¨æ€ import å¹¶æ³¨å†Œ ======
    registry = MCPRegistry()
    for item in config.get("tools", []):
        mod = importlib.import_module(item["module"])
        cls = getattr(mod, item["class"])
        kwargs = item.get("init_kwargs", {})
        registry.register(cls(**kwargs) if kwargs else cls())

    # ====== Runtime ======
    runtime_cfg = config["runtime"]
    agent = AgentRuntime(
        profile=profile,
        planner=planner,
        tools=registry,
        summarizer=(
            generator if runtime_cfg.get("summarizer") == "reuse_generator" else None
        ),
        # memory=None,  # å¦‚éœ€æ¥å…¥ MemoryServiceAdapterï¼Œå†æŒ‰é…ç½®æ‰“å¼€
        max_steps=runtime_cfg.get("max_steps", 6),
    )

    # ====== è·‘ä¸€é queries======
    for q in iter_queries(config["source"]):
        print("\n==========================")
        print(f"ğŸ§‘â€ğŸ’» User: {q}")
        ans = agent.execute({"query": q})
        print(f"ğŸ¤– Agent:\n{ans}")


if __name__ == "__main__":
    # å’Œ RAG ç¤ºä¾‹ä¸€è‡´çš„â€œæµ‹è¯•æ¨¡å¼â€å‹å¥½è¾“å‡º
    if (
        os.getenv("SAGE_EXAMPLES_MODE") == "test"
        or os.getenv("SAGE_TEST_MODE") == "true"
    ):
        try:
            main()
            print("\nâœ… Test passed: Agent pipeline structure validated")
        except Exception as e:
            print(f"âŒ Test failed: {e}")
            sys.exit(1)
    else:
        main()
