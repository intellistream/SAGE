#!/usr/bin/env python3
"""LLM workflow DAG demo that wires SageDB retrieval into the SAGE pipeline.

@test:allow-demo
"""

from __future__ import annotations

import argparse
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Sequence

import numpy as np
from sage.common.utils.logging.custom_logger import CustomLogger
from sage.kernel.api.function.map_function import MapFunction
from sage.kernel.api.function.source_function import SourceFunction
from sage.kernel.api.local_environment import LocalEnvironment
from sage.middleware.operators.rag import QAPromptor

# Ensure repository packages are importable when running the script directly
REPO_ROOT = Path(__file__).resolve().parents[1]
PACKAGE_SRC_ROOTS = [
    REPO_ROOT / "packages" / "sage" / "src",
    REPO_ROOT / "packages" / "sage-common" / "src",
    REPO_ROOT / "packages" / "sage-kernel" / "src",
    REPO_ROOT / "packages" / "sage-libs" / "src",
    REPO_ROOT / "packages" / "sage-middleware" / "src",
    REPO_ROOT / "packages" / "sage-tools" / "src",
]
for path in PACKAGE_SRC_ROOTS:
    if path.exists() and str(path) not in sys.path:
        sys.path.insert(0, str(path))


try:
    from sage.common.components.sage_embedding.embedding_model import EmbeddingModel
    from sage.middleware.components.sage_db.python.micro_service.sage_db_service import (
        SageDBService,
    )
except ImportError as exc:  # pragma: no cover - surface build guidance early
    if "_sage_db" in str(exc):
        raise SystemExit(
            "âŒ SageDB native extension not found. Install it before running this demo:\n"
            "   sage extensions install sage_db  # add --force to rebuild"
        ) from exc
    raise

SERVICE_NAME = "vector_store_service"


@dataclass
class KnowledgeEntry:
    title: str
    text: str
    topic: str
    tags: List[str]


KNOWLEDGE_BASE: List[KnowledgeEntry] = [
    KnowledgeEntry(
        title="SAGE æ¨ç†ç®¡é“æ€»è§ˆ",
        text=(
            "SAGE çš„å¤§æ¨¡å‹æ¨ç† DAG é€šè¿‡ LocalEnvironment ä¸²è” Sourceã€Map ä¸ Sink èŠ‚ç‚¹ï¼Œ"
            "åœ¨ JobManager ä¸­è°ƒåº¦æ‰§è¡Œï¼Œå¹¶æ”¯æŒæœåŠ¡è°ƒç”¨ä¸åé¦ˆå›è·¯ã€‚"
        ),
        topic="architecture",
        tags=["dag", "runtime", "overview"],
    ),
    KnowledgeEntry(
        title="SageDB ä¸ RAG é›†æˆ",
        text=(
            "SageDB å¯ä»¥ä½œä¸º RAG æ£€ç´¢åç«¯ï¼Œç»“åˆåµŒå…¥æ¨¡å‹å°†æ–‡æ¡£å‘é‡åŒ–åå†™å…¥ï¼Œ"
            "åœ¨æŸ¥è¯¢é˜¶æ®µé€šè¿‡æœåŠ¡è°ƒç”¨æä¾› Top-K ç›¸ä¼¼ç‰‡æ®µã€‚"
        ),
        topic="rag",
        tags=["sage_db", "retrieval", "integration"],
    ),
    KnowledgeEntry(
        title="æœåŠ¡ç¼–æ’èŠ‚ç‚¹",
        text=(
            "LocalEnvironment.register_service ä¼šåœ¨ DAG æ‰§è¡Œæ—¶è‡ªåŠ¨æ³¨å…¥å¯å¤ç”¨çš„æœåŠ¡å®ä¾‹ï¼Œ"
            "ç®—å­å¯é€šè¿‡ self.call_service['name'] ä»¥åŒæ­¥æ–¹å¼è®¿é—®æ•°æ®åº“æˆ–ç¼“å­˜ã€‚"
        ),
        topic="runtime",
        tags=["service", "call_service", "localenvironment"],
    ),
    KnowledgeEntry(
        title="Prompt æ„å»ºé˜¶æ®µ",
        text=(
            "QAPromptor æ¥æ”¶æ£€ç´¢ç»“æœåˆ—è¡¨ï¼Œæ‹¼è£… system ä¸ user æ¶ˆæ¯ï¼Œä¸º OpenAI å…¼å®¹ç”Ÿæˆå™¨æä¾›æç¤ºæ¨¡æ¿ã€‚"
        ),
        topic="prompt",
        tags=["promptor", "qa", "template"],
    ),
]

DEFAULT_QUERIES = [
    "SAGE çš„ DAG å¦‚ä½•æŠŠ SageDB æ£€ç´¢ä¸²è¿›æ¨ç†æµç¨‹?",
    "QAPromptor åœ¨è¿™ä¸ªæµç¨‹é‡Œèµ·åˆ°ä»€ä¹ˆä½œç”¨?",
]


class BootstrappedSageDBService(SageDBService):
    """Wrapper service that loads embeddings at construction time."""

    def __init__(
        self,
        *,
        initial_vectors: Sequence[Sequence[float]] | np.ndarray | None = None,
        initial_metadata: Sequence[Dict[str, str]] | None = None,
        **kwargs: Any,
    ) -> None:
        super().__init__(**kwargs)
        if initial_vectors is not None:
            vectors = (
                np.asarray(initial_vectors, dtype=np.float32)
                if not isinstance(initial_vectors, np.ndarray)
                else initial_vectors.astype(np.float32, copy=False)
            )

            if vectors.size == 0:
                return

            if vectors.ndim != 2:
                raise ValueError(
                    "initial_vectors must be a 2D array-like of shape (N, dim)"
                )

            expected_count = vectors.shape[0]
            if initial_metadata is None:
                metadata = [{} for _ in range(expected_count)]
            else:
                metadata = list(initial_metadata)
                if len(metadata) != expected_count:
                    raise ValueError(
                        "initial_metadata length must match number of initial_vectors"
                    )

            self.add_batch(vectors, metadata)
            # Build index once after ingestion to accelerate queries
            self._db.build_index()


class QuerySource(SourceFunction):
    def __init__(self, queries: Iterable[str], **kwargs: Any) -> None:
        super().__init__(**kwargs)
        self._queries = list(queries)
        self._cursor = 0

    def execute(self) -> Dict[str, str] | None:
        if self._cursor >= len(self._queries):
            return None
        question = self._queries[self._cursor]
        self._cursor += 1
        return {"query": question}


class SageDBRetrieverNode(MapFunction):
    def __init__(
        self,
        embedder_config: Dict[str, Any],
        *,
        service_name: str = SERVICE_NAME,
        top_k: int = 3,
        service_timeout: float = 10.0,
        **kwargs: Any,
    ) -> None:
        super().__init__(**kwargs)
        self.embedder = EmbeddingModel(**embedder_config)
        self.service_name = service_name
        self.top_k = top_k
        self.service_timeout = service_timeout

    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        query = payload.get("query", "")
        if not query:
            return {**payload, "results": [], "retrieved_docs": []}

        query_vector = np.asarray(self.embedder.embed(query), dtype=np.float32)
        service = self.call_service[self.service_name]
        raw_results = service.search(
            query_vector, k=self.top_k, timeout=self.service_timeout
        )

        formatted_results: List[Dict[str, Any]] = []
        corpus_snippets: List[str] = []
        references: List[Dict[str, Any]] = []

        for item in raw_results:
            metadata = dict(item.get("metadata") or {})
            snippet = metadata.get("text", "")
            formatted_results.append(
                {
                    "text": snippet,
                    "score": item.get("score"),
                    "metadata": metadata,
                }
            )
            corpus_snippets.append(snippet)
            references.append(
                {
                    "title": metadata.get("title", "unknown"),
                    "score": float(item.get("score", 0.0)),
                    "tags": (
                        metadata.get("tags", "").split(",")
                        if metadata.get("tags")
                        else []
                    ),
                }
            )

        enriched = dict(payload)
        enriched.update(
            {
                "results": formatted_results,
                "retrieved_docs": corpus_snippets,
                "references": references,
            }
        )
        return enriched


class MockLLMGenerator(MapFunction):
    """Minimal generator that emulates an LLM using retrieved passages."""

    def execute(self, data: List[Any]) -> Dict[str, Any]:
        if not isinstance(data, list) or len(data) != 2:
            raise ValueError(
                "Generator expects QAPromptor output: [original_payload, messages]"
            )
        original, messages = data
        top_hit = None
        if isinstance(original, dict):
            hits = original.get("results", []) or []
            top_hit = hits[0] if hits else None
        answer: str
        if top_hit:
            title = top_hit["metadata"].get("title", "èµ„æ–™")
            answer = (
                f"å‚è€ƒã€Š{title}ã€‹ä¸­çš„è¦ç‚¹ï¼š{top_hit['text']}"
                " â€”â€” è¯¥å†…å®¹ç» SageDB æ£€ç´¢è¿”å›ã€‚"
            )
        else:
            answer = "çŸ¥è¯†åº“æ²¡æœ‰æ£€ç´¢åˆ°åŒ¹é…å†…å®¹ï¼Œå»ºè®®æ‰©å…… SageDB è¯­æ–™ã€‚"

        enriched = dict(original)
        enriched["prompt_messages"] = messages
        enriched["answer"] = answer
        return enriched


class ConsoleReporter(MapFunction):
    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        query = payload.get("query", "<empty>")
        answer = payload.get("answer", "<no answer>")
        refs = payload.get("references", [])

        print("\n================ Pipeline Result ================")
        print(f"â“ Query : {query}")
        print(f"ğŸ’¡ Answer: {answer}")
        if refs:
            print("ğŸ“š References:")
            for idx, ref in enumerate(refs, start=1):
                title = ref.get("title")
                tags = ", ".join(ref.get("tags", []))
                score = ref.get("score")
                print(f"  {idx}. {title}  (score={score:.4f}, tags={tags})")
        else:
            print("ğŸ“š References: <none>")
        print("================================================\n")
        return payload


def build_embeddings(
    entries: Sequence[KnowledgeEntry], model: EmbeddingModel
) -> np.ndarray:
    vectors = []
    for item in entries:
        vectors.append(model.embed(item.text))
    return np.asarray(vectors, dtype=np.float32)


def prepare_metadata(entries: Sequence[KnowledgeEntry]) -> List[Dict[str, str]]:
    metadata: List[Dict[str, str]] = []
    for item in entries:
        metadata.append(
            {
                "title": item.title,
                "text": item.text,
                "topic": item.topic,
                "tags": ",".join(item.tags),  # Serialize list to comma-separated string
            }
        )
    return metadata


def run_pipeline(top_k: int, queries: Sequence[str]) -> None:
    CustomLogger.disable_global_console_debug()

    embedder_config = {"method": "mockembedder", "fixed_dim": 128}
    embedder = EmbeddingModel(**embedder_config)

    vectors = build_embeddings(KNOWLEDGE_BASE, embedder)
    metadata = prepare_metadata(KNOWLEDGE_BASE)

    env = LocalEnvironment("sage_db_workflow_demo")
    env.register_service(
        SERVICE_NAME,
        BootstrappedSageDBService,
        dimension=embedder.get_dim(),
        index_type="AUTO",
        initial_vectors=vectors,
        initial_metadata=metadata,
    )

    (
        env.from_source(QuerySource, queries)
        .map(
            SageDBRetrieverNode,
            embedder_config,
            service_name=SERVICE_NAME,
            top_k=top_k,
        )
        .map(QAPromptor, {"use_short_answer": False})
        .map(MockLLMGenerator)
        .map(ConsoleReporter)
    )

    env.submit()

    # Wait for processing to complete
    import time

    time.sleep(5)  # Allow enough time for processing

    # Clean up environment
    env.stop()


def parse_args(argv: Sequence[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--top-k",
        type=int,
        default=3,
        help="Number of neighbors to fetch from SageDB for each query.",
    )
    parser.add_argument(
        "--query",
        action="append",
        help="Override default demo queries (can be specified multiple times).",
    )
    return parser.parse_args(argv)


def main(argv: Sequence[str] | None = None) -> None:
    args = parse_args(argv or sys.argv[1:])
    queries = args.query if args.query else DEFAULT_QUERIES
    run_pipeline(args.top_k, queries)


if __name__ == "__main__":
    main()
