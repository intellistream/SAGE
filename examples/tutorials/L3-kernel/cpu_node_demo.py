#!/usr/bin/env python3
"""
SAGE CPU Node Demonstration
============================

This example demonstrates how SAGE supports CPU-only compute nodes for task execution.

Key Features Demonstrated:
1. âœ“ CPU-only task submission to JobManager
2. âœ“ Resource-aware node selection (CPU nodes)
3. âœ“ Task execution monitoring and logging
4. âœ“ Basic health checks and status reporting
5. âœ“ Resource requirements specification
6. âœ“ Multi-node task distribution
7. âœ“ Performance metrics collection
8. âœ“ Cluster inspection utilities

@test:timeout=120
@test:category=cpu
@test:requires=jobmanager
"""

import os
import socket
import time
from typing import Any

from sage.common.core.functions.map_function import MapFunction
from sage.common.core.functions.sink_function import SinkFunction
from sage.common.core.functions.source_function import SourceFunction
from sage.kernel.api.remote_environment import RemoteEnvironment
from sage.kernel.runtime.communication.packet import StopSignal
from sage.kernel.scheduler.api import BaseScheduler
from sage.kernel.scheduler.decision import PlacementDecision
from sage.kernel.scheduler.node_selector import NodeSelector


class CPUIntensiveSource(SourceFunction):
    """CPUå¯†é›†å‹æ•°æ®æº - ç”Ÿæˆéœ€è¦CPUå¤„ç†çš„æ•°æ®"""

    def __init__(self, max_count: int = 10, **kwargs):
        super().__init__(**kwargs)
        self.counter = 0
        self.max_count = max_count

    def execute(self, data=None):
        if self.counter >= self.max_count:
            return StopSignal(f"CPUIntensiveSource_{self.counter}")

        self.counter += 1
        # æ¨¡æ‹ŸCPUå¯†é›†å‹æ•°æ®ç”Ÿæˆ
        data_item = {
            "id": self.counter,
            "task_type": "cpu_compute",
            "compute_value": self.counter * 100,
            "timestamp": time.time(),
        }
        self.logger.info(f"[CPU Source] Generated item {self.counter}/{self.max_count}")
        return data_item


class CPUComputeProcessor(MapFunction):
    """CPUè®¡ç®—å¤„ç†å™¨ - æ‰§è¡ŒCPUå¯†é›†å‹è®¡ç®—"""

    # æ˜ç¡®å£°æ˜CPUèµ„æºéœ€æ±‚ï¼ˆç”±è°ƒåº¦å™¨ä½¿ç”¨ï¼‰
    cpu_required = 2  # éœ€è¦2ä¸ªCPUæ ¸å¿ƒ
    memory_required = "2GB"  # éœ€è¦2GBå†…å­˜
    gpu_required = 0  # æ˜ç¡®ä¸éœ€è¦GPU

    def execute(self, data: dict[str, Any]) -> dict[str, Any]:
        if not isinstance(data, dict):
            return data

        # æ¨¡æ‹ŸCPUå¯†é›†å‹è®¡ç®—
        task_id = data.get("id", 0)
        compute_value = data.get("compute_value", 0)

        # ç®€å•çš„è®¡ç®—ä»»åŠ¡ï¼ˆå¯ä»¥æ›¿æ¢ä¸ºæ›´å¤æ‚çš„CPUä»»åŠ¡ï¼‰
        result = sum(range(compute_value)) % 1000000

        # è·å–æ‰§è¡ŒèŠ‚ç‚¹ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        node_info = {
            "hostname": socket.gethostname(),
            "processor": self.name,
            "cpu_cores": os.cpu_count(),
        }

        processed_data = {
            **data,
            "processed": True,
            "result": result,
            "node_info": node_info,
            "process_time": time.time(),
        }

        self.logger.info(
            f"[CPU Processor] Processed task {task_id}, result={result}, "
            f"node={node_info['hostname']}"
        )
        return processed_data


class CPUResultSink(SinkFunction):
    """CPUè®¡ç®—ç»“æœæ¥æ”¶å™¨"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.processed_count = 0
        self.total_results = []
        self.start_time = time.time()
        self.node_distribution = {}  # è®°å½•ä»»åŠ¡åœ¨å„èŠ‚ç‚¹çš„åˆ†å¸ƒ

    def execute(self, data: dict[str, Any]):
        if not isinstance(data, dict):
            return

        self.processed_count += 1
        self.total_results.append(data)

        task_id = data.get("id", "unknown")
        result = data.get("result", "N/A")
        node_info = data.get("node_info", {})
        hostname = node_info.get("hostname", "unknown")
        processor = node_info.get("processor", "unknown")

        # ç»Ÿè®¡èŠ‚ç‚¹åˆ†å¸ƒ
        self.node_distribution[hostname] = self.node_distribution.get(hostname, 0) + 1

        self.logger.info(
            f"[CPU Sink] Received result #{self.processed_count}: "
            f"Task {task_id}, Result={result}, Node={hostname}, Processor={processor}"
        )
        print(
            f"âœ… [CPU Node] Completed task {task_id}: result={result} "
            f"(node: {hostname}, processor: {processor})"
        )

    def get_statistics(self) -> dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        return {
            "total_processed": self.processed_count,
            "elapsed_time": elapsed,
            "throughput": self.processed_count / elapsed if elapsed > 0 else 0,
            "node_distribution": self.node_distribution,
        }


class CPUOnlyScheduler(BaseScheduler):
    """
    CPUä¸“ç”¨è°ƒåº¦å™¨

    ç‰¹ç‚¹:
    - åªé€‰æ‹©CPUèŠ‚ç‚¹ï¼ˆä¸éœ€è¦GPUï¼‰
    - ä¼˜å…ˆé€‰æ‹©CPUèµ„æºå……è¶³çš„èŠ‚ç‚¹
    - æ”¯æŒè´Ÿè½½å‡è¡¡
    """

    def __init__(self):
        super().__init__()
        self.node_selector = NodeSelector()

    def make_decision(self, task_node):
        """
        ä¸ºä»»åŠ¡é€‰æ‹©CPUèŠ‚ç‚¹

        ç­–ç•¥:
        1. ä¸éœ€è¦GPUèµ„æº
        2. é€‰æ‹©CPUè´Ÿè½½æœ€ä½çš„èŠ‚ç‚¹
        3. ç¡®ä¿æœ‰è¶³å¤Ÿçš„CPUå’Œå†…å­˜
        """

        # æå–CPUèµ„æºéœ€æ±‚ï¼ˆé»˜è®¤1æ ¸ï¼‰
        cpu = (
            getattr(task_node.transformation, "cpu_required", 1)
            if hasattr(task_node, "transformation")
            else 1
        )

        # æå–å†…å­˜éœ€æ±‚ï¼ˆé»˜è®¤1GBï¼‰
        memory = (
            getattr(task_node.transformation, "memory_required", "1GB")
            if hasattr(task_node, "transformation")
            else "1GB"
        )

        # é€‰æ‹©CPUèŠ‚ç‚¹ï¼ˆä¸éœ€è¦GPUï¼‰
        target_node = self.node_selector.select_best_node(
            cpu_required=cpu,
            gpu_required=0,  # æ˜ç¡®æŒ‡å®šä¸éœ€è¦GPU
            strategy="balanced",  # è´Ÿè½½å‡è¡¡ç­–ç•¥
        )

        decision = PlacementDecision(
            target_node=target_node,
            resource_requirements={
                "cpu": cpu,
                "memory": memory,
                "gpu": 0,  # CPUèŠ‚ç‚¹ä¸éœ€è¦GPU
            },
            placement_strategy="cpu_only",
            reason=f"CPU task: selected CPU node {target_node} (no GPU required)",
        )

        self.scheduled_count += 1
        self.decision_history.append(decision)

        return decision


def demo_basic_cpu_node():
    """
    ç¤ºä¾‹1: åŸºæœ¬çš„CPUèŠ‚ç‚¹ä»»åŠ¡æ‰§è¡Œ

    æ¼”ç¤º:
    - CPU-onlyä»»åŠ¡æäº¤
    - ä»»åŠ¡åœ¨CPUèŠ‚ç‚¹ä¸Šæ‰§è¡Œ
    - ç›‘æ§å’Œæ—¥å¿—è®°å½•
    """
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹1: åŸºæœ¬CPUèŠ‚ç‚¹ä»»åŠ¡æ‰§è¡Œ")
    print("=" * 70)
    print("\nğŸ“Š åŠŸèƒ½: æäº¤CPUè®¡ç®—ä»»åŠ¡åˆ°JobManagerå¹¶åœ¨CPUèŠ‚ç‚¹æ‰§è¡Œ")
    print("ğŸ¯ éªŒæ”¶æ ‡å‡†:")
    print("  âœ“ å¯ä»¥é€šè¿‡JobManagerå°†ä»»åŠ¡åˆ†é…ç»™CPU SAGEèŠ‚ç‚¹")
    print("  âœ“ èŠ‚ç‚¹èƒ½å¤Ÿæ­£å¸¸æ‰§è¡Œå¹¶è¿”å›ç»“æœ")
    print("  âœ“ ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å…·å¤‡åŸºæœ¬çš„ç›‘æ§å’Œæ—¥å¿—è®°å½•èƒ½åŠ›\n")

    # åˆ›å»ºRemoteEnvironmentï¼ˆé»˜è®¤ä¼šä½¿ç”¨CPUèŠ‚ç‚¹ï¼‰
    env = RemoteEnvironment(name="cpu_node_basic_demo")

    # æ„å»ºCPUä»»åŠ¡æµ
    (
        env.from_source(CPUIntensiveSource, max_count=5, delay=0.5)
        .map(CPUComputeProcessor, parallelism=2)  # 2ä¸ªå¹¶è¡ŒCPUå¤„ç†å™¨
        .sink(CPUResultSink)
    )

    print("ğŸš€ æäº¤ä»»åŠ¡åˆ°JobManager...")
    print("ğŸ“ ä»»åŠ¡å°†è¢«åˆ†é…åˆ°å¯ç”¨çš„CPUèŠ‚ç‚¹\n")

    # æäº¤å¹¶è‡ªåŠ¨åœæ­¢
    env.submit(autostop=True)

    print("\nâœ… ç¤ºä¾‹1å®Œæˆ!")
    print("=" * 70)


def demo_cpu_scheduler():
    """
    ç¤ºä¾‹2: ä½¿ç”¨CPUä¸“ç”¨è°ƒåº¦å™¨

    æ¼”ç¤º:
    - è‡ªå®šä¹‰CPUèŠ‚ç‚¹é€‰æ‹©ç­–ç•¥
    - èµ„æºæ„ŸçŸ¥è°ƒåº¦
    - è´Ÿè½½å‡è¡¡
    """
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹2: CPUä¸“ç”¨è°ƒåº¦å™¨")
    print("=" * 70)
    print("\nğŸ“Š åŠŸèƒ½: ä½¿ç”¨è‡ªå®šä¹‰è°ƒåº¦å™¨ç¡®ä¿ä»»åŠ¡åªåˆ†é…åˆ°CPUèŠ‚ç‚¹")
    print("ğŸ¯ ç‰¹æ€§:")
    print("  âœ“ æ˜ç¡®æ’é™¤GPUèŠ‚ç‚¹")
    print("  âœ“ CPUèµ„æºæ„ŸçŸ¥è°ƒåº¦")
    print("  âœ“ è´Ÿè½½å‡è¡¡ç­–ç•¥\n")

    # åˆ›å»ºä½¿ç”¨CPUä¸“ç”¨è°ƒåº¦å™¨çš„ç¯å¢ƒ
    cpu_scheduler = CPUOnlyScheduler()
    env = RemoteEnvironment(
        name="cpu_scheduler_demo",
        scheduler=cpu_scheduler,
    )

    # æ„å»ºCPUä»»åŠ¡æµ
    (
        env.from_source(CPUIntensiveSource, max_count=8, delay=0.3)
        .map(CPUComputeProcessor, parallelism=3)  # 3ä¸ªå¹¶è¡Œå¤„ç†å™¨
        .sink(CPUResultSink)
    )

    print("ğŸš€ ä½¿ç”¨CPUä¸“ç”¨è°ƒåº¦å™¨æäº¤ä»»åŠ¡...")
    print("ğŸ“ è°ƒåº¦å™¨å°†é€‰æ‹©æœ€ä¼˜çš„CPUèŠ‚ç‚¹\n")

    # æäº¤å¹¶è‡ªåŠ¨åœæ­¢
    env.submit(autostop=True)

    # æŸ¥çœ‹è°ƒåº¦ç»Ÿè®¡
    metrics = cpu_scheduler.get_metrics()
    print("\nğŸ“Š è°ƒåº¦å™¨ç»Ÿè®¡:")
    print(f"  - è°ƒåº¦ä»»åŠ¡æ•°: {metrics.get('scheduled_count', 0)}")
    print(f"  - è·³è¿‡ä»»åŠ¡æ•°: {metrics.get('skipped_count', 0)}")

    print("\nâœ… ç¤ºä¾‹2å®Œæˆ!")
    print("=" * 70)


def demo_cpu_node_monitoring():
    """
    ç¤ºä¾‹3: CPUèŠ‚ç‚¹ç›‘æ§å’Œæ—¥å¿—

    æ¼”ç¤º:
    - ä»»åŠ¡æ‰§è¡Œç›‘æ§
    - æ—¥å¿—è®°å½•
    - çŠ¶æ€æŸ¥è¯¢
    """
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹3: CPUèŠ‚ç‚¹ç›‘æ§å’Œæ—¥å¿—")
    print("=" * 70)
    print("\nğŸ“Š åŠŸèƒ½: å±•ç¤ºCPUèŠ‚ç‚¹çš„ç›‘æ§å’Œæ—¥å¿—èƒ½åŠ›")
    print("ğŸ¯ ç‰¹æ€§:")
    print("  âœ“ å®æ—¶ä»»åŠ¡çŠ¶æ€ç›‘æ§")
    print("  âœ“ è¯¦ç»†çš„æ—¥å¿—è®°å½•")
    print("  âœ“ JobManagerå¥åº·æ£€æŸ¥\n")

    env = RemoteEnvironment(name="cpu_monitoring_demo")

    # æ„å»ºä»»åŠ¡æµ
    (
        env.from_source(CPUIntensiveSource, max_count=6, delay=0.4)
        .map(CPUComputeProcessor, parallelism=2)
        .sink(CPUResultSink)
    )

    print("ğŸš€ æäº¤ä»»åŠ¡å¹¶ç›‘æ§æ‰§è¡Œ...")

    # æäº¤ä»»åŠ¡
    env.submit(autostop=True)

    print("\nğŸ“‹ ç›‘æ§ä¿¡æ¯:")
    print("  - ä»»åŠ¡æ—¥å¿—: æŸ¥çœ‹ .sage/logs/jobmanager/ ç›®å½•")
    print("  - æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå‡æœ‰æ—¥å¿—è®°å½•")
    print("  - JobManager æä¾›å¥åº·æ£€æŸ¥æ¥å£")

    print("\nâœ… ç¤ºä¾‹3å®Œæˆ!")
    print("=" * 70)


def demo_cluster_inspection():
    """
    ç¤ºä¾‹4: é›†ç¾¤èŠ‚ç‚¹æ£€æŸ¥

    æ¼”ç¤º:
    - æŸ¥çœ‹å¯ç”¨çš„CPUèŠ‚ç‚¹
    - èŠ‚ç‚¹èµ„æºä¿¡æ¯
    - é›†ç¾¤ç»Ÿè®¡
    """
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹4: é›†ç¾¤èŠ‚ç‚¹æ£€æŸ¥")
    print("=" * 70)
    print("\nğŸ“Š åŠŸèƒ½: æ£€æŸ¥é›†ç¾¤ä¸­çš„CPUèŠ‚ç‚¹ä¿¡æ¯")
    print("ğŸ¯ å±•ç¤º:")
    print("  âœ“ å¯ç”¨CPUèŠ‚ç‚¹åˆ—è¡¨")
    print("  âœ“ èŠ‚ç‚¹èµ„æºç»Ÿè®¡")
    print("  âœ“ é›†ç¾¤æ€»ä½“çŠ¶æ€\n")

    try:
        import ray

        if not ray.is_initialized():
            print("âš ï¸  Ray æœªåˆå§‹åŒ–ï¼Œè·³è¿‡é›†ç¾¤æ£€æŸ¥")
            return

        # åˆ›å»ºèŠ‚ç‚¹é€‰æ‹©å™¨
        node_selector = NodeSelector()

        # è·å–é›†ç¾¤ç»Ÿè®¡ä¿¡æ¯
        stats = node_selector.get_cluster_stats()

        print("ğŸ“Š é›†ç¾¤èµ„æºç»Ÿè®¡:")
        print(f"  â€¢ èŠ‚ç‚¹æ•°é‡: {stats.get('node_count', 0)}")
        print(f"  â€¢ æ€»CPUæ ¸å¿ƒ: {stats.get('total_cpu', 0):.1f}")
        print(f"  â€¢ å¯ç”¨CPU: {stats.get('available_cpu', 0):.1f}")
        print(f"  â€¢ CPUä½¿ç”¨ç‡: {stats.get('avg_cpu_usage', 0):.1%}")
        print(f"  â€¢ æ€»å†…å­˜: {stats.get('total_memory', 0) / (1024**3):.2f} GB")
        print(f"  â€¢ å¯ç”¨å†…å­˜: {stats.get('available_memory', 0) / (1024**3):.2f} GB")
        print(f"  â€¢ æ€»ä»»åŠ¡æ•°: {stats.get('total_tasks', 0)}")

        # åˆ—å‡ºæ‰€æœ‰èŠ‚ç‚¹
        nodes = stats.get("nodes", [])
        if nodes:
            print(f"\nğŸ“‹ èŠ‚ç‚¹è¯¦æƒ… ({len(nodes)} ä¸ªèŠ‚ç‚¹):")
            for i, node in enumerate(nodes, 1):
                print(f"\n  èŠ‚ç‚¹ #{i}:")
                print(f"    ä¸»æœºå: {node.get('hostname', 'unknown')}")
                print(f"    CPUä½¿ç”¨ç‡: {node.get('cpu_usage', 0):.1%}")
                print(f"    GPUä½¿ç”¨ç‡: {node.get('gpu_usage', 0):.1%}")
                print(f"    å†…å­˜ä½¿ç”¨ç‡: {node.get('memory_usage', 0):.1%}")
                print(f"    ä»»åŠ¡æ•°: {node.get('task_count', 0)}")

        # é€‰æ‹©CPUèŠ‚ç‚¹
        print("\nğŸ” é€‰æ‹©æœ€ä½³CPUèŠ‚ç‚¹:")
        cpu_node = node_selector.select_best_node(
            cpu_required=2, gpu_required=0, strategy="balanced"
        )
        if cpu_node:
            print(f"  âœ“ é€‰ä¸­èŠ‚ç‚¹: {cpu_node[:16]}...")
            node_res = node_selector.get_node(cpu_node)
            if node_res:
                print(f"    ä¸»æœºå: {node_res.hostname}")
                print(f"    å¯ç”¨CPU: {node_res.available_cpu:.1f}")
                print(f"    CPUä½¿ç”¨ç‡: {node_res.cpu_usage:.1%}")
        else:
            print("  âš ï¸  æœªæ‰¾åˆ°åˆé€‚çš„CPUèŠ‚ç‚¹")

        print("\nâœ… ç¤ºä¾‹4å®Œæˆ!")
        print("=" * 70)

    except ImportError:
        print("âš ï¸  Ray æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œé›†ç¾¤æ£€æŸ¥")
    except Exception as e:
        print(f"âš ï¸  é›†ç¾¤æ£€æŸ¥å¤±è´¥: {e}")


def demo_resource_requirements():
    """
    ç¤ºä¾‹5: æ˜¾å¼èµ„æºéœ€æ±‚è§„èŒƒ

    æ¼”ç¤º:
    - åœ¨Operatorçº§åˆ«æŒ‡å®šCPU/å†…å­˜éœ€æ±‚
    - è°ƒåº¦å™¨æ ¹æ®èµ„æºéœ€æ±‚é€‰æ‹©èŠ‚ç‚¹
    - èµ„æºæ„ŸçŸ¥ä»»åŠ¡åˆ†é…
    """
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹5: æ˜¾å¼èµ„æºéœ€æ±‚è§„èŒƒ")
    print("=" * 70)
    print("\nğŸ“Š åŠŸèƒ½: ä¸ºCPUä»»åŠ¡æŒ‡å®šç²¾ç¡®çš„èµ„æºéœ€æ±‚")
    print("ğŸ¯ ç‰¹æ€§:")
    print("  âœ“ Operatorçº§åˆ«èµ„æºå£°æ˜")
    print("  âœ“ è°ƒåº¦å™¨èµ„æºæ„ŸçŸ¥")
    print("  âœ“ æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©\n")

    # åˆ›å»ºç¯å¢ƒ
    env = RemoteEnvironment(name="cpu_resource_demo")

    # CPUComputeProcessor å·²å£°æ˜: cpu_required=2, memory_required="2GB", gpu_required=0
    print("ğŸ’¡ CPUComputeProcessor èµ„æºéœ€æ±‚:")
    print(f"  â€¢ CPU: {CPUComputeProcessor.cpu_required} æ ¸")
    print(f"  â€¢ å†…å­˜: {CPUComputeProcessor.memory_required}")
    print(f"  â€¢ GPU: {CPUComputeProcessor.gpu_required} (ä¸éœ€è¦)")
    print()

    # æ„å»ºä»»åŠ¡æµ
    (
        env.from_source(CPUIntensiveSource, max_count=10, delay=0.2)
        .map(CPUComputeProcessor, parallelism=3)  # æ¯ä¸ªå®ä¾‹éœ€è¦2æ ¸CPU
        .sink(CPUResultSink)
    )

    print("ğŸš€ æäº¤ä»»åŠ¡ï¼ˆè°ƒåº¦å™¨å°†é€‰æ‹©æ»¡è¶³èµ„æºéœ€æ±‚çš„CPUèŠ‚ç‚¹ï¼‰...")
    env.submit(autostop=True)

    print("\nâœ… ç¤ºä¾‹5å®Œæˆ!")
    print("=" * 70)


def check_jobmanager_available():
    """æ£€æŸ¥ JobManager æ˜¯å¦å¯ç”¨"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex(("localhost", 19001))
        sock.close()
        return result == 0
    except Exception:
        return False


def print_usage_guide():
    """æ‰“å°ä½¿ç”¨æŒ‡å—"""
    print("\n" + "=" * 70)
    print("ğŸ“š CPUèŠ‚ç‚¹ä½¿ç”¨æŒ‡å—")
    print("=" * 70)

    print("\n1ï¸âƒ£  å¯åŠ¨JobManager (å¿…éœ€):")
    print("   $ sage jobmanager start")
    print("   æˆ–è€…æ‰‹åŠ¨å¯åŠ¨:")
    print(
        "   $ python -m sage.kernel.runtime.job_manager --host 127.0.0.1 --port 19001"
    )

    print("\n2ï¸âƒ£  å¯åŠ¨Rayé›†ç¾¤ (å¯é€‰ï¼ŒJobManagerä¼šè‡ªåŠ¨åˆå§‹åŒ–):")
    print("   $ ray start --head  # å¯åŠ¨å¤´èŠ‚ç‚¹")
    print("   $ ray start --address=<head_address>  # æ·»åŠ CPUå·¥ä½œèŠ‚ç‚¹")

    print("\n3ï¸âƒ£  é…ç½®CPUå·¥ä½œèŠ‚ç‚¹:")
    print("   # åœ¨å·¥ä½œèŠ‚ç‚¹æœºå™¨ä¸Š")
    print("   $ ray start --address=<head_address> --num-cpus=8 --num-gpus=0")
    print("   # æŒ‡å®šåªæœ‰CPUèµ„æºï¼Œä¸åˆ†é…GPU")

    print("\n4ï¸âƒ£  æ£€æŸ¥é›†ç¾¤çŠ¶æ€:")
    print("   $ sage jobmanager status")
    print("   $ ray status")

    print("\n5ï¸âƒ£  è¿è¡ŒCPUä»»åŠ¡:")
    print("   $ python cpu_node_demo.py")

    print("\n6ï¸âƒ£  æŸ¥çœ‹æ—¥å¿—:")
    print("   $ ls -la .sage/logs/jobmanager/")
    print("   $ tail -f .sage/logs/jobmanager/session_*/jobmanager.log")

    print("\n" + "=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    print(
        """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   SAGE CPU Node å®Œæ•´æ¼”ç¤º                              â•‘
â•‘                                                                      â•‘
â•‘  æœ¬ç¤ºä¾‹æ¼”ç¤ºSAGEæ¡†æ¶å¯¹CPUç‰ˆæœ¬è®¡ç®—èŠ‚ç‚¹çš„å®Œæ•´æ”¯æŒ                         â•‘
â•‘                                                                      â•‘
â•‘  éªŒæ”¶æ ‡å‡†:                                                            â•‘
â•‘  âœ“ å¯ä»¥é€šè¿‡JobManagerå°†ä»»åŠ¡åˆ†é…ç»™CPU SAGEèŠ‚ç‚¹                         â•‘
â•‘  âœ“ èŠ‚ç‚¹èƒ½å¤Ÿæ­£å¸¸æ‰§è¡Œå¹¶è¿”å›ç»“æœ                                          â•‘
â•‘  âœ“ ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å…·å¤‡åŸºæœ¬çš„ç›‘æ§å’Œæ—¥å¿—è®°å½•èƒ½åŠ›                           â•‘
â•‘  âœ“ æ”¯æŒèµ„æºéœ€æ±‚è§„èŒƒå’Œæ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©                                      â•‘
â•‘  âœ“ æä¾›é›†ç¾¤æ£€æŸ¥å’Œç»Ÿè®¡åŠŸèƒ½                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    )

    # æ£€æŸ¥JobManageræ˜¯å¦å¯ç”¨
    if not check_jobmanager_available():
        print("\nâš ï¸  JobManager æœªè¿è¡Œ!")
        print_usage_guide()
        print("\nğŸ’¡ è¯·å…ˆå¯åŠ¨ JobManagerï¼Œç„¶åé‡æ–°è¿è¡Œæœ¬ç¤ºä¾‹\n")
        return

    print("\nâœ… JobManager å·²å°±ç»ª\n")

    try:
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        demo_basic_cpu_node()
        time.sleep(1)

        demo_cpu_scheduler()
        time.sleep(1)

        demo_cpu_node_monitoring()
        time.sleep(1)

        demo_cluster_inspection()
        time.sleep(1)

        demo_resource_requirements()

        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰€æœ‰CPUèŠ‚ç‚¹æ¼”ç¤ºå®Œæˆ!")
        print("=" * 70)

        print("\nğŸ“‹ éªŒæ”¶æ ‡å‡†ç¡®è®¤:")
        print("  âœ… JobManageræˆåŠŸåˆ†é…ä»»åŠ¡ç»™CPUèŠ‚ç‚¹")
        print("  âœ… CPUèŠ‚ç‚¹æ­£å¸¸æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœ")
        print("  âœ… æä¾›å®Œæ•´çš„ç›‘æ§å’Œæ—¥å¿—è®°å½•")
        print("  âœ… æ”¯æŒèµ„æºéœ€æ±‚è§„èŒƒå’ŒèŠ‚ç‚¹é€‰æ‹©")
        print("  âœ… æä¾›é›†ç¾¤æ£€æŸ¥å’Œç»Ÿè®¡åŠŸèƒ½")

        print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
        print("  â€¢ CPUèŠ‚ç‚¹é€šè¿‡NodeSelectorè‡ªåŠ¨é€‰æ‹©ï¼ˆgpu_required=0ï¼‰")
        print("  â€¢ RemoteEnvironmentè‡ªåŠ¨ä¸JobManageråä½œ")
        print("  â€¢ æ”¯æŒè‡ªå®šä¹‰è°ƒåº¦ç­–ç•¥ï¼ˆCPUOnlySchedulerï¼‰")
        print("  â€¢ å†…ç½®ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ")
        print("  â€¢ å¯åœ¨æ— GPUç¯å¢ƒä¸­è¿è¡Œ")
        print("  â€¢ æ”¯æŒOperatorçº§åˆ«èµ„æºéœ€æ±‚å£°æ˜")
        print("  â€¢ æä¾›é›†ç¾¤èµ„æºæ£€æŸ¥å·¥å…·")

        print("\nğŸ”— ç›¸å…³æ–‡ä»¶:")
        print("  â€¢ JobManager: sage/kernel/runtime/job_manager.py")
        print("  â€¢ NodeSelector: sage/kernel/scheduler/node_selector.py")
        print("  â€¢ RemoteEnvironment: sage/kernel/api/remote_environment.py")
        print("  â€¢ Scheduler: sage/kernel/scheduler/impl/resource_aware_scheduler.py")
        print("  â€¢ æ—¥å¿—ç›®å½•: .sage/logs/jobmanager/")

        print_usage_guide()

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
        print("\nğŸ’¡ æç¤º:")
        print("  1. ç¡®ä¿JobManagerå·²å¯åŠ¨: sage jobmanager start")
        print("  2. æ£€æŸ¥Rayæ˜¯å¦è¿è¡Œ: ray status")
        print("  3. æŸ¥çœ‹æ—¥å¿—: .sage/logs/jobmanager/")


if __name__ == "__main__":
    main()
