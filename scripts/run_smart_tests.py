#!/usr/bin/env python3
"""
æœ¬åœ°æ™ºèƒ½æµ‹è¯•ç³»ç»Ÿ
æ£€æµ‹ä»£ç å˜åŒ–å¹¶è‡ªåŠ¨è¿è¡Œç›¸å…³æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
  python scripts/run_smart_tests.py                    # æ£€æµ‹gitå˜åŒ–å¹¶è¿è¡Œç›¸å…³æµ‹è¯•
  python scripts/run_smart_tests.py --all              # è¿è¡Œæ‰€æœ‰æµ‹è¯•
  python scripts/run_smart_tests.py --files file1.py file2.py  # æŒ‡å®šæ–‡ä»¶è¿è¡Œæµ‹è¯•
  python scripts/run_smart_tests.py --since HEAD~3     # æ£€æµ‹æœ€è¿‘3ä¸ªcommitçš„å˜åŒ–
"""

import os
import sys
import subprocess
import argparse
import json
from pathlib import Path
from typing import List, Set
import time


class SmartTestRunner:
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path(__file__).parent.parent
        os.chdir(self.project_root)
        
        # å®šä¹‰ç›®å½•åˆ°æµ‹è¯•çš„æ˜ å°„
        self.test_mappings = {
            # æ ¸å¿ƒæ¨¡å—æµ‹è¯•æ˜ å°„
            'sage.core/': [
                'tests/test_final_verification.py',
                'tests/test_service_task_base.py'
            ],
            'sage.runtime/': [
                'tests/test_final_verification.py',
                'tests/test_service_task_base.py'
            ],
            'sage.jobmanager/': [
                'tests/test_service_task_base.py'
            ],
            'sage.utils/mmap_queue/': [
                'sage.utils/mmap_queue/tests/test_comprehensive.py',
                'sage.utils/mmap_queue/tests/test_multiprocess_concurrent.py',
                'sage.utils/mmap_queue/tests/test_performance_benchmark.py',
                'sage.utils/mmap_queue/tests/test_ray_integration.py'
            ],
            'sage_libs/': [
                'tests/test_final_verification.py'
            ],
            'sage_examples/': [
                'tests/test_final_verification.py',
                'tests/test_service_task_base.py'
            ],
            # æµ‹è¯•æ–‡ä»¶è‡ªèº«çš„å˜åŒ–
            'tests/': [
                'tests/run_core_tests.py'
            ],
        }
        
        # è§¦å‘æ‰€æœ‰æµ‹è¯•çš„æ–‡ä»¶
        self.critical_files = {
            'setup.py', 'requirements.txt', 'pyproject.toml'
        }
        
        # æ‰€æœ‰å¯ç”¨çš„æµ‹è¯•
        self.all_tests = [
            'tests/test_final_verification.py',
            'tests/test_service_task_base.py',
            'sage.utils/mmap_queue/tests/test_comprehensive.py',
            'sage.utils/mmap_queue/tests/test_multiprocess_concurrent.py',
            'sage.utils/mmap_queue/tests/test_performance_benchmark.py',
            'sage.utils/mmap_queue/tests/test_ray_integration.py'
        ]

    def get_changed_files(self, since: str = "HEAD~1") -> List[str]:
        """è·å–å˜åŒ–çš„æ–‡ä»¶åˆ—è¡¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨gitä»“åº“ä¸­
            subprocess.run(['git', 'status'], check=True, capture_output=True)
            
            # è·å–å˜åŒ–çš„æ–‡ä»¶
            if since == "working":
                # å·¥ä½œç›®å½•ä¸­çš„å˜åŒ–ï¼ˆåŒ…æ‹¬æœªæäº¤çš„ï¼‰
                result = subprocess.run(
                    ['git', 'diff', '--name-only', 'HEAD'],
                    capture_output=True, text=True, check=True
                )
                staged_result = subprocess.run(
                    ['git', 'diff', '--name-only', '--cached'],
                    capture_output=True, text=True, check=True
                )
                untracked_result = subprocess.run(
                    ['git', 'ls-files', '--others', '--exclude-standard'],
                    capture_output=True, text=True, check=True
                )
                
                changed_files = []
                changed_files.extend(result.stdout.strip().split('\n') if result.stdout.strip() else [])
                changed_files.extend(staged_result.stdout.strip().split('\n') if staged_result.stdout.strip() else [])
                changed_files.extend(untracked_result.stdout.strip().split('\n') if untracked_result.stdout.strip() else [])
                
            else:
                # ä¸æŒ‡å®šcommitæ¯”è¾ƒ
                result = subprocess.run(
                    ['git', 'diff', '--name-only', since],
                    capture_output=True, text=True, check=True
                )
                changed_files = result.stdout.strip().split('\n') if result.stdout.strip() else []
            
            # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å’ŒéPythonæ–‡ä»¶
            changed_files = [f for f in changed_files if f and (f.endswith('.py') or f in self.critical_files)]
            
            return changed_files
            
        except subprocess.CalledProcessError:
            print("Warning: Not in a git repository or git command failed")
            return []

    def find_tests_for_files(self, changed_files: List[str]) -> Set[str]:
        """æ ¹æ®å˜åŒ–çš„æ–‡ä»¶æ‰¾åˆ°ç›¸åº”çš„æµ‹è¯•"""
        tests_to_run = set()
        run_all_tests = False
        
        print(f"Analyzing {len(changed_files)} changed files...")
        
        for changed_file in changed_files:
            print(f"  ğŸ“ {changed_file}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å…³é”®æ–‡ä»¶ï¼ˆè§¦å‘æ‰€æœ‰æµ‹è¯•ï¼‰
            if any(changed_file.endswith(critical) for critical in self.critical_files):
                run_all_tests = True
                print(f"    âš¡ Critical file detected - will run ALL tests")
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…åˆ°æµ‹è¯•æ˜ å°„
            matched = False
            for pattern, tests in self.test_mappings.items():
                if changed_file.startswith(pattern):
                    for test in tests:
                        if self.project_root.joinpath(test).exists():
                            tests_to_run.add(test)
                            print(f"    âœ… Added test: {test}")
                        else:
                            print(f"    âš ï¸  Test not found: {test}")
                    matched = True
                    break
            
            if not matched:
                # å¯¹äºæœªæ˜ å°„çš„æ–‡ä»¶ï¼Œæ£€æŸ¥åŒç›®å½•ä¸‹æ˜¯å¦æœ‰testsç›®å½•
                file_path = Path(changed_file)
                current_dir = file_path.parent
                
                # å‘ä¸ŠæŸ¥æ‰¾testsç›®å½•
                for parent in [current_dir] + list(current_dir.parents):
                    tests_dir = self.project_root / parent / 'tests'
                    if tests_dir.exists() and tests_dir.is_dir():
                        # æ‰¾åˆ°testsç›®å½•ï¼Œæ·»åŠ å…¶ä¸­çš„æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
                        for test_file in tests_dir.glob('test_*.py'):
                            test_path = str(test_file.relative_to(self.project_root))
                            tests_to_run.add(test_path)
                            print(f"    ğŸ“‹ Found test in {tests_dir.name}: {test_path}")
                        matched = True
                        break
                
                if not matched:
                    print(f"    â“ No specific tests found")
        
        # å¦‚æœéœ€è¦è¿è¡Œæ‰€æœ‰æµ‹è¯•
        if run_all_tests:
            print("\nâš¡ Running ALL tests due to critical file changes...")
            tests_to_run.update(self.all_tests)
        
        # è¿‡æ»¤å­˜åœ¨çš„æµ‹è¯•æ–‡ä»¶
        existing_tests = set()
        for test in tests_to_run:
            test_path = self.project_root / test
            if test_path.exists():
                existing_tests.add(test)
            else:
                print(f"âš ï¸  Test file not found: {test}")
        
        return existing_tests

    def run_tests(self, test_files: Set[str]) -> dict:
        """è¿è¡ŒæŒ‡å®šçš„æµ‹è¯•æ–‡ä»¶"""
        if not test_files:
            print("No tests to run.")
            return {"total": 0, "passed": 0, "failed": 0, "results": []}
        
        print(f"\nğŸš€ Running {len(test_files)} tests...")
        print("=" * 60)
        
        results = []
        total_tests = len(test_files)
        passed_tests = 0
        failed_tests = 0
        
        for i, test_file in enumerate(sorted(test_files), 1):
            print(f"\n[{i}/{total_tests}] Running: {test_file}")
            print("-" * 50)
            
            start_time = time.time()
            
            try:
                result = subprocess.run(
                    [sys.executable, str(test_file)],
                    cwd=self.project_root,
                    capture_output=False,  # æ˜¾ç¤ºå®æ—¶è¾“å‡º
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                )
                
                duration = time.time() - start_time
                
                if result.returncode == 0:
                    print(f"âœ… PASSED: {test_file} ({duration:.2f}s)")
                    passed_tests += 1
                    results.append({"test": test_file, "status": "PASSED", "duration": duration})
                else:
                    print(f"âŒ FAILED: {test_file} ({duration:.2f}s)")
                    failed_tests += 1
                    results.append({"test": test_file, "status": "FAILED", "duration": duration})
                    
            except subprocess.TimeoutExpired:
                print(f"â° TIMEOUT: {test_file}")
                failed_tests += 1
                results.append({"test": test_file, "status": "TIMEOUT", "duration": 300})
            except Exception as e:
                print(f"ğŸ’¥ ERROR: {test_file} - {e}")
                failed_tests += 1
                results.append({"test": test_file, "status": "ERROR", "duration": 0})
        
        return {
            "total": total_tests,
            "passed": passed_tests,
            "failed": failed_tests,
            "results": results
        }

    def print_summary(self, test_results: dict, changed_files: List[str]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ§ª SMART TESTING SUMMARY")
        print("=" * 60)
        
        print(f"ğŸ“ Changed files analyzed: {len(changed_files)}")
        for f in changed_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"   - {f}")
        if len(changed_files) > 5:
            print(f"   ... and {len(changed_files) - 5} more")
        
        print(f"\nğŸ“Š Test results:")
        print(f"   Total tests: {test_results['total']}")
        print(f"   Passed: {test_results['passed']}")
        print(f"   Failed: {test_results['failed']}")
        
        if test_results['failed'] == 0:
            print("\nğŸ‰ All tests passed! Ready to commit.")
        else:
            print(f"\nâš ï¸  {test_results['failed']} tests failed. Please fix before committing.")
            print("\nFailed tests:")
            for result in test_results['results']:
                if result['status'] != 'PASSED':
                    print(f"   âŒ {result['test']} ({result['status']})")


def main():
    parser = argparse.ArgumentParser(
        description="Smart Test Runner - Automatically run tests based on code changes",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s                           # Test changed files since last commit
  %(prog)s --all                     # Run all tests
  %(prog)s --since HEAD~5            # Test changes since 5 commits ago
  %(prog)s --since working           # Test working directory changes
  %(prog)s --files file1.py file2.py # Test specific files
        """
    )
    
    parser.add_argument('--all', action='store_true',
                        help='Run all available tests')
    parser.add_argument('--since', default='HEAD~1',
                        help='Git reference to compare against (default: HEAD~1)')
    parser.add_argument('--files', nargs='+',
                        help='Specific files to analyze for testing')
    parser.add_argument('--project-root',
                        help='Project root directory (default: auto-detect)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = SmartTestRunner(args.project_root)
    
    print("ğŸ” SAGE Smart Test Runner")
    print("=" * 40)
    
    if args.all:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        print("Running ALL tests...")
        test_files = set(runner.all_tests)
        changed_files = ["<all tests requested>"]
        
    elif args.files:
        # è¿è¡ŒæŒ‡å®šæ–‡ä»¶çš„ç›¸å…³æµ‹è¯•
        print(f"Analyzing specified files: {args.files}")
        test_files = runner.find_tests_for_files(args.files)
        changed_files = args.files
        
    else:
        # è‡ªåŠ¨æ£€æµ‹å˜åŒ–çš„æ–‡ä»¶
        changed_files = runner.get_changed_files(args.since)
        
        if not changed_files:
            print("No changes detected. Running core tests as fallback...")
            test_files = {
                'tests/test_final_verification.py',
                'tests/test_service_task_base.py'
            }
        else:
            test_files = runner.find_tests_for_files(changed_files)
    
    # è¿‡æ»¤å­˜åœ¨çš„æµ‹è¯•æ–‡ä»¶
    existing_tests = {t for t in test_files if (runner.project_root / t).exists()}
    
    if not existing_tests:
        print("No valid tests found to run.")
        return 0
    
    print(f"\nğŸ¯ Tests to run ({len(existing_tests)}):")
    for test in sorted(existing_tests):
        print(f"   - {test}")
    
    # è¿è¡Œæµ‹è¯•
    test_results = runner.run_tests(existing_tests)
    
    # æ‰“å°æ‘˜è¦
    runner.print_summary(test_results, changed_files)
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    return 0 if test_results['failed'] == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
