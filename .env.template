# SAGE Environment Configuration Template
# Copy this file to .env and fill in your actual API keys
# NEVER commit .env files with real API keys to git!

# ==================================================
# LLM Service API Keys
# ==================================================

# OpenAI API Key (for GPT models)
# Get from: https://platform.openai.com/api-keys
# For qwen-turbo via DashScope, use DashScope API key here
OPENAI_API_KEY=your_openai_or_dashscope_api_key_here
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
OPENAI_MODEL_NAME=qwen-turbo-2025-02-11

# SiliconCloud API Key (for alternative LLM services)
SILICONCLOUD_API_KEY=your_siliconcloud_api_key_here

# Jina API Key (for embedding services)
JINA_API_KEY=your_jina_api_key_here

# Alibaba DashScope API Key
ALIBABA_API_KEY=your_alibaba_api_key_here

# Huawei Pangu API Key
PANGU_API_KEY=your_pangu_api_key_here

# vLLM API Key (for local/self-hosted vLLM services)
# For local vLLM servers, you can use a simple token or leave empty if no auth is required
# Example: token-abc123 for development, or empty string for no authentication
VLLM_API_KEY=token-abc123
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL_NAME=meta-llama/Llama-2-13b-chat-hf

# Web Search API Key (for searcher tool in multiagent)
WEB_SEARCH_API_KEY=your_web_search_api_key_here

# Pangu API Key
PANGU_API_KEY=your_pangu_api_key_here

# ==================================================
# Temporary API Keys (for Examples & Demos)
# ==================================================
# These are temporary API keys used for running examples and demos.
# Configure these if you want to use specific models/backends for testing.
# NOTE: These should NOT be used in production!

# ==================================================
# Hugging Face Configuration
# ==================================================

# Hugging Face Token (for model downloads)
# Get from: https://huggingface.co/settings/tokens
HF_TOKEN=your_hf_token_here

# Hugging Face Mirror Endpoint (for China users)
HF_ENDPOINT=https://hf-mirror.com

# ==================================================
# Development Settings
# ==================================================

# Set to true to enable debug logging
SAGE_DEBUG=false

# Set to true to skip C++ extensions compilation (faster development)
SAGE_SKIP_CPP_EXTENSIONS=false

# Set log level (DEBUG, INFO, WARNING, ERROR)
SAGE_LOG_LEVEL=INFO

# Set to true when running tests
SAGE_TEST_MODE=false

# Set to test when running examples in test mode
SAGE_EXAMPLES_MODE=normal

# ==================================================
# SAGE Gateway / Studio Chat Mode Configuration
# ==================================================
# Gateway 和 Studio Chat 使用智能 LLM 选择策略：
# 1. 优先检测本地 vLLM 服务 (localhost:8001 或 8000)
# 2. 如果本地服务不可用，降级到云端 API
#
# 云端 API 配置（作为降级方案）：
SAGE_CHAT_API_KEY=your_dashscope_api_key_here
SAGE_CHAT_MODEL=qwen-turbo-2025-02-11
SAGE_CHAT_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# ==================================================
# Development Tools Cache Configuration
# ==================================================
# Configure cache directories for development tools to keep them centralized
# All cache files will be stored in .sage/cache/ directory

# Ruff cache directory (for linting)
RUFF_CACHE_DIR=.sage/cache/ruff

# Mypy cache directory (for type checking)
MYPY_CACHE_DIR=.sage/cache/mypy
