# SAGE Environment Configuration Template
# Copy this file to .env and fill in your actual API keys
# NEVER commit .env files with real API keys to git!

# ==================================================
# LLM Service API Keys
# ==================================================

# OpenAI API Key (for GPT models)
# Get from: https://platform.openai.com/api-keys
# For qwen-turbo via DashScope, use DashScope API key here
OPENAI_API_KEY=your_openai_or_dashscope_api_key_here
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
OPENAI_MODEL_NAME=qwen-turbo-2025-02-11

# SiliconCloud API Key (for alternative LLM services)
SILICONCLOUD_API_KEY=your_siliconcloud_api_key_here

# Jina API Key (for embedding services)
JINA_API_KEY=your_jina_api_key_here

# Alibaba DashScope API Key
ALIBABA_API_KEY=your_alibaba_api_key_here

# vLLM API Key (for local/self-hosted vLLM services)
# For local vLLM servers, you can use a simple token or leave empty if no auth is required
# Example: token-abc123 for development, or empty string for no authentication
VLLM_API_KEY=token-abc123
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL_NAME=meta-llama/Llama-2-13b-chat-hf

# Web Search API Key (for searcher tool in multiagent)
WEB_SEARCH_API_KEY=your_web_search_api_key_here

# ==================================================
# Temporary API Keys (for Examples & Demos)
# ==================================================
# These are temporary API keys used for running examples and demos.
# Configure these if you want to use specific models/backends for testing.
# NOTE: These should NOT be used in production!

# Debug Generator Backend (for development & testing)
SAGE_DEBUG_BACKEND=openai
SAGE_DEBUG_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
SAGE_DEBUG_MODEL=qwen-turbo-2025-02-11
SAGE_DEBUG_API_KEY=your_temporary_api_key_here
SAGE_DEBUG_SEED=42

# ==================================================
# Hugging Face Configuration
# ==================================================

# Hugging Face Token (for model downloads)
# Get from: https://huggingface.co/settings/tokens
HF_TOKEN=your_hf_token_here

# Hugging Face Mirror Endpoint (for China users)
HF_ENDPOINT=https://hf-mirror.com

# ==================================================
# Development Settings
# ==================================================

# Set to true to enable debug logging
SAGE_DEBUG=false

# Set to true to skip C++ extensions compilation (faster development)
SAGE_SKIP_CPP_EXTENSIONS=false

# Set log level (DEBUG, INFO, WARNING, ERROR)
SAGE_LOG_LEVEL=INFO

# Set to true when running tests
SAGE_TEST_MODE=false

# Set to test when running examples in test mode
SAGE_EXAMPLES_MODE=normal

# ==================================================
# SAGE Gateway / Studio Chat Mode Configuration
# ==================================================
# Gateway 和 Studio Chat 使用智能 LLM 选择策略：
# 1. 优先检测本地 vLLM 服务 (localhost:8001 或 8000)
# 2. 如果本地服务不可用，降级到云端 API
#
# 云端 API 配置（作为降级方案）：
SAGE_CHAT_API_KEY=your_dashscope_api_key_here
SAGE_CHAT_MODEL=qwen-turbo-2025-02-11
SAGE_CHAT_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# 强制使用云端 API（跳过本地服务检测）：
# SAGE_FORCE_CLOUD_API=true

# 其他云端 API 示例：
# OpenAI:
# SAGE_CHAT_API_KEY=sk-your-openai-api-key
# SAGE_CHAT_MODEL=gpt-4o-mini
# SAGE_CHAT_BASE_URL=https://api.openai.com/v1

# 本地 vLLM 服务说明：
# - 本地 vLLM 服务会被自动检测（优先 8001，然后 8000）
# - 推荐使用 8001 端口避免与 Gateway (8000) 冲突
# - 启动命令示例：
#   sage llm run Qwen/Qwen2.5-7B-Instruct --port 8001
#   sage finetune serve <model-name> --port 8001
# - 不需要额外配置，会自动检测并使用本地服务

# ==================================================
# Pipeline Builder / Workflow Generation Configuration
# ==================================================
# 用于智能工作流生成（Studio 的 Chat 转工作流功能）
# 如果不配置，将使用 SAGE_CHAT_* 或 OPENAI_* 作为后备
SAGE_PIPELINE_BUILDER_API_KEY=your_dashscope_api_key_here
SAGE_PIPELINE_BUILDER_MODEL=qwen-max
SAGE_PIPELINE_BUILDER_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# ==================================================
# Development Tools Cache Configuration
# ==================================================
# Configure cache directories for development tools to keep them centralized
# All cache files will be stored in .sage/cache/ directory

# Ruff cache directory (for linting)
RUFF_CACHE_DIR=.sage/cache/ruff

# Mypy cache directory (for type checking)
MYPY_CACHE_DIR=.sage/cache/mypy
