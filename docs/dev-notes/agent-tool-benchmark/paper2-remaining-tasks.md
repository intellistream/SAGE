# Paper 2 (SAGE-Agent Method) å‰©ä½™ä»»åŠ¡ - å®Œæ•´æŒ‡å—

> æœ¬æ–‡æ¡£å®šä¹‰äº†å®Œæˆ SAGE-Agent æ–¹æ³•è®ºæ–‡æ‰€éœ€çš„æ‰€æœ‰ä»»åŠ¡
> è®ºæ–‡æ ¸å¿ƒï¼šStreaming Adaptive Learning for Tool-Augmented LLM Agents
>
> **ç”Ÿæˆæ—¥æœŸ**: 2025-11-27

---

## ğŸš€ ç»Ÿä¸€å…¥å£ CLI

```bash
cd /home/shuhao/SAGE/packages/sage-benchmark/src/sage/benchmark/benchmark_agent/scripts

# æ–¹å¼ 1: äº¤äº’å¼è¿è¡Œ
python sage_benchmark_cli.py

# æ–¹å¼ 2: ç›´æ¥æŒ‡å®šå®éªŒ (è·³è¿‡ç¡®è®¤)
python sage_benchmark_cli.py --paper 2 --experiment streaming_comparison --yes
python sage_benchmark_cli.py --paper 2 --experiment full_training --yes

# æ–¹å¼ 3: åˆ—å‡ºæ‰€æœ‰å¯ç”¨å®éªŒ
python sage_benchmark_cli.py --list
```

**CLI æ”¯æŒçš„ Paper 2 å®éªŒï¼š**

| ID | åç§° | æè¿° | é¢„ä¼°æ—¶é—´ |
|----|------|------|----------|
| `streaming_comparison` | æµå¼ vs æ‰¹é‡ | å¯¹æ¯” Streaming å’Œ Batch è®­ç»ƒ | ~2 hours |
| `full_training` | å®Œæ•´è®­ç»ƒå¯¹æ¯” | æ‰€æœ‰æ–¹æ³•è®­ç»ƒå¯¹æ¯” | ~8 hours |
| `coreset_ablation` | Coreset æ¶ˆè | æ ·æœ¬é€‰æ‹©ç­–ç•¥æ¶ˆè | ~1 hour |
| `continual_learning` | æŒç»­å­¦ä¹  | æ–°å·¥å…·å¢é‡å­¦ä¹  | ~2 hours |

---

## ğŸ“Š å½“å‰çŠ¶æ€æ¦‚è§ˆ

| ç»„ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| SSIS (Sample Importance) | âš ï¸ éœ€éªŒè¯ | å·²æœ‰æ¡†æ¶ï¼Œéœ€ç«¯åˆ°ç«¯æµ‹è¯• |
| Coreset Selection | âš ï¸ éœ€éªŒè¯ | æœ‰å®ç°ï¼Œæœªå……åˆ†æµ‹è¯• |
| Streaming Training | âš ï¸ éœ€éªŒè¯ | åŸºç¡€æµç¨‹å®Œæˆ |
| Continual Learning | âŒ æœªå®Œæˆ | EWC/ER ç­–ç•¥éœ€å®ç° |
| RL Fine-tuning | âŒ æœªå®Œæˆ | PPO/DPO é›†æˆéœ€éªŒè¯ |
| è®ºæ–‡å›¾è¡¨ | âŒ æœªå¼€å§‹ | éœ€è¦è®­ç»ƒç»“æœ |

---

## ğŸ”§ Task 1: Streaming vs Batch è®­ç»ƒå¯¹æ¯”

### ç›®æ ‡
éªŒè¯ Streaming Learning ç›¸å¯¹ Batch Learning çš„ä¼˜åŠ¿ï¼š
- æ ·æœ¬æ•ˆç‡ï¼ˆSample Efficiencyï¼‰
- è®¡ç®—æ•ˆç‡ï¼ˆCompute Efficiencyï¼‰
- é€‚åº”æ€§ï¼ˆAdaptation Speedï¼‰

### å…³é”®æ–‡ä»¶

```
packages/sage-benchmark/src/sage/benchmark/benchmark_agent/scripts/
  run_full_training_comparison.py   # è®­ç»ƒå¯¹æ¯”è„šæœ¬

packages/sage-libs/src/sage/libs/agentic/training/
  streaming_trainer.py              # æµå¼è®­ç»ƒå™¨
  batch_trainer.py                  # æ‰¹é‡è®­ç»ƒå™¨
```

### å®éªŒé…ç½®

```python
# å¯¹æ¯”å®éªŒè®¾ç½®
experiments = {
    "batch_full": {"method": "batch", "data_ratio": 1.0},
    "batch_50pct": {"method": "batch", "data_ratio": 0.5},
    "streaming_full": {"method": "streaming", "buffer_size": 1000},
    "streaming_coreset": {"method": "streaming", "coreset": True},
}
```

---

## ğŸ”§ Task 2: Coreset Selection æ¶ˆèå®éªŒ

### ç›®æ ‡
éªŒè¯ä¸åŒæ ·æœ¬é€‰æ‹©ç­–ç•¥çš„æ•ˆæœï¼š
- Random Sampling
- Uncertainty Sampling
- Diversity Sampling
- SSIS (Our Method)

### å…³é”®æ–‡ä»¶

```
packages/sage-libs/src/sage/libs/agentic/training/
  coreset/
    random_selector.py
    uncertainty_selector.py
    diversity_selector.py
    ssis_selector.py     # Streaming Sample Importance Scorer
```

---

## ğŸ”§ Task 3: Continual Learning å®éªŒ

### ç›®æ ‡
éªŒè¯æ¨¡å‹åœ¨æ–°å·¥å…·æŒç»­å¢åŠ æ—¶çš„æ€§èƒ½ï¼š
- é¿å…ç¾éš¾æ€§é—å¿˜
- å¿«é€Ÿé€‚åº”æ–°å·¥å…·
- çŸ¥è¯†è¿ç§»

### å®éªŒè®¾è®¡

```python
# Phase 1: åœ¨ 1000 å·¥å…·ä¸Šè®­ç»ƒ
train(tools[:1000])

# Phase 2: å¢é‡å­¦ä¹  200 æ–°å·¥å…·
# å¯¹æ¯”: Fine-tune vs EWC vs Experience Replay vs SAGE-Agent
continual_learn(tools[1000:1200])

# è¯„ä¼°: æ—§å·¥å…·æ€§èƒ½ + æ–°å·¥å…·æ€§èƒ½
evaluate(tools[:1200])
```

---

## ğŸ”§ Task 4: RL Fine-tuning éªŒè¯

### ç›®æ ‡
éªŒè¯åŸºäºæ‰§è¡Œåé¦ˆçš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒæ•ˆæœï¼š
- PPO (Proximal Policy Optimization)
- DPO (Direct Preference Optimization)

### å…³é”®æ–‡ä»¶

```
packages/sage-libs/src/sage/libs/agentic/training/
  rl/
    ppo_trainer.py
    dpo_trainer.py
    reward_model.py
```

---

## ğŸ”§ Task 5: è®ºæ–‡å›¾è¡¨ç”Ÿæˆ

### éœ€è¦çš„å›¾è¡¨

1. **Figure 1**: SAGE-Agent æ¶æ„å›¾
2. **Figure 2**: Streaming vs Batch å­¦ä¹ æ›²çº¿
3. **Figure 3**: Coreset Selection æ¶ˆè
4. **Figure 4**: Continual Learning é—å¿˜æ›²çº¿
5. **Figure 5**: RL Fine-tuning æ•ˆæœ

### éœ€è¦çš„è¡¨æ ¼

1. **Table 1**: ä¸ SOTA æ–¹æ³•å¯¹æ¯”ï¼ˆGorilla, ToolLLM, etc.ï¼‰
2. **Table 2**: ä¸‰ä¸ª Challenge ä¸Šçš„ç»“æœ
3. **Table 3**: æ¶ˆèå®éªŒç»“æœ
4. **Table 4**: è·¨æ•°æ®é›†æ³›åŒ–ç»“æœ

---

## ğŸ”§ Task 6: å®Œæ•´è®­ç»ƒæµç¨‹

### è®­ç»ƒè„šæœ¬

```bash
# å®Œæ•´è®­ç»ƒå¯¹æ¯” (éœ€è¦ GPU)
cd /home/shuhao/SAGE/packages/sage-benchmark/src/sage/benchmark/benchmark_agent/scripts
python run_full_training_comparison.py --config config/full_training.yaml
```

### LLM æ¨ç†æ–¹å¼é€‰æ‹©

**æ¨è**: ä½¿ç”¨ `UnifiedInferenceClient` + æœ¬åœ° vLLM Server

åŸå› ï¼š
1. **èµ„æºå…±äº«**: å¤šä¸ªè®­ç»ƒè¿›ç¨‹å¯ä»¥å…±äº«ä¸€ä¸ª LLM æœåŠ¡
2. **æ˜¾å­˜ç®¡ç†**: vLLM çš„ PagedAttention ä¼˜åŒ–æ˜¾å­˜
3. **ååé‡**: æ‰¹é‡è¯·æ±‚å¯ä»¥åˆå¹¶å¤„ç†
4. **å¯è§‚æµ‹æ€§**: æœåŠ¡ç«¯æœ‰ç»Ÿä¸€çš„ç›‘æ§å’Œæ—¥å¿—

```python
# æ¨èç”¨æ³•
from sage.common.components.sage_llm import UnifiedInferenceClient

client = UnifiedInferenceClient.create_auto()
# è‡ªåŠ¨æ£€æµ‹: æœ¬åœ° vLLM â†’ äº‘ç«¯ API
```

---

## ğŸ“ æ‰§è¡Œé¡ºåºå»ºè®®

1. âœ… Task 1: Streaming vs Batch (è·å¾—æ ¸å¿ƒå®éªŒæ•°æ®)
2. Task 2: Coreset Ablation (éªŒè¯æ ·æœ¬é€‰æ‹©)
3. Task 3: Continual Learning (éªŒè¯é€‚åº”æ€§)
4. Task 4: RL Fine-tuning (éªŒè¯å¼ºåŒ–å­¦ä¹ )
5. Task 5: å›¾è¡¨ç”Ÿæˆ (è®ºæ–‡å†™ä½œ)
6. Task 6: å®Œæ•´è®­ç»ƒ (æœ€ç»ˆéªŒè¯)

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [Paper 1 ä»»åŠ¡](./paper1-remaining-tasks.md) - SAGE-Bench Benchmark è®ºæ–‡
- [ICML æ–¹æ³•è®ºæ–‡æç¤ºè¯](./icml-method-paper-prompt.md) - è®ºæ–‡ç”Ÿæˆæç¤ºè¯
- [æ¶æ„è¯´æ˜](./task3-decomposition-plan.md) - ç³»ç»Ÿæ¶æ„è®¾è®¡
