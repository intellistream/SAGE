# Intelligent LLM Client é‡æ„æ–‡æ¡£

## èƒŒæ™¯

**é—®é¢˜ï¼š** `sage-gateway` (L6) ç›´æ¥ä¾èµ– `sage-tools` (L6) çš„ LLM æ£€æµ‹å·¥å…·ï¼Œè¿åäº†æ¶æ„è§„åˆ™ï¼ˆL6 ä¸èƒ½ä¾èµ– L6ï¼‰ã€‚

**é”™è¯¯ç¤ºä¾‹ï¼š**
```python
# âŒ æ¶æ„è¿è§„ï¼šL6 -> L6 ä¾èµ–
from sage.tools.cli.utils.llm_detection import detect_vllm
```

## è§£å†³æ–¹æ¡ˆ

### 1. åœ¨ L1 å±‚åˆ›å»ºæ™ºèƒ½ LLM å®¢æˆ·ç«¯

**ä½ç½®ï¼š** `packages/sage-common/src/sage/common/components/sage_llm/client.py`

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- âœ… è‡ªåŠ¨æ£€æµ‹æœ¬åœ° vLLM æœåŠ¡ï¼ˆç«¯å£ 8001, 8000ï¼‰
- âœ… è‡ªåŠ¨é™çº§åˆ°äº‘ç«¯ APIï¼ˆå¦‚ DashScopeï¼‰
- âœ… æ”¯æŒç”¨æˆ·æ˜¾å¼é…ç½®ï¼ˆç¯å¢ƒå˜é‡ï¼‰
- âœ… ç¼“å­˜æ£€æµ‹ç»“æœï¼Œé¿å…é‡å¤æ¢æµ‹
- âœ… ç»Ÿä¸€çš„ OpenAI å…¼å®¹æ¥å£
- ğŸ¯ **é›†æˆ Control Plane** - é«˜çº§å¤šå®ä¾‹è°ƒåº¦ï¼ˆå¯é€‰ï¼‰

**æ¶æ„ä¼˜åŠ¿ï¼š**
- L1 å±‚ç»„ä»¶ï¼Œæ‰€æœ‰å±‚éƒ½å¯ä½¿ç”¨
- é›¶ä¾èµ–å…¶ä»– SAGE åŒ…ï¼ˆä»…ä¾èµ– `openai` å¤–éƒ¨åº“ï¼‰
- è‡ªåŒ…å«çš„æœåŠ¡å‘ç°é€»è¾‘
- å¯é€‰çš„ Control Plane é›†æˆï¼Œæ— éœ€å¼ºåˆ¶ä¾èµ–

### 2. ä¸¤ç§ä½¿ç”¨æ¨¡å¼

#### æ¨¡å¼ 1: Simple Modeï¼ˆç®€å•æ¨¡å¼ - é»˜è®¤ï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- å•å®ä¾‹ vLLM æœåŠ¡æˆ–äº‘ç«¯ API
- å¿«é€Ÿå¯åŠ¨ï¼Œä½å¼€é”€
- åŸºæœ¬çš„è¯·æ±‚/å“åº”

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from sage.common.components.sage_llm.client import IntelligentLLMClient

# è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ€ä½³æœåŠ¡
client = IntelligentLLMClient.create_auto()

# ç”Ÿæˆå“åº”
response = client.chat([
    {"role": "user", "content": "Hello!"}
])
print(response)
```

#### æ¨¡å¼ 2: Control Plane Modeï¼ˆæ§åˆ¶å¹³é¢æ¨¡å¼ - é«˜çº§ï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- å¤šå®ä¾‹ vLLM éƒ¨ç½²
- éœ€è¦ SLO ä¿è¯ï¼ˆå»¶è¿Ÿã€ä¼˜å…ˆçº§ï¼‰
- éœ€è¦è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
- éœ€è¦ Prefilling/Decoding åˆ†ç¦»ä¼˜åŒ–
- éœ€è¦æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from sage.common.components.sage_llm.client import IntelligentLLMClient

# é…ç½®å¤šå®ä¾‹ Control Plane
client = IntelligentLLMClient.create_with_control_plane(
    instances=[
        {
            "host": "localhost",
            "port": 8001,
            "model_name": "llama-2-7b",
            "instance_type": "PREFILL",  # ä¸“é—¨å¤„ç†é¢„å¡«å……
            "gpu_count": 2,
        },
        {
            "host": "localhost",
            "port": 8002,
            "model_name": "llama-2-7b",
            "instance_type": "DECODE",   # ä¸“é—¨å¤„ç†è§£ç 
            "gpu_count": 1,
        },
        {
            "host": "192.168.1.100",
            "port": 8001,
            "model_name": "llama-2-13b",  # ä¸åŒæœºå™¨ã€ä¸åŒæ¨¡å‹
            "gpu_count": 4,
        },
    ],
    scheduling_policy="slo_aware",      # SLO æ„ŸçŸ¥è°ƒåº¦
    routing_strategy="topology_aware",   # æ‹“æ‰‘æ„ŸçŸ¥è·¯ç”±
    enable_pd_separation=True,           # å¯ç”¨ P/D åˆ†ç¦»
)

# é«˜ä¼˜å…ˆçº§è¯·æ±‚ï¼Œ1ç§’ SLO
response = client.chat(
    messages=[{"role": "user", "content": "Urgent query!"}],
    priority="HIGH",
    slo_deadline_ms=1000,
    max_tokens=500,
)

# æŸ¥çœ‹æ€§èƒ½æŒ‡æ ‡
metrics = client.get_metrics()
print(f"P95 å»¶è¿Ÿ: {metrics['p95_latency_ms']}ms")
print(f"SLO åˆè§„ç‡: {metrics['slo_compliance_rate']}%")

# æŸ¥çœ‹å®ä¾‹çŠ¶æ€
instances = client.get_instances()
for inst in instances:
    print(f"{inst['instance_id']}: è´Ÿè½½={inst['current_load']}, "
          f"å¥åº·={inst['is_healthy']}")

# æ¸…ç†èµ„æºï¼ˆé‡è¦ï¼ï¼‰
client.cleanup()
```

**Control Plane è°ƒåº¦ç­–ç•¥ï¼š**
- `fifo`: å…ˆè¿›å…ˆå‡ºï¼ˆæœ€ç®€å•ï¼‰
- `priority`: åŸºäºä¼˜å…ˆçº§ï¼ˆHIGH > NORMAL > LOWï¼‰
- `slo_aware`: SLO æ„ŸçŸ¥ï¼ˆè€ƒè™‘æˆªæ­¢æ—¶é—´ï¼‰
- `cost_optimized`: æˆæœ¬ä¼˜åŒ–ï¼ˆé€‰æ‹©æœ€ç»æµçš„å®ä¾‹ï¼‰
- `adaptive`: è‡ªé€‚åº”ï¼ˆæ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´ï¼‰

**è·¯ç”±ç­–ç•¥ï¼š**
- `load_balanced`: è´Ÿè½½å‡è¡¡ï¼ˆé»˜è®¤ï¼‰
- `affinity`: ä¼šè¯äº²å’Œæ€§
- `locality`: æ•°æ®å±€éƒ¨æ€§
- `topology_aware`: æ‹“æ‰‘æ„ŸçŸ¥ï¼ˆNVLINKã€NUMAï¼‰

### 3. ä½¿ç”¨ç¤ºä¾‹

#### è‡ªåŠ¨æ£€æµ‹æ¨¡å¼ï¼ˆæ¨èï¼‰

```python
from sage.common.components.sage_llm.client import IntelligentLLMClient

# è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ€ä½³æœåŠ¡
client = IntelligentLLMClient.create_auto()

# ç”Ÿæˆå“åº”
response = client.chat([
    {"role": "user", "content": "Hello!"}
])
print(response)
```

#### æ‰‹åŠ¨é…ç½®æ¨¡å¼

```python
# ä½¿ç”¨æœ¬åœ° vLLM
client = IntelligentLLMClient(
    model_name="meta-llama/Llama-2-7b-chat-hf",
    base_url="http://localhost:8001/v1",
    api_key="empty"
)

# æˆ–ä½¿ç”¨äº‘ç«¯ API
client = IntelligentLLMClient(
    model_name="qwen-max",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key="your-api-key"
)
```

### 4. ç¯å¢ƒå˜é‡é…ç½®

```bash
# æ˜¾å¼é…ç½®äº‘ç«¯æœåŠ¡
export SAGE_CHAT_MODEL="qwen-max"
export SAGE_CHAT_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1"
export SAGE_CHAT_API_KEY="sk-xxx"

# æ˜¾å¼é…ç½®æœ¬åœ° vLLM
export SAGE_CHAT_MODEL="meta-llama/Llama-2-7b-chat-hf"
export SAGE_CHAT_BASE_URL="http://localhost:8001/v1"
# SAGE_CHAT_API_KEY å¯çœç•¥ï¼ˆæœ¬åœ°æœåŠ¡ï¼‰
```

## æœåŠ¡æ£€æµ‹é€»è¾‘

**ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š**

1. **ç”¨æˆ·æ˜¾å¼é…ç½®** - ç¯å¢ƒå˜é‡ `SAGE_CHAT_BASE_URL` å­˜åœ¨
   - è·³è¿‡è‡ªåŠ¨æ£€æµ‹ï¼Œç›´æ¥ä½¿ç”¨é…ç½®çš„ç«¯ç‚¹

2. **æœ¬åœ° vLLM è‡ªåŠ¨æ£€æµ‹** - æ¢æµ‹æœ¬åœ°ç«¯ç‚¹
   - `http://localhost:8001/v1` ï¼ˆæ¨èï¼Œé¿å…ä¸ Gateway 8000 å†²çªï¼‰
   - `http://127.0.0.1:8001/v1`
   - `http://localhost:8000/v1` ï¼ˆvLLM é»˜è®¤ç«¯å£ï¼‰
   - `http://127.0.0.1:8000/v1`

3. **äº‘ç«¯ API é™çº§** - æœ¬åœ°æœåŠ¡ä¸å¯ç”¨æ—¶
   - ä½¿ç”¨ DashScope é»˜è®¤ç«¯ç‚¹
   - éœ€è¦è®¾ç½® `SAGE_CHAT_API_KEY`

**æ¢æµ‹æœºåˆ¶ï¼š**
- HTTP GET `/v1/models` ç«¯ç‚¹
- è¶…æ—¶æ—¶é—´ï¼š1.5 ç§’
- å¤±è´¥é™é»˜å¤„ç†ï¼ˆç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹ï¼‰

## æ¶æ„æ”¹è¿›

### Before (è¿è§„)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sage-gateway â”‚ (L6)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ âŒ éæ³•ä¾èµ–
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sage-tools   â”‚ (L6)
â”‚ llm_detectionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### After (åˆè§„)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sage-gateway â”‚ (L6)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ âœ… åˆæ³•ä¾èµ–
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sage-common  â”‚ (L1)
â”‚ sage_llm     â”‚
â”‚ client.py    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Gateway é‡æ„

**æ–‡ä»¶ï¼š** `packages/sage-gateway/src/sage/gateway/rag_pipeline.py`

**å˜æ›´ï¼š**

```python
# Before: æ‰‹åŠ¨æ£€æµ‹ + é…ç½®é€»è¾‘
def _detect_local_vllm(self) -> tuple[str | None, str | None]:
    from sage.tools.cli.utils.llm_detection import detect_vllm  # âŒ L6 -> L6
    # ... 50+ è¡Œæ£€æµ‹é€»è¾‘

# After: ç®€å•è°ƒç”¨ L1 å®¢æˆ·ç«¯
def _get_llm_client(self):
    from sage.common.components.sage_llm.client import IntelligentLLMClient
    if self._llm_client is None:
        self._llm_client = IntelligentLLMClient.create_auto()  # âœ… è‡ªåŠ¨æ£€æµ‹
    return self._llm_client
```

**ä»£ç å‡å°‘ï¼š** ~100 è¡Œ â†’ ~10 è¡Œ

## æœªæ¥è§„åˆ’

### sage-libs é›†æˆé‡æ„

`sage-libs/integrations/openaiclient.py` åº”è¯¥ï¼š
1. ~~è‡ªå·±å®ç° OpenAI å®¢æˆ·ç«¯~~ â†’ ä¾èµ– L1 çš„ `IntelligentLLMClient`
2. ä¿ç•™é«˜çº§é›†æˆé€»è¾‘ï¼ˆå¦‚ ChromaDBã€Milvus é›†æˆï¼‰

```python
# æœªæ¥é‡æ„å»ºè®®
# sage-libs/integrations/openaiclient.py
from sage.common.components.sage_llm.client import IntelligentLLMClient

class OpenAIClient(IntelligentLLMClient):
    """é«˜çº§ OpenAI å®¢æˆ·ç«¯ï¼ˆL3ï¼‰

    åŸºäº L1 çš„ IntelligentLLMClientï¼Œæ·»åŠ ï¼š
    - é«˜çº§é‡è¯•é€»è¾‘
    - æµå¼å¤„ç†ä¼˜åŒ–
    - ä¸ sage-libs å…¶ä»–ç»„ä»¶é›†æˆ
    """
    pass
```

## æµ‹è¯•éªŒè¯

### å•å…ƒæµ‹è¯•

```bash
# æµ‹è¯•é…ç½®æ£€æµ‹
python -c "
from sage.common.components.sage_llm.client import IntelligentLLMClient
config = IntelligentLLMClient._detect_llm_config()
print(config)
"
```

### æ¶æ„æ£€æŸ¥

```bash
# è¿è¡Œæ¶æ„åˆè§„æ€§æ£€æŸ¥
sage-dev architecture check

# é¢„æœŸç»“æœï¼šâœ… æ¶æ„åˆè§„æ€§æ£€æŸ¥é€šè¿‡ï¼
```

## è¿ç§»æŒ‡å—

### å¯¹äºä½¿ç”¨ `sage.tools.cli.utils.llm_detection` çš„ä»£ç 

**æ›¿æ¢å‰ï¼š**
```python
from sage.tools.cli.utils.llm_detection import detect_vllm

vllm_info = detect_vllm()
if vllm_info:
    base_url = vllm_info.base_url
    model = vllm_info.default_model
```

**æ›¿æ¢åï¼š**
```python
from sage.common.components.sage_llm.client import IntelligentLLMClient

# æ–¹å¼ 1: ç›´æ¥ä½¿ç”¨å®¢æˆ·ç«¯ï¼ˆæ¨èï¼‰
client = IntelligentLLMClient.create_auto()

# æ–¹å¼ 2: ä»…è·å–é…ç½®
config = IntelligentLLMClient._detect_llm_config()
base_url = config["base_url"]
model = config["model_name"]
```

### å¯¹äºä½¿ç”¨ `sage.libs.integrations.openaiclient.OpenAIClient` çš„ä»£ç 

**æ›¿æ¢å‰ï¼š**
```python
from sage.libs.integrations.openaiclient import OpenAIClient

client = OpenAIClient(
    model_name=model,
    base_url=base_url,
    api_key=api_key,
    seed=42
)
response = client.generate(messages)
```

**æ›¿æ¢åï¼š**
```python
from sage.common.components.sage_llm.client import IntelligentLLMClient

# è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰
client = IntelligentLLMClient.create_auto()
response = client.chat(messages)

# æˆ–æ‰‹åŠ¨é…ç½®
client = IntelligentLLMClient(
    model_name=model,
    base_url=base_url,
    api_key=api_key
)
response = client.chat(messages)
```

**å…¼å®¹æ€§ï¼š** `IntelligentLLMClient` åŒæ—¶æä¾› `chat()` å’Œ `generate()` æ–¹æ³•

## ç›¸å…³æ–‡ä»¶

**æ–°å¢ï¼š**
- `packages/sage-common/src/sage/common/components/sage_llm/client.py`

**ä¿®æ”¹ï¼š**
- `packages/sage-common/src/sage/common/components/sage_llm/__init__.py`
- `packages/sage-gateway/src/sage/gateway/__init__.py` (æ·»åŠ  `__layer__` æ ‡è®°)
- `packages/sage-gateway/src/sage/gateway/rag_pipeline.py` (é‡æ„)

**å¾…å¼ƒç”¨ï¼š**
- `packages/sage-tools/src/sage/tools/cli/utils/llm_detection.py` (L6 CLI å·¥å…·ä¿ç•™)
- `packages/sage-libs/src/sage/libs/integrations/openaiclient.py` (å¾…é‡æ„ä¸ºä¾èµ– L1)

## æ¶æ„åˆè§„æ€§

âœ… **æ£€æŸ¥ç»“æœï¼š** æ— è¿è§„

```
ğŸ“Š æ¶æ„åˆè§„æ€§æ£€æŸ¥æŠ¥å‘Š
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:
  â€¢ æ£€æŸ¥æ–‡ä»¶æ•°: 213
  â€¢ å¯¼å…¥è¯­å¥æ•°: 0
  â€¢ éæ³•ä¾èµ–: 0
  â€¢ æ¨¡å—ä½ç½®é”™è¯¯: 0
  â€¢ å†…éƒ¨å¯¼å…¥: 0
  â€¢ ç¼ºå°‘æ ‡è®°: 0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… æ¶æ„åˆè§„æ€§æ£€æŸ¥é€šè¿‡ï¼
```

## æ€»ç»“

è¿™æ¬¡é‡æ„å®ç°äº†ï¼š

1. âœ… **è§£å†³æ¶æ„è¿è§„** - æ¶ˆé™¤ L6 â†’ L6 éæ³•ä¾èµ–
2. âœ… **ä»£ç å¤ç”¨** - L1 å±‚ç»„ä»¶å¯è¢«æ‰€æœ‰å±‚ä½¿ç”¨
3. âœ… **ç®€åŒ–ä»£ç ** - Gateway ä»£ç ä» ~150 è¡Œå‡å°‘åˆ° ~50 è¡Œ
4. âœ… **æ™ºèƒ½åŒ–** - è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æœåŠ¡ï¼Œæ— ç¼é™çº§
5. âœ… **å¯é…ç½®** - æ”¯æŒç¯å¢ƒå˜é‡æ˜¾å¼é…ç½®
6. âœ… **ç»Ÿä¸€æ¥å£** - OpenAI å…¼å®¹ï¼Œæ˜“äºè¿ç§»

**è®¾è®¡åŸåˆ™ï¼š**
- ğŸ“¦ **å…³æ³¨ç‚¹åˆ†ç¦»** - LLM å®¢æˆ·ç«¯é€»è¾‘åœ¨ L1ï¼Œä¸šåŠ¡é€»è¾‘åœ¨ L6
- ğŸ”„ **å¯æ‰©å±•æ€§** - æœªæ¥å¯è½»æ¾æ·»åŠ æ›´å¤šæœåŠ¡ç±»å‹
- ğŸ›¡ï¸ **æ¶æ„åˆè§„** - ä¸¥æ ¼éµå®ˆ SAGE åˆ†å±‚æ¶æ„
- ğŸ¯ **å¼€å‘ä½“éªŒ** - ç®€å•çš„ APIï¼Œåˆç†çš„é»˜è®¤é…ç½®
