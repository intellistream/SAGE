# Pull Request: sageLLM Hybrid Scheduler

## ğŸ¯ PR æ¦‚è¿°

**åˆ†æ”¯**: `feature/embedding_lmm_mixed_scheduler` â†’ `main`

**æ ‡é¢˜**: feat(sage-llm): å®ç° LLM å’Œ Embedding æ··åˆè°ƒåº¦ç³»ç»Ÿ

### ğŸ“‹ å˜æ›´æ‘˜è¦

æœ¬ PR å®ç°äº† sageLLM æ··åˆè°ƒåº¦ç³»ç»Ÿï¼Œå°† `IntelligentLLMClient` å’Œ `IntelligentEmbeddingClient` åˆå¹¶ä¸ºç»Ÿä¸€çš„ `UnifiedInferenceClient`ï¼Œå¹¶é€šè¿‡å¢å¼ºçš„ Control Plane å®ç° LLM å’Œ Embedding è¯·æ±‚åœ¨ç»Ÿä¸€ GPU èµ„æºæ± å†…çš„æ··åˆè°ƒåº¦ã€‚

**æ ¸å¿ƒä»·å€¼**:
- ğŸ”„ **ç»Ÿä¸€å…¥å£**: å•ä¸€å®¢æˆ·ç«¯å¤„ç† LLM (chat/generate) å’Œ Embedding è¯·æ±‚
- ğŸ“Š **æ™ºèƒ½è°ƒåº¦**: åŸºäºè¯·æ±‚ç±»å‹ã€è´Ÿè½½çŠ¶æ€å’Œä¼˜å…ˆçº§çš„è‡ªé€‚åº”è°ƒåº¦ç­–ç•¥
- ğŸš€ **èµ„æºä¼˜åŒ–**: Embedding æ‰¹å¤„ç†èšåˆï¼Œå‡å°‘ GPU ç¢ç‰‡åŒ–ï¼Œæé«˜ååé‡
- ğŸ”Œ **OpenAI å…¼å®¹**: ç»Ÿä¸€ API Server å®Œå…¨å…¼å®¹ OpenAI API è§„èŒƒ
- âœ… **å‘åå…¼å®¹**: ç°æœ‰ `IntelligentLLMClient` å’Œ `IntelligentEmbeddingClient` ä»£ç æ— éœ€ä¿®æ”¹

---

## ğŸ”„ å®¢æˆ·ç«¯é€‰æ‹©æŒ‡å—

### ä¸‰ç§å®¢æˆ·ç«¯å¹¶å­˜

æœ¬ PR **æ–°å¢** `UnifiedInferenceClient`ï¼Œä½† **ä¿ç•™** åŸæœ‰çš„ `IntelligentLLMClient` å’Œ `IntelligentEmbeddingClient`ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ç”¨æˆ·å¯é€‰çš„å®¢æˆ·ç«¯                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ UnifiedInferenceClient â”‚    â”‚ IntelligentLLMClient (ä¿ç•™)         â”‚  â”‚
â”‚  â”‚ (æ–°å¢ - æ¨è)          â”‚    â”‚ IntelligentEmbeddingClient (ä¿ç•™)   â”‚  â”‚
â”‚  â”‚                       â”‚    â”‚                                     â”‚  â”‚
â”‚  â”‚ â€¢ chat()              â”‚    â”‚ â€¢ ç‹¬ç«‹ä½¿ç”¨åœºæ™¯                       â”‚  â”‚
â”‚  â”‚ â€¢ generate()          â”‚    â”‚ â€¢ ç°æœ‰ä»£ç æ— éœ€ä»»ä½•ä¿®æ”¹               â”‚  â”‚
â”‚  â”‚ â€¢ embed()             â”‚    â”‚ â€¢ ç®€å•åœºæ™¯æ›´ç®€æ´                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                               â”‚                          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚              sageLLM Control Plane (å…±äº«è°ƒåº¦)                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                              â”‚                                          â”‚
â”‚                              â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚                    ç»Ÿä¸€èµ„æºæ±  (GPU Instances)                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¦‚ä½•é€‰æ‹©ï¼Ÿ

| åœºæ™¯ | æ¨èå®¢æˆ·ç«¯ | ç†ç”± |
|------|-----------|------|
| æ–°é¡¹ç›®ï¼ŒåŒæ—¶éœ€è¦ LLM å’Œ Embedding | `UnifiedInferenceClient` | ç»Ÿä¸€å…¥å£ï¼Œäº«å—æ··åˆè°ƒåº¦ |
| ç°æœ‰é¡¹ç›®ï¼Œåªä½¿ç”¨ LLM | `IntelligentLLMClient` | æ— éœ€ä¿®æ”¹ï¼Œå‘åå…¼å®¹ |
| ç°æœ‰é¡¹ç›®ï¼Œåªä½¿ç”¨ Embedding | `IntelligentEmbeddingClient` | æ— éœ€ä¿®æ”¹ï¼Œå‘åå…¼å®¹ |
| ç®€å•è„šæœ¬ï¼Œåªéœ€è¦å•ä¸€åŠŸèƒ½ | ç‹¬ç«‹å®¢æˆ·ç«¯ | ä»£ç æ›´ç®€æ´ |
| éœ€è¦é«˜çº§è°ƒåº¦ï¼ˆControl Planeï¼‰ | `UnifiedInferenceClient` | æ”¯æŒ Control Plane æ¨¡å¼ |

### ä»£ç ç¤ºä¾‹

```python
# æ–¹å¼ 1: æ–°ä»£ç  - ä½¿ç”¨ UnifiedInferenceClient (æ¨è)
from sage.common.components.sage_llm import UnifiedInferenceClient
client = UnifiedInferenceClient.create_auto()
response = client.chat([{"role": "user", "content": "Hello"}])
vectors = client.embed(["text1", "text2"])

# æ–¹å¼ 2: ç°æœ‰ä»£ç  - ç»§ç»­ä½¿ç”¨ç‹¬ç«‹å®¢æˆ·ç«¯ (ä»ç„¶æœ‰æ•ˆ)
from sage.common.components.sage_llm import IntelligentLLMClient
from sage.common.components.sage_embedding import IntelligentEmbeddingClient
llm = IntelligentLLMClient.create_auto()
embedder = IntelligentEmbeddingClient.create_auto()
```

> **é‡è¦**: ä¸‰ç§å®¢æˆ·ç«¯**éƒ½è¿æ¥åˆ°åŒä¸€ä¸ª sageLLM èµ„æºæ± **ï¼Œäº«å—æ··åˆè°ƒåº¦çš„å¥½å¤„ã€‚é€‰æ‹©å“ªç§å®¢æˆ·ç«¯å–å†³äºä½ çš„ä½¿ç”¨åœºæ™¯å’Œä»£ç é£æ ¼åå¥½ã€‚

---

## ğŸ“Š å˜æ›´ç»Ÿè®¡

| ç±»å‹ | æ•°é‡ |
|------|------|
| æ–°å¢æ–‡ä»¶ | 12 |
| ä¿®æ”¹æ–‡ä»¶ | 8 |
| æ–°å¢ä»£ç è¡Œ | ~6,500 è¡Œ |
| å•å…ƒæµ‹è¯• | 55 ä¸ª |
| é›†æˆæµ‹è¯• | 87 ä¸ª |
| CLI æµ‹è¯• | 23 ä¸ª |
| **æ€»æµ‹è¯•æ•°** | **165 ä¸ª** |

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           åº”ç”¨å±‚ (Application Layer)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      UnifiedInferenceClient                              â”‚
â”‚                 chat() | generate() | embed()                            â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚        â”‚   Simple Mode       â”‚  Control Plane Mode â”‚                    â”‚
â”‚        â”‚  (ç›´è¿åç«¯ API)      â”‚  (é€šè¿‡è°ƒåº¦å™¨è·¯ç”±)    â”‚                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                       UnifiedAPIServer                                   â”‚
â”‚              (OpenAI-Compatible REST API Gateway)                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ /v1/chat/      â”‚ /v1/           â”‚ /v1/           â”‚ /v1/models   â”‚   â”‚
â”‚   â”‚ completions    â”‚ completions    â”‚ embeddings     â”‚ /health      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    sageLLM Control Plane (å¢å¼ºç‰ˆ)                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                   RequestClassifier                              â”‚   â”‚
â”‚   â”‚    (è¯·æ±‚åˆ†ç±»: LLM_CHAT / LLM_GENERATE / EMBEDDING)               â”‚   â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚   â”‚                  HybridSchedulingPolicy                          â”‚   â”‚
â”‚   â”‚  â€¢ è¯·æ±‚ç±»å‹åˆ†ç»„          â€¢ Embedding æ‰¹å¤„ç†èšåˆ                    â”‚   â”‚
â”‚   â”‚  â€¢ ä¼˜å…ˆçº§è°ƒåº¦            â€¢ æ··åˆå®ä¾‹è´Ÿè½½å‡è¡¡                        â”‚   â”‚
â”‚   â”‚  â€¢ ä¸“ç”¨å®ä¾‹ä¼˜å…ˆ          â€¢ å¯é…ç½® LLM å›é€€ç­–ç•¥                     â”‚   â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚   â”‚    ExecutionCoordinator        EmbeddingExecutor                 â”‚   â”‚
â”‚   â”‚    (LLM è¯·æ±‚æ‰§è¡Œ)              (Embedding æ‰¹å¤„ç†æ‰§è¡Œ)             â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        ç»Ÿä¸€èµ„æºæ±  (GPU Pool)                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚  vLLM Instance  â”‚  â”‚  vLLM Instance  â”‚  â”‚  TEI Instance   â”‚        â”‚
â”‚   â”‚  (LLM Only)     â”‚  â”‚  (LLM+Embed)    â”‚  â”‚  (Embed Only)   â”‚        â”‚
â”‚   â”‚  Type: GENERAL  â”‚  â”‚  Type: MIXED    â”‚  â”‚  Type: EMBEDDINGâ”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶å…³ç³»

```
UnifiedInferenceClient
    â”‚
    â”œâ”€â”€ Simple Mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       â”‚                                              â”‚
    â”‚       â”œâ”€â”€ OpenAI Client (LLM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Backend LLM
    â”‚       â””â”€â”€ OpenAI Client (Embedding) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Backend Embedding
    â”‚
    â””â”€â”€ Control Plane Mode
            â”‚
            â””â”€â”€ ControlPlaneManager
                    â”‚
                    â”œâ”€â”€ RequestClassifier â”€â”€â–º RequestType åˆ†ç±»
                    â”‚
                    â”œâ”€â”€ HybridSchedulingPolicy
                    â”‚       â”‚
                    â”‚       â”œâ”€â”€ LLM è¯·æ±‚ â”€â”€â–º ç°æœ‰è°ƒåº¦ç­–ç•¥ (Adaptive/FIFO/Priority)
                    â”‚       â””â”€â”€ Embedding è¯·æ±‚ â”€â”€â–º æ‰¹å¤„ç†èšåˆ + EmbeddingExecutor
                    â”‚
                    â””â”€â”€ ExecutionCoordinator â”€â”€â–º Backend Instances
```

---

## ğŸ“ æ–‡ä»¶å˜æ›´æ¸…å•

### æ–°å¢æ–‡ä»¶

#### Control Plane æ ¸å¿ƒ (`sageLLM/control_plane/`)

| æ–‡ä»¶ | è¡Œæ•° | æè¿° |
|------|------|------|
| `request_classifier.py` | ~576 | è¯·æ±‚åˆ†ç±»å™¨ï¼šè‡ªåŠ¨è¯†åˆ« LLM/Embedding è¯·æ±‚ï¼Œç­›é€‰å…¼å®¹å®ä¾‹ |
| `strategies/hybrid_policy.py` | ~885 | æ··åˆè°ƒåº¦ç­–ç•¥ï¼šè¯·æ±‚åˆ†ç»„ã€Embedding æ‰¹å¤„ç†ã€è´Ÿè½½å‡è¡¡ |

#### ç»Ÿä¸€å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨ (`sage_llm/`)

| æ–‡ä»¶ | è¡Œæ•° | æè¿° |
|------|------|------|
| `unified_client.py` | ~1062 | ç»Ÿä¸€æ¨ç†å®¢æˆ·ç«¯ï¼šåˆå¹¶ LLM å’Œ Embedding æ¥å£ |
| `unified_api_server.py` | ~956 | OpenAI å…¼å®¹ API æœåŠ¡å™¨ï¼šç»Ÿä¸€ REST ç½‘å…³ |

#### CLI å‘½ä»¤ (`sage-cli/`)

| æ–‡ä»¶ | è¡Œæ•° | æè¿° |
|------|------|------|
| `commands/apps/inference.py` | ~650 | æ¨ç†æœåŠ¡ç®¡ç†å‘½ä»¤ï¼šstart/stop/status/config |

#### æµ‹è¯•æ–‡ä»¶

| æ–‡ä»¶ | æµ‹è¯•æ•° | æè¿° |
|------|--------|------|
| `tests/unit/.../test_unified_client.py` | 38 | å®¢æˆ·ç«¯å•å…ƒæµ‹è¯• |
| `tests/unit/.../test_compat.py` | 17 | å‘åå…¼å®¹æµ‹è¯• |
| `tests/integration/conftest.py` | - | æµ‹è¯• fixtures å’Œ Mock åç«¯ |
| `tests/integration/test_hybrid_scheduling_e2e.py` | 22 | æ··åˆè°ƒåº¦ç«¯åˆ°ç«¯æµ‹è¯• |
| `tests/integration/test_unified_api_server.py` | 33 | API æœåŠ¡å™¨é›†æˆæµ‹è¯• |
| `tests/integration/test_unified_client_e2e.py` | 32 | å®¢æˆ·ç«¯é›†æˆæµ‹è¯• |
| `sage-cli/tests/test_inference_cli.py` | 23 | CLI å‘½ä»¤æµ‹è¯• |

### ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | å˜æ›´ç±»å‹ | æè¿° |
|------|----------|------|
| `sageLLM/control_plane/types.py` | æ‰©å±• | æ–°å¢ `RequestType` æšä¸¾ã€æ‰©å±• `RequestMetadata` å’Œ `ExecutionInstance` |
| `sageLLM/control_plane/strategies/__init__.py` | æ‰©å±• | å¯¼å‡º `HybridSchedulingPolicy` |
| `sageLLM/control_plane/__init__.py` | æ‰©å±• | å¯¼å‡ºæ–°å¢ç±»å‹ |
| `sage_llm/__init__.py` | æ‰©å±• | å¯¼å‡º `UnifiedInferenceClient` å’Œ `UnifiedAPIServer` |
| `sage_llm/client.py` | å…¼å®¹å±‚ | ä¿æŒå‘åå…¼å®¹ï¼Œå†…éƒ¨ä½¿ç”¨ UnifiedInferenceClient |
| `sage_embedding/client.py` | å…¼å®¹å±‚ | ä¿æŒå‘åå…¼å®¹ï¼Œå†…éƒ¨ä½¿ç”¨ UnifiedInferenceClient |
| `sage-cli/commands/apps/__init__.py` | æ‰©å±• | æ³¨å†Œ inference å‘½ä»¤ç»„ |
| `sage-cli/main.py` | æ‰©å±• | æ·»åŠ  inference å­å‘½ä»¤ |

---

## ğŸ”§ æ ¸å¿ƒå®ç°è¯¦æƒ…

### 1. è¯·æ±‚ç±»å‹æ‰©å±• (`types.py`)

```python
class RequestType(Enum):
    """è¯·æ±‚ç±»å‹æšä¸¾"""
    LLM_CHAT = "llm_chat"        # å¯¹è¯è¯·æ±‚
    LLM_GENERATE = "llm_generate" # æ–‡æœ¬ç”Ÿæˆè¯·æ±‚
    EMBEDDING = "embedding"       # å‘é‡åµŒå…¥è¯·æ±‚

class ExecutionInstanceType(Enum):
    """å®ä¾‹ç±»å‹æšä¸¾ - æ–°å¢æ··åˆç±»å‹"""
    GENERAL = "general"
    PREFILLING = "prefilling"
    DECODING = "decoding"
    HYBRID = "hybrid"
    EMBEDDING = "embedding"       # æ–°å¢ï¼šçº¯ Embedding å®ä¾‹
    LLM_EMBEDDING = "llm_embedding" # æ–°å¢ï¼šæ··åˆå®ä¾‹

@dataclass
class RequestMetadata:
    # ... ç°æœ‰å­—æ®µ ...
    
    # æ–°å¢ Embedding ç›¸å…³å­—æ®µ
    request_type: RequestType = RequestType.LLM_CHAT
    embedding_texts: list[str] | None = None
    embedding_model: str | None = None
    embedding_batch_size: int = 32
```

### 2. è¯·æ±‚åˆ†ç±»å™¨ (`request_classifier.py`)

```python
class RequestClassifier:
    """è¯·æ±‚åˆ†ç±»å™¨ - è‡ªåŠ¨è¯†åˆ«è¯·æ±‚ç±»å‹å¹¶ç­›é€‰å…¼å®¹å®ä¾‹"""
    
    def classify(self, request: RequestMetadata) -> RequestType:
        """åˆ†ç±»é€»è¾‘:
        1. å¦‚æœ request_type å·²è®¾ç½®ï¼Œç›´æ¥è¿”å›
        2. å¦‚æœ embedding_texts éç©ºï¼Œè¿”å› EMBEDDING
        3. å¦‚æœ prompt éç©ºï¼Œæ ¹æ®ä¸Šä¸‹æ–‡è¿”å› LLM_CHAT æˆ– LLM_GENERATE
        4. é»˜è®¤è¿”å› LLM_CHAT
        """
    
    def get_compatible_instances(
        self,
        request_type: RequestType,
        instances: list[ExecutionInstance],
    ) -> list[ExecutionInstance]:
        """æ ¹æ®è¯·æ±‚ç±»å‹ç­›é€‰å…¼å®¹çš„æ‰§è¡Œå®ä¾‹"""
    
    def validate_request(self, request: RequestMetadata) -> ValidationResult:
        """éªŒè¯è¯·æ±‚å®Œæ•´æ€§"""
```

### 3. æ··åˆè°ƒåº¦ç­–ç•¥ (`hybrid_policy.py`)

```python
@dataclass
class HybridSchedulingConfig:
    embedding_batch_size: int = 32          # Embedding æ‰¹å¤§å°
    embedding_priority: str = "normal"       # high/normal/low/adaptive
    llm_fallback_policy: str = "adaptive"   # fifo/priority/slo_aware/adaptive
    hybrid_instance_ratio: float = 0.7      # æ··åˆå®ä¾‹ LLM:Embedding æ¯”ä¾‹
    prefer_specialized_instances: bool = True

class HybridSchedulingPolicy(SchedulingPolicy):
    """æ··åˆè°ƒåº¦ç­–ç•¥"""
    
    def schedule(
        self,
        requests: list[RequestMetadata],
        instances: list[ExecutionInstance],
    ) -> list[SchedulingDecision]:
        """è°ƒåº¦é€»è¾‘:
        1. æŒ‰ request_type åˆ†ç»„è¯·æ±‚
        2. Embedding è¯·æ±‚ï¼šæ‰¹é‡èšåˆ â†’ ä¼˜å…ˆä¸“ç”¨å®ä¾‹ â†’ æ¬¡é€‰æ··åˆå®ä¾‹
        3. LLM è¯·æ±‚ï¼šä½¿ç”¨é…ç½®çš„å›é€€ç­–ç•¥ â†’ æ’é™¤çº¯ Embedding å®ä¾‹
        4. æ··åˆå®ä¾‹è´Ÿè½½å‡è¡¡
        """
    
    def _aggregate_embedding_batches(
        self,
        requests: list[RequestMetadata],
    ) -> list[EmbeddingBatch]:
        """å°†å¤šä¸ª Embedding è¯·æ±‚èšåˆä¸ºæ‰¹æ¬¡"""
```

### 4. ç»Ÿä¸€æ¨ç†å®¢æˆ·ç«¯ (`unified_client.py`)

```python
class UnifiedInferenceClient:
    """ç»Ÿä¸€æ¨ç†å®¢æˆ·ç«¯ - åˆå¹¶ LLM å’Œ Embedding åŠŸèƒ½"""
    
    @classmethod
    def create_auto(
        cls,
        llm_model: str | None = None,
        embedding_model: str | None = None,
        **kwargs,
    ) -> UnifiedInferenceClient:
        """è‡ªåŠ¨æ£€æµ‹æ¨¡å¼:
        1. ç¯å¢ƒå˜é‡: SAGE_UNIFIED_BASE_URL
        2. æœ¬åœ° LLM: localhost:8001, 8000
        3. æœ¬åœ° Embedding: localhost:8090, 8080
        4. äº‘ç«¯ API: DashScope
        """
    
    @classmethod
    def create_with_control_plane(
        cls,
        instances: list[dict],
        scheduling_policy: str = "hybrid",
        **kwargs,
    ) -> UnifiedInferenceClient:
        """Control Plane æ¨¡å¼ - æ”¯æŒé«˜çº§è°ƒåº¦"""
    
    def chat(self, messages: list[dict], **kwargs) -> str:
        """èŠå¤©è¡¥å…¨"""
    
    def generate(self, prompt: str, **kwargs) -> str:
        """æ–‡æœ¬ç”Ÿæˆ"""
    
    def embed(self, texts: list[str], **kwargs) -> list[list[float]]:
        """æ–‡æœ¬åµŒå…¥"""
```

### 5. ç»Ÿä¸€ API æœåŠ¡å™¨ (`unified_api_server.py`)

```python
class UnifiedAPIServer:
    """OpenAI å…¼å®¹çš„ç»Ÿä¸€ API æœåŠ¡å™¨"""
    
    # ç«¯ç‚¹
    # GET  /              # æœåŠ¡å™¨ä¿¡æ¯
    # GET  /health        # å¥åº·æ£€æŸ¥
    # GET  /v1/models     # æ¨¡å‹åˆ—è¡¨
    # POST /v1/chat/completions   # èŠå¤©è¡¥å…¨
    # POST /v1/completions        # æ–‡æœ¬è¡¥å…¨
    # POST /v1/embeddings         # å‘é‡åµŒå…¥
    
    def __init__(self, config: UnifiedServerConfig):
        """åˆå§‹åŒ–æœåŠ¡å™¨"""
    
    async def start(self) -> None:
        """å¯åŠ¨æœåŠ¡å™¨"""
    
    async def stop(self) -> None:
        """ä¼˜é›…å…³é—­"""
```

### 6. CLI å‘½ä»¤ (`inference.py`)

```bash
# å¯åŠ¨ç»Ÿä¸€æ¨ç†æœåŠ¡
sage inference start \
    --llm-model Qwen/Qwen2.5-7B-Instruct \
    --embedding-model BAAI/bge-m3 \
    --scheduling-policy hybrid \
    --port 8000 \
    --background

# åœæ­¢æœåŠ¡
sage inference stop [--force]

# æŸ¥çœ‹çŠ¶æ€
sage inference status

# æŸ¥çœ‹æ—¥å¿—
sage inference logs [--follow] [--lines 100]

# é…ç½®ç®¡ç†
sage inference config show
sage inference config set --key llm_model --value "..."
```

---

## ğŸ§ª æµ‹è¯•è¦†ç›–

### æµ‹è¯•ç»Ÿè®¡

| ç±»åˆ« | æ–‡ä»¶ | æµ‹è¯•æ•° | çŠ¶æ€ |
|------|------|--------|------|
| å•å…ƒæµ‹è¯• - å®¢æˆ·ç«¯ | `test_unified_client.py` | 38 | âœ… å…¨éƒ¨é€šè¿‡ |
| å•å…ƒæµ‹è¯• - å…¼å®¹æ€§ | `test_compat.py` | 17 | âœ… å…¨éƒ¨é€šè¿‡ |
| é›†æˆæµ‹è¯• - è°ƒåº¦ | `test_hybrid_scheduling_e2e.py` | 22 | âœ… å…¨éƒ¨é€šè¿‡ |
| é›†æˆæµ‹è¯• - æœåŠ¡å™¨ | `test_unified_api_server.py` | 33 | âœ… å…¨éƒ¨é€šè¿‡ |
| é›†æˆæµ‹è¯• - å®¢æˆ·ç«¯ | `test_unified_client_e2e.py` | 32 | âœ… å…¨éƒ¨é€šè¿‡ |
| CLI æµ‹è¯• | `test_inference_cli.py` | 23 | âœ… å…¨éƒ¨é€šè¿‡ |
| **æ€»è®¡** | **6 ä¸ªæµ‹è¯•æ–‡ä»¶** | **165** | âœ… |

### æµ‹è¯•è¿è¡Œå‘½ä»¤

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
cd /home/yjy/SAGE

# å•å…ƒæµ‹è¯•
conda run -n sage python -m pytest packages/sage-common/tests/unit/components/sage_llm/ -v

# é›†æˆæµ‹è¯•
conda run -n sage python -m pytest packages/sage-common/tests/integration/ -v

# CLI æµ‹è¯•
conda run -n sage python -m pytest packages/sage-cli/tests/test_inference_cli.py -v

# å…¨é‡æµ‹è¯•
conda run -n sage python -m pytest \
    packages/sage-common/tests/unit/components/sage_llm/ \
    packages/sage-common/tests/integration/ \
    packages/sage-cli/tests/test_inference_cli.py \
    -v --tb=short
```

### å…³é”®æµ‹è¯•åœºæ™¯

| åœºæ™¯ | æè¿° | è¦†ç›– |
|------|------|------|
| è¯·æ±‚åˆ†ç±» | LLM/Embedding è‡ªåŠ¨è¯†åˆ« | âœ… |
| å®ä¾‹ç­›é€‰ | æŒ‰ç±»å‹ç­›é€‰å…¼å®¹å®ä¾‹ | âœ… |
| Embedding æ‰¹å¤„ç† | è¯·æ±‚èšåˆä¸æ‹†åˆ† | âœ… |
| æ··åˆè°ƒåº¦ | LLM + Embedding å¹¶å‘å¤„ç† | âœ… |
| ç«¯ç‚¹å…¼å®¹ | OpenAI API è§„èŒƒ | âœ… |
| è‡ªåŠ¨æ£€æµ‹ | æœ¬åœ°/äº‘ç«¯æœåŠ¡æ£€æµ‹ | âœ… |
| å‘åå…¼å®¹ | ç°æœ‰å®¢æˆ·ç«¯æ— ä¿®æ”¹ | âœ… |
| å•ä¾‹æ¨¡å¼ | å®¢æˆ·ç«¯å®ä¾‹ç¼“å­˜ | âœ… |
| é”™è¯¯å¤„ç† | è¶…æ—¶ã€é‡è¯•ã€é™çº§ | âœ… |
| CLI å‘½ä»¤ | start/stop/status | âœ… |

---

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### 1. ç»Ÿä¸€å®¢æˆ·ç«¯ - è‡ªåŠ¨æ£€æµ‹æ¨¡å¼

```python
from sage.common.components.sage_llm import UnifiedInferenceClient

# è‡ªåŠ¨æ£€æµ‹æœ€ä½³å¯ç”¨æœåŠ¡
client = UnifiedInferenceClient.create_auto()

# èŠå¤©
response = client.chat([
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"},
    {"role": "user", "content": "ä»€ä¹ˆæ˜¯æ··åˆè°ƒåº¦ï¼Ÿ"}
])
print(response)

# æ–‡æœ¬ç”Ÿæˆ
text = client.generate("ä»å‰æœ‰åº§å±±ï¼Œå±±ä¸Šæœ‰åº§åº™ï¼Œ")
print(text)

# å‘é‡åµŒå…¥
vectors = client.embed(["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"])
print(f"ç»´åº¦: {len(vectors[0])}")
```

### 2. ç»Ÿä¸€å®¢æˆ·ç«¯ - Control Plane æ¨¡å¼

```python
from sage.common.components.sage_llm import UnifiedInferenceClient

# é…ç½®å¤šå®ä¾‹ + æ··åˆè°ƒåº¦
client = UnifiedInferenceClient.create_with_control_plane(
    instances=[
        {
            "host": "localhost",
            "port": 8001,
            "model_name": "Qwen/Qwen2.5-7B-Instruct",
            "instance_type": "llm",
        },
        {
            "host": "localhost",
            "port": 8090,
            "model_name": "BAAI/bge-m3",
            "instance_type": "embedding",
        },
    ],
    scheduling_policy="hybrid",
    embedding_batch_size=32,
)

# ä½¿ç”¨æ–¹å¼ä¸ Simple æ¨¡å¼å®Œå…¨ç›¸åŒ
response = client.chat([{"role": "user", "content": "Hello"}])
vectors = client.embed(["Hello", "World"])
```

### 3. å¯åŠ¨ç»Ÿä¸€ API æœåŠ¡å™¨

```python
from sage.common.components.sage_llm import (
    UnifiedAPIServer,
    UnifiedServerConfig,
    BackendInstanceConfig,
)

config = UnifiedServerConfig(
    host="0.0.0.0",
    port=8000,
    llm_backends=[
        BackendInstanceConfig(
            host="localhost",
            port=8001,
            model_name="Qwen/Qwen2.5-7B-Instruct",
            instance_type="llm",
        ),
    ],
    embedding_backends=[
        BackendInstanceConfig(
            host="localhost",
            port=8090,
            model_name="BAAI/bge-m3",
            instance_type="embedding",
        ),
    ],
    scheduling_policy="hybrid",
)

server = UnifiedAPIServer(config)
server.start()  # é˜»å¡è¿è¡Œ
```

### 4. ä½¿ç”¨ CLI

```bash
# å¯åŠ¨æœåŠ¡ (å‰å°)
sage inference start

# å¯åŠ¨æœåŠ¡ (åå° + è‡ªå®šä¹‰é…ç½®)
sage inference start \
    --llm-backend http://localhost:8001 \
    --embedding-backend http://localhost:8090 \
    --scheduling-policy hybrid \
    --port 8000 \
    --background

# æŸ¥çœ‹çŠ¶æ€
sage inference status

# æŸ¥çœ‹æ—¥å¿—
sage inference logs --follow

# åœæ­¢æœåŠ¡
sage inference stop
```

### 5. ä½¿ç”¨ OpenAI SDK è°ƒç”¨

```python
from openai import OpenAI

# è¿æ¥ç»Ÿä¸€ API æœåŠ¡å™¨
client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed",  # æœ¬åœ°æœåŠ¡æ— éœ€ API Key
)

# èŠå¤©
response = client.chat.completions.create(
    model="Qwen/Qwen2.5-7B-Instruct",
    messages=[{"role": "user", "content": "Hello"}],
)
print(response.choices[0].message.content)

# åµŒå…¥
response = client.embeddings.create(
    model="BAAI/bge-m3",
    input=["Hello", "World"],
)
print(len(response.data[0].embedding))
```

---

## ğŸ”§ é…ç½®å‚è€ƒ

### ç¯å¢ƒå˜é‡

| å˜é‡å | ç”¨é€” | ç¤ºä¾‹å€¼ |
|--------|------|--------|
| `SAGE_UNIFIED_BASE_URL` | ç»Ÿä¸€æœåŠ¡ç«¯ç‚¹ | `http://localhost:8000/v1` |
| `SAGE_CHAT_BASE_URL` | LLM æœåŠ¡ç«¯ç‚¹ | `http://localhost:8001/v1` |
| `SAGE_EMBEDDING_BASE_URL` | Embedding æœåŠ¡ç«¯ç‚¹ | `http://localhost:8090/v1` |
| `SAGE_CHAT_MODEL` | é»˜è®¤ LLM æ¨¡å‹ | `Qwen/Qwen2.5-7B-Instruct` |
| `SAGE_EMBEDDING_MODEL` | é»˜è®¤ Embedding æ¨¡å‹ | `BAAI/bge-m3` |
| `SAGE_CHAT_API_KEY` | LLM API å¯†é’¥ | `sk-xxx` |

### è°ƒåº¦ç­–ç•¥é…ç½®

```python
HybridSchedulingConfig(
    embedding_batch_size=32,           # Embedding æ‰¹å¤„ç†å¤§å°
    embedding_priority="normal",        # high/normal/low/adaptive
    llm_fallback_policy="adaptive",    # fifo/priority/slo_aware/adaptive
    hybrid_instance_ratio=0.7,         # æ··åˆå®ä¾‹ LLM:Embedding æ¯”ä¾‹
    prefer_specialized_instances=True, # ä¼˜å…ˆä½¿ç”¨ä¸“ç”¨å®ä¾‹
    max_embedding_wait_ms=50.0,        # æ‰¹å¤„ç†æœ€å¤§ç­‰å¾…æ—¶é—´
)
```

---

## âš ï¸ ç ´åæ€§å˜æ›´

**æ— ç ´åæ€§å˜æ›´**ã€‚æœ¬ PR å®Œå…¨å‘åå…¼å®¹ï¼š

1. âœ… `IntelligentLLMClient` ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
2. âœ… `IntelligentEmbeddingClient` ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
3. âœ… ç°æœ‰ API ç­¾åä¿æŒä¸å˜
4. âœ… ç°æœ‰ç¯å¢ƒå˜é‡ç»§ç»­ç”Ÿæ•ˆ

---

## ğŸ”® æœªæ¥æ¶æ„æ¼”è¿›

### å½“å‰æ¶æ„

```
sage-common/components/
â”œâ”€â”€ sage_embedding/        # ç‹¬ç«‹çš„ Embedding åç«¯é€‚é…å±‚ï¼ˆ~20 ä¸ªæ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ client.py          # IntelligentEmbeddingClient
â”‚   â”œâ”€â”€ factory.py         # EmbeddingFactory (HF, OpenAI, Jina...)
â”‚   â””â”€â”€ wrappers/          # å„ç§åç«¯å°è£…
â”‚
â””â”€â”€ sage_llm/              # LLM ç»„ä»¶ + sageLLM è°ƒåº¦æ¡†æ¶
    â”œâ”€â”€ client.py          # IntelligentLLMClient
    â”œâ”€â”€ unified_client.py  # UnifiedInferenceClient (æœ¬ PR æ–°å¢)
    â””â”€â”€ sageLLM/           # Control Plane è°ƒåº¦æ¡†æ¶
        â””â”€â”€ control_plane/
            â””â”€â”€ strategies/hybrid_policy.py  # æ··åˆè°ƒåº¦ç­–ç•¥
```

### æœ¬ PR çš„è®¾è®¡å†³ç­–

**ä¿æŒ `sage_embedding` ç‹¬ç«‹**ï¼ŒåŸå› ï¼š

| åŸå›  | è¯´æ˜ |
|------|------|
| **èŒè´£åˆ†ç¦»** | `sage_embedding` æ˜¯"åç«¯é€‚é…å±‚"ï¼Œ`sageLLM` æ˜¯"è°ƒåº¦æ¡†æ¶å±‚" |
| **æœ€å°å˜æ›´** | æœ¬ PR ç›®æ ‡æ˜¯"å®ç°æ··åˆè°ƒåº¦"ï¼Œè€Œé"é‡æ„ç›®å½•ç»“æ„" |
| **å‘åå…¼å®¹** | ç°æœ‰ `from sage_embedding import ...` çš„ä»£ç æ— éœ€ä¿®æ”¹ |
| **ç‹¬ç«‹æ¼”è¿›** | Embedding åç«¯ç§ç±»ç¹å¤šï¼Œç‹¬ç«‹ç»´æŠ¤æ›´æ¸…æ™° |

`UnifiedInferenceClient` å·²åœ¨**é€»è¾‘ä¸Š**ç»Ÿä¸€äº† LLM å’Œ Embeddingï¼Œç‰©ç†ç›®å½•çš„æ•´åˆå¯ç•™å¾…åç»­ã€‚

### æœªæ¥å¯é€‰é‡æ„ (TODO)

å¦‚æœå›¢é˜Ÿå†³å®šè¿›ä¸€æ­¥æ•´åˆï¼Œå»ºè®®çš„ç›®å½•ç»“æ„ï¼š

```
sage_llm/
â”œâ”€â”€ sageLLM/
â”‚   â”œâ”€â”€ control_plane/     # è°ƒåº¦å±‚ (ä¸å˜)
â”‚   â””â”€â”€ backends/          # åç«¯é€‚é…å±‚ (æ–°)
â”‚       â”œâ”€â”€ llm/           # LLM åç«¯ (vLLM, OpenAI, ...)
â”‚       â””â”€â”€ embedding/     # ä» sage_embedding è¿ç§»
â”œâ”€â”€ unified_client.py
â””â”€â”€ ...
```

**é‡æ„èŒƒå›´**ï¼š
- è¿ç§» `sage_embedding/` åˆ° `sage_llm/sageLLM/backends/embedding/`
- æ›´æ–°æ‰€æœ‰ import è·¯å¾„
- æ·»åŠ å…¼å®¹æ€§ re-export å±‚
- æ›´æ–°æ–‡æ¡£å’Œæµ‹è¯•

> **å»ºè®®**: å¼€ä¸€ä¸ªå•ç‹¬çš„ Issue è·Ÿè¸ªæ­¤é‡æ„ï¼Œä¸åœ¨æœ¬ PR ä¸­è¿›è¡Œã€‚

---

## ğŸ“‹ Checklist

- [x] ä»£ç ç¬¦åˆé¡¹ç›®ç¼–ç è§„èŒƒ (`sage-dev quality` é€šè¿‡)
- [x] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ (55 ä¸ª)
- [x] æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ (87 ä¸ª)
- [x] æ‰€æœ‰ CLI æµ‹è¯•é€šè¿‡ (23 ä¸ª)
- [x] ç±»å‹æ³¨è§£å®Œæ•´ (Mypy æ£€æŸ¥é€šè¿‡)
- [x] æ–‡æ¡£å­—ç¬¦ä¸²å®Œæ•´ (æ‰€æœ‰å…¬å¼€ API)
- [x] å‘åå…¼å®¹æ€§éªŒè¯é€šè¿‡
- [x] å¼€å‘æ–‡æ¡£å·²æ›´æ–° (`DEVELOPMENT_SUMMARY.md`)

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä»»åŠ¡ä¹¦](./task-spec.md)
- [å¼€å‘å·¥ä½œæ€»ç»“](./DEVELOPMENT_SUMMARY.md)
- [SAGE æ¶æ„æ–‡æ¡£](../../../docs-public/docs_src/dev-notes/package-architecture.md)
- [copilot-instructions.md (LLM & Embedding ç« èŠ‚)](../../../../.github/copilot-instructions.md)

---

## ğŸ‘¥ å®¡é˜…è€…

- [ ] @team-lead - æ¶æ„å®¡é˜…
- [ ] @backend-dev - ä»£ç å®¡é˜…
- [ ] @qa-team - æµ‹è¯•è¦†ç›–å®¡é˜…

---

*PR åˆ›å»ºæ—¥æœŸ: 2025å¹´11æœˆ27æ—¥*
