# SAGE Studio æœ¬åœ°æ¨ç†ä½¿ç”¨å¿«é€ŸæŒ‡å—

## é—®é¢˜è§£ç­”

### 1. åº”è¯¥ä½¿ç”¨ä»€ä¹ˆï¼Ÿ
**ç­”ï¼šä½¿ç”¨ vLLM Server**
- `sage-llm` æ˜¯ SAGE çš„å°è£…ï¼Œåº•å±‚è¿˜æ˜¯ vLLM
- æˆ‘ä»¬éœ€è¦å¯åŠ¨çš„æ˜¯ **vLLM OpenAI-compatible Server**

### 2. ç«¯å£é…ç½®

**é‡è¦ï¼šé¿å…ç«¯å£å†²çªï¼**

| æœåŠ¡ | é»˜è®¤ç«¯å£ | æ¨èç«¯å£ | è¯´æ˜ |
|------|---------|---------|------|
| Gateway | 8000 | 8000 | ä¿æŒä¸å˜ |
| vLLM | 8000 | **8001** | **é¿å…å†²çª** |
| Studio Frontend | 4200 | 4200 | ä¿æŒä¸å˜ |
| Studio Backend | 8080 | 8080 | ä¿æŒä¸å˜ |

**æ£€æµ‹ä¼˜å…ˆçº§ï¼š**
- ä»£ç ä¼šå…ˆæ£€æµ‹ `8001` ç«¯å£ï¼ˆæ¨èï¼‰
- ç„¶åæ£€æµ‹ `8000` ç«¯å£ï¼ˆå¤‡é€‰ï¼‰

### 3. å¯åŠ¨æœ¬åœ° vLLM æœåŠ¡

#### æ–¹å¼ 1: ä½¿ç”¨ SAGE CLIï¼ˆæ¨èï¼‰

```bash
# å¯åŠ¨ vLLM æœåŠ¡ï¼ˆæ³¨æ„ä½¿ç”¨ 8001 ç«¯å£ï¼‰
sage llm run Qwen/Qwen2.5-7B-Instruct --port 8001

# æˆ–è€…ä½¿ç”¨å…¶ä»–æ¨¡å‹
sage llm run Qwen/Qwen2.5-1.5B-Instruct --port 8001  # ä½æ˜¾å­˜ç‰ˆæœ¬
```

#### æ–¹å¼ 2: ä½¿ç”¨å¾®è°ƒå·¥å…·

```bash
# å¯åŠ¨å¾®è°ƒåçš„æ¨¡å‹
sage finetune serve <model-name> --port 8001
```

#### æ–¹å¼ 3: ç›´æ¥ä½¿ç”¨ vLLM

```bash
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-7B-Instruct \
    --port 8001 \
    --gpu-memory-utilization 0.9
```

### 4. ä½¿ç”¨æµç¨‹

#### åœºæ™¯ A: å®Œå…¨è‡ªåŠ¨ï¼ˆæ¨èï¼‰

```bash
# 1. å¯åŠ¨æœ¬åœ° vLLMï¼ˆåœ¨ä¸€ä¸ªç»ˆç«¯ï¼‰
sage llm run Qwen/Qwen2.5-7B-Instruct --port 8001

# 2. å¯åŠ¨ Studioï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼‰
sage studio start

# 3. æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® Chat é¡µé¢
# ç»“æœï¼šè‡ªåŠ¨æ£€æµ‹åˆ°æœ¬åœ° vLLMï¼Œä½¿ç”¨æœ¬åœ°æœåŠ¡ âœ…
```

#### åœºæ™¯ B: ä»…ä½¿ç”¨äº‘ç«¯ API

```bash
# 1. ä¸å¯åŠ¨æœ¬åœ° vLLM

# 2. å¯åŠ¨ Studio
sage studio start

# 3. æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® Chat é¡µé¢
# ç»“æœï¼šæ£€æµ‹ä¸åˆ°æœ¬åœ°æœåŠ¡ï¼Œè‡ªåŠ¨é™çº§åˆ°äº‘ç«¯ API â˜ï¸
```

#### åœºæ™¯ C: å¼ºåˆ¶ä½¿ç”¨äº‘ç«¯ï¼ˆå³ä½¿æœ‰æœ¬åœ°æœåŠ¡ï¼‰

```bash
# .env æ–‡ä»¶ä¸­æ·»åŠ 
SAGE_FORCE_CLOUD_API=true

# å¯åŠ¨ Studio
sage studio start

# ç»“æœï¼šè·³è¿‡æœ¬åœ°æ£€æµ‹ï¼Œç›´æ¥ä½¿ç”¨äº‘ç«¯ API
```

### 5. æŸ¥çœ‹æ—¥å¿—

#### Gateway æ—¥å¿—
```bash
tail -f ~/.sage/studio/chat/gateway.log

# æŸ¥çœ‹ä½¿ç”¨çš„æ˜¯å“ªä¸ªæœåŠ¡ï¼š
# âœ… Using local vLLM: Qwen/Qwen2.5-7B-Instruct @ http://localhost:8001/v1
# æˆ–
# â˜ï¸  Using cloud API: qwen-turbo-2025-02-11 @ https://dashscope.aliyuncs.com/...
```

#### vLLM æ—¥å¿—
```bash
# å¦‚æœä½¿ç”¨ sage llm runï¼Œæ—¥å¿—ä¼šæ˜¾ç¤ºåœ¨ç»ˆç«¯
# æˆ–æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
tail -f ~/.sage/llm_8001.log
```

### 6. æ£€æŸ¥æœåŠ¡çŠ¶æ€

```bash
# æ£€æŸ¥ vLLM æ˜¯å¦è¿è¡Œ
curl http://localhost:8001/health

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
curl http://localhost:8001/v1/models

# æµ‹è¯•ç”Ÿæˆ
curl http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "max_tokens": 50
  }'
```

### 7. å¸¸è§é—®é¢˜

#### Q: ç«¯å£ 8001 è¢«å ç”¨æ€ä¹ˆåŠï¼Ÿ
```bash
# ä½¿ç”¨å…¶ä»–ç«¯å£
sage llm run Qwen/Qwen2.5-7B-Instruct --port 8002

# æ³¨æ„ï¼šéœ€è¦ä¿®æ”¹ä»£ç ä¸­çš„æ£€æµ‹ç«¯å£åˆ—è¡¨
```

#### Q: GPU æ˜¾å­˜ä¸è¶³ï¼Ÿ
```bash
# ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
sage llm run Qwen/Qwen2.5-1.5B-Instruct --port 8001

# æˆ–é™ä½ GPU æ˜¾å­˜å ç”¨
sage llm run Qwen/Qwen2.5-7B-Instruct --port 8001 --gpu-util 0.7
```

#### Q: å¦‚ä½•åœæ­¢æœ¬åœ° vLLMï¼Ÿ
```bash
# å¦‚æœåœ¨å‰å°è¿è¡Œï¼Œç›´æ¥ Ctrl+C

# å¦‚æœåå°è¿è¡Œ
sage llm stop --port 8001
```

### 8. æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | æœ¬åœ° vLLM (RTX 3090) | äº‘ç«¯ API (DashScope) |
|------|---------------------|---------------------|
| é¦– Token å»¶è¿Ÿ | ~100ms | ~500ms |
| ç”Ÿæˆé€Ÿåº¦ | ~50 tokens/s | ~30 tokens/s |
| æˆæœ¬ | å…è´¹ï¼ˆç”µè´¹ï¼‰ | æŒ‰é‡æ”¶è´¹ |
| éšç§ | âœ… å®Œå…¨æœ¬åœ° | âš ï¸ æ•°æ®ä¸Šä¼  |
| ç½‘ç»œä¾èµ– | âŒ ä¸éœ€è¦ | âœ… éœ€è¦ç¨³å®šç½‘ç»œ |

## æœªæ¥åŠŸèƒ½ï¼šStudio ä¸€é”®å¯åŠ¨

æˆ‘å·²ç»åˆ›å»ºäº†è®¾è®¡æ–‡æ¡£ï¼š`docs/dev-notes/l6-interfaces/studio/LOCAL_INFERENCE_ENGINE.md`

**è®¡åˆ’åŠŸèƒ½ï¼š**
1. âœ… Studio é¡¶éƒ¨æ˜¾ç¤ºæœ¬åœ°å¼•æ“çŠ¶æ€
2. ğŸ”˜ ä¸€é”®å¯åŠ¨/åœæ­¢æœ¬åœ° vLLM
3. ğŸ›ï¸ Chat é¡µé¢é€‰æ‹© LLM æºï¼ˆæœ¬åœ°/äº‘ç«¯/è‡ªåŠ¨ï¼‰
4. ğŸ“Š å®æ—¶ GPU ç›‘æ§
5. ğŸ“¦ æ¨¡å‹ç®¡ç†ï¼ˆä¸‹è½½ã€åˆ‡æ¢ï¼‰

**å®ç°ä¼˜å…ˆçº§ï¼š**
- Phase 1 (1-2å¤©): çŠ¶æ€æ˜¾ç¤º + å¯åŠ¨/åœæ­¢
- Phase 2 (2-3å¤©): LLM æºé€‰æ‹© + GPU ç›‘æ§
- Phase 3 (3-5å¤©): æ¨¡å‹ç®¡ç† + æ€§èƒ½è°ƒä¼˜

**éœ€è¦çš„æŠ€æœ¯ï¼š**
- åç«¯ï¼šFastAPI ç«¯ç‚¹ç®¡ç† vLLM è¿›ç¨‹
- å‰ç«¯ï¼šAnt Design ç»„ä»¶ï¼ˆButton, Select, Statisticï¼‰
- è¿›ç¨‹ç®¡ç†ï¼šsubprocess + PID æ–‡ä»¶
- çŠ¶æ€æ£€æµ‹ï¼šHTTP health check + psutil

æƒ³è¦æˆ‘å¼€å§‹å®ç°å—ï¼Ÿæˆ‘å¯ä»¥å…ˆå®ç° Phase 1 çš„åŸºç¡€åŠŸèƒ½ã€‚
