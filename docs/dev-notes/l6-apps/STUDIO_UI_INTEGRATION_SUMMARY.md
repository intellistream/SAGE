# ✅ Studio 微调模型 - Web UI 完整集成

## 🎉 好消息：Studio UI 已完全支持微调模型操作！

你**可以完全在 Web UI 中操作**微调模型，无需使用命令行！

## 🖥️ 在 Web UI 中可以做什么？

### ✅ 已实现的功能

#### 1. **创建微调任务**
- 📋 可视化表单配置
- 📤 拖拽上传数据集
- ⚙️ 参数自动推荐（基于 GPU）
- 🚀 一键创建并开始训练

#### 2. **监控训练进度**
- 📊 实时进度条
- 📈 当前 epoch 和 loss
- 📝 实时日志查看器
- 🔄 自动刷新（每 3 秒）

#### 3. **模型热切换** 🔥 核心功能
- 🎯 下拉框选择模型
- 🔄 自动重启 LLM 服务
- ⚡ 秒级切换，无需重启 Studio
- ✅ 立即生效，直接对话

#### 4. **任务管理**
- 📋 查看所有任务
- 🔍 查看详细配置
- 📊 查看训练指标
- 🗑️ 取消排队任务

#### 5. **模型列表**
- 👀 查看所有可用模型
- 🏷️ 区分基础模型和微调模型
- 📍 显示模型路径
- 🎨 标签可视化

## 🎯 完整操作流程（Web UI）

### 从微调到使用，只需 5 步：

```
1. 启动 Studio
   sage studio start

2. 创建微调任务
   Finetune 面板 > 上传数据集 > 配置参数 > 创建

3. 等待完成
   查看进度条，状态变为 ✅ 完成

4. 热切换模型
   下拉框选择微调模型 > 自动重启 LLM 服务

5. 开始对话
   切换到 Chat 标签 > 输入消息 > 享受！
```

**全程在浏览器中操作，无需命令行！**

## 🆕 最新增强（刚刚实现）

### 1. **真正的热切换**

**之前**：切换模型只更新环境变量，需重启 Studio

**现在**：
```python
# 后端自动执行
1. 停止当前 LLM 服务
2. 启动新模型的 LLM 服务  
3. Gateway 自动检测新服务
4. 立即可用！
```

**用户体验**：
- ✅ 切换后显示："模型已切换并生效 - LLM 服务已自动重启"
- ⏱️ 切换时间：< 30 秒（含模型加载）
- 💬 无需任何额外操作，直接去 Chat 对话

### 2. **智能提示**

切换模型后会显示：

| 提示 | 含义 |
|------|------|
| ✅ **"模型已切换并生效"** | LLM 服务重启成功，立即可用 |
| ⚠️ **"模型已切换（需重启生效）"** | LLM 服务未运行，需重启 Studio |
| ❌ **"切换模型失败"** | 出现错误，检查日志 |

## 📍 UI 位置导航

### Finetune 面板布局

```
顶部导航栏
├── Canvas（流程编排）
├── Chat（对话界面）
└── ▶️ Finetune（微调面板）◀️ 在这里！

Finetune 面板内容
├── 📌 当前使用的模型
│   └── [下拉框] ◀️ 在这里切换模型！
├── ➕ 创建微调任务
│   ├── 基础模型选择
│   ├── 数据集上传
│   └── 参数配置
└── 📋 微调任务列表
    └── [切换为对话后端] ◀️ 快速切换按钮
```

## 🎨 Web UI vs CLI 对比

| 操作 | Web UI | CLI | 推荐 |
|------|--------|-----|------|
| 创建任务 | ✅ 表单配置 | ✅ 命令参数 | **Web UI** |
| 监控进度 | ✅ 实时图表 | ❌ 查看日志 | **Web UI** |
| 切换模型 | ✅ 下拉 + 热切换 | ✅ 重启命令 | **Web UI** |
| 查看日志 | ✅ 内置查看 | ✅ 文件查看 | **Web UI** |
| 批量操作 | ❌ 逐个操作 | ✅ 脚本 | **CLI** |
| 易用性 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | **Web UI** |

**结论**：日常使用 **强烈推荐 Web UI**！

## 🚀 两种使用方式示例

### 方式 1: 纯 Web UI（推荐）

```bash
# 只需一条命令启动
sage studio start

# 然后在浏览器中：
# 1. Finetune > 创建任务 > 上传数据 > 配置 > 创建
# 2. 等待训练完成（看进度条）
# 3. 下拉框选择微调模型（自动热切换）
# 4. Chat > 开始对话
```

**优势**：
- 全程可视化
- 实时反馈
- 热切换秒生效
- 适合新手

### 方式 2: CLI + Web UI（高级）

```bash
# 用 CLI 快速创建任务
sage finetune start --task code --model Qwen/Qwen2.5-Coder-1.5B

# 启动 Studio
sage studio start

# 在浏览器中：
# 1. Finetune > 查看进度
# 2. 完成后切换模型
# 3. Chat > 对话
```

**优势**：
- CLI 批量处理
- UI 监控和使用
- 灵活组合

## 💡 最佳实践

### ✅ 推荐做法

1. **首次使用**：在 Web UI 中完成整个流程，熟悉操作
2. **日常使用**：用 Web UI 创建、监控、切换
3. **批量任务**：用 CLI 脚本创建多个任务
4. **监控训练**：始终用 Web UI 查看实时进度
5. **切换模型**：优先用 Web UI 下拉框（热切换）

### ❌ 不推荐做法

1. ~~创建任务后关闭浏览器~~ - 进度会丢失（建议保持打开）
2. ~~手动修改配置文件~~ - 用 UI 操作更安全
3. ~~重启 Studio 来切换模型~~ - 直接用热切换更快
4. ~~在训练时关闭 Studio~~ - 任务会继续，但无法监控

## 🔧 技术细节

### 热切换实现流程

```python
# 用户在 UI 点击下拉框选择模型
↓
# 前端发送请求
POST /api/finetune/switch-model?model_path=xxx
↓
# 后端处理
1. finetune_manager.switch_model(model_path)  # 更新环境变量
2. chat_manager._stop_llm_service()            # 停止当前服务
3. chat_manager._start_llm_service(model)      # 启动新服务
↓
# 返回结果
{
  "message": "Model switched and LLM service restarted successfully",
  "current_model": "xxx",
  "llm_service_restarted": true  ← 关键标志
}
↓
# 前端显示提示
✅ "模型已切换并生效 - LLM 服务已自动重启"
```

### 自动检测机制

Gateway 的 `IntelligentLLMClient` 会自动检测：

```python
检测顺序：
1. localhost:8001 (本地 LLM) ← 微调模型运行在这里
2. localhost:8000 (备用端口)
3. 云端 API (DashScope)
```

所以切换模型后，Gateway 会自动使用新启动的 LLM 服务！

## 📚 相关文档

- [详细集成文档](./STUDIO_FINETUNE_INTEGRATION.md) - 完整技术细节
- [快速参考卡](./STUDIO_UI_QUICK_REFERENCE.md) - 常用操作速查
- [微调最佳实践](../../cross-layer/best-practices/FINETUNING.md) - 参数优化建议

## 🎯 总结

### 是的，完全可以在 Studio UI 中操作！

**核心优势**：
1. ✅ **全可视化** - 无需记命令
2. ✅ **实时反馈** - 进度一目了然  
3. ✅ **热切换** - 秒级生效
4. ✅ **易用性** - 适合所有用户

**使用建议**：
- 🎨 **日常使用**：Web UI（推荐）
- 🔧 **批量处理**：CLI + Web UI
- 🚀 **快速测试**：CLI 直接启动

**一句话总结**：
> 在 Studio UI 中微调和使用模型，就像使用 ChatGPT 一样简单！从微调到对话，全程点击操作，无需命令行！🎉

---

**现在就试试吧！**

```bash
sage studio start
# 打开浏览器 > Finetune > 开始微调！
```
