# SAGE Copilot Instructions

## Overview

**SAGE** is a Python 3.10+ framework for building AI/LLM data processing pipelines with declarative
dataflow. 11 functional packages + 1 meta-package, ~400MB dev install, uses C++ extensions (CMake).

## ğŸš¨ CRITICAL Architectural Constraints

### âŒ NEVER BYPASS CONTROL PLANE - ABSOLUTE RULE

**ALL LLM engine operations MUST go through Control Plane. Direct engine startup is FORBIDDEN.**

This is a **non-negotiable architectural constraint**. Violating this breaks resource management, scheduling, and monitoring.

#### âŒ FORBIDDEN Operations:

```bash
sage llm serve -m <model>              # âŒ Command removed
python -m vllm.entrypoints.openai      # âŒ Direct vLLM
requests.post("http://localhost:8001/v1/...")  # âŒ Direct endpoint
```

```python
from vllm import LLM  # âŒ Direct import
engine = LLM(model="...")  # âŒ Direct instantiation
```

#### âœ… CORRECT Operations:

```bash
sage llm engine start <model> --engine-kind llm    # âœ… Control Plane
sage llm engine list                               # âœ… Managed
sage llm engine stop <id>                          # âœ… Controlled
```

```python
from sage.llm import UnifiedInferenceClient
client = UnifiedInferenceClient.create()  # âœ… Auto-routes through Control Plane
response = client.chat([{"role": "user", "content": "Hello"}])
```

**Why**: Resource management, load balancing, fault tolerance, monitoring, SLO-aware scheduling.

**Enforcement**: Pre-commit hooks, CI/CD checks, code review. Commands `sage llm serve/run/stop/restart/status/logs` have been completely deleted.

## CRITICAL Coding Principles

### âŒ NEVER MANUAL PIP INSTALL - ALWAYS USE pyproject.toml
**ALL dependencies MUST be declared in pyproject.toml. NEVER use manual `pip install` commands.**

This is a **project-wide principle** to ensure reproducibility and consistency.

#### âŒ FORBIDDEN Operations:

```bash
pip install transformers              # âŒ Manual install
pip install torch==2.7.0              # âŒ Manual version
pip install vllm                      # âŒ Manual dependency
```

#### âœ… CORRECT Operations:

```toml
# In packages/*/pyproject.toml
dependencies = [
    "transformers>=4.52.0,<4.54.0",  # âœ… Declared in pyproject.toml
    "torch>=2.7.0,<3.0.0",           # âœ… Version constraints
    "vllm>=0.9.2,<0.10",             # âœ… Optional dependencies
]
```

```bash
# Then reinstall packages
pip install -e packages/sage-middleware -e packages/sage-apps -e packages/sage-libs
```

**Why**: Ensures reproducibility, tracks dependency changes in git, prevents version conflicts, maintains single source of truth.

**Enforcement**: Code review, CI/CD checks. Any manual pip install should trigger immediate refactoring to pyproject.toml.

### âŒ NO FALLBACK LOGIC - PROJECT-WIDE RULE
**NEVER use try-except fallback patterns anywhere in the codebase.**

This is a **project-wide principle**, not just for version management. Fallbacks hide problems and make debugging harder.

#### âŒ BAD Examples (Do NOT do this):

```python
# Version imports
try:
    from ._version import __version__
except ImportError:
    __version__ = "unknown"  # âŒ NO - hides missing file

# Configuration loading
try:
    config = load_config("config.yaml")
except FileNotFoundError:
    config = {}  # âŒ NO - hides missing config

# Environment variables
api_key = os.getenv("API_KEY") or "default_key"  # âŒ NO - hides missing var
```

#### âœ… GOOD Examples (Do this instead):

```python
# Let exceptions propagate with clear error messages
config = load_config("config.yaml")  # FileNotFoundError if missing
api_key = os.environ["API_KEY"]  # KeyError if missing

# Or provide helpful error messages
if not os.path.exists("config.yaml"):
    raise FileNotFoundError(
        "config.yaml not found. Please create it from config.yaml.template"
    )
```

#### When Fallbacks ARE Acceptable (Rare):

1. **Feature detection**: `HAS_CUDA = torch.cuda.is_available()`
2. **Explicit optional behavior**: `use_gpu = config.get("use_gpu", False)`  
3. **Graceful degradation with logging**: Log warning and use alternative

**Rationale**: Fail fast, fail loud. Silent fallbacks hide bugs, make debugging harder, and are unacceptable in production.

### Version Management

Each package manages its own version independently via `_version.py`:
```python
"""Version information for <package-name>."""
__version__ = "0.2.0"
__author__ = "IntelliStream Team"
__email__ = "shuhao_zhang@hust.edu.cn"
```

**Architecture (L1-L6)** - CRITICAL: No upward dependencies

```
L6: sage-cli, sage-studio, sage-tools, sage-llm-gateway, sage-edge  # Interfaces & gateways
L5: sage-apps, sage-benchmark          # Apps & Benchmarks  
L4: sage-middleware                    # Operators (C++ extensions)
L3: sage-kernel, sage-libs             # Core & Algorithms
L2: sage-platform                      # Platform Services
L1: sage-common, sage-llm-core         # Foundation & LLM control plane/client
```

Notes:
- `sage-llm-gateway` is published to PyPI as `isage-llm-gateway` (OpenAI/Anthropic-compatible API Gateway).
- `sage-llm-core` is published to PyPI as `isage-llm-core` (Unified client + control plane).
- `sage-edge` is an opt-in aggregator shell that can mount the LLM gateway; behavior is unchanged unless it is explicitly started.
- Legacy `sage-gateway` has been superseded; do not add new code under that namespace.

All in `/packages/<name>/`. L6 imports L1-L5, L5 imports L1-L4, etc.

## How Copilot Should Learn SAGE (Readme-First)

When answering questions or making code changes in this repo, the assistant **must first rely on the project docs/READMEs instead of guessing**.

**Before doing any non-trivial work, Copilot should at least skim:**

- Root overview: `README.md` (features, quick start)  
- Dev workflow: `DEVELOPER.md`, `CONTRIBUTING.md`  
- Architecture: `docs-public/docs_src/dev-notes/package-architecture.md`  
- Cross-layer index: `docs-public/docs_src/dev-notes/cross-layer/README.md`

**When working on a specific layer/package, Copilot should additionally read:**

- The corresponding dev-notes README, e.g.  
  - `docs-public/docs_src/dev-notes/l1-common/README.md`  
  - `docs-public/docs_src/dev-notes/l2-platform/README.md`  
  - `docs-public/docs_src/dev-notes/l3-kernel/README.md` / `l3-libs/README.md`  
  - `docs-public/docs_src/dev-notes/l4-middleware/README.md`  
  - `docs-public/docs_src/dev-notes/l5-apps/README.md`, `l5-benchmark/README.md`  
  - `docs-public/docs_src/dev-notes/l6-cli/README.md`, `l6-studio/README.md`, `l6-gateway/README.md`

**ğŸ” When encountering difficulties or uncertainties:**

- **ALWAYS read relevant documentation in `docs-public/` first** before making assumptions
- Look for topic-specific guides in `docs-public/docs_src/dev-notes/cross-layer/` (e.g., `documentation-policy.md`, `ci-cd.md`)
- Check package-specific docs in `packages/<package-name>/README.md` or `packages/<package-name>/docs/`
- If the issue involves installation, testing, or CI/CD, consult `DEVELOPER.md` or `CONTRIBUTING.md`
- Use `grep_search` or `semantic_search` to find relevant documentation before implementing solutions

**Rule:** Don't guess architectural decisions or policies. Read the docs. They exist for this reason.

Only after consulting these READMEs should the assistant propose designs, refactors, or architectural explanations. If documentation and code appear inconsistent, Copilot should **call it out explicitly** in the answer and, when in doubt, ask the user which source of truth to follow.

## Documentation Location Policy - CRITICAL

**The root `docs/` directory is STRICTLY FORBIDDEN for committed documentation.**

### âŒ NEVER Create Files in Root `docs/`

- Root `docs/` is gitignored and must not contain committed files
- Pre-commit hooks will REJECT any commits with files in root `docs/`
- This directory should not exist in the repository
- âœ… **Exception:** Package and submodule `docs/` directories ARE ALLOWED

### âœ… CORRECT Documentation Locations

**All documentation must go to these approved locations:**

1. **User-facing docs:** `docs-public/docs_src/` (guides, tutorials, concepts)
2. **Developer notes:** `docs-public/docs_src/dev-notes/<layer>/` (architecture, design)
3. **Package docs:** `packages/<package-name>/README.md` or `packages/<package-name>/docs/`
4. **Submodule docs:** `packages/.../submodule/docs/` (sageLLM, sageFlow, sageTSDB, etc.)
5. **Tool docs:** `tools/<tool-name>/README.md` or `tools/<tool-name>/docs/`
6. **Examples:** `examples/<name>/README.md`
7. **Root files:** Only `README.md`, `CONTRIBUTING.md`, `DEVELOPER.md`, `LICENSE`, `CHANGELOG.md`

**Rationale:**
- Prevents confusion between root `docs/` and `docs-public/`
- Maintains single source of truth for project-level documentation
- Allows packages, submodules, and tools to maintain their own documentation
- Submodules are independent Git repositories with their own version control
- Tools are independent components that may have complex documentation needs
- Avoids accidental gitignore of important documentation

**Enforcement:**
- Hook `markdown-files-location-check`: Rejects any `.md` files in root `docs/` ONLY
- Hook `root-directory-cleanup-check`: Flags root `docs/` directory as unauthorized
- Package/submodule `docs/` directories are explicitly allowed and encouraged

**See:** `docs-public/docs_src/dev-notes/cross-layer/documentation-policy.md` for full policy.

## Inference Components Map (Reality-First)

SAGE is an inference pipeline system, not just an LLM server. When writing docs, abstracts, design notes, or code changes, prefer describing/using these existing modules (and their correct layer placement) instead of inventing new components.

Canonical namespaces (post-refactor):
- Gateway: `sage.llm.gateway.*` (package: `sage-llm-gateway`)
- Control plane + unified client: `sage.llm.*` (package: `sage-llm-core`)
- Optional edge aggregator: `sage.edge.*` (package: `sage-edge`)
- Avoid legacy `sage.gateway.*` imports; they have been superseded.

**Gateway (L6, OpenAI/Anthropic-compatible + control plane + sessions)**

- Entry point: `packages/sage-llm-gateway/src/sage/llm/gateway/server.py`
- Control plane management API: `packages/sage-llm-gateway/src/sage/llm/gateway/routes/engine_control_plane.py`
- Studio backend routes (merged into gateway): `packages/sage-llm-gateway/src/sage/llm/gateway/routes/studio.py`
- OpenAI adapter (runs persistent RAG pipeline, can trigger agentic operators):
  `packages/sage-llm-gateway/src/sage/llm/gateway/adapters/openai.py`
- Pipeline-as-a-service for RAG: `packages/sage-llm-gateway/src/sage/llm/gateway/rag_pipeline.py`
- Session + memory backends (short-term + NeuroMem VDB/KV/Graph):
  `packages/sage-llm-gateway/src/sage/llm/gateway/session/manager.py`
- Edge aggregator (optional shell mounting the gateway, keeps /v1/* intact by default):
  `packages/sage-edge/src/sage/edge/app.py`

**Control Plane + Unified Client (L1, sageLLM integration)**

- Unified LLM+Embedding client (must use factory):
  `packages/sage-llm-core/src/sage/llm/unified_client.py`
- Control plane implementation lives under:
  `packages/sage-llm-core/src/sage/llm/control_plane/`
  (tests: `.../control_plane/tests/`)

**Middleware inference building blocks (L4, including C++ extensions)**

- Vector DB core (C++20, self-developed, pluggable ANNS, multimodal fusion):
  `packages/sage-middleware/src/sage/middleware/components/sage_db/sageDB/README.md`
  - **SageDB VDB Backend**: Self-developed high-performance C++ vector database
  - **NOT FAISS-based**: Fully custom implementation
  - **ANNS Algorithms**: Migrated to `sage-libs/anns/` (faiss_HNSW, vsag_hnsw, diskann, etc.)
  - Python API: `sage.middleware.components.sage_db.python.sage_db.SageDB`
  - Supports: similarity search, metadata filtering, hybrid search, batch operations
  - NeuroMem integration: `sage_mem/neuromem/search_engine/vdb_index/sagedb_index.py`
  - Available backends in NeuroMem: FAISS (Python wrapper), SageDB (C++ self-developed)
  - Configuration: Set `backend_type="SageDB"` in VDB index config to use C++ backend
- Vector-native stream processing engine for incremental semantic state snapshots (C++):
  `packages/sage-middleware/src/sage/middleware/components/sage_flow/sageFlow/README.md`
- Memory system (NeuromMem: store/recall; VDB/KV/Graph; services wrapper):
  `packages/sage-middleware/src/sage/middleware/components/sage_mem/neuromem/README.md`
- Context compression for RAG (LongRefiner/REFORM/Provence adapters):
  `packages/sage-middleware/src/sage/middleware/components/sage_refiner/sageRefiner/README.md`
- Time-series DB + window ops/join + out-of-order handling (C++ + pybind11):
  `packages/sage-middleware/src/sage/middleware/components/sage_tsdb/sageTSDB/README.md`

**Benchmarks (L5)**

- Control plane scheduling benchmark (throughput/TTFT/TBT/p99/SLO):
  `packages/sage-benchmark/src/sage/benchmark/benchmark_control_plane/README.md`
- Agent benchmarks (tool selection / planning / timing):
  `packages/sage-benchmark/src/sage/benchmark/benchmark_agent/README.md`

**Kernel + Libs (L3)**

- Dataflow runtime, distributed execution, fault tolerance: `packages/sage-kernel/`
- Algorithms, RAG tools, agent framework/integrations: `packages/sage-libs/`
  - **ANN Interface**: `sage.libs.ann` - Unified ANN algorithm interface
    - Base classes: `AnnIndex`, `AnnIndexMeta` (in `sage.libs.ann.base`)
    - Factory: `create()`, `register()`, `registered()` (in `sage.libs.ann.factory`)
    - Implementations: `sage.libs.anns/` (faiss_HNSW, vsag_hnsw, diskann, candy_*, cufe, gti, puck, etc.)
    - Reusable by: benchmark_anns, SageDB, SageFlow

**Rule of thumb**: if you mention a capability (retrieval, memory, refinement, vector DB, streaming semantic state, scheduling), ensure it maps to a real module/path above.

## Installation

**Prerequisites**: Python 3.10+, Git, build-essential, cmake, pkg-config, libopenblas-dev,
liblapack-dev

**Commands** (10-25 min install):

```bash
./quickstart.sh --dev --yes        # Development (REQUIRED for dev)
./quickstart.sh --core --yes       # Minimal production
./quickstart.sh --standard --yes   # Standard with CLI
./quickstart.sh --full --yes       # Full with examples
```

Options: `--pip` (current env), `--conda` (create env), `--sync-submodules` / `--no-sync-submodules`

**Submodules** - CRITICAL: NEVER use `git submodule update --init`

```bash
./manage.sh                        # Bootstrap submodules + hooks
./tools/maintenance/sage-maintenance.sh submodule init    # Initialize
./tools/maintenance/sage-maintenance.sh submodule switch  # Fix detached HEAD
```

C++ extension submodules in `packages/sage-middleware/src/sage/middleware/components/`

**Environment**: Copy `.env.template` to `.env`, set `OPENAI_API_KEY`, `HF_TOKEN`

**Pre-commit Hooks**: `./quickstart.sh --dev` automatically installs pre-commit hooks. If missing, run:
```bash
pip install pre-commit
pre-commit install  # Install Git hooks
```

## Conda ToS Bypass - Unified Utils

**CRITICAL**: All Conda operations MUST use unified utils in `tools/lib/conda_install_utils.sh` to bypass Conda 25.x ToS restrictions.

**Core Functions**:
```bash
# Load utils (auto-loaded in most install scripts)
source "$SAGE_ROOT/tools/lib/conda_install_utils.sh"

# Install packages (auto-uses Tsinghua mirrors + --override-channels)
conda_install_bypass nodejs python=3.11 numpy

# Create environment
conda_create_bypass myenv python=3.11

# Install with progress indicator
conda_install_with_progress "å®‰è£… Node.js" nodejs

# Get mirror URL
mirror=$(get_conda_mirror "main")    # or "forge"
```

**Never use direct conda commands** without `--override-channels`:
```bash
# âŒ WRONG - will trigger ToS error
conda install -y nodejs
conda create -n myenv python=3.11 -y

# âœ… CORRECT - use unified utils
conda_install_bypass nodejs
conda_create_bypass myenv python=3.11
```

**Implementation**:
- Mirror: `https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main`
- Forge: `https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge`
- Auto-fallback: main â†’ forge if package not found
- All install scripts pre-load these utils

## Progress Display - Unified Utils

**All long-running tasks MUST use progress indicators** from `tools/lib/progress_utils.sh`:

```bash
# Load utils
source "$SAGE_ROOT/tools/lib/progress_utils.sh"

# 1. Spinner (recommended for unknown duration)
long_command &
show_spinner $! "æ­£åœ¨æ‰§è¡Œä»»åŠ¡..."

# 2. Progress bar (known steps)
print_progress 50 100 "ä¸‹è½½ä¸­..."

# 3. Long task with keepalive (30s intervals)
long_task_with_keepalive "å®‰è£…ç³»ç»Ÿä¾èµ–" 30 sudo apt-get install -y build-essential

# 4. Simplified wrapper (most common)
run_with_progress "å®‰è£… Node.js" conda install -y nodejs

# 5. Installation steps
show_installation_progress 2 5 "å®‰è£…æ ¸å¿ƒä¾èµ–"
```

**Why**: Prevents users thinking installation is frozen during long tasks (apt-get, conda install, C++ builds).

## Build, Test, Lint

**Build**: Happens during install. C++ extensions in `.sage/build/`, auto-built with `--dev`.

**Test** (ALWAYS from repo root):

```bash
sage-dev project test --coverage              # All tests
sage-dev project test --quick                 # Quick tests only
sage-dev examples test                        # Examples
pytest packages/sage-kernel/tests/unit/ -v   # Specific package
```

Config: `tools/pytest.ini`, cache: `.sage/cache/pytest/`, env: `SAGE_TEST_MODE=true`

**Lint & Format**:

```bash
sage-dev quality                              # Auto-fix
sage-dev quality --check-only                 # Check only
pre-commit run --all-files --config tools/pre-commit-config.yaml
./tools/install/check_tool_versions.sh        # Check version consistency
./tools/install/check_tool_versions.sh --fix  # Auto-fix version mismatch
```

Tools: Ruff (format+lint, line 100), Mypy (types, warning mode), Shellcheck Config:
`tools/pre-commit-config.yaml`, `tools/ruff.toml`

**Tool Version Consistency** - CRITICAL:
- `ruff` version is pinned in both `tools/pre-commit-config.yaml` (rev) and
  `packages/sage-tools/pyproject.toml` (==x.y.z) to ensure local and CI consistency.
- Run `./tools/install/check_tool_versions.sh` to verify versions match.

**Make shortcuts**: `make help`, `make test`, `make format`, `make clean`, `make docs`

## CI/CD (.github/workflows/)

**Main workflows**: build-test.yml (45m), examples-test.yml (30m), code-quality.yml (10m),
installation-test.yml, publish-pypi.yml, paper1-experiments.yml (GPU, manual)

**CI Installation Standards** - CRITICAL for new workflows:

| åœºæ™¯ | æ¨èå®‰è£…æ–¹å¼ | è¯´æ˜ |
|------|-------------|------|
| GitHub Actions (ubuntu-latest) | `./tools/install/core/ci_install_wrapper.sh --dev --yes` | æ ‡å‡† CIï¼Œå®‰è£…åˆ° `~/.local` |
| GitHub Actions + Conda | `unset CI GITHUB_ACTIONS && ./quickstart.sh --dev --yes --pip` | éœ€å–æ¶ˆ CI å˜é‡ï¼Œå®‰è£…åˆ° conda env |
| Self-hosted GPU runner (ä¸­å›½) | `unset CI GITHUB_ACTIONS && SAGE_FORCE_CHINA_MIRROR=true ./quickstart.sh --dev --yes --pip` | å¼ºåˆ¶ä½¿ç”¨ä¸­å›½é•œåƒ |

**ä¸ºä»€ä¹ˆéœ€è¦ `unset CI GITHUB_ACTIONS`**ï¼š
- `quickstart.sh` åœ¨æ£€æµ‹åˆ° CI ç¯å¢ƒæ—¶ä¼šæ·»åŠ  `--user` å‚æ•°ï¼Œå®‰è£…åˆ° `~/.local`
- å¦‚æœä½¿ç”¨ conda ç¯å¢ƒï¼Œéœ€è¦å–æ¶ˆè¿™äº›å˜é‡è®©åŒ…å®‰è£…åˆ°å½“å‰æ¿€æ´»çš„ç¯å¢ƒ

**`SAGE_FORCE_CHINA_MIRROR=true`**ï¼š
- å¼ºåˆ¶ä½¿ç”¨ä¸­å›½é•œåƒï¼ˆæ¸…å PyPI + hf-mirror.comï¼‰
- é€‚ç”¨äºä½äºä¸­å›½çš„ self-hosted runner
- ä¼šè¦†ç›– CI ç¯å¢ƒçš„é»˜è®¤å®˜æ–¹æºè®¾ç½®

**CI uses**: Ubuntu latest, Python 3.11, GitHub Secrets (OPENAI_API_KEY, HF_TOKEN), pip cache

**Replicate CI locally**:

```bash
./quickstart.sh --dev --yes
sage-dev project test --coverage --jobs 4 --timeout 300
pre-commit run --all-files --config tools/pre-commit-config.yaml
```

**CI debug**: Check job logs â†’ Look for submodule/C++ build issues â†’ Verify API keys â†’ Run locally

## Key Locations

```
.github/workflows/      # CI/CD
docs-public/docs_src/dev-notes/ # Dev docs (by layer: l1-l6, cross-layer)
examples/               # apps/, tutorials/ (by layer)
packages/               # 11 packages + meta
  sage-*/src/sage/      # Source
  sage-*/tests/         # Tests (unit/, integration/)
tools/
  dev.sh                # Helper (â†’ sage-dev)
  maintenance/          # Submodule mgmt
  pytest.ini            # Test config
  pre-commit-config.yaml # Hooks
  ruff.toml             # Linter
.env.template           # API keys template
.pre-commit-config.yaml # â†’ tools/pre-commit-config.yaml
.sage/                  # Build artifacts, cache, logs (gitignored, project-level)
manage.sh               # Submodule wrapper
quickstart.sh           # Installer
Makefile                # Shortcuts
```

## User Paths - XDG Standard

**CRITICAL**: User configuration and data follow [XDG Base Directory Specification](https://specifications.freedesktop.org/basedir-spec/).

```python
from sage.common.config.user_paths import get_user_paths

paths = get_user_paths()
log_file = paths.logs_dir / "app.log"  # ~/.local/state/sage/logs/app.log
model_dir = paths.models_dir           # ~/.local/share/sage/models/
```

**Project Configuration**: Edit `config/config.yaml` and `config/cluster.yaml` directly in project root.

**Directory Structure**:
| Path | Purpose |
|------|---------|
| `config/config.yaml` | Main configuration (LLM, gateway, studio) |
| `config/cluster.yaml` | Cluster configuration (nodes, SSH, Ray) |
| `~/.local/share/sage/` | Persistent data (models, sessions, vector_db) |
| `~/.local/state/sage/` | Runtime state (logs) |
| `~/.cache/sage/` | Cached data (can be deleted) |

**Project-level** `.sage/` (gitignored): Build artifacts, pytest cache, temp files.

**DO NOT** use `~/.sage/` for new code. Use `get_user_paths()` for user data.

## Common Installation Issues

**Install hangs**: Check network, try `--resume` for checkpoint recovery (10-25min normal)
**C++ build fails**: Install deps: `build-essential cmake pkg-config libopenblas-dev liblapack-dev`
**Detached HEAD**: Use `./tools/maintenance/sage-maintenance.sh submodule switch`
**Tests fail CI not local**: Run `sage-dev project test --coverage` from repo root
**Import errors**: Must use `--dev` install, run from repo root
**Pre-commit fails**: Run `sage-dev quality` to auto-fix
**Old artifacts**: `make clean` or `rm -rf .sage/build/ build/ dist/ *.egg-info/`
**Bash exclamation mark**: NEVER use `!` in terminal commands (causes `bash: !': event not found`).
  Use period `.` instead: `print("Done.")` not `print("Done!")`

## Port Configuration - CRITICAL

**ç»Ÿä¸€ç«¯å£é…ç½®**: æ‰€æœ‰ç«¯å£å·å¿…é¡»ä½¿ç”¨ `sage.common.config.ports.SagePorts`ï¼Œç¦æ­¢ç¡¬ç¼–ç ã€‚

```python
from sage.common.config.ports import SagePorts

# âœ… æ­£ç¡®ç”¨æ³•
port = SagePorts.LLM_DEFAULT           # 8001
gateway_port = SagePorts.GATEWAY_DEFAULT  # 8889

# âœ… WSL2 ç¯å¢ƒæ¨èç”¨æ³•
port = SagePorts.get_recommended_llm_port()  # è‡ªåŠ¨æ£€æµ‹ WSL2 å¹¶é€‰æ‹©åˆé€‚ç«¯å£

# âŒ é”™è¯¯ç”¨æ³• - ç¦æ­¢ç¡¬ç¼–ç 
port = 8001  # ä¸è¦è¿™æ ·å†™
```

**ç«¯å£åˆ†é…è¡¨**:
| å¸¸é‡ | ç«¯å£ | ç”¨é€” |
|------|------|------|
| `GATEWAY_DEFAULT` | 8889 | sage-llm-gateway (OpenAI å…¼å®¹ API Gateway) |
| `EDGE_DEFAULT` | 8899 | sage-edge èšåˆå™¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤æŒ‚è½½ gateway ä¿æŒ /v1/*ï¼‰ |
| `LLM_DEFAULT` | 8001 | vLLM æ¨ç†æœåŠ¡ |
| `LLM_WSL_FALLBACK` | 8901 | WSL2 å¤‡ç”¨ LLM ç«¯å£ |
| `STUDIO_BACKEND` | 8889| sage-studio åç«¯ API |
| `STUDIO_FRONTEND` | 5173 | sage-studio å‰ç«¯ (Vite) |
| `EMBEDDING_DEFAULT` | 8090 | Embedding æœåŠ¡ |
| `BENCHMARK_LLM` | 8901 | Benchmark ä¸“ç”¨ LLM ç«¯å£ |

**æ¶æ„**: `User â†’ Edge (8899, å¯é€‰) â†’ Gateway (8889) â†’ LLM (8001)`ï¼ˆEdge é»˜è®¤ç›´é€š Gatewayï¼Œç›´æ¥è®¿é—® Gateway ä¹Ÿæœ‰æ•ˆï¼‰

**WSL2 å·²çŸ¥é—®é¢˜**:
- ç«¯å£ 8001 åœ¨ WSL2 ä¸Šå¯èƒ½å‡ºç°"ç«¯å£ç›‘å¬ä½†è¿æ¥è¢«æ‹’ç»"çš„é—®é¢˜
- ä½¿ç”¨ `SagePorts.get_recommended_llm_port()` è‡ªåŠ¨é€‰æ‹©åˆé€‚ç«¯å£
- æˆ–ç›´æ¥ä½¿ç”¨ `SagePorts.BENCHMARK_LLM` (8901) ä½œä¸ºå¤‡ç”¨

**é…ç½®æ–‡ä»¶ä½ç½®**: `packages/sage-common/src/sage/common/config/ports.py`

## API Client Usage - CRITICAL

**UnifiedInferenceClient must be created via the factory** (direct instantiation is intentionally blocked).

```python
from sage.llm import UnifiedInferenceClient

client = UnifiedInferenceClient.create()
```

If you see code attempting `UnifiedInferenceClient(...)`, treat it as a bug and refactor to `create()`.

## Dependency Management - CRITICAL

**Rule**: All dependency versions MUST be unified across packages to avoid [DEDUP] warnings.

**Single Source of Truth**: `dependencies-spec.yaml` at project root
- Defines unified versions for torch, transformers, fastapi, uvicorn, etc.
- Documents historical conflicts and resolution strategies
- Guides future updates

**Tools**:
- `tools/scripts/check_dependency_consistency.py` - Auto-check version consistency
- `tools/scripts/unify_dependencies.sh` - Batch update tool

**vLLM Dependencies** (é‡é‡çº§å¯é€‰ä¾èµ–):
- `vllm-minimal` - vLLM only (for users with existing torch >= 2.7.0)
- `vllm` - Full install (includes torch >= 2.7.0)
- `torch` - Standalone torch (for other components)

**Smart Installation**:
- Detects existing torch version
- Chooses `vllm-minimal` if torch >= 2.7.0 (reuse existing)
- Chooses `vllm` if torch missing or < 2.7.0 (install/upgrade)

**Conflict Resolution**:
- `environment_doctor.sh` detects conda/pip mixed management
- `fix_mixed_packages()` intelligently resolves version conflicts
- Preserves higher version, removes lower version

**Docs**: `docs-public/docs_src/dev-notes/cross-layer/vllm-dependency-management.md`

## Features

**CPU Node Support**: SAGE fully supports CPU-only compute nodes via JobManager + NodeSelector.
Tasks can specify `cpu_required`, `memory_required`, `gpu_required=0` for CPU-only execution. See
`examples/tutorials/L3-kernel/cpu_node_demo.py` and `docs/dev-notes/l3-kernel/cpu-node-setup.md`.

## Development Workflow

**Setup**: `./quickstart.sh --dev --yes` â†’ `./manage.sh` (if C++ needed)
**During**: Run `sage-dev project test`, `sage-dev quality` frequently
**Before commit**: `sage-dev quality --check-only`, `sage-dev project test --coverage`
**Commits**: `<type>(<scope>): <summary>` (types: feat, fix, refactor, docs, test, ci, etc.)
**PR**: Local CI checks first, update CHANGELOG.md, reference issues

**Critical files** (review before modifying): quickstart.sh, manage.sh, .github/workflows/,
tools/pytest.ini, tools/pre-commit-config.yaml

## PyPI Publishing - CRITICAL: Use sage-dev

**SAGE æœ‰ä¸“ç”¨çš„ PyPI å‘å¸ƒå·¥å…·ï¼Œé€šè¿‡ sage-dev CLI ç®¡ç†ã€‚NEVER æ‰‹åŠ¨ä½¿ç”¨ twine æˆ– buildã€‚**

### Publishing Commands

```bash
# 1. Build and upload to PyPI (production)
sage-dev package pypi build <package-name> --upload --no-dry-run

# 2. Build and upload to TestPyPI (testing)
sage-dev package pypi build <package-name> --upload --no-dry-run --test-pypi

# 3. Dry-run (default, safe mode - check build without uploading)
sage-dev package pypi build <package-name> --upload  # --dry-run is default

# 4. Build only (no upload)
sage-dev package pypi build <package-name>

# 5. Upload pre-built wheel
sage-dev package pypi upload <package-name> --no-dry-run
```

**CRITICAL**: `--dry-run` é»˜è®¤ä¸º `True`ï¼Œå¿…é¡»æ˜¾å¼ä½¿ç”¨ `--no-dry-run` æ‰ä¼šçœŸæ­£ä¸Šä¼ ã€‚

### Package Names

SAGE çš„ PyPI åŒ…åä¸å†…éƒ¨åŒ…åä¸åŒï¼š

| å†…éƒ¨åŒ…å | PyPI åŒ…å | ç”¨é€” |
|---------|----------|------|
| `sage-common` | `isage-common` | L1 Foundation |
| `sage-libs` | `isage-libs` | L3 Algorithms & ANNS |
| `sage-llm-gateway` | `isage-llm-gateway` | L6 OpenAI-compatible Gateway |
| `sage-llm-core` | `isage-llm-core` | L1 LLM control plane + client |

### Pre-publish Checklist

1. **Bump version**: æ›´æ–° `packages/<package>/src/sage/.../version.py`
2. **Update CHANGELOG.md**: è®°å½•æœ¬æ¬¡å‘å¸ƒçš„å˜æ›´
3. **Run tests**: `sage-dev project test --coverage`
4. **Run quality checks**: `sage-dev quality --check-only`
5. **Test build**: `sage-dev package pypi build <package> --dry-run`
6. **Test on TestPyPI**: `sage-dev package pypi build <package> --upload --no-dry-run --test-pypi`
7. **Verify installation**: `pip install -i https://test.pypi.org/simple/ isage-<package>`
8. **Publish to PyPI**: `sage-dev package pypi build <package> --upload --no-dry-run`

### Configuration

PyPI tokens åº”é…ç½®åœ¨ `~/.pypirc`:

```ini
[distutils]
index-servers =
    pypi
    testpypi

[pypi]
username = __token__
password = pypi-xxx

[testpypi]
repository = https://test.pypi.org/legacy/
username = __token__
password = pypi-xxx
```

### Implementation Details

- **Build System**: `sage-dev` ä½¿ç”¨ `BytecodeCompiler` å°è£…æ„å»ºæµç¨‹
- **Location**: `packages/sage-tools/src/sage/tools/cli/commands/dev/package/pypi.py`
- **Functions**: `build_package()`, `upload_package()`
- **Safety**: é»˜è®¤ dry-run æ¨¡å¼é˜²æ­¢è¯¯æ“ä½œ

### PyPI Publishing Issues

**é—®é¢˜**: `ruamel.yaml.clib` ç¼–è¯‘å¤±è´¥
- **åŸå› **: æŸäº›ä¾èµ–ï¼ˆå¦‚ vllmï¼‰éœ€è¦ ruamel.yamlï¼Œä½† C æ‰©å±•ç¼–è¯‘å¯èƒ½å¤±è´¥
- **è§£å†³**: é€šå¸¸å¯å¿½ç•¥ï¼Œä½¿ç”¨çº¯ Python fallbackã€‚å¦‚å¿…é¡»ä¿®å¤ï¼Œæ£€æŸ¥ç¼–è¯‘å™¨å’Œ Python å¤´æ–‡ä»¶

**é—®é¢˜**: ç‰ˆæœ¬å·ä¸ä¸€è‡´
- **æ£€æŸ¥**: `./tools/install/check_tool_versions.sh`
- **ä¿®å¤**: `./tools/install/check_tool_versions.sh --fix`

## Resources

- Architecture: `docs-public/docs_src/dev-notes/package-architecture.md`
- Guides: `CONTRIBUTING.md` (CN), `DEVELOPER.md` (EN)
- Dev notes: `docs/dev-notes/` (l1-l6, cross-layer/ci-cd/)

## LLM & Embedding Services - sageLLM æ¶æ„

**è®¾è®¡åŸåˆ™**: ç»Ÿä¸€è°ƒåº¦ï¼Œèµ„æºå…±äº«ã€‚æ‰€æœ‰ LLM å’Œ Embedding è¯·æ±‚é€šè¿‡ **sageLLM Control Plane** ç»Ÿä¸€ç®¡ç†ã€‚

### æ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           åº”ç”¨å±‚ (Application Layer)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      UnifiedInferenceClient                              â”‚
â”‚                 chat() | generate() | embed()                            â”‚
â”‚                    Control Plane Mode (å”¯ä¸€æ¨¡å¼)                         â”‚
â”‚              ï¼ˆæ‰€æœ‰è¯·æ±‚é€šè¿‡è°ƒåº¦å™¨ç»Ÿä¸€è·¯ç”±ï¼‰                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 sage.llm.gateway (L6 Gateway)                              â”‚
â”‚              (OpenAI-Compatible REST API + Control Plane)               â”‚
â”‚   /v1/chat/completions | /v1/embeddings | /v1/management/* | /sessions â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    sageLLM Control Plane (æ ¸å¿ƒ)                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  RequestClassifier (LLM_CHAT / LLM_GENERATE / EMBEDDING)        â”‚   â”‚
â”‚   â”‚  HybridSchedulingPolicy (è¯·æ±‚åˆ†ç»„ã€ä¼˜å…ˆçº§ã€æ‰¹å¤„ç†èšåˆ)            â”‚   â”‚
â”‚   â”‚  ExecutionCoordinator (LLM) | EmbeddingExecutor (Embedding)     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        ç»Ÿä¸€èµ„æºæ±  (GPU Pool)                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚  vLLM Instance  â”‚  â”‚  vLLM Instance  â”‚  â”‚  Embedding Srv  â”‚        â”‚
â”‚   â”‚  (LLM Only)     â”‚  â”‚  (LLM+Embed)    â”‚  â”‚  (Embed Only)   â”‚        â”‚
â”‚   â”‚  Type: GENERAL  â”‚  â”‚  Type: MIXED    â”‚  â”‚  Type: EMBEDDINGâ”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

*å¯é€‰ Edge å±‚*: `sage-edge` (8899) å¯ä»¥å°† `sage.llm.gateway` æŒ‚è½½åœ¨ `/`ï¼ˆä¿æŒ `/v1/*` å…¼å®¹ï¼‰ï¼Œæˆ–åœ¨è‡ªå®šä¹‰å‰ç¼€ä¸‹æä¾›å¤šåŸŸèšåˆã€‚æœªå¯åŠ¨ edge æ—¶ï¼Œç›´æ¥è®¿é—® Gateway å³å¯ã€‚

### æ¨èç”¨æ³•ï¼šControl Plane æ¨¡å¼

```python
from sage.llm import UnifiedInferenceClient

# é»˜è®¤ï¼ˆæ¨èï¼‰: è‡ªåŠ¨æ£€æµ‹æœ¬åœ°/è¿œç«¯ç«¯ç‚¹ï¼Œä¼˜å…ˆæœ¬åœ°
client = UnifiedInferenceClient.create()

# å¤–éƒ¨ Control Plane: æŒ‡å‘å·²è¿è¡Œçš„ Control Plane/Gateway
client = UnifiedInferenceClient.create(
  control_plane_url="http://127.0.0.1:8888/v1",
  default_llm_model="Qwen/Qwen2.5-7B-Instruct",
  default_embedding_model="BAAI/bge-m3",
)

# å†…åµŒ Control Plane: åœ¨å½“å‰è¿›ç¨‹å¯åŠ¨è°ƒåº¦å™¨ï¼ˆå®éªŒæ€§ï¼Œé€‚åˆç¦»çº¿æ‰¹å¤„ç†ï¼‰
# embedded mode deprecated; use control_plane_url instead

### å¯åŠ¨æœåŠ¡æ ˆ

```bash
# æ¨èï¼šå¯åŠ¨ Gatewayï¼ˆåŒ…å« Control Planeï¼‰
sage gateway start                                 # å¯åŠ¨ Gatewayï¼ˆç«¯å£ 8888ï¼‰
sage gateway status                                # æŸ¥çœ‹ Gateway çŠ¶æ€
sage gateway stop                                  # åœæ­¢ Gateway
sage gateway logs --follow                         # æŸ¥çœ‹æ—¥å¿—

# å¼•æ“ç®¡ç†ï¼ˆé€šè¿‡ Gateway Control Planeï¼‰
sage llm engine start Qwen/Qwen2.5-7B-Instruct --engine-kind llm    # å¯åŠ¨ LLM å¼•æ“
sage llm engine start BAAI/bge-m3 --engine-kind embedding           # é»˜è®¤ CPU
sage llm engine start BAAI/bge-m3 --engine-kind embedding --use-gpu # ä½¿ç”¨ GPU
sage llm engine list                                                 # æŸ¥çœ‹å¼•æ“åˆ—è¡¨
sage llm engine stop <engine-id>                                     # åœæ­¢å¼•æ“

# æŸ¥çœ‹è¿è¡ŒçŠ¶æ€
ps aux | grep -E "vllm|embedding_server"
```

### Embedding å¼•æ“ GPU æ”¯æŒ

é»˜è®¤æƒ…å†µä¸‹ï¼ŒEmbedding å¼•æ“è¿è¡Œåœ¨ CPU ä¸Šã€‚å¯¹äºå¤§å‹ Embedding æ¨¡å‹ï¼ˆå¦‚ BGE-M3ï¼‰ï¼Œå¯ä»¥æ˜¾å¼å¯ç”¨ GPUï¼š

```python
# CLI æ–¹å¼
# sage llm engine start BAAI/bge-m3 --engine-kind embedding --use-gpu

# é¢„è®¾æ–‡ä»¶ (preset.yaml)
engines:
  - name: embed-gpu
    kind: embedding
    model: BAAI/bge-m3
    use_gpu: true  # æ˜¾å¼ä½¿ç”¨ GPU
```

**`use_gpu` å‚æ•°è¡Œä¸º**ï¼š
- `use_gpu=None` (é»˜è®¤): LLM ä½¿ç”¨ GPUï¼ŒEmbedding ä¸ä½¿ç”¨
- `use_gpu=True`: å¼ºåˆ¶ä½¿ç”¨ GPU
- `use_gpu=False`: å¼ºåˆ¶ä¸ä½¿ç”¨ GPUï¼ˆå³ä½¿æ˜¯ LLMï¼‰

### Control Plane æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | ä½ç½® | åŠŸèƒ½ |
|------|------|------|
| `ControlPlaneManager` | `sage.llm.control_plane.manager` | æ ¸å¿ƒè°ƒåº¦ç®¡ç†å™¨ |
| `RequestClassifier` | `sage.llm.control_plane.request_classifier` | è¯·æ±‚ç±»å‹åˆ†ç±» |
| `HybridSchedulingPolicy` | `sage.llm.control_plane.strategies.hybrid_policy` | æ··åˆè°ƒåº¦ç­–ç•¥ |
| `EmbeddingExecutor` | `sage.llm.control_plane.executors.embedding_executor` | Embedding æ‰¹å¤„ç† |
| `ControlPlaneService` | `sage.llm.control_plane_service` | Control Plane SAGE å°è£… |

### å…³é”®æ–‡ä»¶ä½ç½®

```
packages/sage-llm-core/src/sage/llm/
  unified_client.py         # UnifiedInferenceClient (factory-only construction)
  control_plane_service.py  # Control Plane facade
  control_plane/            # Control Plane core implementation
    manager.py              # è°ƒåº¦ç®¡ç†å™¨
    request_classifier.py   # è¯·æ±‚åˆ†ç±»å™¨
    strategies/hybrid_policy.py  # LLM + Embedding æ··åˆè°ƒåº¦
    executors/embedding_executor.py # Embedding æ‰¹å¤„ç†æ‰§è¡Œ

packages/sage-llm-gateway/src/sage/llm/gateway/
  server.py                 # FastAPI åº”ç”¨å…¥å£ (OpenAI/Anthropic-compatible)
  routes/
    engine_control_plane.py # Control Plane ç®¡ç† API
    llm.py                  # LLM ä»£ç†
    embedding.py            # Embedding ä»£ç†
    studio.py               # Studio backend routes (merged)
    sessions.py             # ä¼šè¯ç®¡ç†
  adapters/openai.py        # OpenAI adapter
  rag_pipeline.py           # Pipeline-as-a-service
  session/manager.py        # Session + memory backends

packages/sage-edge/src/sage/edge/
  app.py                    # FastAPI aggregator shell (mounts gateway, keeps /v1/* by default)
  server.py                 # uvicorn entrypoint / CLI target

packages/sage-common/src/sage/common/components/
  sage_embedding/
    embedding_server.py     # OpenAI å…¼å®¹ Embedding æœåŠ¡å™¨
    factory.py              # EmbeddingFactory (æœ¬åœ°æ¨¡å‹)
```

### å®¢æˆ·ç«¯æ¨¡å¼å¯¹æ¯”ï¼ˆç»Ÿä¸€ Control Planeï¼‰

> Simple æ¨¡å¼å·²ç§»é™¤ï¼›æ‰€æœ‰è¯·æ±‚éƒ½ç»ç”± Control Planeã€‚

| æ¨¡å¼ | åˆ›å»ºæ–¹å¼ | è°ƒåº¦ | é€‚ç”¨åœºæ™¯ |
|------|----------|------|---------|
| è‡ªåŠ¨æ£€æµ‹ | `UnifiedInferenceClient.create()` | è‡ªåŠ¨æ¢æµ‹æœ¬åœ°/è¿œç«¯ç«¯ç‚¹ï¼Œç»Ÿä¸€è°ƒåº¦ | é»˜è®¤æ¨èï¼ˆæœ¬åœ°å¼€å‘ã€å•æœºå®éªŒï¼‰ |
| å¤–éƒ¨ Control Plane | `UnifiedInferenceClient.create(control_plane_url=...)` | é€šè¿‡å·²è¿è¡Œçš„ Control Plane/Gateway è·¯ç”± | ç”Ÿäº§éƒ¨ç½²ã€ç½‘å…³ç»Ÿä¸€å…¥å£ |
| å†…åµŒ Control Plane (deprecated) | ä½¿ç”¨ control_plane_url æˆ–æœ¬åœ° Gateway | åœ¨è¿›ç¨‹å†…å¯åŠ¨è°ƒåº¦å™¨ | ç¦»çº¿æ‰¹å¤„ç†/æ— å¤–éƒ¨æœåŠ¡æ—¶ |

### å†…åµŒæ¨¡å¼ (VLLMService) - æ‰¹å¤„ç†ä¸“ç”¨

```python
from sage.llm import VLLMService

# è¿›ç¨‹å†…åŠ è½½æ¨¡å‹ï¼Œé€‚åˆæ‰¹å¤„ç†ä»»åŠ¡
service = VLLMService({
    "model_id": "Qwen/Qwen2.5-0.5B-Instruct",
    "auto_download": True,
})
service.setup()  # åŠ è½½æ¨¡å‹åˆ° GPU
results = service.generate("Hello, world!")
service.teardown()
```

### ç¯å¢ƒå˜é‡ (.env)

```bash
# === æœ¬åœ°æœåŠ¡ï¼ˆæ¨èï¼Œé»˜è®¤ï¼‰===
# æ— éœ€é…ç½®ï¼Œä½¿ç”¨ SagePorts é»˜è®¤ç«¯å£
# UnifiedInferenceClient ä¼šè‡ªåŠ¨æ¢æµ‹ localhost:8001, localhost:8901

# === æ˜¾å¼è¿œç«¯è¦†ç›–ï¼ˆä»…å½“éœ€è¦å¼ºåˆ¶ä½¿ç”¨äº‘ç«¯APIæ—¶è®¾ç½®ï¼‰===
# è­¦å‘Šï¼šä»…ç”¨äºæ˜¾å¼è¿œç«¯è¦†ç›–ï¼Œä¸æ˜¯é»˜è®¤è¡Œä¸º
# æœ¬åœ°å¼€å‘åº”å§‹ç»ˆä½¿ç”¨æœ¬åœ°ç«¯ç‚¹ï¼Œä¸è¦ä¾èµ–äº‘ç«¯ fallback
SAGE_CHAT_API_KEY=sk-xxx              # äº‘ç«¯ API Key (DashScope/OpenAI compatible)
SAGE_CHAT_MODEL=qwen-turbo-2025-02-11
SAGE_CHAT_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# === HuggingFace ===
HF_TOKEN=hf_xxx
# HF_ENDPOINT æ— éœ€æ‰‹åŠ¨è®¾ç½®ï¼ŒSAGE ä¼šè‡ªåŠ¨æ£€æµ‹ç½‘ç»œå¹¶é…ç½®é•œåƒ
```

> **CRITICAL**: DashScope/äº‘ç«¯å˜é‡**ä»…ç”¨äºæ˜¾å¼è¿œç«¯è¦†ç›–**ï¼Œä¸æ˜¯é»˜è®¤è¡Œä¸ºã€‚
> - **æœ¬åœ°ä¼˜å…ˆ**ï¼šé»˜è®¤æ¢æµ‹ `localhost:8001` å’Œ `localhost:8901`
> - **æ— éšå¼ fallback**ï¼šå¦‚æœæœ¬åœ°ç«¯ç‚¹ä¸å¯è¾¾ï¼Œä¼š**å¿«é€Ÿå¤±è´¥**ï¼Œä¸ä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°äº‘ç«¯
> - **æ˜¾å¼è¦†ç›–**ï¼šä»…å½“è®¾ç½®äº† `SAGE_CHAT_BASE_URL` æ—¶æ‰ä½¿ç”¨è¿œç«¯
> - **CI ç¯å¢ƒ**ï¼šGitHub Actions åœ¨æ— æœ¬åœ°æœåŠ¡æ—¶ä½¿ç”¨ DashScope fallbackï¼ˆCI onlyï¼‰

### ç½‘ç»œæ£€æµ‹å’Œ HuggingFace é•œåƒè‡ªåŠ¨é…ç½®

SAGE ä¼šåœ¨è¿è¡Œæ—¶è‡ªåŠ¨æ£€æµ‹ç½‘ç»œåŒºåŸŸï¼Œå¦‚æœæ£€æµ‹åˆ°ä¸­å›½å¤§é™†ç½‘ç»œï¼Œä¼šè‡ªåŠ¨è®¾ç½® `HF_ENDPOINT=https://hf-mirror.com`ã€‚

```python
from sage.common.config import (
    detect_china_mainland,      # æ£€æµ‹æ˜¯å¦åœ¨ä¸­å›½å¤§é™†
    get_hf_endpoint,            # è·å–æ¨èçš„ HF endpoint
    ensure_hf_mirror_configured,  # è‡ªåŠ¨é…ç½® HF é•œåƒï¼ˆæ¨èåœ¨ CLI å‘½ä»¤å…¥å£è°ƒç”¨ï¼‰
)

# æ£€æµ‹ç½‘ç»œåŒºåŸŸ
is_china = detect_china_mainland()  # True/False

# è‡ªåŠ¨é…ç½®ï¼ˆå¦‚æœåœ¨ä¸­å›½å¤§é™†ï¼Œè®¾ç½® HF_ENDPOINT ç¯å¢ƒå˜é‡ï¼‰
ensure_hf_mirror_configured()  # åªä¼šåœ¨é¦–æ¬¡è°ƒç”¨æ—¶æ£€æµ‹ï¼Œç»“æœä¼šç¼“å­˜
```

**è‡ªåŠ¨é…ç½®çš„å‘½ä»¤**ï¼š
- `sage llm engine start` - å¯åŠ¨ LLM/Embedding å¼•æ“
- `sage llm model download` - ä¸‹è½½æ¨¡å‹
- `sage llm fine-tune` - å¾®è°ƒæ¨¡å‹
- Embedding ç›¸å…³æœåŠ¡

### EmbeddingFactory (æœ¬åœ°æ¨¡å‹ï¼Œæ— éœ€æœåŠ¡)

ç”¨äºä¸æƒ³å¯åŠ¨ Embedding æœåŠ¡çš„åœºæ™¯ï¼š

```python
from sage.common.components.sage_embedding import (
    EmbeddingFactory, EmbeddingClientAdapter
)

# æœ¬åœ°åŠ è½½ HuggingFace æ¨¡å‹
raw_embedder = EmbeddingFactory.create("hf", model="BAAI/bge-small-zh-v1.5")
client = EmbeddingClientAdapter(raw_embedder)  # é€‚é…ä¸ºæ‰¹é‡æ¥å£
vectors = client.embed(["æ–‡æœ¬1", "æ–‡æœ¬2"])
```

**æ¥å£å¯¹æ¯”**:
| æ¥å£ | ç­¾å | æ¥æº |
|------|------|------|
| å•æ–‡æœ¬ (BaseEmbedding) | `embed(text: str) -> list[float]` | `EmbeddingFactory.create()` |
| æ‰¹é‡ (EmbeddingProtocol) | `embed(texts: list[str], model=None) -> list[list[float]]` | `EmbeddingClientAdapter` |

**é”™è¯¯ç¤ºä¾‹** (ä¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯):
```python
# é”™è¯¯: EmbeddingFactory è¿”å›çš„æ˜¯å•æ–‡æœ¬æ¥å£
embedder = EmbeddingFactory.create("hf", model="...")
embedder.embed(texts=["a", "b"])  # TypeError: embed() got unexpected keyword argument 'texts'
```

## sage-benchmark ç»„ä»¶

Agent èƒ½åŠ›å’Œ Control Plane è¯„æµ‹æ¡†æ¶ï¼Œä½äº `packages/sage-benchmark/`ï¼š

### benchmark_agent (Agent èƒ½åŠ›è¯„æµ‹)

è¯„ä¼° Agent ä¸‰ä¸ªæ ¸å¿ƒèƒ½åŠ›ï¼šå·¥å…·é€‰æ‹©ã€ä»»åŠ¡è§„åˆ’ã€æ—¶æœºåˆ¤æ–­ã€‚

**æ ¸å¿ƒæ¨¡å—**:
```
src/sage/benchmark/benchmark_agent/
  adapter_registry.py      # ç­–ç•¥æ³¨å†Œè¡¨ (selector.*, planner.*, timing.*)
  experiments/
    base_experiment.py     # å®éªŒåŸºç±» + æ•°æ®æ¨¡å‹
    tool_selection_exp.py  # å·¥å…·é€‰æ‹©è¯„æµ‹
    planning_exp.py        # ä»»åŠ¡è§„åˆ’è¯„æµ‹
    timing_detection_exp.py # æ—¶æœºå†³ç­–è¯„æµ‹
  evaluation/
    metrics.py             # è¯„æµ‹æŒ‡æ ‡ (accuracy, precision, recall, etc.)
  scripts/                 # è¯„æµ‹è„šæœ¬
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from sage.benchmark.benchmark_agent import get_adapter_registry

registry = get_adapter_registry()

# å·¥å…·é€‰æ‹©ç­–ç•¥
selector = registry.get("selector.keyword")  # keyword, embedding, hybrid, gorilla, dfsdt

# ä»»åŠ¡è§„åˆ’ç­–ç•¥
planner = registry.get("planner.react")  # simple, hierarchical, llm_based, react, tot

# æ—¶æœºå†³ç­–ç­–ç•¥
decider = registry.get("timing.rule_based")  # rule_based, llm_based, hybrid
```

### benchmark_control_plane (è°ƒåº¦ç­–ç•¥è¯„æµ‹)

è¯„ä¼° sageLLM Control Plane çš„è°ƒåº¦ç­–ç•¥æ€§èƒ½ï¼ˆååé‡ã€å»¶è¿Ÿã€SLO åˆè§„ç‡ï¼‰ã€‚

**CLI**:
```bash
# LLM è°ƒåº¦è¯„æµ‹
sage-cp-bench run --mode llm --policy fifo --requests 100

# Hybrid (LLM + Embedding) è¯„æµ‹
sage-cp-bench run --mode hybrid --policy hybrid_slo --llm-ratio 0.7

# ç­–ç•¥å¯¹æ¯”
sage-cp-bench compare --mode llm --policies fifo,priority,slo_aware
```

**è¯¦ç»†æ–‡æ¡£**: `packages/sage-benchmark/src/sage/benchmark/benchmark_control_plane/README.md`

## SageDB Vector Database Backend

### Overview

SageDB is a **self-developed high-performance C++ vector database**, fully custom implementation (NOT based on FAISS), integrated into SAGE's NeuroMem VDB system.

**Features**:
- âœ… Self-developed C++ core (independent implementation)
- âœ… High-performance similarity search (C++ optimized)
- âœ… Metadata filtering (`filtered_search`, `search_by_metadata`)
- âœ… Hybrid search (vector + text)
- âœ… Batch operations with numpy optimization
- âœ… Persistent storage (save/load)
- âœ… Multiple index types (AUTO, FLAT, IVF, HNSW)
- âœ… Distance metrics (L2, INNER_PRODUCT, COSINE)
- âœ… **ANNS Algorithms**: Available in `sage-libs/anns/` (faiss_HNSW, vsag_hnsw, diskann, candy_*, cufe, gti, puck, etc.)

### Location

**Core Implementation**:
- C++ Backend: `packages/sage-middleware/src/sage/middleware/components/sage_db/sageDB/`
- Python API: `packages/sage-middleware/src/sage/middleware/components/sage_db/python/sage_db.py`
- NeuroMem Adapter: `packages/sage-middleware/src/sage/middleware/components/sage_mem/neuromem/search_engine/vdb_index/sagedb_index.py`

### Usage in NeuroMem VDB Collections

**Creating a VDB collection with SageDB backend**:

```python
from sage.middleware.components.sage_mem.neuromem.memory_manager import MemoryManager

manager = MemoryManager()

# Create collection
collection = manager.create_collection({
    "name": "my_collection",
    "backend_type": "VDB"
})

# Create SageDB index
collection.create_index({
    "name": "my_index",
    "dim": 1024,
    "backend_type": "SageDB",  # Use SageDB instead of FAISS
    "description": "High-performance SageDB index"
})

# Insert vectors
collection.insert("my_index", text="example text", vector=embedding_vector)

# Search
results = collection.search("my_index", query_vector, top_k=10)
```

**Gateway Session Storage Configuration**:

```python
# In packages/sage-llm-gateway/src/sage/llm/gateway/session/manager.py

# Default: FAISS backend
index_config = {
    "backend_type": "FAISS",  # Python FAISS
    ...
}

# Optimized: SageDB backend (C++ performance)
index_config = {
    "backend_type": "SageDB",  # C++ optimized
    ...
}
```

**Current Status** (2025-12-28):
- âœ… SageDB backend registered in VDB index factory
- âœ… SageDBIndex adapter implements all BaseVDBIndex methods
- âœ… Tests pass: insert, batch_insert, search, delete, update
- âš ï¸ Gateway default remains FAISS (change to "SageDB" to use C++ backend)

**Performance Characteristics** (5000 vectors, dim=128):
- âœ… **Insert**: SageDB 10x faster (single), 1.14x faster (batch) - C++ optimized write path
- âš ï¸ **Search**: FAISS 2.8-3x faster across all k values (Python wrapper overhead in current implementation)
- â¡ï¸ **Memory**: Nearly identical (~945 MB)
- âœ… **ANNS Algorithms**: Now available in `sage-libs/anns/` for modularity

**When to use SageDB**:
- Write-heavy workloads (frequent insertions/updates)
- Session storage with many new messages
- Real-time chat applications
- When insert latency is critical
- Custom C++ extensions and integrations

**When to use FAISS**:
- Read-heavy workloads (frequent similarity searches)
- Large-scale retrieval systems
- When search latency is critical
- Production RAG pipelines with high QPS

### Direct SageDB API (without NeuroMem)

**Important**: SageDB is a self-developed C++ vector database, not based on FAISS.

```python
from sage.middleware.components.sage_db.python.sage_db import SageDB, IndexType, DistanceMetric

# Create database (C++ core)
db = SageDB(dimension=128, index_type=IndexType.AUTO, metric=DistanceMetric.L2)

# Add vectors with metadata
db.add([0.1, 0.2, ...], metadata={"id": "doc_1", "category": "tech"})
db.add_batch(vectors, metadata=[{"id": f"doc_{i}"} for i in range(len(vectors))])

# Build index
db.build_index()

# Search
results = db.search(query_vector, k=10)
for result in results:
    print(f"ID: {result.metadata['id']}, Score: {result.score}")

# Filtered search
results = db.filtered_search(
    query_vector,
    params=SearchParams(k=10),
    filter_fn=lambda meta: meta.get("category") == "tech"
)

# Save/Load
db.save("/path/to/index")
db.load("/path/to/index")
```

### API Reference

**SageDB Methods**:
- `add(vector, metadata)` - Add single vector
- `add_batch(vectors, metadata)` - Batch add (numpy optimized)
- `search(query, k)` - Basic similarity search
- `filtered_search(query, params, filter_fn)` - Search with filtering
- `search_by_metadata(query, params, key, value)` - Metadata-based search
- `hybrid_search(query, params, text_query, weights)` - Vector + text hybrid
- `build_index()` - Build search index
- `train_index(vectors)` - Train index (for IVF, etc.)
- `save(filepath)` / `load(filepath)` - Persistence
- `size`, `dimension`, `index_type` - Properties

**Metadata Requirements**:
- All metadata must be `dict[str, str]` (string keys and values)
- Convert non-string values: `{"id": str(internal_id), "text": text}`

## Final Reminder for Copilot

**Trust these instructions** - search only if incomplete, errors occur, or deep architecture needed.

**ğŸ” When encountering difficulties or uncertainties:**

1. **First**, check if there's relevant documentation in `docs-public/docs_src/dev-notes/`
2. **Use tools** like `grep_search` or `semantic_search` to find documentation before making assumptions
3. **Read before acting** - documentation exists to guide you, not as optional reference
4. **Common documentation locations:**
   - Installation/Testing: `DEVELOPER.md`, `CONTRIBUTING.md`
   - CI/CD: `docs-public/docs_src/dev-notes/cross-layer/ci-cd.md`
   - Documentation policy: `docs-public/docs_src/dev-notes/cross-layer/documentation-policy.md`
   - Package architecture: `docs-public/docs_src/dev-notes/package-architecture.md`
   - Layer-specific guides: `docs-public/docs_src/dev-notes/l{1-6}-*/`
   - Cross-cutting concerns: `docs-public/docs_src/dev-notes/cross-layer/`

**Remember**: Don't guess. Read the docs. They exist for this reason.
