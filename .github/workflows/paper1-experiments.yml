name: Paper 1 - SAGE Agent Bench Full Experiments

# Manual trigger only - self-hosted GPU server
on:
  workflow_dispatch:
    inputs:
      section:
        description: 'Section to run (all/5.2/5.3/5.4/5.5)'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - '5.2'
          - '5.3'
          - '5.4'
          - '5.5'
      experiment:
        description: 'Specific experiment (optional)'
        required: false
        default: ''
        type: choice
        options:
          - ''
          - timing
          - planning
          - selection
          - error
          - scaling
          - robustness
          - ablation
          - cross-dataset
          - training
      quick_mode:
        description: 'Quick mode (reduced samples for testing)'
        required: false
        default: false
        type: boolean
      skip_llm:
        description: 'Skip LLM-based methods (faster)'
        required: false
        default: false
        type: boolean
      skip_llm_scaling:
        description: 'Skip LLM Scaling test (saves time, uses estimates)'
        required: false
        default: false
        type: boolean
      generate_paper:
        description: 'Generate paper figures and tables'
        required: false
        default: true
        type: boolean

env:
  CI: true
  HF_TOKEN: ${{ secrets.HF_TOKEN }}
  HF_ENDPOINT: https://hf-mirror.com
  SAGE_TEST_MODE: false
  SAGE_LOG_LEVEL: INFO
  # LLM Service Configuration
  SAGE_CHAT_API_KEY: ${{ secrets.ALIBABA_API_KEY }}
  SAGE_CHAT_BASE_URL: https://dashscope.aliyuncs.com/compatible-mode/v1
  SAGE_CHAT_MODEL: qwen-turbo-2025-02-11


jobs:
  run-experiments:
    name: Run SAGE Agent Bench Experiments
    runs-on: [self-hosted, A100]
    timeout-minutes: 480  # 8 hours for full experiments

    # Use dedicated conda environment to avoid conflicts with any existing "sage" env
    env:
      CONDA_ENV_NAME: sage-paper1-ci

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          clean: true
          submodules: 'recursive'

      # Setup dedicated conda environment for this workflow
      - name: Setup Conda Environment
        run: |
          echo "ðŸ”§ Setting up dedicated conda environment: $CONDA_ENV_NAME"

          # Remove existing environment if it exists (clean slate)
          conda env remove -n $CONDA_ENV_NAME -y 2>/dev/null || true

          # Create fresh environment with Python 3.11
          conda create -n $CONDA_ENV_NAME python=3.11 -y

          # Verify environment
          conda run -n $CONDA_ENV_NAME python --version
          echo "âœ… Conda environment $CONDA_ENV_NAME created"

      - name: Install SAGE in Conda Environment
        run: |
          echo "ðŸš€ Installing SAGE in $CONDA_ENV_NAME environment..."

          # Set environment variables for installation
          export SAGE_ENV_NAME=$CONDA_ENV_NAME
          export PIP_CMD="conda run -n $CONDA_ENV_NAME pip"
          export PYTHON_CMD="conda run -n $CONDA_ENV_NAME python"

          # Install system dependencies if needed
          for cmd in cmake pkg-config; do
            if ! command -v $cmd &> /dev/null; then
              sudo apt-get update -qq
              sudo apt-get install -y --no-install-recommends build-essential cmake pkg-config libopenblas-dev liblapack-dev git
              break
            fi
          done

          # Install SAGE in dev mode
          conda run -n $CONDA_ENV_NAME pip install --upgrade pip setuptools wheel
          conda run -n $CONDA_ENV_NAME pip install -e "packages/sage[dev]" --no-build-isolation

          # Verify installation
          conda run -n $CONDA_ENV_NAME python -c "import sage; print(f'SAGE {sage.__version__} installed successfully')"
          echo "âœ… SAGE installation completed"
        timeout-minutes: 25

      - name: Create Experiment Environment File
        run: |
          # Create .env with all required settings
          cat > .env << EOF
          # SAGE Environment Configuration (auto-generated for Paper 1 experiments)
          HF_TOKEN=${{ secrets.HF_TOKEN }}
          HF_ENDPOINT=https://hf-mirror.com

          # LLM Service (DashScope/Qwen)
          SAGE_CHAT_API_KEY=${{ secrets.ALIBABA_API_KEY }}
          SAGE_CHAT_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
          SAGE_CHAT_MODEL=qwen-turbo-2025-02-11

          # Embedding Service
          SAGE_EMBEDDING_MODEL=BAAI/bge-small-zh-v1.5

          # Experiment Settings
          SAGE_TEST_MODE=false
          EOF

          echo "Done: Experiment .env settings added"

      - name: Check GPU Availability
        run: |
          echo "Checking GPU status..."
          nvidia-smi || echo "No NVIDIA GPU found"

          conda run -n $CONDA_ENV_NAME python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPUs: {torch.cuda.device_count()}')" || true

      - name: Check Local LLM Service
        if: ${{ !inputs.skip_llm }}
        run: |
          echo "Checking local LLM service..."

          # Check if local vLLM is already running
          if curl -s http://localhost:8901/v1/models > /dev/null 2>&1; then
            echo "Done: Local LLM service running on port 8901"
          else
            echo "Warning: Local LLM not available, will use cloud API (DashScope)"
          fi

      - name: Run Paper 1 Experiments
        run: |
          echo "Running SAGE Agent Bench experiments..."

          # Navigate to scripts directory
          cd packages/sage-benchmark/src/sage/benchmark/benchmark_agent/scripts/experiments

          # Build command
          CMD="conda run -n $CONDA_ENV_NAME python run_paper1_experiments.py"

          # Add section selection
          if [ "${{ inputs.section }}" != "all" ]; then
            CMD="$CMD --section ${{ inputs.section }}"
          fi

          # Add specific experiment if provided
          if [ -n "${{ inputs.experiment }}" ]; then
            CMD="$CMD --exp ${{ inputs.experiment }}"
          fi

          # Quick mode
          if [ "${{ inputs.quick_mode }}" == "true" ]; then
            CMD="$CMD --quick"
          fi

          # Skip LLM if requested
          if [ "${{ inputs.skip_llm }}" == "true" ]; then
            CMD="$CMD --skip-llm"
          fi

          # Skip LLM Scaling if requested (saves ~1-2 hours)
          if [ "${{ inputs.skip_llm_scaling }}" == "true" ]; then
            CMD="$CMD --skip-llm-scaling"
          fi

          # Verbose output
          CMD="$CMD --verbose"

          echo "Running: $CMD"
          $CMD

      - name: Generate Paper Materials
        if: ${{ inputs.generate_paper && success() }}
        run: |
          echo "Generating paper figures and tables..."

          cd packages/sage-benchmark/src/sage/benchmark/benchmark_agent/scripts/experiments

          # Generate figures
          conda run -n $CONDA_ENV_NAME python -c "from figure_generator import generate_all_figures; generate_all_figures(); print('Figures generated.')"

          # Generate tables
          conda run -n $CONDA_ENV_NAME python -c "from table_generator import generate_all_tables; generate_all_tables(); print('Tables generated.')"

      - name: Upload Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: paper1-results-${{ github.run_number }}
          path: |
            .sage/benchmark/paper1/
          retention-days: 90

      - name: Upload Paper Materials
        uses: actions/upload-artifact@v4
        if: ${{ inputs.generate_paper && success() }}
        with:
          name: paper1-figures-tables-${{ github.run_number }}
          path: |
            .sage/benchmark/paper1/figures/
            .sage/benchmark/paper1/tables/
          retention-days: 90

      - name: Print Summary
        if: always()
        run: |
          echo ""
          echo "=============================================="
          echo "       SAGE Agent Bench - Experiment Summary"
          echo "=============================================="
          echo ""
          echo "Configuration:"
          echo "  Section: ${{ inputs.section }}"
          echo "  Experiment: ${{ inputs.experiment || 'all' }}"
          echo "  Quick Mode: ${{ inputs.quick_mode }}"
          echo "  Skip LLM: ${{ inputs.skip_llm }}"
          echo "  Generate Paper: ${{ inputs.generate_paper }}"
          echo ""
          echo "=============================================="
          echo "  Control Constants:"
          echo "  - RANDOM_SEED: 42"
          echo "  - EMBEDDING_MODEL: BAAI/bge-small-zh-v1.5"
          echo "  - LLM_TEMPERATURE: 0.1"
          echo "=============================================="
          echo ""

          # Print results summary if available
          if [ -d ".sage/benchmark/paper1" ]; then
            echo "Results directory structure:"
            find .sage/benchmark/paper1 -type f -name "*.json" | head -20
            echo ""

            # Print main results if available
            for section in section_5_2_main section_5_3_analysis section_5_4_generalization section_5_5_training; do
              dir=".sage/benchmark/paper1/$section"
              if [ -d "$dir" ]; then
                echo "[$section]"
                ls -la "$dir"/*.json 2>/dev/null || echo "  (no results)"
                echo ""
              fi
            done
          else
            echo "No results directory found."
          fi

          echo ""
          echo "========================================"
          echo "  HOW TO DOWNLOAD EXPERIMENT RESULTS"
          echo "========================================"
          echo ""
          echo "Your experiment results have been uploaded as GitHub Artifacts."
          echo ""
          echo "To download:"
          echo "  1. Go to this workflow run page:"
          echo "     https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo ""
          echo "  2. Scroll down to the 'Artifacts' section"
          echo ""
          echo "  3. Download:"
          echo "     - paper1-results-${{ github.run_number }}: Full results"
          echo "     - paper1-figures-tables-${{ github.run_number }}: Figures and LaTeX tables"
          echo ""
          echo "Artifacts retained for 90 days."
          echo ""
          echo "GitHub CLI:"
          echo "  gh run download ${{ github.run_id }} --repo ${{ github.repository }}"
          echo "========================================"
