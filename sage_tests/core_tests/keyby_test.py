import pytest
import time
import threading
from typing import List, Dict, Any
from sage_core.environment.local_environment import LocalEnvironment
from sage_core.function.source_function import SourceFunction
from sage_core.function.keyby_function import KeyByFunction
from sage_core.function.base_function import BaseFunction
from sage_core.function.sink_function import SinkFunction


class TestDataSource(SourceFunction):
    """ç”Ÿæˆå¸¦æœ‰ç”¨æˆ·IDçš„æµ‹è¯•æ•°æ®"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.counter = 0
        self.user_ids = ["user1", "user2", "user3", "user1", "user2", "user3"]
    
    def execute(self):
        if self.counter >= len(self.user_ids):
            return None  # åœæ­¢ç”Ÿæˆæ•°æ®
        
        data = {
            "id": self.counter,
            "user_id": self.user_ids[self.counter],
            "content": f"Message {self.counter} from {self.user_ids[self.counter]}"
        }
        self.counter += 1
        self.logger.info(f"Generated data: {data}")
        return data


class UserIdKeyExtractor(KeyByFunction):
    """æå–ç”¨æˆ·IDä½œä¸ºåˆ†åŒºé”®"""
    
    def execute(self, data: Any) -> str:
        user_id = data["user_id"]
        self.logger.info(f"Extracted key '{user_id}' from data: {data}")
        return user_id


class ParallelDebugSink(SinkFunction):
    """å¹¶è¡Œè°ƒè¯•Sinkï¼Œè®°å½•æ¥æ”¶åˆ°çš„æ•°æ®åˆ†å¸ƒ"""
    
    # ç±»çº§åˆ«çš„ç»Ÿè®¡ï¼Œæ‰€æœ‰å®ä¾‹å…±äº«
    _received_data: Dict[int, List[Dict]] = {}
    _lock = threading.Lock()
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.parallel_index = None
        self.received_count = 0
    
    def execute(self, data: Any):
        # ä»runtime_contextè·å–parallel_index
        if self.runtime_context:
            self.parallel_index = self.runtime_context.parallel_index
        
        with self._lock:
            if self.parallel_index not in self._received_data:
                self._received_data[self.parallel_index] = []
            
            self._received_data[self.parallel_index].append(data)
        
        self.received_count += 1
        
        self.logger.info(
            f"[Parallel Instance {self.parallel_index}] "
            f"Received data #{self.received_count}: {data}"
        )
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” [Instance {self.parallel_index}] User: {data['user_id']}, "
              f"Content: {data['content']}")
        
        return data
    
    @classmethod
    def get_received_data(cls) -> Dict[int, List[Dict]]:
        """è·å–æ‰€æœ‰å¹¶è¡Œå®ä¾‹æ¥æ”¶åˆ°çš„æ•°æ®"""
        with cls._lock:
            return dict(cls._received_data)
    
    @classmethod
    def clear_data(cls):
        """æ¸…ç©ºç»Ÿè®¡æ•°æ®"""
        with cls._lock:
            cls._received_data.clear()


class TestKeyByFunctionality:
    """æµ‹è¯•KeyByåŠŸèƒ½çš„åˆ†åŒºæ•ˆæœ"""
    
    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„è®¾ç½®"""
        ParallelDebugSink.clear_data()
    
    def test_keyby_hash_partitioning(self):
        """æµ‹è¯•åŸºäºhashçš„åˆ†åŒºåŠŸèƒ½"""
        print("\nğŸš€ Testing KeyBy Hash Partitioning")
        
        # åˆ›å»ºç¯å¢ƒ
        env = LocalEnvironment("keyby_test")
        
        # æ„å»ºæ•°æ®æµï¼šsource -> keyby -> parallel sink
        result_stream = (
            env.from_source(TestDataSource, delay=0.5)
            .keyby(UserIdKeyExtractor, strategy="hash")
            .sink(ParallelDebugSink, parallelism=2)  # 2ä¸ªå¹¶è¡Œå®ä¾‹
        )
        
        print("ğŸ“Š Pipeline: TestDataSource -> KeyBy(UserIdExtractor) -> ParallelDebugSink(parallelism=2)")
        print("ğŸ¯ Expected: Same user_id data should go to same parallel instance\n")
        
        try:
            # æäº¤å¹¶è¿è¡Œ
            env.submit()
            # env.run_streaming()
            
            # è¿è¡Œä¸€æ®µæ—¶é—´è®©æ•°æ®æµè¿‡
            time.sleep(3)
            
        except Exception as e:
            print(f"âŒ Error during execution: {e}")
            raise
        finally:
            env.close()
        
        # éªŒè¯åˆ†åŒºæ•ˆæœ
        self._verify_hash_partitioning()
    
    def test_keyby_broadcast_strategy(self):
        """æµ‹è¯•å¹¿æ’­ç­–ç•¥"""
        print("\nğŸš€ Testing KeyBy Broadcast Strategy")
        
        env = LocalEnvironment("keyby_broadcast_test")
        
        result_stream = (
            env.from_source(TestDataSource, delay=0.3)
            .keyby(UserIdKeyExtractor, strategy="broadcast")
            .sink(ParallelDebugSink, parallelism=3)  # 3ä¸ªå¹¶è¡Œå®ä¾‹
        )
        
        print("ğŸ“Š Pipeline: TestDataSource -> KeyBy(broadcast) -> ParallelDebugSink(parallelism=3)")
        print("ğŸ¯ Expected: All data should be sent to all parallel instances\n")
        
        try:
            env.submit()
            # env.run_streaming()
            time.sleep(2)
        finally:
            env.close()
        
        # éªŒè¯å¹¿æ’­æ•ˆæœ
        self._verify_broadcast_strategy()
    
    def _verify_hash_partitioning(self):
        """éªŒè¯hashåˆ†åŒºçš„æ­£ç¡®æ€§"""
        received_data = ParallelDebugSink.get_received_data()
        
        print("\nğŸ“‹ Hash Partitioning Results:")
        print("=" * 50)
        
        # ç»Ÿè®¡æ¯ä¸ªå®ä¾‹æ¥æ”¶åˆ°çš„ç”¨æˆ·æ•°æ®
        user_distribution = {}
        for instance_id, data_list in received_data.items():
            print(f"\nğŸ”¹ Parallel Instance {instance_id}:")
            user_counts = {}
            for data in data_list:
                user_id = data["user_id"]
                user_counts[user_id] = user_counts.get(user_id, 0) + 1
            
            for user_id, count in user_counts.items():
                print(f"   - {user_id}: {count} messages")
                if user_id not in user_distribution:
                    user_distribution[user_id] = set()
                user_distribution[user_id].add(instance_id)
        
        print(f"\nğŸ¯ User Distribution Across Instances:")
        for user_id, instances in user_distribution.items():
            print(f"   - {user_id}: routed to instance(s) {instances}")
        
        # éªŒè¯ï¼šæ¯ä¸ªç”¨æˆ·çš„æ•°æ®åº”è¯¥åªè·¯ç”±åˆ°ä¸€ä¸ªå®ä¾‹
        for user_id, instances in user_distribution.items():
            assert len(instances) == 1, (
                f"âŒ User {user_id} data was routed to multiple instances: {instances}. "
                f"Hash partitioning should send same key to same instance."
            )
        
        print("âœ… Hash partitioning test passed: Each user routed to exactly one instance")
    
    def _verify_broadcast_strategy(self):
        """éªŒè¯å¹¿æ’­ç­–ç•¥çš„æ­£ç¡®æ€§"""
        received_data = ParallelDebugSink.get_received_data()
        
        print("\nğŸ“‹ Broadcast Strategy Results:")
        print("=" * 50)
        
        instance_counts = {}
        total_unique_messages = 0
        
        for instance_id, data_list in received_data.items():
            instance_counts[instance_id] = len(data_list)
            print(f"\nğŸ”¹ Parallel Instance {instance_id}: {len(data_list)} messages")
            
            for data in data_list[:3]:  # åªæ˜¾ç¤ºå‰3æ¡
                print(f"   - {data['user_id']}: {data['content']}")
        
        if received_data:
            # è·å–ç¬¬ä¸€ä¸ªå®ä¾‹çš„æ•°æ®ä½œä¸ºåŸºå‡†
            first_instance_data = list(received_data.values())[0]
            total_unique_messages = len(first_instance_data)
        
        print(f"\nğŸ¯ Broadcast Verification:")
        print(f"   - Total unique messages generated: {total_unique_messages}")
        print(f"   - Instances message counts: {instance_counts}")
        
        # éªŒè¯ï¼šæ¯ä¸ªå®ä¾‹åº”è¯¥æ¥æ”¶åˆ°ç›¸åŒæ•°é‡çš„æ¶ˆæ¯ï¼ˆå¹¿æ’­æ•ˆæœï¼‰
        if len(set(instance_counts.values())) <= 1:
            print("âœ… Broadcast test passed: All instances received same number of messages")
        else:
            print(f"âš ï¸  Note: Instance counts differ, this might be due to timing or test duration")


class AdvancedKeyExtractor(KeyByFunction):
    """å¤æ‚çš„keyæå–å™¨ï¼Œç”¨äºé«˜çº§æµ‹è¯•"""
    
    def execute(self, data: Any) -> str:
        # åŸºäºç”¨æˆ·IDå’Œæ¶ˆæ¯IDçš„ç»„åˆç”Ÿæˆkey
        key = f"{data['user_id']}_{data['id'] % 2}"
        self.logger.info(f"Advanced key extraction: {key} from {data}")
        return key


class TestAdvancedKeyBy:
    """é«˜çº§KeyByåŠŸèƒ½æµ‹è¯•"""
    
    def setup_method(self):
        ParallelDebugSink.clear_data()
    
    def test_advanced_key_extraction(self):
        """æµ‹è¯•å¤æ‚çš„keyæå–é€»è¾‘"""
        print("\nğŸš€ Testing Advanced Key Extraction")
        
        env = LocalEnvironment("advanced_keyby_test")
        
        result_stream = (
            env.from_source(TestDataSource, delay=0.4)
            .keyby(AdvancedKeyExtractor, strategy="hash")
            .sink(ParallelDebugSink, parallelism=4)  # 4ä¸ªå¹¶è¡Œå®ä¾‹
        )
        
        print("ğŸ“Š Pipeline: TestDataSource -> KeyBy(AdvancedKeyExtractor) -> ParallelDebugSink(parallelism=4)")
        print("ğŸ¯ Key format: 'user_id + message_id%2' (e.g., 'user1_0', 'user1_1')\n")
        
        try:
            env.submit()
            # env.run_streaming()
            time.sleep(3)
        finally:
            env.close()
        
        self._analyze_advanced_distribution()
    
    def _analyze_advanced_distribution(self):
        """åˆ†æé«˜çº§keyæå–çš„åˆ†å¸ƒæ•ˆæœ"""
        received_data = ParallelDebugSink.get_received_data()
        
        print("\nğŸ“‹ Advanced Key Distribution Analysis:")
        print("=" * 50)
        
        key_distribution = {}
        for instance_id, data_list in received_data.items():
            print(f"\nğŸ”¹ Parallel Instance {instance_id}:")
            
            for data in data_list:
                key = f"{data['user_id']}_{data['id'] % 2}"
                if key not in key_distribution:
                    key_distribution[key] = set()
                key_distribution[key].add(instance_id)
                print(f"   - Key '{key}': {data['content']}")
        
        print(f"\nğŸ¯ Key-to-Instance Mapping:")
        for key, instances in key_distribution.items():
            print(f"   - Key '{key}': routed to instance(s) {instances}")
        
        # éªŒè¯ä¸€è‡´æ€§ï¼šç›¸åŒkeyåº”è¯¥è·¯ç”±åˆ°ç›¸åŒå®ä¾‹
        for key, instances in key_distribution.items():
            assert len(instances) == 1, (
                f"âŒ Key '{key}' was routed to multiple instances: {instances}"
            )
        
        print("âœ… Advanced key extraction test passed: Each unique key consistently routed")


if __name__ == "__main__":
    # å¯ä»¥ç›´æ¥è¿è¡Œå•ä¸ªæµ‹è¯•
    test = TestKeyByFunctionality()
    test.setup_method()
    test.test_keyby_hash_partitioning()


'''
# è¿è¡Œæ‰€æœ‰KeyByæµ‹è¯•
pytest tests/test_keyby_functionality.py -v -s

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_keyby_functionality.py::TestKeyByFunctionality::test_keyby_hash_partitioning -v -s


'''