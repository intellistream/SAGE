# SAGE Cluster Configuration
# ==============================================================================
#
# Location: <project_root>/config/cluster.yaml
# Edit this file to configure your cluster nodes, SSH, and Ray settings.
#
# Documentation: https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/on-premises.html
# ==============================================================================

# ------------------------------------------------------------------------------
# Cluster Identity
# ------------------------------------------------------------------------------
cluster_name: sage-cluster
max_workers: 10

# ------------------------------------------------------------------------------
# Provider Configuration (On-Premise)
# ------------------------------------------------------------------------------
provider:
  type: local

  # Head node IP (where Ray GCS runs)
  # sage1 is the current primary node
  head_ip: 10.0.1.18

  # Worker node IPs
  worker_ips:
  - 10.0.1.10   # sage2
  - 10.0.1.6    # sage3
  - 10.0.1.8    # sage4

# ------------------------------------------------------------------------------
# SSH Authentication
# ------------------------------------------------------------------------------
# IMPORTANT: Use SSH key authentication, NOT passwords!
# Setup: ssh-keygen && ssh-copy-id user@host
auth:
  ssh_user: shuhao
  ssh_private_key: ~/.ssh/id_rsa
  connect_timeout: 10

# ------------------------------------------------------------------------------
# Ray Configuration
# ------------------------------------------------------------------------------
ray:
  head_port: 6379
  dashboard_port: 8265
  dashboard_host: 0.0.0.0
  temp_dir: /tmp/ray

  # Optional: Resource overrides
  # head_resources:
  #   CPU: 4
  #   memory: 8589934592  # 8GB
  # worker_resources:
  #   CPU: 8
  #   GPU: 1

# ------------------------------------------------------------------------------
# Remote Environment
# ------------------------------------------------------------------------------
remote:
  conda_env: sage
  sage_home: /home/shuhao/SAGE
  auto_sync_ray_version: true
  # python_path: /opt/conda/envs/sage/bin/python  # Auto-detected
  # ray_command: /opt/conda/envs/sage/bin/ray     # Auto-detected

# ------------------------------------------------------------------------------
# Worker Configuration
# ------------------------------------------------------------------------------
worker:
  log_dir: /tmp/sage_worker_logs
  bind_host: 0.0.0.0

# ------------------------------------------------------------------------------
# JobManager
# ------------------------------------------------------------------------------
jobmanager:
  port: 19001
  timeout: 30
  retry_attempts: 3

# ------------------------------------------------------------------------------
# Output Settings
# ------------------------------------------------------------------------------
output:
  format: table  # table, json, yaml
  colors: true

monitor:
  refresh_interval: 5

# ------------------------------------------------------------------------------
# SAGE Studio Deployment
# ------------------------------------------------------------------------------
# Configuration for deploying SAGE Studio to multiple nodes
studio:
  # Enable multi-node deployment
  enabled: true

  # Deployment nodes (subset of cluster nodes or separate servers)
  # If empty, uses head_ip only
  nodes:
  - host: 10.0.1.18       # sage1 (当前主节点)
    role: primary          # Primary node with Cloudflare Tunnel
    port: 5173
    tunnel_domain: studio.sage.org.ai
  - host: 10.0.1.10       # sage2
    role: replica          # Replica nodes (optional, for load balancing)
    port: 5173
  - host: 10.0.1.6        # sage3
    role: replica
    port: 5173
  - host: 10.0.1.8        # sage4
    role: replica
    port: 5173

  # LLM service configuration
  llm:
    enabled: true
    model: Qwen/Qwen2.5-0.5B-Instruct
    # For larger deployments, can use different models per node
    # gpu_memory_utilization: 0.9

  # Embedding service configuration
  embedding:
    enabled: true
    model: BAAI/bge-m3

  # Deployment settings
  deploy:
    branch: main           # Branch to deploy (stable)
    auto_update: false     # Auto-update on push to branch
    health_check_interval: 60  # seconds
