# <div align="center">ğŸ§  SAGE: A Dataflow-Native Framework for LLM Reasoning<div>


SAGE is a dataflow-native reasoning framework built from the ground up to support modular, controllable, and transparent workflows over Large Language Models (LLMs). It addresses common problems in existing LLM-augmented systems (like RAG and Agents), such as hard-coded orchestration logic, opaque execution paths, and limited runtime control. SAGE introduces a dataflow-centric abstraction, modeling reasoning workflows as directed acyclic graphs (DAGs) composed of typed operators.

![](./.github/asset/framework.png)


## ğŸ“¦ Quick Installation

### ğŸš€ ä¸€é”®å®‰è£…ï¼ˆæ¨èï¼‰

æœ€ç®€å•çš„å®‰è£…æ–¹å¼ï¼Œé€‚åˆæ‰€æœ‰ç”¨æˆ·ï¼š

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/intellistream/SAGE.git
cd SAGE

# è¿è¡Œä¸€é”®å®‰è£…è„šæœ¬
./quickstart.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨å¤„ç†æ‰€æœ‰å®‰è£…æ­¥éª¤ï¼ŒåŒ…æ‹¬ï¼š
- ğŸ”„ åˆå§‹åŒ–å’Œæ›´æ–°Gitå­æ¨¡å—ï¼ˆdocs-publicç­‰ï¼‰
- ğŸ ç¯å¢ƒé…ç½®å’ŒCondaç¯å¢ƒåˆ›å»º
- ğŸ“¦ ä¾èµ–å®‰è£…å’Œé¡¹ç›®æ„å»º
- âœ… å®‰è£…éªŒè¯å’Œå¥åº·æ£€æŸ¥

#### ğŸ”§ é«˜çº§å®‰è£…é€‰é¡¹
```bash
# å¼€å‘æ¨¡å¼å®‰è£…ï¼ˆé»˜è®¤ï¼‰
./quickstart.sh --dev

# ç”Ÿäº§æ¨¡å¼å®‰è£…
./quickstart.sh --prod

# é‡æ–°å®‰è£…
./quickstart.sh --reinstall

# å¼ºåˆ¶æ›´æ–°æ‰€æœ‰å­æ¨¡å—
./quickstart.sh --update-submodules
```

#### ğŸ“š å­æ¨¡å—ç®¡ç†
å¦‚æœéœ€è¦å•ç‹¬ç®¡ç†Gitå­æ¨¡å—ï¼ˆå¦‚docs-publicæ–‡æ¡£ä»“åº“ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ä¸“é—¨çš„ç®¡ç†å·¥å…·ï¼š

```bash
# æŸ¥çœ‹å­æ¨¡å—çŠ¶æ€
./scripts/submodule_manager.sh status

# æ›´æ–°æ–‡æ¡£å­æ¨¡å—
./scripts/submodule_manager.sh docs-update

# æŸ¥çœ‹æ›´å¤šé€‰é¡¹
./scripts/submodule_manager.sh help
```

### ğŸƒ ä» PyPI å®‰è£…

#### ğŸ¯ æ¨èï¼šä½¿ç”¨å®‰è£…å‘å¯¼ (æœ€ç®€å•)
```bash
# å®‰è£…åŸºç¡€åŒ…å¹¶å¯åŠ¨å®‰è£…å·¥å…·
pip install isage
sage-install

# æˆ–è€…ä¸€æ­¥åˆ°ä½ï¼ˆæ¨èï¼‰
pip install isage && sage-install
```
å®‰è£…å·¥å…·ä¼šå¸®æ‚¨ï¼š
- âœ… éªŒè¯SAGEå®‰è£…çŠ¶æ€
- ğŸ”— æ£€æŸ¥JobManagerè¿æ¥
- ğŸš€ æä¾›å¯åŠ¨æŒ‡å¯¼
- ï¿½ æ˜¾ç¤ºæ•…éšœæ’é™¤å»ºè®®
- ğŸ§ª éªŒè¯å®‰è£…ç»“æœ
- ğŸ“š æä¾›åç»­æŒ‡å¯¼

#### æ‰‹åŠ¨å®‰è£…é€‰é¡¹
```bash
# æ ¸å¿ƒæ¡†æ¶ (æœ€å°å®‰è£…)
pip install isage

# åŸºç¡€å·¥å…·åŒ… (CLIå¢å¼º)
pip install isage[basic]

# å¼€å‘å·¥å…·åŒ… (æµ‹è¯•ã€è°ƒè¯•ã€æ€§èƒ½åˆ†æ)
pip install isage[dev]

# å‰ç«¯åŠŸèƒ½åŒ… (Webç•Œé¢ã€ä»ªè¡¨æ¿)
pip install isage[frontend]

# ä¼ä¸šç‰ˆåŠŸèƒ½ (é«˜æ€§èƒ½è®¡ç®—ã€å•†ä¸šç‰¹æ€§)
pip install isage[enterprise]

# æ–‡æ¡£ç”Ÿæˆå·¥å…·
pip install isage[docs]

# å®Œæ•´å®‰è£… (æ‰€æœ‰åŠŸèƒ½)
pip install isage[all]
```

#### å•ç‹¬ç»„ä»¶å®‰è£…
```bash
# ä»…å®‰è£…åŸºç¡€å·¥å…·å’ŒCLI
pip install isage-common

# ä»…å®‰è£…æ ¸å¿ƒè®¡ç®—å¼•æ“
pip install isage-kernel

# ä»…å®‰è£…ä¸­é—´ä»¶æœåŠ¡
pip install isage-middleware

# ä»…å®‰è£…åº”ç”¨ç¨‹åºæ¡†æ¶
pip install isage-apps
```
```

#### å¿«é€Ÿå¼€å§‹
```bash
# å®‰è£…å®Œæ•´å¼€å‘ç¯å¢ƒ
pip install isage isage-common[full]

# éªŒè¯å®‰è£…
sage --help
sage-dev --help
```

ğŸ“– é‡åˆ°é—®é¢˜å¯æŸ¥çœ‹ [åœ¨çº¿æ–‡æ¡£](https://intellistream.github.io/SAGE-Pub/)

## ğŸ› ï¸ SAGE Development Toolkit

The SAGE Development Toolkit provides unified development tools for the SAGE project. It integrates various development utilities into a single, easy-to-use command-line interface.

### Quick Start

```bash
# Install the toolkit
pip install intellistream-sage-dev-toolkit

# Show all available commands
sage-dev --help

# Check toolkit status
sage-dev status

# Run tests on changed files
sage-dev test --mode diff

# Update VS Code paths
sage-dev update-vscode
```

### ğŸ¯ User-Friendly CLI Commands

SAGE provides intuitive standalone CLI commands with tab completion support:

```bash
# JobManager (supports tab completion)
sage-jobmanager start    # Start JobManager
sage-jobmanager status   # Check status

# Cluster management
sage-cluster start       # Start cluster
sage-cluster scale       # Scale cluster

# Job management  
sage-job submit job.py   # Submit job
sage-job status          # Check job status

# Other tools
sage-worker start        # Start worker node
sage-head start          # Start head node
sage-config show         # Show configuration
```

ğŸ’¡ **Tip**: Use `sage-<TAB>` to see all available standalone commands!

### Available Commands

- `sage-dev test` - Intelligent test execution with parallel support
- `sage-dev analyze` - Comprehensive dependency analysis  
- `sage-dev package` - Package management across SAGE ecosystem
- `sage-dev report` - Generate development reports
- `sage-dev fix-imports` - Fix import paths automatically
- `sage-dev update-vscode` - Update VS Code Python configurations
- `sage-dev setup-test` - One-click environment setup and testing
- `sage-dev list-tests` - List all available tests

For detailed documentation, see [dev-toolkit/README.md](dev-toolkit/README.md).


## âœ¨ Features

- ğŸ§© **Declarative & Modular Composition**: Build complex reasoning pipelines from typed, reusable operators. The dataflow graph cleanly separates what to compute from how to compute it.

- ğŸ”€ **Unified Data and Control Flow**: Express conditional branching, tool routing, and fallback logic declaratively within the graph structure, eliminating brittle, imperative control code.

- ğŸ’¾ **Native Stateful Operators**: Memory is a first-class citizen. Model session, task, and long-term memory as stateful nodes directly within the graph for persistent, context-aware computation.

- âš¡ **Asynchronous & Resilient Runtime**: The engine executes DAGs asynchronously in a non-blocking, data-driven manner. It features stream-aware queues, event-driven scheduling, and built-in backpressure to handle complex workloads gracefully.

- ğŸ“Š **Built-in Observability & Introspection**: An interactive dashboard provides runtime instrumentation out-of-the-box. Visually inspect execution graphs, monitor operator-level metrics, and debug pipeline behavior in real-time.

## æ–‡æ¡£ä¿¡æ¯

é˜…è¯»æ–‡æ¡£è¯·referåˆ° [https://intellistream.github.io/SAGE-Pub/](https://intellistream.github.io/SAGE-Pub/)

ç»´æŠ¤æ–‡æ¡£è¯·referåˆ° [https://github.com/intellistream/SAGE-Pub](https://github.com/intellistream/SAGE-Pub)

##  Quick Start
### ğŸ§  Memory Toolkit

SAGE provides a comprehensive memory management system with a lightweight in-memory vector database (VDB) supporting text embeddings, vector indexing, multi-index management, metadata filtering, persistence to disk, and recovery. The memory system is a first-class citizen in SAGE's dataflow architecture.

---

#### (1). Initialize Memory Manager and Vector Database

```python
from sage.middleware.services.memory.memory_manager import MemoryManager
from sage.middleware.utils.embedding.embedding_api import apply_embedding_model

# Create memory manager with default or custom data directory
mgr = MemoryManager()

# Apply embedding model (supports various models including OpenAI, HuggingFace, etc.)
embedder = apply_embedding_model("default")  # or specify model like "openai" or "huggingface"
dim = embedder.get_dim()

# Create a vector database collection
col = mgr.create_collection(
    name="test_vdb",
    backend_type="VDB",                    # Vector Database
    description="Test vector database collection",
    embedding_model=embedder,
    dim=dim
)
```

#### (2). Insert Text Entries with Rich Metadata

```python
# Add metadata fields for structured filtering
col.add_metadata_field("tag")
col.add_metadata_field("category") 
col.add_metadata_field("source")

# Insert documents with associated metadata
col.insert("Artificial Intelligence is transforming industries worldwide", {
    "tag": "technology", 
    "category": "AI",
    "source": "research_paper"
})
col.insert("Machine Learning algorithms learn from data patterns", {
    "tag": "technology", 
    "category": "ML",
    "source": "textbook"
})
col.insert("Deep learning uses neural networks with multiple layers", {
    "tag": "technology", 
    "category": "DL", 
    "source": "tutorial"
})
```

#### (3). Create Multiple Indexes with Filtering

```python
# Create global index for all documents
col.create_index("global_index")

# Create filtered indexes based on metadata
col.create_index("ai_index", metadata_filter_func=lambda m: m.get("category") == "AI")
col.create_index("tech_index", metadata_filter_func=lambda m: m.get("tag") == "technology")
```

#### (4). Retrieve Similar Vectors with Smart Querying

```python
# Retrieve from global index
global_results = col.retrieve("What is artificial intelligence?", topk=3, index_name="global_index")

# Retrieve from filtered index
ai_results = col.retrieve("AI applications", topk=5, index_name="ai_index")

# Display results with similarity scores and metadata
for result in global_results:
    print(f"Text: {result['text']}")
    print(f"Metadata: {result['metadata']}")
    print(f"Score: {result.get('score', 'N/A')}")
```

#### (5). Persist and Manage Collections

```python
# Save collection to persistent storage
mgr.store_collection()
print(f"Collection saved to: {mgr.data_dir}")

# List all available collections
available_collections = mgr.list_collections()
print(f"Available collections: {available_collections}")
```

#### (6). Reload and Connect to Persisted Collections

```python
# Create new manager instance
mgr2 = MemoryManager()

# Reconnect to existing collection (requires compatible embedding model)
embedder2 = apply_embedding_model("default")
col2 = mgr2.connect_collection("test_vdb", embedding_model=embedder2)

# Verify collection is loaded and functional
test_results = col2.retrieve("machine learning", topk=2, index_name="global_index")
print(f"Reconnected collection works: {len(test_results)} results found")
```

#### (7). Advanced Memory Operations

```python
# Update existing documents
col.update("doc_id_1", "Updated content about AI and its applications", {"updated": True})

# Delete specific documents
col.delete("doc_id_2")

# Clear specific collection data
from sage.middleware.services.memory.memory_collection.vdb_collection import VDBMemoryCollection
VDBMemoryCollection.clear("test_vdb", mgr.data_dir)

# Clean up manager metadata
import os
manager_json = os.path.join(mgr.data_dir, "manager.json")
if os.path.exists(manager_json):
    os.remove(manager_json)
```

### ğŸ”§ Step-by-Step: Build a Local RAG Pipeline
SAGE uses a **fluent-style API** to declaratively define RAG pipelines with comprehensive support for memory management, distributed execution, and real-time monitoring.

---

```python
from sage.api.local_environment import LocalEnvironment  # Updated import
from sage.lib.io.source import FileSource
from sage.lib.rag.retriever import DenseRetriever
from sage.lib.rag.promptor import QAPromptor
from sage.lib.rag.generator import OpenAIGenerator
from sage.lib.io.sink import TerminalSink
from sage.utils.config.loader import load_config

# Load configuration
config = load_config("config.yaml")

# Create local execution environment with memory support
env = LocalEnvironment("rag_pipeline")
env.set_memory(config=None)  # Initialize built-in memory system

# Build pipeline using Fluent API with method chaining
query_stream = (env
                .from_source(FileSource, config["source"])
                .map(DenseRetriever, config["retriever"])
                .map(QAPromptor, config["promptor"])
                .map(OpenAIGenerator, config["generator"]["local"])
                .sink(TerminalSink, config["sink"])
                )

# Submit and execute the pipeline
try:
    env.submit()
    print("âœ… Pipeline submitted successfully")
    # Pipeline runs asynchronously - you can do other work here
    
except Exception as e:
    print(f"âŒ Pipeline execution failed: {e}")
```

#### ğŸ“˜ About Configuration

Each operator in the pipeline requires a configuration dictionary that provides runtime parameters, connection details, and behavioral settings. SAGE provides flexible configuration management:

```yaml
# Example config.yaml structure
source:
  file_path: "data/questions.txt"
  batch_size: 10

retriever:
  collection_name: "knowledge_base"
  top_k: 5
  similarity_threshold: 0.7

promptor:
  template: "Answer the question based on context: {context}\nQuestion: {query}\nAnswer:"
  max_context_length: 2000

generator:
  local:
    model: "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 500
  vllm:
    model_path: "/models/llama-7b"
    gpu_memory_utilization: 0.9

sink:
  output_format: "json"
  file_path: "results/answers.json"
```

You can find comprehensive example configurations under [sage-examples/config/](./sage-examples/config/).

#### ğŸ“˜ About Distributed Execution with Ray

SAGE supports seamless scaling from local to distributed execution using Ray:

```python
from sage.api.remote_environment import RemoteEnvironment

# Create distributed environment  
env = RemoteEnvironment("distributed_rag", jobmanager_address="localhost:19001")
env.set_memory(config=config["memory"])

# Same pipeline code works in distributed mode
query_stream = (env
                .from_source(FileSource, config["source"])
                .map(DenseRetriever, config["retriever"])
                .map(QAPromptor, config["promptor"])  
                .map(OpenAIGenerator, config["generator"]["vllm"])
                .sink(TerminalSink, config["sink"])
                )

# Submit to Ray cluster
job_id = env.submit()
print(f"Job submitted with ID: {job_id}")
env.wait_for_completion(job_id)
```

#### ğŸ“˜ About Service Integration

SAGE supports service-oriented architecture with memory services and other specialized services:

```python
from sage.middleware.services.memory import MemoryService

# Register memory service
def memory_service_factory():
    service = MemoryService()
    result = service.create_collection(
        name="qa_collection",
        backend_type="VDB", 
        description="QA pipeline memory"
    )
    return service

env.register_service("memory_service", memory_service_factory)

# Use in pipeline
query_stream = (env
                .from_source(FileSource, config["source"])
                .map(DenseRetriever, config["retriever"])  # Uses registered memory service
                .map(QAPromptor, config["promptor"])
                .map(OpenAIGenerator, config["generator"]["local"])
                .sink(TerminalSink, config["sink"])
                )
```

#### ğŸ“˜ About Production Deployment

For production deployments, SAGE provides:

- **Docker containerization** with `docker-compose` support
- **Kubernetes deployments** with Helm charts
- **Monitoring and observability** via built-in dashboard
- **Auto-scaling** based on workload demands

See more comprehensive examples under [sage-examples/](./sage-examples/) directory.

## ğŸ§© Components

### ğŸ¯ Command-Line Interface (CLI)

SAGE provides a comprehensive CLI system for managing distributed deployments, cluster operations, and job lifecycle:

```bash
# Cluster management (unified approach)
sage cluster start                    # Start entire Ray cluster (Head + Workers)
sage cluster stop                     # Stop entire cluster
sage cluster status                   # Check cluster health and status
sage cluster deploy                   # Deploy SAGE to all worker nodes
sage cluster scale add worker:22      # Dynamic scaling: add worker nodes
sage cluster scale remove worker:22   # Dynamic scaling: remove worker nodes

# System deployment
sage deploy start                      # Start SAGE system (Ray + JobManager)
sage deploy stop                      # Stop system components
sage deploy status                    # Check system health

# Job management
sage job list                         # List all running jobs
sage job show <job_id>                # Show detailed job information
sage job stop <job_id>                # Stop specific job
sage job logs <job_id>                # View job logs

# Individual node management (advanced)
sage head start/stop/status           # Head node management
sage worker start/stop/status         # Worker nodes management
```

**Key CLI Features:**
- **Unified Cluster Management**: Single command to manage entire distributed clusters
- **Automated Deployment**: One-click deployment to multiple worker nodes with SSH
- **Dynamic Scaling**: Add/remove worker nodes without stopping running jobs
- **Health Monitoring**: Real-time status checking and health diagnostics
- **Configuration Management**: Centralized configuration with validation
- **Job Lifecycle Control**: Complete job management from submission to termination

### Operator
SAGE follows a Flink-style pipeline architecture where each `Operator` acts as a modular and composable processing unit. Operators can be chained together using a fluent API to form a streaming data pipeline. Internally, each `Operator` wraps a stateless or stateful `Function` that defines its core logic.

#### ğŸ”§ Supported Operators
| Operator Method | Description                                                                                                    |
| --------------- | -------------------------------------------------------------------------------------------------------------- |
| `from_source()` | Adds a `SourceFunction` to read input data from external systems.                                              |
| `map()`         | Applies a stateless `Function` to each element of the stream, one-to-one transformation.                       |
| `flatmap()`    | Similar to `map()`, but allows one input to emit zero or more outputs (many-to-many).                          |
| `sink()`        | Defines the terminal output of the stream, consuming the final data (e.g., write to terminal, file, database). |

#### ğŸ”§ Supported Function Types

| Function Type         | Description                                                                                                        | Example Usage |
| --------------------- | ------------------------------------------------------------------------------------------------------------------ | ------------- |
| `SourceFunction`      | Entry point of the pipeline. Ingests input data from external sources such as files, APIs, databases, or user queries | `FileSource`, `KafkaSource`, `HFDatasetBatch` |
| `RetrievalFunction`   | Performs dense, sparse, or hybrid retrieval from vector databases, document stores, or knowledge bases based on input queries | `DenseRetriever`, `BM25Retriever`, `HybridRetriever` |
| `RefineFunction`      | Compresses, filters, or optimizes retrieved context to reduce input length for faster and more accurate model inference | `LongRefinerAdapter`, `ContextCompressor` |
| `RerankFunction`      | Reorders retrieved documents using reranker models (e.g., cross-encoder, LLM-based) to improve relevance scoring | `CrossEncoderReranker`, `LLMbasedReranker` |
| `PromptFunction`      | Builds model-ready prompts by formatting queries and context into specific templates or structured formats | `QAPromptor`, `ChatPromptor`, `FewShotPromptor` |
| `GenerationFunction`  | Generates answers using large language models (OpenAI, LLaMA, vLLM, HuggingFace) based on constructed prompts | `OpenAIGenerator`, `VLLMGenerator`, `HuggingFaceGenerator` |
| `AgentFunction`       | Enables multi-step decision-making agents that call tools, APIs, or other services based on reasoning strategies | `AnswerBot`, `SearcherBot`, `ChiefBot` |
| `EvaluateFunction`    | Calculates comprehensive metrics like F1, ROUGE, BLEU, BERTScore for model output evaluation and benchmarking | `F1Evaluate`, `RougeLEvaluate`, `BERTRecallEvaluate` |
| `TransformFunction`   | Handles data transformation, preprocessing, chunking, and format conversion operations | `CharacterSplitter`, `DocumentParser`, `DataNormalizer` |
| `RoutingFunction`     | Implements conditional branching, fallback logic, and dynamic workflow control within pipelines | `ConditionalRouter`, `LoadBalancer`, `FallbackHandler` |
| `SinkFunction`        | Terminal point of the pipeline. Outputs final results to various destinations like terminal, files, databases, or APIs | `TerminalSink`, `FileSink`, `DatabaseSink`, `APISink` |

### Memory
![Memory Architecture](./.github/asset/Memory_framework.png)

SAGE's memory system provides a comprehensive solution for persistent knowledge management, vector storage, and intelligent retrieval:

**Core Features:**
- **Multi-Backend Support**: Vector databases (VDB), key-value stores (KV), and graph databases (Graph)
- **Advanced Indexing**: Multi-index support with metadata filtering and semantic search
- **Persistent Storage**: Automatic serialization, disk persistence, and recovery mechanisms  
- **Service Integration**: Memory-as-a-Service with REST API and pipeline integration
- **Scalable Architecture**: From single-machine to distributed memory clusters

**Supported Operations:**
- Document insertion with rich metadata
- Semantic similarity search and retrieval
- Index management and optimization
- Collection lifecycle management
- Cross-collection queries and federated search

## Engineï¼ˆæ‰§è¡Œå¼•æ“ï¼‰

SAGE Engine is the sophisticated execution component that orchestrates the compilation and execution of dataflow pipelines. It uses a modern layered architecture to transform logical pipelines into optimized physical execution graphs and efficiently execute them across different runtime environments, supporting both local multi-threaded acceleration and distributed execution on platforms like Ray.

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SAGE Engine Architecture                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User API (LocalEnvironment / RemoteEnvironment)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              JobManager (Centralized Orchestration)        â”‚
â”‚  â€¢ Job Lifecycle Management    â€¢ Resource Allocation       â”‚
â”‚  â€¢ Execution Graph Compilation â€¢ Health Monitoring         â”‚
â”‚  â€¢ Distributed Coordination    â€¢ Service Integration       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Execution Runtime                        â”‚
â”‚  LocalEnvironment     â”‚      RemoteEnvironment             â”‚
â”‚  (Multi-threaded)     â”‚      (Ray Distributed)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              ExecutionGraph Compiler                       â”‚
â”‚         (Optimization & Parallelization)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Function Layer     â”‚      Operator Layer                â”‚
â”‚    (Business Logic)   â”‚      (Runtime Execution)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Communication & Memory                         â”‚
â”‚            (Queues, Services, Storage)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

The Engine operates through a well-defined four-phase execution model:

1. **Pipeline Collection & Validation**: Gathers user-defined logical pipelines built through the DataStream API, validates pipeline integrity, and performs dependency analysis

2. **Compilation & Optimization**: Uses the ExecutionGraph system to transform logical pipelines into optimized physical execution graphs with automatic parallelism expansion, operator fusion, and resource allocation

3. **Runtime Scheduling**: Intelligently selects appropriate Runtime (LocalEnvironment/RemoteEnvironment), converts execution graphs into concrete DAG nodes, and handles resource management

4. **Execution Monitoring**: Continuously monitors pipeline execution status, collects comprehensive performance metrics, handles fault recovery, and provides real-time observability

### Key Features

- **Centralized Job Management**: The JobManager acts as a singleton orchestrator, managing job lifecycle, resource allocation, and distributed coordination across the entire cluster
- **Declarative Programming Model**: Users describe "what to compute", Engine handles "how to compute it" with automatic optimization
- **Intelligent Auto-Parallelization**: Automatically determines optimal parallel execution strategies based on data dependencies and resource availability  
- **Platform Agnostic Design**: Same logical pipeline code runs seamlessly on both local and distributed environments without modification
- **Advanced Performance Optimization**: Combines compile-time graph optimization with runtime adaptive tuning for maximum efficiency
- **Comprehensive Fault Tolerance**: Built-in error handling, automatic recovery mechanisms, and checkpoint-restart capabilities
- **Real-time Observability**: Rich monitoring, profiling, and debugging support through integrated dashboard and metrics collection
- **Service-Oriented Architecture**: Native support for microservices integration with automatic service discovery and load balancing

### Execution Environments

**LocalEnvironment**: High-performance single-machine execution with:
- Multi-threaded parallel processing  
- Direct JobManager integration
- Optimized memory management
- Local service integration
- Development and testing support

**RemoteEnvironment**: Distributed execution capabilities with:
- Ray-based cluster computing
- Remote JobManager communication via TCP
- Horizontal scaling across nodes  
- Fault tolerance and high availability
- Production-grade performance
- Automatic resource management

### JobManager Features

The JobManager serves as the central brain of SAGE's distributed system:

- **Job Lifecycle Management**: Complete job submission, execution, monitoring, and cleanup
- **Resource Orchestration**: Intelligent resource allocation and load balancing
- **Health Monitoring**: Real-time health checks and system diagnostics  
- **Service Registry**: Centralized service discovery and management
- **TCP Daemon**: High-performance network communication for remote clients
- **Persistence**: Job state persistence and recovery capabilities

## ğŸ¨ SAGE-Dashboard

<p>With the <strong>SAGE-Dashboard</strong>, you can quickly orchestrate complex LLM applications and monitor them with one click. Our meticulously designed visual interface helps you efficiently build, monitor, and manage sophisticated AI workflows in real-time!</p>

### âœ¨ Advanced Features

- **Real-time DAG Visualization**
  - Interactive rendering of running DAGs (Directed Acyclic Graphs) with live updates
  - Intuitive display of data flows, component dependencies, and execution paths
  - Color-coded status indicators and progress tracking
  - Zoom, pan, and drill-down capabilities for complex workflows

- **Comprehensive Live Monitoring**
  - Real-time resource utilization monitoring (CPU, memory, GPU, network)
  - Operator-level performance metrics with latency heatmaps
  - Queue occupancy, throughput statistics, and bottleneck detection
  - Memory usage patterns and garbage collection insights
  - Error tracking and exception handling visualization

- **Intelligent Drag-and-Drop DAG Construction**
  - Visual pipeline builder with rich component library
  - Smart connector system with type checking and validation
  - Template gallery for common patterns (RAG, agents, evaluation pipelines)
  - Real-time syntax checking and configuration validation
  - One-click deployment from visual design to execution

- **Advanced Analytics & Debugging**
  - Performance profiling with detailed execution traces
  - A/B testing capabilities for pipeline variants
  - Historical performance analysis and trend monitoring
  - Debug mode with step-by-step execution and breakpoints
  - Export capabilities for reports and documentation

- **Multi-tenant & Collaboration Support**
  - User authentication and role-based access control
  - Project workspaces with sharing and collaboration features
  - Version control integration for pipeline definitions
  - Team activity feeds and notification system

<details>
<summary>ğŸ–¼ï¸ Dashboard Screenshots</summary>

 <!-- ![](./.github/asset/UI.png) -->
 <img src="./.github/asset/UI.png" alt="sage-dashboard" width="800"/>
 
 **Key Dashboard Components:**
 - **Pipeline Canvas**: Visual DAG editor with drag-and-drop components
 - **Component Palette**: Library of pre-built operators and functions
 - **Monitoring Panel**: Real-time metrics and performance indicators
 - **Configuration Editor**: YAML/JSON configuration with syntax highlighting
 - **Execution Console**: Live logs and execution status
</details>

#### ğŸš€ Experience the Power of SAGE-Dashboard

Start the integrated development and monitoring environment:

```bash
# Start the backend server
cd frontend/web_ui
python main.py --host 0.0.0.0 --port 8080 --log-level info

# In a new terminal, start the frontend dashboard
cd ../dashboard
npm install
npm start

# Access at http://localhost:4200
```

**Production Deployment:**
```bash
# Build for production
cd frontend/dashboard
npm run build

# Deploy with Docker
docker-compose up -d sage-dashboard
```

The dashboard provides a complete IDE experience for SAGE development, from visual pipeline design to real-time monitoring and debugging.

## âš ï¸ å¿«é€Ÿæ•…éšœæ’é™¤

### 1. PyPI å®‰è£…é—®é¢˜

**å®‰è£…å¤±è´¥æˆ–åŒ…å†²çªï¼Ÿ**
```bash
# æ¨èï¼šä½¿ç”¨äº¤äº’å¼å®‰è£…å‘å¯¼
pip install isage
sage-install

# æˆ–è€…æ‰‹åŠ¨è§£å†³ä¾èµ–é—®é¢˜
pip install --upgrade pip
pip install isage --force-reinstall
```

**å¯¼å…¥é”™è¯¯ï¼Ÿ**
```bash
# éªŒè¯å®‰è£…
python -c "import sage; print('SAGEå®‰è£…æˆåŠŸï¼')"

# æ£€æŸ¥åŒ…ç‰ˆæœ¬
pip list | grep isage
```

### 2. RemoteEnvironment è¿æ¥å¤±è´¥

å¦‚æœé‡åˆ°è¿æ¥é”™è¯¯ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ£€æŸ¥ï¼š

```bash
# 1. æ£€æŸ¥JobManagerçŠ¶æ€
sage jobmanager status

# 2. å¦‚æœæœªå¯åŠ¨ï¼Œå¯åŠ¨JobManager
sage jobmanager start

# 3. é‡æ–°è¿è¡Œæ‚¨çš„ä»£ç 
python your_script.py
```

**å¸¸è§é”™è¯¯è§£å†³**ï¼š
- `Failed to connect to JobManager`: è¿è¡Œ `sage jobmanager start`
- `Permission denied`: æ£€æŸ¥ç«¯å£æƒé™æˆ–ä½¿ç”¨é»˜è®¤ç«¯å£19001
- `Health check failed`: è¿è¡Œ `sage jobmanager restart`

### 3. å¼€å‘ç¯å¢ƒé—®é¢˜

**quickstart.sh å¤±è´¥ï¼Ÿ**
```bash
# æ£€æŸ¥Condaç¯å¢ƒ
conda info

# æ‰‹åŠ¨åˆ›å»ºç¯å¢ƒ
conda create -n sage-dev python=3.11 -y
conda activate sage-dev
./quickstart.sh
```

**æ„å»ºé”™è¯¯ï¼Ÿ**
```bash
# æ¸…ç†å¹¶é‡æ–°æ„å»º
./quickstart.sh --clean
```

### 4. ä¼ä¸šåŠŸèƒ½é—®é¢˜

**è®¸å¯è¯éªŒè¯å¤±è´¥ï¼Ÿ**
```bash
# æ£€æŸ¥è®¸å¯è¯æ–‡ä»¶
sage license check

# é‡æ–°æ¿€æ´»è®¸å¯è¯
sage license activate --key YOUR_LICENSE_KEY
```

**åŠ å¯†é€šä¿¡é—®é¢˜ï¼Ÿ**
```bash
# é‡æ–°ç”ŸæˆSSLè¯ä¹¦
sage ssl-cert generate

# éªŒè¯è¯ä¹¦
sage ssl-cert verify
```

ğŸ“‹ **è·å–å¸®åŠ©**ï¼š
- ğŸ” å®Œæ•´æ•…éšœæ’é™¤æŒ‡å—ï¼š[docs/troubleshooting/](docs/troubleshooting/)
- ï¿½ PyPIå®‰è£…æŒ‡å—ï¼š[docs/PYPI_INSTALLATION_GUIDE.md](docs/PYPI_INSTALLATION_GUIDE.md)
- ï¿½ğŸ› æäº¤BugæŠ¥å‘Šï¼š[GitHub Issues](https://github.com/ShuhuaGao/SAGE/issues)
- ğŸ’¬ ç¤¾åŒºæ”¯æŒï¼š[GitHub Discussions](https://github.com/ShuhuaGao/SAGE/discussions)
- ğŸ“§ ä¼ä¸šæ”¯æŒï¼šenterprise@sage-ai.com

## ğŸ”– License

SAGE is licensed under the [MIT License](./LICENSE).

---

## ğŸ“š Additional Resources

- **Documentation**: [https://intellistream.github.io/SAGE-Pub/](https://intellistream.github.io/SAGE-Pub/)
- **Source Repository**: [https://github.com/intellistream/SAGE-Pub](https://github.com/intellistream/SAGE-Pub)
- **Installation Guide**: [INSTALL_GUIDE.md](INSTALL_GUIDE.md)
- **SAGE Examples**: [sage-examples/](./sage-examples/) directory
- **Configuration Samples**: [config/](./config/) directory

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines and join our community:

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/intellistream/SAGE/issues)
- ğŸ’¡ **Feature Requests**: [GitHub Discussions](https://github.com/intellistream/SAGE/discussions)
- ğŸ“– **Documentation**: Help improve our docs and examples
- ğŸš€ **Code Contributions**: Submit pull requests for new features and fixes

---

**Built with â¤ï¸ by the SAGE Team | Transforming AI Application Development**
