#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SAGE Examples æµ‹è¯•çš„ pytest é›†æˆ
å°† examples æµ‹è¯•é›†æˆåˆ°ç°æœ‰çš„ pytest æµ‹è¯•æ¡†æ¶ä¸­
"""

import os
import sys
from pathlib import Path

import pytest
from example_strategies import (
    ExampleEnvironmentManager,
    ExampleTestFilters,
    ExampleTestStrategies,
)
from sage.tools.dev.issues.tests import IssuesTestSuite
from test_examples import ExampleAnalyzer, ExampleTestSuite

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir.parent.parent / "packages" / "sage-tools" / "src"))
sys.path.insert(0, str(current_dir))


class TestExamplesIntegration:
    """Examples æµ‹è¯•é›†æˆåˆ° pytest"""

    @pytest.fixture(scope="function")
    def example_suite(self):
        """åˆ›å»ºç¤ºä¾‹æµ‹è¯•å¥—ä»¶"""
        return ExampleTestSuite()

    @pytest.fixture(scope="class")
    def analyzer(self):
        """åˆ›å»ºç¤ºä¾‹åˆ†æå™¨"""
        return ExampleAnalyzer()

    @pytest.fixture(scope="class")
    def env_manager(self):
        """åˆ›å»ºç¯å¢ƒç®¡ç†å™¨"""
        manager = ExampleEnvironmentManager()
        yield manager
        manager.cleanup()

    @pytest.mark.quick_examples
    def test_examples_discovery(self, analyzer):
        """æµ‹è¯•ç¤ºä¾‹å‘ç°åŠŸèƒ½"""
        examples = analyzer.discover_examples()
        assert len(examples) > 0, "åº”è¯¥å‘ç°è‡³å°‘ä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶"

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸åŒç±»åˆ«çš„ç¤ºä¾‹
        categories = {example.category for example in examples}
        expected_categories = {"tutorials", "apps"}
        assert expected_categories.issubset(
            categories
        ), f"åº”è¯¥åŒ…å«åŸºæœ¬ç±»åˆ«: {expected_categories}"

    @pytest.mark.quick_examples
    @pytest.mark.parametrize("category", ["tutorials", "apps"])
    def test_category_examples(self, analyzer, category):
        """æµ‹è¯•ç‰¹å®šç±»åˆ«çš„ç¤ºä¾‹å‘ç°"""
        # åªæµ‹è¯•å‘ç°åŠŸèƒ½ï¼Œä¸å®é™…æ‰§è¡Œç¤ºä¾‹ï¼ˆé¿å…é•¿æ—¶é—´è¿è¡Œï¼‰
        examples = analyzer.discover_examples()
        category_examples = [e for e in examples if e.category == category]

        # è‡³å°‘åº”è¯¥æœ‰ä¸€äº›ç¤ºä¾‹æ–‡ä»¶
        assert len(category_examples) > 0, f"ç±»åˆ« {category} åº”è¯¥æœ‰ç¤ºä¾‹æ–‡ä»¶"

        # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶çš„åŸºæœ¬å±æ€§
        for example in category_examples:
            assert example.file_path, "ç¤ºä¾‹åº”è¯¥æœ‰æ–‡ä»¶è·¯å¾„"
            assert example.category == category, f"ç¤ºä¾‹ç±»åˆ«åº”è¯¥æ˜¯ {category}"
            assert isinstance(example.imports, list), "ç¤ºä¾‹åº”è¯¥æœ‰å¯¼å…¥åˆ—è¡¨"
            assert isinstance(example.dependencies, list), "ç¤ºä¾‹åº”è¯¥æœ‰ä¾èµ–åˆ—è¡¨"

    @pytest.mark.quick_examples
    def test_tutorials_hello_world(self, example_suite):
        """æµ‹è¯•åŸºç¡€çš„ hello_world ç¤ºä¾‹"""
        # ä¸“é—¨æµ‹è¯•æœ€åŸºç¡€çš„ç¤ºä¾‹
        analyzer = ExampleAnalyzer()
        examples = analyzer.discover_examples()

        hello_world_examples = [
            e
            for e in examples
            if "hello_world" in e.file_path.lower() and e.category == "tutorials"
        ]

        assert len(hello_world_examples) > 0, "åº”è¯¥æ‰¾åˆ° hello_world ç¤ºä¾‹"

        # è¿è¡Œ hello_world ç¤ºä¾‹
        for example in hello_world_examples:
            result = example_suite.runner.run_example(example)
            assert (
                result.status == "passed"
            ), f"hello_world ç¤ºä¾‹åº”è¯¥è¿è¡ŒæˆåŠŸ: {result.error}"

    @pytest.mark.quick_examples
    def test_example_categorization(self, analyzer):
        """æµ‹è¯•ç¤ºä¾‹åˆ†ç±»çš„æ­£ç¡®æ€§"""
        examples = analyzer.discover_examples()

        # æ£€æŸ¥æ¯ä¸ªç¤ºä¾‹æ˜¯å¦è¢«æ­£ç¡®åˆ†ç±»
        for example in examples:
            # ç±»åˆ«åº”è¯¥ä¸ä¸ºç©º
            assert example.category, f"ç¤ºä¾‹ {example.file_path} åº”è¯¥æœ‰ç±»åˆ«"

            # ç±»åˆ«åº”è¯¥ä¸æ–‡ä»¶è·¯å¾„åŒ¹é…
            path_parts = Path(example.file_path).parts
            assert (
                example.category in path_parts
            ), f"ç±»åˆ« {example.category} åº”è¯¥åœ¨è·¯å¾„ä¸­: {example.file_path}"

    @pytest.mark.quick_examples
    def test_dependency_analysis(self, analyzer):
        """æµ‹è¯•ä¾èµ–åˆ†æçš„å‡†ç¡®æ€§"""
        examples = analyzer.discover_examples()

        for example in examples:
            # æ£€æŸ¥å¯¼å…¥åˆ†æ
            assert isinstance(example.imports, list), "imports åº”è¯¥æ˜¯åˆ—è¡¨"
            assert isinstance(example.dependencies, list), "dependencies åº”è¯¥æ˜¯åˆ—è¡¨"

            # SAGEç›¸å…³çš„å¯¼å…¥åº”è¯¥è¢«æ­£ç¡®è¯†åˆ«
            sage_imports = [imp for imp in example.imports if imp.startswith("sage")]
            if sage_imports:
                # å¦‚æœæœ‰SAGEå¯¼å…¥ï¼Œæ–‡ä»¶åº”è¯¥è¢«è¯†åˆ«ä¸ºæœ‰ä¸»å‡½æ•°
                assert (
                    example.has_main or len(sage_imports) > 0
                ), "æœ‰SAGEå¯¼å…¥çš„æ–‡ä»¶åº”è¯¥æœ‰å¯æ‰§è¡Œå†…å®¹"

    def test_environment_setup(self, env_manager):
        """æµ‹è¯•ç¯å¢ƒè®¾ç½®åŠŸèƒ½"""
        categories = ["tutorials", "rag", "memory"]

        for category in categories:
            env = env_manager.setup_category_environment(category)

            # æ£€æŸ¥åŸºæœ¬ç¯å¢ƒå˜é‡
            assert "SAGE_TEST_MODE" in env, f"ç±»åˆ« {category} åº”è¯¥è®¾ç½®æµ‹è¯•æ¨¡å¼"
            assert "PYTHONPATH" in env, f"ç±»åˆ« {category} åº”è¯¥è®¾ç½® Python è·¯å¾„"

            # æ£€æŸ¥ç±»åˆ«ç‰¹å®šçš„è®¾ç½®
            strategy = ExampleTestStrategies.get_strategies().get(category)
            if strategy and strategy.environment_vars:
                for key in strategy.environment_vars:
                    assert key in env, f"ç±»åˆ« {category} åº”è¯¥åŒ…å«ç¯å¢ƒå˜é‡ {key}"

    @pytest.mark.quick_examples
    def test_skip_filters(self, analyzer):
        """æµ‹è¯•è·³è¿‡è¿‡æ»¤å™¨"""
        # ä½¿ç”¨çœŸå®çš„ç¤ºä¾‹æ–‡ä»¶è·¯å¾„è¿›è¡Œæµ‹è¯•
        examples = analyzer.discover_examples()

        # æ‰¾åˆ°ä¸€äº›çœŸå®çš„ç¤ºä¾‹ç”¨äºæµ‹è¯•
        hello_world_examples = [e for e in examples if "hello_world" in e.file_path]
        [e for e in examples if e.category == "rag"]

        # æµ‹è¯• hello_world ç¤ºä¾‹ä¸åº”è¯¥è¢«è·³è¿‡
        if hello_world_examples:
            example = hello_world_examples[0]
            skip, reason = ExampleTestFilters.should_skip_file(
                Path(example.file_path), example.category, example
            )
            assert not skip, f"æ–‡ä»¶ {example.file_path} ä¸åº”è¯¥è¢«è·³è¿‡: {reason}"

        # æµ‹è¯•ä¸€èˆ¬çš„è¿‡æ»¤é€»è¾‘
        # æ³¨æ„ï¼šshould_skip_file åªæ£€æŸ¥æµ‹è¯•æ ‡è®°ï¼Œä¸æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥åº”è¯¥åœ¨æ”¶é›†ç¤ºä¾‹æ—¶å®Œæˆ

        # æµ‹è¯•åŸºäºæ ‡è®°çš„è·³è¿‡é€»è¾‘ï¼ˆéœ€è¦å®é™…çš„ example_infoï¼‰
        # è¿™é‡Œåªæµ‹è¯•ä¸å¸¦ example_info çš„åŸºæœ¬æƒ…å†µï¼ˆåº”è¯¥ä¸è·³è¿‡ï¼‰
        test_cases = [
            (Path("examples/rag/simple_rag.py"), "rag", False),
            (Path("examples/tutorials/hello_world.py"), "tutorials", False),
        ]

        for file_path, category, should_skip in test_cases:
            skip, reason = ExampleTestFilters.should_skip_file(
                file_path, category, None
            )
            if should_skip:
                assert skip, f"æ–‡ä»¶ {file_path} åº”è¯¥è¢«è·³è¿‡: {reason}"
            else:
                assert not skip, f"æ–‡ä»¶ {file_path} ä¸åº”è¯¥è¢«è·³è¿‡ä½†è¢«è·³è¿‡äº†: {reason}"

    @pytest.mark.integration
    @pytest.mark.skipif(
        not any(
            os.getenv(var) for var in ["GITHUB_TOKEN", "GIT_TOKEN", "SAGE_REPO_TOKEN"]
        ),
        reason="éœ€è¦ GitHub token (GITHUB_TOKEN, GIT_TOKEN æˆ– SAGE_REPO_TOKEN) æ‰èƒ½è¿è¡Œæ­¤æµ‹è¯•",
    )
    def test_examples_integration_with_issues_manager(self):
        """æµ‹è¯•ä¸ Issues ç®¡ç†å™¨çš„é›†æˆ

        æ³¨æ„ï¼šæ­¤æµ‹è¯•éœ€è¦ GitHub token æ‰èƒ½è¿è¡Œã€‚
        å¦‚æœæ²¡æœ‰è®¾ç½® GITHUB_TOKENã€GIT_TOKEN æˆ– SAGE_REPO_TOKENï¼Œ
        æµ‹è¯•å°†è‡ªåŠ¨è·³è¿‡ã€‚
        """
        print("ğŸ§ª å¼€å§‹é›†æˆæµ‹è¯•: test_examples_integration_with_issues_manager")

        # è¿™ä¸ªæµ‹è¯•éªŒè¯ examples æµ‹è¯•å¯ä»¥ä¸ç°æœ‰çš„é—®é¢˜ç®¡ç†ç³»ç»Ÿé›†æˆ
        try:
            issues_suite = IssuesTestSuite()

            print(f"\nğŸ“‚ å…ƒæ•°æ®ç›®å½•: {issues_suite.manager.metadata_dir}")
            print(f"ğŸ“‚ å·¥ä½œç›®å½•: {issues_suite.manager.workspace_dir}")

            # éªŒè¯ token å·²åŠ è½½
            if not issues_suite.manager.config.github_token:
                pytest.fail("GitHub token æœªèƒ½æ­£ç¡®åŠ è½½åˆ° IssuesTestSuite ä¸­")
                return

            # å¦‚æœå›¢é˜Ÿä¿¡æ¯æœªæ‰¾åˆ°ï¼Œå°è¯•æ›´æ–°
            if not issues_suite.manager.team_info:
                print("\nğŸ“‹ å›¢é˜Ÿä¿¡æ¯æœªæ‰¾åˆ°ï¼Œæ­£åœ¨æ›´æ–°...")
                success = issues_suite.manager.update_team_info()

                if not success:
                    pytest.fail(
                        "âŒ æ— æ³•è·å–å›¢é˜Ÿä¿¡æ¯ã€‚\n"
                        f"GitHub Token æ¥æº: {issues_suite.manager.config.github_token_env}\n"
                        "è¯·æ£€æŸ¥:\n"
                        "  1. Token æƒé™æ˜¯å¦æ­£ç¡® (éœ€è¦ read:org æƒé™)\n"
                        "  2. æ˜¯å¦æœ‰è®¿é—® intellistream ç»„ç»‡çš„æƒé™\n"
                        "  3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸"
                    )

                # é‡æ–°åŠ è½½å›¢é˜Ÿä¿¡æ¯
                issues_suite.manager.team_info = issues_suite.manager._load_team_info()

                if not issues_suite.manager.team_info:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
                    team_config_path = (
                        issues_suite.manager.metadata_dir / "team_config.py"
                    )
                    if team_config_path.exists():
                        print(f"âš ï¸ team_config.py å­˜åœ¨ä½†åŠ è½½å¤±è´¥: {team_config_path}")
                        # è¯»å–æ–‡ä»¶å†…å®¹æŸ¥çœ‹
                        with open(team_config_path, "r") as f:
                            content = f.read()
                            print(f"æ–‡ä»¶å†…å®¹ (å‰ 500 å­—ç¬¦):\n{content[:500]}")

                    pytest.fail(
                        "âŒ æ›´æ–°å›¢é˜Ÿä¿¡æ¯åä»ç„¶æ— æ³•åŠ è½½ã€‚\n"
                        f"å…ƒæ•°æ®ç›®å½•: {issues_suite.manager.metadata_dir}\n"
                        f"team_config.py å­˜åœ¨: {team_config_path.exists()}\n"
                        "è¯·æ£€æŸ¥æ–‡ä»¶å†™å…¥æƒé™å’Œ Python æ¨¡å—å¯¼å…¥"
                    )

                print(
                    f"âœ… æˆåŠŸåŠ è½½å›¢é˜Ÿä¿¡æ¯ ({len(issues_suite.manager.team_info.get('all_usernames', []))} ä½æˆå‘˜)"
                )
            else:
                print(
                    f"âœ… å›¢é˜Ÿä¿¡æ¯å·²å­˜åœ¨ ({len(issues_suite.manager.team_info.get('all_usernames', []))} ä½æˆå‘˜)"
                )

        except Exception:
            import traceback

            pytest.fail(f"IssuesTestSuiteåˆå§‹åŒ–å¤±è´¥:\n{traceback.format_exc()}")

        example_suite = ExampleTestSuite()

        # åªè¿è¡Œåˆ†æï¼Œä¸å®é™…æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆé¿å…é‡å¤ï¼‰
        analyzer = ExampleAnalyzer()
        examples = analyzer.discover_examples()

        # éªŒè¯åŸºç¡€åŠŸèƒ½
        assert len(examples) > 0, "åº”è¯¥èƒ½å¤Ÿå‘ç°ç¤ºä¾‹æ–‡ä»¶"

        # æµ‹è¯•ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼ˆä¸æ˜¯å…¨éƒ¨ï¼‰
        quick_examples = [e for e in examples if "hello_world" in e.file_path]
        if quick_examples:
            result = example_suite.runner.run_example(quick_examples[0])
            # éªŒè¯ç»“æœæ ¼å¼æ­£ç¡®
            assert hasattr(result, "status"), "ç»“æœåº”è¯¥æœ‰statuså±æ€§"
            assert hasattr(result, "execution_time"), "ç»“æœåº”è¯¥æœ‰execution_timeå±æ€§"


# å•ç‹¬çš„æµ‹è¯•æ ‡è®°
pytestmark = [pytest.mark.examples, pytest.mark.integration]


# é¢å¤–çš„æµ‹è¯•ç”¨ä¾‹ - åŸºäºå‘ç°çš„ç¤ºä¾‹æ–‡ä»¶åŠ¨æ€ç”Ÿæˆ
class TestIndividualExamples:
    """ä¸ºæ¯ä¸ªç¤ºä¾‹æ–‡ä»¶ç”Ÿæˆç‹¬ç«‹çš„æµ‹è¯•"""

    def test_individual_example(self, example_file):
        """æµ‹è¯•å•ä¸ªç¤ºä¾‹æ–‡ä»¶"""
        suite = ExampleTestSuite()

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡
        skip, reason = ExampleTestFilters.should_skip_file(
            Path(example_file.file_path), example_file.category, example_file
        )
        if skip:
            pytest.skip(reason)

        # è¿è¡Œç¤ºä¾‹
        result = suite.runner.run_example(example_file)

        # éªŒè¯ç»“æœ
        if result.status == "skipped":
            pytest.skip(result.error or "Example was skipped")
        elif result.status == "timeout":
            # åœ¨CIç¯å¢ƒä¸­æä¾›æ›´è¯¦ç»†çš„è¶…æ—¶ä¿¡æ¯
            if os.environ.get("CI") == "true":
                pytest.fail(
                    f"Example timed out after {suite.runner._get_test_timeout(example_file)}s: {result.error}\n"
                    f"File: {example_file.file_path}\n"
                    f"Category: {example_file.category}\n"
                    f"Estimated runtime: {example_file.estimated_runtime}\n"
                    f"Test tags: {example_file.test_tags}\n"
                    f"Execution time: {result.execution_time:.2f}s\n"
                    f"Output: {result.output[:2000] if result.output else 'No output captured'}\n"
                    f"Error: {result.error}"
                )
            else:
                pytest.fail(f"Example timed out: {result.error}")
        elif result.status == "failed":
            # å¯¹äºæŸäº›ç±»å‹çš„å¤±è´¥ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦æ›´å®½æ¾çš„å¤„ç†
            if example_file.category == "rag" and "API key" in (result.error or ""):
                pytest.skip("Missing API key for RAG example")
            else:
                # åœ¨CIç¯å¢ƒä¸­æä¾›æ›´è¯¦ç»†çš„å¤±è´¥ä¿¡æ¯
                if os.environ.get("CI") == "true":
                    pytest.fail(
                        f"Example failed: {result.error}\n"
                        f"File: {example_file.file_path}\n"
                        f"Category: {example_file.category}\n"
                        f"Execution time: {result.execution_time:.2f}s\n"
                        f"Test tags: {example_file.test_tags}\n"
                        f"Output: {result.output[:2000] if result.output else 'No output captured'}\n"
                        f"Error: {result.error}"
                    )
                else:
                    pytest.fail(f"Example failed: {result.error}")
        else:
            # æˆåŠŸçš„æƒ…å†µ
            assert result.status == "passed", f"Unexpected status: {result.status}"
