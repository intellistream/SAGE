#!/usr/bin/env python3
"""
Copilot Issuesæ ¼å¼åŒ–å™¨ - æŒ‰å›¢é˜Ÿåˆ†ç»„æ•´ç†opençŠ¶æ€çš„issues
ç”Ÿæˆæ ¼å¼åŒ–æ–‡æ¡£ä¾›Copilotåˆ†æï¼Œå»æ‰ç¡¬ç¼–ç è§„åˆ™
"""

import os
import sys
import json
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict

class CopilotIssueFormatter:
    def __init__(self):
        self.script_dir = Path(__file__).parent
        self.project_root = self.script_dir.parent
        self.workspace_dir = self.project_root / "issues_workspace"
        self.output_dir = self.project_root / "output"
        self.meta_data_dir = self.project_root / "meta-data"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(exist_ok=True)
        
        # åŠ è½½å›¢é˜Ÿé…ç½®
        self.teams = self._load_team_config()
        
    def _load_team_config(self):
        """åŠ è½½å›¢é˜Ÿé…ç½®ä¿¡æ¯"""
        try:
            sys.path.insert(0, str(self.meta_data_dir))
            import team_config
            return team_config.TEAMS
        except ImportError:
            print("âš ï¸ æœªæ‰¾åˆ°å›¢é˜Ÿé…ç½®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œå›¢é˜Ÿæˆå‘˜è·å–è„šæœ¬")
            return {}
    
    def load_open_issues(self, time_filter=None):
        """åŠ è½½æ‰€æœ‰opençŠ¶æ€çš„issuesï¼Œæ”¯æŒæ—¶é—´è¿‡æ»¤
        
        Args:
            time_filter (str): æ—¶é—´è¿‡æ»¤é€‰é¡¹ - 'week', 'month', 'all'
        """
        issues_dir = self.workspace_dir / "issues"
        if not issues_dir.exists():
            print("âŒ Issuesç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½issues")
            return []
        
        # è®¡ç®—æ—¶é—´è¿‡æ»¤çš„èµ·å§‹æ—¥æœŸ
        cutoff_date = None
        if time_filter == 'week':
            cutoff_date = datetime.now() - timedelta(days=7)
            print(f"ğŸ“… åŠ è½½è¿‘ä¸€å‘¨çš„open issues (è‡ª {cutoff_date.strftime('%Y-%m-%d')} èµ·)")
        elif time_filter == 'month':
            cutoff_date = datetime.now() - timedelta(days=30)
            print(f"ğŸ“… åŠ è½½è¿‘ä¸€ä¸ªæœˆçš„open issues (è‡ª {cutoff_date.strftime('%Y-%m-%d')} èµ·)")
        else:
            print(f"ğŸ“… åŠ è½½å…¨éƒ¨open issues")
        
        open_issues = []
        total_open = 0
        filtered_count = 0
        
        for md_file in issues_dir.glob("open_*.md"):
            total_open += 1
            issue_data = self._parse_issue_file(md_file)
            if issue_data:
                # åº”ç”¨æ—¶é—´è¿‡æ»¤
                if cutoff_date and self._should_filter_by_date(issue_data, cutoff_date):
                    filtered_count += 1
                    continue
                open_issues.append(issue_data)
        
        if cutoff_date:
            print(f"ğŸ“Š æ—¶é—´è¿‡æ»¤ç»“æœ: æ€»å…±{total_open}ä¸ªopen issuesï¼Œè¿‡æ»¤æ‰{filtered_count}ä¸ªï¼ŒåŠ è½½äº†{len(open_issues)}ä¸ª")
        else:
            print(f"ğŸ“Š åŠ è½½äº† {len(open_issues)} ä¸ªopençŠ¶æ€çš„issues")
        
        return open_issues
    
    def _should_filter_by_date(self, issue_data, cutoff_date):
        """åˆ¤æ–­issueæ˜¯å¦åº”è¯¥è¢«æ—¶é—´è¿‡æ»¤æ‰"""
        created_at = issue_data.get('created_at', '')
        if not created_at:
            return False  # æ²¡æœ‰åˆ›å»ºæ—¶é—´çš„ä¸è¿‡æ»¤
        
        try:
            # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
            for date_format in ['%Y-%m-%dT%H:%M:%SZ', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d']:
                try:
                    issue_date = datetime.strptime(created_at, date_format)
                    return issue_date < cutoff_date
                except ValueError:
                    continue
            
            # å¦‚æœæ‰€æœ‰æ ¼å¼éƒ½ä¸åŒ¹é…ï¼Œä¸è¿‡æ»¤
            print(f"âš ï¸ æ— æ³•è§£ææ—¥æœŸæ ¼å¼: {created_at}")
            return False
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ—¥æœŸæ—¶å‡ºé”™: {e}")
            return False
    
    def _parse_issue_file(self, md_file):
        """è§£æissue markdownæ–‡ä»¶"""
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–åŸºæœ¬ä¿¡æ¯
            lines = content.split('\n')
            issue_data = {
                'filename': md_file.name,
                'title': '',
                'number': 0,
                'assignee': None,
                'labels': [],
                'created_at': '',
                'author': '',
                'body': '',
                'url': ''
            }
            
            # ä»æ–‡ä»¶åæå–issueå·ç 
            filename = md_file.name
            if filename.startswith('open_') or filename.startswith('closed_'):
                try:
                    # æ ¼å¼: open_136_[Feature]_...
                    parts = filename.split('_')
                    if len(parts) >= 2:
                        issue_data['number'] = int(parts[1])
                except:
                    pass
            
            # è§£æmarkdownå†…å®¹
            current_section = None
            body_lines = []
            collecting_body = False
            
            for i, line in enumerate(lines):
                line = line.strip()
                
                # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œçš„ #ï¼‰
                if line.startswith('# ') and not issue_data['title']:
                    issue_data['title'] = line[2:].strip()
                    continue
                
                # è§£æå…ƒæ•°æ®å­—æ®µ
                if line.startswith('**Issue #**:'):
                    try:
                        issue_data['number'] = int(line.split(':')[1].strip())
                    except:
                        pass
                elif line.startswith('**åˆ›å»ºæ—¶é—´**:') or line.startswith('**åˆ›å»ºè€…**:'):
                    if 'åˆ›å»ºæ—¶é—´' in line:
                        issue_data['created_at'] = line.split(':', 1)[1].strip()
                    elif 'åˆ›å»ºè€…' in line:
                        issue_data['author'] = line.split(':', 1)[1].strip()
                elif line.startswith('**çŠ¶æ€**:'):
                    # å·²ç»ä»æ–‡ä»¶åè·å–çŠ¶æ€
                    pass
                elif line.startswith('**æ›´æ–°æ—¶é—´**:'):
                    # å¯ä»¥å¿½ç•¥æ›´æ–°æ—¶é—´
                    pass
                
                # å¤„ç†åˆ†é…éƒ¨åˆ†
                elif line == '## åˆ†é…ç»™':
                    current_section = 'assignee'
                    continue
                elif current_section == 'assignee' and line and not line.startswith('#'):
                    if line != 'æœªåˆ†é…' and line != 'null':
                        issue_data['assignee'] = line
                    current_section = None
                    continue
                
                # å¤„ç†æ ‡ç­¾éƒ¨åˆ†
                elif line == '## æ ‡ç­¾':
                    current_section = 'labels'
                    continue
                elif current_section == 'labels' and line and not line.startswith('#'):
                    if line.strip():
                        # æ ‡ç­¾å¯èƒ½æ˜¯é€—å·åˆ†éš”çš„
                        labels = [l.strip() for l in line.split(',') if l.strip()]
                        issue_data['labels'].extend(labels)
                    else:
                        current_section = None
                
                # å¤„ç†æè¿°éƒ¨åˆ†
                elif line == '## æè¿°':
                    current_section = 'description'
                    collecting_body = True
                    continue
                elif collecting_body and not line.startswith('#'):
                    body_lines.append(lines[i])  # ä¿æŒåŸå§‹æ ¼å¼åŒ…æ‹¬ç©ºè¡Œ
            
            # è®¾ç½®bodyå†…å®¹
            if body_lines:
                issue_data['body'] = '\n'.join(body_lines).strip()
            
            return issue_data
            
        except Exception as e:
            print(f"âš ï¸ è§£ææ–‡ä»¶ {md_file.name} å¤±è´¥: {e}")
            return None
    
    def group_issues_by_team(self, issues):
        """æŒ‰å›¢é˜Ÿåˆ†ç»„issues"""
        team_issues = defaultdict(list)
        unassigned_issues = []
        external_issues = []
        
        # åˆ›å»ºç”¨æˆ·ååˆ°å›¢é˜Ÿçš„æ˜ å°„
        user_to_team = {}
        for team_name, team_data in self.teams.items():
            for member in team_data.get('members', []):
                username = member.get('username')
                if username:
                    user_to_team[username] = team_name
        
        for issue in issues:
            assignee = issue.get('assignee')
            author = issue.get('author')
            
            # ä¼˜å…ˆæ ¹æ®assigneeåˆ†ç»„
            if assignee and assignee in user_to_team:
                team_issues[user_to_team[assignee]].append(issue)
            # å…¶æ¬¡æ ¹æ®authoråˆ†ç»„
            elif author and author in user_to_team:
                team_issues[user_to_team[author]].append(issue)
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¤–éƒ¨è´¡çŒ®è€…
            elif assignee or author:
                external_issues.append(issue)
            # å®Œå…¨æœªåˆ†é…
            else:
                unassigned_issues.append(issue)
        
        return dict(team_issues), unassigned_issues, external_issues
    
    def generate_team_analysis_document(self, team_name, team_issues, time_filter=None):
        """ä¸ºå•ä¸ªå›¢é˜Ÿç”Ÿæˆåˆ†ææ–‡æ¡£"""
        if not team_issues:
            return ""
        
        team_data = self.teams.get(team_name, {})
        team_display_name = team_data.get('name', team_name)
        team_description = team_data.get('description', '')
        
        # æ—¶é—´èŒƒå›´æè¿°
        time_desc = {
            'week': 'è¿‘ä¸€å‘¨',
            'month': 'è¿‘ä¸€ä¸ªæœˆ',
            None: 'å…¨éƒ¨'
        }.get(time_filter, 'å…¨éƒ¨')
        
        doc = f"""# {team_display_name} - Open Issues åˆ†æ ({time_desc})

## å›¢é˜Ÿä¿¡æ¯
- **å›¢é˜Ÿåç§°**: {team_display_name}
- **å›¢é˜Ÿæè¿°**: {team_description}
- **æˆå‘˜æ•°é‡**: {len(team_data.get('members', []))}
- **æ—¶é—´èŒƒå›´**: {time_desc}
- **å¾…å¤„ç†Issues**: {len(team_issues)}

## å›¢é˜Ÿæˆå‘˜
"""
        
        # åˆ—å‡ºå›¢é˜Ÿæˆå‘˜
        for member in team_data.get('members', []):
            username = member.get('username', 'Unknown')
            # ç»Ÿè®¡è¯¥æˆå‘˜åˆ†é…çš„issues
            member_issues = [issue for issue in team_issues if issue.get('assignee') == username]
            doc += f"- **{username}**: {len(member_issues)} ä¸ªåˆ†é…çš„issues\n"
        
        doc += f"""
## Open Issues è¯¦æƒ… ({len(team_issues)} ä¸ª)

"""
        
        # æŒ‰ä¼˜å…ˆçº§å’Œç±»å‹æ’åº
        sorted_issues = self._sort_issues_by_priority(team_issues)
        
        for i, issue in enumerate(sorted_issues, 1):
            title = issue.get('title', 'No Title')
            number = issue.get('number', 'N/A')
            assignee = issue.get('assignee', 'æœªåˆ†é…')
            author = issue.get('author', 'Unknown')
            labels = issue.get('labels', [])
            created_at = issue.get('created_at', '')
            url = issue.get('url', '')
            body = issue.get('body', '')
            
            # æˆªå–bodyçš„å‰300å­—ç¬¦
            body_preview = body[:300] + "..." if len(body) > 300 else body
            
            doc += f"""### {i}. Issue #{number}: {title}

**åŸºæœ¬ä¿¡æ¯:**
- **URL**: {url}
- **åˆ†é…ç»™**: {assignee}
- **åˆ›å»ºè€…**: {author}
- **åˆ›å»ºæ—¶é—´**: {created_at}
- **æ ‡ç­¾**: {', '.join(labels) if labels else 'æ— '}

**æè¿°é¢„è§ˆ:**
```
{body_preview}
```

---

"""
        
        return doc
    
    def _sort_issues_by_priority(self, issues):
        """æ ¹æ®ä¼˜å…ˆçº§å’Œé‡è¦æ€§æ’åºissues"""
        def get_priority_score(issue):
            score = 0
            title = issue.get('title', '').lower()
            labels = [label.lower() for label in issue.get('labels', [])]
            
            # é«˜ä¼˜å…ˆçº§å…³é”®è¯
            high_priority_keywords = ['critical', 'urgent', 'ç´§æ€¥', 'é‡è¦', 'crash', 'å´©æºƒ', 'bug', 'error', 'é”™è¯¯']
            if any(keyword in title for keyword in high_priority_keywords):
                score += 100
            
            # æ ‡ç­¾ä¼˜å…ˆçº§
            if any(label in ['bug', 'critical', 'high-priority'] for label in labels):
                score += 50
            
            # æ˜¯å¦å·²åˆ†é…
            if issue.get('assignee'):
                score += 10
            
            return score
        
        return sorted(issues, key=get_priority_score, reverse=True)
    
    def generate_comprehensive_analysis_document(self, team_issues, unassigned_issues, external_issues, time_filter=None):
        """ç”Ÿæˆç»¼åˆåˆ†ææ–‡æ¡£"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # æ—¶é—´èŒƒå›´æè¿°
        time_desc = {
            'week': 'è¿‘ä¸€å‘¨',
            'month': 'è¿‘ä¸€ä¸ªæœˆ',
            None: 'å…¨éƒ¨'
        }.get(time_filter, 'å…¨éƒ¨')
        
        doc = f"""# SAGE Project - Open Issues ç»¼åˆåˆ†æ ({time_desc})

**ç”Ÿæˆæ—¶é—´**: {timestamp}
**æ—¶é—´èŒƒå›´**: {time_desc}
**åˆ†æç›®çš„**: ä¸ºCopilotæä¾›ç»“æ„åŒ–çš„issuesæ•°æ®ï¼Œä¾¿äºæ™ºèƒ½åˆ†æå’Œå»ºè®®

## ğŸ“Š æ€»ä½“æ¦‚å†µ

### æ•°æ®ç»Ÿè®¡
- **æ—¶é—´èŒƒå›´**: {time_desc}
- **æ€»è®¡Open Issues**: {sum(len(issues) for issues in team_issues.values()) + len(unassigned_issues) + len(external_issues)}
- **å›¢é˜Ÿåˆ†é…Issues**: {sum(len(issues) for issues in team_issues.values())}
- **æœªåˆ†é…Issues**: {len(unassigned_issues)}
- **å¤–éƒ¨è´¡çŒ®è€…Issues**: {len(external_issues)}

### å›¢é˜Ÿåˆ†å¸ƒ
"""
        
        for team_name, issues in team_issues.items():
            team_display_name = self.teams.get(team_name, {}).get('name', team_name)
            doc += f"- **{team_display_name}**: {len(issues)} ä¸ªissues\n"
        
        doc += """
## ğŸ¯ åˆ†æé‡ç‚¹

è¯·Copiloté‡ç‚¹å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š

1. **ä¼˜å…ˆçº§è¯„ä¼°**: è¯†åˆ«éœ€è¦ç«‹å³å¤„ç†çš„é«˜ä¼˜å…ˆçº§issues
2. **èµ„æºåˆ†é…**: åˆ†æå„å›¢é˜Ÿçš„å·¥ä½œè´Ÿè½½æ˜¯å¦å‡è¡¡
3. **é—®é¢˜åˆ†ç±»**: å°†issuesæŒ‰ç±»å‹åˆ†ç±»ï¼ˆBugä¿®å¤ã€åŠŸèƒ½å¢å¼ºã€æ–‡æ¡£æ”¹è¿›ç­‰ï¼‰
4. **ä¾èµ–å…³ç³»**: è¯†åˆ«issuesä¹‹é—´çš„æ½œåœ¨ä¾èµ–å’Œå…³è”
5. **å·¥ä½œæµç¨‹**: å»ºè®®æ”¹è¿›é¡¹ç›®ç®¡ç†å’Œissueå¤„ç†æµç¨‹
6. **é‡å¤é—®é¢˜**: å‘ç°å¯èƒ½é‡å¤æˆ–ç›¸ä¼¼çš„issues
7. **æ ‡ç­¾ä¼˜åŒ–**: å»ºè®®æ ‡ç­¾ä½¿ç”¨å’Œåˆ†ç±»çš„æ”¹è¿›æ–¹æ¡ˆ

## ğŸ“‹ è¯·Copilotåˆ†æçš„é—®é¢˜

1. å“ªäº›issuesåº”è¯¥ä¼˜å…ˆå¤„ç†ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
2. å„å›¢é˜Ÿçš„å·¥ä½œè´Ÿè½½åˆ†å¸ƒæ˜¯å¦åˆç†ï¼Ÿ
3. æ˜¯å¦å­˜åœ¨é‡å¤æˆ–ç›¸ä¼¼çš„issuesï¼Ÿ
4. å“ªäº›issueså¯èƒ½å­˜åœ¨ä¾èµ–å…³ç³»ï¼Ÿ
5. å½“å‰çš„æ ‡ç­¾åˆ†ç±»æ˜¯å¦æœ‰æ•ˆï¼Ÿå¦‚ä½•ä¼˜åŒ–ï¼Ÿ
6. æœªåˆ†é…çš„issuesåº”è¯¥å¦‚ä½•åˆ†é…ï¼Ÿ
7. æ˜¯å¦æœ‰issueså¯ä»¥åˆå¹¶æˆ–æ‹†åˆ†ï¼Ÿ
8. é¡¹ç›®ç®¡ç†æµç¨‹æœ‰å“ªäº›å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Ÿ

---

"""
        return doc
    
    def generate_formatted_documents(self, output_format='all', time_filter=None):
        """ç”Ÿæˆæ ¼å¼åŒ–æ–‡æ¡£
        
        Args:
            output_format (str): è¾“å‡ºæ ¼å¼é€‰é¡¹
            time_filter (str): æ—¶é—´è¿‡æ»¤é€‰é¡¹ - 'week', 'month', 'all'
        """
        print("ğŸ“Š å¼€å§‹ç”Ÿæˆæ ¼å¼åŒ–issuesæ–‡æ¡£...")
        
        # åŠ è½½open issues withæ—¶é—´è¿‡æ»¤
        issues = self.load_open_issues(time_filter)
        if not issues:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„opençŠ¶æ€issues")
            return False
        
        # æŒ‰å›¢é˜Ÿåˆ†ç»„
        team_issues, unassigned_issues, external_issues = self.group_issues_by_team(issues)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æ ¹æ®æ—¶é—´è¿‡æ»¤æ·»åŠ æ–‡ä»¶ååç¼€
        time_suffix = ""
        if time_filter == 'week':
            time_suffix = "_week"
        elif time_filter == 'month':
            time_suffix = "_month"
        
        generated_files = []
        
        # ç”Ÿæˆç»¼åˆåˆ†ææ–‡æ¡£
        if output_format in ['all', 'comprehensive']:
            comprehensive_doc = self.generate_comprehensive_analysis_document(team_issues, unassigned_issues, external_issues, time_filter)
            comprehensive_file = self.output_dir / f"copilot_comprehensive_analysis{time_suffix}_{timestamp}.md"
            
            with open(comprehensive_file, 'w', encoding='utf-8') as f:
                f.write(comprehensive_doc)
            
            print(f"âœ… ç»¼åˆåˆ†ææ–‡æ¡£: {comprehensive_file}")
            generated_files.append(str(comprehensive_file))
        
        # ç”Ÿæˆå„å›¢é˜Ÿè¯¦ç»†æ–‡æ¡£
        if output_format in ['all', 'teams']:
            for team_name, issues in team_issues.items():
                if issues:  # åªä¸ºæœ‰issuesçš„å›¢é˜Ÿç”Ÿæˆæ–‡æ¡£
                    team_doc = self.generate_team_analysis_document(team_name, issues, time_filter)
                    team_file = self.output_dir / f"copilot_team_{team_name}{time_suffix}_{timestamp}.md"
                    
                    with open(team_file, 'w', encoding='utf-8') as f:
                        f.write(team_doc)
                    
                    print(f"âœ… {team_name} å›¢é˜Ÿæ–‡æ¡£: {team_file}")
                    generated_files.append(str(team_file))
        
        # ç”Ÿæˆæœªåˆ†é…issuesæ–‡æ¡£
        if output_format in ['all', 'unassigned'] and (unassigned_issues or external_issues):
            unassigned_doc = self._generate_unassigned_document(unassigned_issues, external_issues, timestamp, time_filter)
            unassigned_file = self.output_dir / f"copilot_unassigned_issues{time_suffix}_{timestamp}.md"
            
            with open(unassigned_file, 'w', encoding='utf-8') as f:
                f.write(unassigned_doc)
            
            print(f"âœ… æœªåˆ†é…issuesæ–‡æ¡£: {unassigned_file}")
            generated_files.append(str(unassigned_file))
        
        # ç”Ÿæˆä½¿ç”¨æŒ‡å—
        self._generate_usage_guide(generated_files, timestamp, time_filter)
        
        time_desc = {
            'week': 'è¿‘ä¸€å‘¨',
            'month': 'è¿‘ä¸€ä¸ªæœˆ',
            None: 'å…¨éƒ¨'
        }.get(time_filter, 'å…¨éƒ¨')
        
        print(f"\nğŸ‰ æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡æ¡£ (æ—¶é—´èŒƒå›´: {time_desc})")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("1. å…ˆæŸ¥çœ‹ç»¼åˆåˆ†ææ–‡æ¡£è·å¾—æ€»ä½“æ¦‚å†µ")
        print("2. å°†æ–‡æ¡£å†…å®¹å¤åˆ¶åˆ°CopilotèŠå¤©çª—å£")
        print("3. è¯·Copilotåˆ†æå¹¶æä¾›æ”¹è¿›å»ºè®®")
        print("4. æ ¹æ®åˆ†æç»“æœåˆ¶å®šè¡ŒåŠ¨è®¡åˆ’")
        
        return True
    
    def _generate_unassigned_document(self, unassigned_issues, external_issues, timestamp, time_filter=None):
        """ç”Ÿæˆæœªåˆ†é…issuesæ–‡æ¡£"""
        time_desc = {
            'week': 'è¿‘ä¸€å‘¨',
            'month': 'è¿‘ä¸€ä¸ªæœˆ',
            None: 'å…¨éƒ¨'
        }.get(time_filter, 'å…¨éƒ¨')
        
        doc = f"""# æœªåˆ†é…å’Œå¤–éƒ¨è´¡çŒ®è€… Issues ({time_desc})

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ—¶é—´èŒƒå›´**: {time_desc}

## ğŸ“‹ æœªåˆ†é…Issues ({len(unassigned_issues)} ä¸ª)

è¿™äº›issuesæ²¡æœ‰æ˜ç¡®çš„è´Ÿè´£äººï¼Œéœ€è¦å®‰æ’å›¢é˜Ÿå¤„ç†ï¼š

"""
        
        for i, issue in enumerate(unassigned_issues, 1):
            title = issue.get('title', 'No Title')
            number = issue.get('number', 'N/A')
            author = issue.get('author', 'Unknown')
            labels = issue.get('labels', [])
            url = issue.get('url', '')
            body = issue.get('body', '')[:200] + "..." if len(issue.get('body', '')) > 200 else issue.get('body', '')
            
            doc += f"""### {i}. Issue #{number}: {title}

- **URL**: {url}
- **åˆ›å»ºè€…**: {author}
- **æ ‡ç­¾**: {', '.join(labels) if labels else 'æ— '}
- **æè¿°**: {body}

---

"""
        
        doc += f"""
## ğŸŒ å¤–éƒ¨è´¡çŒ®è€…Issues ({len(external_issues)} ä¸ª)

è¿™äº›issuesç”±éå›¢é˜Ÿæˆå‘˜åˆ›å»ºæˆ–åˆ†é…ï¼š

"""
        
        for i, issue in enumerate(external_issues, 1):
            title = issue.get('title', 'No Title')
            number = issue.get('number', 'N/A')
            assignee = issue.get('assignee', 'æœªåˆ†é…')
            author = issue.get('author', 'Unknown')
            labels = issue.get('labels', [])
            url = issue.get('url', '')
            body = issue.get('body', '')[:200] + "..." if len(issue.get('body', '')) > 200 else issue.get('body', '')
            
            doc += f"""### {i}. Issue #{number}: {title}

- **URL**: {url}
- **åˆ†é…ç»™**: {assignee}
- **åˆ›å»ºè€…**: {author}
- **æ ‡ç­¾**: {', '.join(labels) if labels else 'æ— '}
- **æè¿°**: {body}

---

"""
        
        return doc
    
    def _generate_usage_guide(self, generated_files, timestamp, time_filter=None):
        """ç”Ÿæˆä½¿ç”¨æŒ‡å—"""
        time_desc = {
            'week': 'è¿‘ä¸€å‘¨',
            'month': 'è¿‘ä¸€ä¸ªæœˆ',
            None: 'å…¨éƒ¨'
        }.get(time_filter, 'å…¨éƒ¨')
        
        time_suffix = ""
        if time_filter == 'week':
            time_suffix = "_week"
        elif time_filter == 'month':
            time_suffix = "_month"
        
        guide_content = f"""# Copilot Issuesåˆ†æä½¿ç”¨æŒ‡å— ({time_desc})

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ—¶é—´èŒƒå›´**: {time_desc}

## ğŸ“ ç”Ÿæˆçš„æ–‡æ¡£

"""
        
        for file_path in generated_files:
            file_name = Path(file_path).name
            doc_type = "ğŸ“Š ç»¼åˆåˆ†æ" if "comprehensive" in file_name else \
                      "ğŸ‘¥ å›¢é˜Ÿåˆ†æ" if "team_" in file_name else \
                      "ğŸ“‹ æœªåˆ†é…Issues" if "unassigned" in file_name else "ğŸ“„ å…¶ä»–"
            
            guide_content += f"- **{doc_type}**: `{file_name}`\n"
        
        guide_content += f"""
## ğŸ¤– å¦‚ä½•ä½¿ç”¨Copilotåˆ†æ

### æ­¥éª¤1: å¤åˆ¶æ–‡æ¡£å†…å®¹
é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªä¸Šè¿°æ–‡æ¡£ï¼Œå¤åˆ¶å…¶å†…å®¹åˆ°å‰ªè´´æ¿ã€‚

### æ­¥éª¤2: ä¸Copilotå¯¹è¯
åœ¨VS Codeä¸­æ‰“å¼€CopilotèŠå¤©ï¼Œç²˜è´´æ–‡æ¡£å†…å®¹ï¼Œç„¶åæé—®ï¼š

#### å»ºè®®çš„åˆ†æé—®é¢˜ï¼š

**ä¼˜å…ˆçº§å’Œç´§æ€¥æ€§åˆ†æ:**
```
è¯·åˆ†æè¿™äº›open issuesï¼Œè¯†åˆ«å‡ºéœ€è¦ç«‹å³å¤„ç†çš„é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼Œå¹¶è¯´æ˜åŸå› ã€‚
```

**å·¥ä½œè´Ÿè½½å’Œèµ„æºåˆ†é…:**
```
è¯·åˆ†æå„å›¢é˜Ÿçš„å·¥ä½œè´Ÿè½½åˆ†å¸ƒï¼Œæ˜¯å¦å­˜åœ¨ä¸å‡è¡¡çš„æƒ…å†µï¼Ÿå“ªäº›å›¢é˜Ÿå¯èƒ½éœ€è¦æ”¯æ´ï¼Ÿ
```

**é—®é¢˜åˆ†ç±»å’Œæ ‡ç­¾ä¼˜åŒ–:**
```
è¯·å°†è¿™äº›issuesæŒ‰ç±»å‹åˆ†ç±»ï¼ˆBugä¿®å¤ã€åŠŸèƒ½å¢å¼ºã€æ–‡æ¡£æ”¹è¿›ç­‰ï¼‰ï¼Œå¹¶å»ºè®®æ ‡ç­¾ä¼˜åŒ–æ–¹æ¡ˆã€‚
```

**é‡å¤å’Œç›¸ä¼¼æ€§åˆ†æ:**
```
è¯·è¯†åˆ«æ˜¯å¦å­˜åœ¨é‡å¤æˆ–ç›¸ä¼¼çš„issuesï¼Œå“ªäº›å¯ä»¥åˆå¹¶å¤„ç†ï¼Ÿ
```

**ä¾èµ–å…³ç³»åˆ†æ:**
```
è¯·åˆ†æè¿™äº›issuesä¹‹é—´æ˜¯å¦å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œå»ºè®®å¤„ç†é¡ºåºã€‚
```

**é¡¹ç›®ç®¡ç†æ”¹è¿›:**
```
åŸºäºè¿™äº›issuesçš„çŠ¶æ€ï¼Œè¯·å»ºè®®é¡¹ç›®ç®¡ç†æµç¨‹çš„æ”¹è¿›æ–¹æ¡ˆã€‚
```

### æ­¥éª¤3: æ·±å…¥åˆ†æ
æ ¹æ®Copilotçš„åˆæ­¥åˆ†æï¼Œå¯ä»¥è¿›ä¸€æ­¥æé—®ï¼š

- "è¯·è¯¦ç»†åˆ†æXXå›¢é˜Ÿçš„issuesï¼Œç»™å‡ºå…·ä½“çš„å¤„ç†å»ºè®®"
- "è¿™äº›Bugç±»issuesä¸­ï¼Œå“ªäº›å¯èƒ½ç›¸å…³è”ï¼Ÿ"
- "æœªåˆ†é…çš„issuesåº”è¯¥å¦‚ä½•åˆ†é…ç»™åˆé€‚çš„å›¢é˜Ÿï¼Ÿ"
- "è¯·åˆ¶å®šä¸€ä¸ª2å‘¨çš„issueså¤„ç†è®¡åˆ’"

### æ­¥éª¤4: ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’
è®©Copilotå¸®åŠ©ç”Ÿæˆå…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’ï¼š

```
åŸºäºä»¥ä¸Šåˆ†æï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’ï¼ŒåŒ…æ‹¬ï¼š
1. ç«‹å³å¤„ç†çš„é«˜ä¼˜å…ˆçº§issues
2. å„å›¢é˜Ÿçš„ä»»åŠ¡åˆ†é…å»ºè®®
3. æ—¶é—´å®‰æ’å’Œé‡Œç¨‹ç¢‘
4. æµç¨‹æ”¹è¿›æªæ–½
```

## ğŸ’¡ åˆ†ææŠ€å·§

1. **åˆ†å—åˆ†æ**: å¦‚æœissueså¤ªå¤šï¼Œå¯ä»¥å…ˆåˆ†æå•ä¸ªå›¢é˜Ÿï¼Œå†ç»¼åˆ
2. **å¯¹æ¯”åˆ†æ**: æ¯”è¾ƒä¸åŒå›¢é˜Ÿçš„issuesç‰¹ç‚¹å’Œå¤„ç†æ–¹å¼
3. **è¶‹åŠ¿åˆ†æ**: è¯·Copilotåˆ†æissuesçš„åˆ›å»ºè¶‹åŠ¿å’Œç±»å‹åˆ†å¸ƒ
4. **ä¼˜åŒ–å»ºè®®**: é‡ç‚¹å…³æ³¨æµç¨‹å’Œæ•ˆç‡çš„æ”¹è¿›å»ºè®®

## ğŸ”„ åç»­æ›´æ–°

è¦æ›´æ–°åˆ†ææ•°æ®ï¼š
1. é‡æ–°ä¸‹è½½æœ€æ–°çš„issues
2. è¿è¡Œæ­¤è„šæœ¬ç”Ÿæˆæ–°çš„åˆ†ææ–‡æ¡£
3. ä¸Copilotåˆ†æå˜åŒ–å’Œè¶‹åŠ¿

---
*ç”±SAGE Issuesç®¡ç†å·¥å…·è‡ªåŠ¨ç”Ÿæˆ*
"""
        
        guide_file = self.output_dir / f"copilot_usage_guide{time_suffix}_{timestamp}.md"
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        print(f"ğŸ“– ä½¿ç”¨æŒ‡å—: {guide_file}")

def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆæ ¼å¼åŒ–çš„issuesæ–‡æ¡£ä¾›Copilotåˆ†æ")
    parser.add_argument("--format", choices=["all", "comprehensive", "teams", "unassigned"], 
                       default="all", help="ç”Ÿæˆæ–‡æ¡£ç±»å‹")
    parser.add_argument("--team", help="åªç”ŸæˆæŒ‡å®šå›¢é˜Ÿçš„æ–‡æ¡£")
    parser.add_argument("--time", choices=["all", "week", "month"], 
                       default="all", help="æ—¶é—´è¿‡æ»¤é€‰é¡¹: all(å…¨éƒ¨), week(è¿‘ä¸€å‘¨), month(è¿‘ä¸€ä¸ªæœˆ)")
    
    args = parser.parse_args()
    
    formatter = CopilotIssueFormatter()
    
    # å¤„ç†æ—¶é—´è¿‡æ»¤å‚æ•°
    time_filter = None if args.time == "all" else args.time
    
    if args.team:
        # å•ç‹¬ç”ŸæˆæŒ‡å®šå›¢é˜Ÿçš„æ–‡æ¡£
        issues = formatter.load_open_issues(time_filter)
        team_issues, _, _ = formatter.group_issues_by_team(issues)
        
        if args.team in team_issues:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            time_suffix = f"_{args.time}" if args.time != "all" else ""
            
            team_doc = formatter.generate_team_analysis_document(args.team, team_issues[args.team], time_filter)
            team_file = formatter.output_dir / f"copilot_team_{args.team}{time_suffix}_{timestamp}.md"
            
            with open(team_file, 'w', encoding='utf-8') as f:
                f.write(team_doc)
            
            print(f"âœ… {args.team} å›¢é˜Ÿæ–‡æ¡£: {team_file}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°å›¢é˜Ÿ '{args.team}' çš„issues")
    else:
        # ç”ŸæˆæŒ‡å®šæ ¼å¼çš„æ–‡æ¡£
        success = formatter.generate_formatted_documents(args.format, time_filter)
        if not success:
            sys.exit(1)

if __name__ == "__main__":
    main()
