#!/usr/bin/env python3
"""éªŒè¯å…³é”®ä¾èµ–çš„ç‰ˆæœ¬å…¼å®¹æ€§

è¿™ä¸ªè„šæœ¬æ£€æŸ¥ SAGE é¡¹ç›®ä¸­å…³é”®ä¾èµ–åŒ…çš„ç‰ˆæœ¬å…¼å®¹æ€§ï¼Œç‰¹åˆ«æ˜¯ï¼š
- torch å’Œ vllm çš„ç‰ˆæœ¬å…¼å®¹æ€§
- Python ç‰ˆæœ¬è¦æ±‚
- CUDA ç‰ˆæœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰

ç”¨æ³•:
    python tools/install/verify_dependencies.py
    python tools/install/verify_dependencies.py --verbose
"""

import sys
import warnings
from typing import Optional

try:
    from packaging import version
except ImportError:
    print("âš ï¸  packaging æ¨¡å—æœªå®‰è£…ï¼Œæ­£åœ¨å°è¯•å®‰è£…...")
    import subprocess

    subprocess.check_call([sys.executable, "-m", "pip", "install", "packaging"])
    from packaging import version


def get_version_safe(module_name: str) -> Optional[str]:
    """å®‰å…¨åœ°è·å–æ¨¡å—ç‰ˆæœ¬ï¼Œå¦‚æœæ¨¡å—ä¸å­˜åœ¨è¿”å› None"""
    try:
        module = __import__(module_name)
        return getattr(module, "__version__", None)
    except ImportError:
        return None
    except Exception as e:
        warnings.warn(f"è·å– {module_name} ç‰ˆæœ¬æ—¶å‡ºé”™: {e}", stacklevel=2)
        return None


def verify_torch_vllm_compatibility() -> tuple[bool, str]:
    """éªŒè¯ torch å’Œ vllm çš„ç‰ˆæœ¬å…¼å®¹æ€§

    Returns:
        (is_compatible, message): å…¼å®¹æ€§çŠ¶æ€å’Œè¯´æ˜ä¿¡æ¯
    """
    torch_ver_str = get_version_safe("torch")
    vllm_ver_str = get_version_safe("vllm")

    # å¦‚æœ vllm æœªå®‰è£…ï¼Œè¿™æ˜¯å¯é€‰ä¾èµ–ï¼Œä¸æŠ¥é”™
    if vllm_ver_str is None:
        return True, "âš ï¸  vLLM æœªå®‰è£…ï¼ˆå¯é€‰ä¾èµ–ï¼‰"

    # å¦‚æœ torch æœªå®‰è£…ä½† vllm å·²å®‰è£…ï¼Œè¿™æ˜¯ä¸€ä¸ªé—®é¢˜
    if torch_ver_str is None:
        return False, "âŒ vLLM å·²å®‰è£…ä½† torch æœªå®‰è£…"

    # è§£æç‰ˆæœ¬ï¼ˆç§»é™¤ +cpu, +cu118 ç­‰åç¼€ï¼‰
    torch_ver = version.parse(torch_ver_str.split("+")[0])
    vllm_ver = version.parse(vllm_ver_str.split("+")[0])

    # å®šä¹‰ç‰ˆæœ¬å…¼å®¹æ€§è§„åˆ™
    compatibility_rules = [
        {
            "vllm_min": version.parse("0.11.0"),
            "vllm_max": version.parse("0.12.0"),
            "torch_min": version.parse("2.5.0"),
            "description": "vLLM 0.11.x éœ€è¦ torch >= 2.5.0",
        },
        {
            "vllm_min": version.parse("0.10.0"),
            "vllm_max": version.parse("0.11.0"),
            "torch_min": version.parse("2.4.0"),
            "description": "vLLM 0.10.x éœ€è¦ torch >= 2.4.0 (éœ€è¦ torch._inductor.config)",
        },
        {
            "vllm_min": version.parse("0.9.0"),
            "vllm_max": version.parse("0.10.0"),
            "torch_min": version.parse("2.3.0"),
            "description": "vLLM 0.9.x éœ€è¦ torch >= 2.3.0",
        },
        {
            "vllm_min": version.parse("0.4.0"),
            "vllm_max": version.parse("0.9.0"),
            "torch_min": version.parse("2.2.0"),
            "description": "vLLM 0.4.x-0.8.x éœ€è¦ torch >= 2.2.0",
        },
    ]

    # æ£€æŸ¥å…¼å®¹æ€§
    for rule in compatibility_rules:
        if rule["vllm_min"] <= vllm_ver < rule["vllm_max"]:
            if torch_ver < rule["torch_min"]:
                msg = (
                    f"âŒ ç‰ˆæœ¬ä¸å…¼å®¹:\n"
                    f"   vLLM: {vllm_ver_str}\n"
                    f"   Torch: {torch_ver_str}\n"
                    f"   è¦æ±‚: {rule['description']}\n"
                    f"\nä¿®å¤æ–¹æ³•:\n"
                    f"   pip uninstall -y torch torchaudio torchvision vllm\n"
                    f"   pip install vllm=={vllm_ver_str.split('+')[0]}"
                )
                return False, msg
            else:
                msg = (
                    f"âœ… ç‰ˆæœ¬å…¼å®¹:\n"
                    f"   vLLM: {vllm_ver_str}\n"
                    f"   Torch: {torch_ver_str}\n"
                    f"   æ»¡è¶³: {rule['description']}"
                )
                return True, msg

    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„è§„åˆ™ï¼Œç»™å‡ºè­¦å‘Š
    msg = (
        f"âš ï¸  æœªçŸ¥çš„ vLLM ç‰ˆæœ¬:\n"
        f"   vLLM: {vllm_ver_str}\n"
        f"   Torch: {torch_ver_str}\n"
        f"   è¯·éªŒè¯å…¼å®¹æ€§: https://docs.vllm.ai/"
    )
    return True, msg


def verify_torch_inductor() -> tuple[bool, str]:
    """éªŒè¯ torch._inductor.config æ˜¯å¦å¯ç”¨ï¼ˆvLLM 0.10+ éœ€è¦ï¼‰

    Returns:
        (is_available, message): å¯ç”¨æ€§çŠ¶æ€å’Œè¯´æ˜ä¿¡æ¯
    """
    vllm_ver_str = get_version_safe("vllm")

    # å¦‚æœ vllm æœªå®‰è£…æˆ–ç‰ˆæœ¬ < 0.10ï¼Œä¸éœ€è¦æ£€æŸ¥
    if vllm_ver_str is None:
        return True, "vLLM æœªå®‰è£…ï¼Œè·³è¿‡æ£€æŸ¥"

    vllm_ver = version.parse(vllm_ver_str.split("+")[0])
    if vllm_ver < version.parse("0.10.0"):
        return True, f"vLLM {vllm_ver_str} < 0.10.0ï¼Œä¸éœ€è¦ torch._inductor.config"

    # æ£€æŸ¥ torch._inductor.config æ˜¯å¦å­˜åœ¨
    try:
        import torch._inductor.config  # noqa: F401

        msg = f"âœ… torch._inductor.config å¯ç”¨ï¼ˆvLLM {vllm_ver_str} éœ€è¦ï¼‰"
        return True, msg
    except (ImportError, AttributeError) as e:
        msg = (
            f"âŒ torch._inductor.config ä¸å¯ç”¨:\n"
            f"   vLLM {vllm_ver_str} éœ€è¦ torch >= 2.4.0\n"
            f"   é”™è¯¯: {e}\n"
            f"\nä¿®å¤æ–¹æ³•:\n"
            f"   pip uninstall -y torch torchaudio torchvision\n"
            f"   pip install torch>=2.4.0"
        )
        return False, msg


def verify_python_version() -> tuple[bool, str]:
    """éªŒè¯ Python ç‰ˆæœ¬æ˜¯å¦æ»¡è¶³è¦æ±‚

    Returns:
        (is_compatible, message): å…¼å®¹æ€§çŠ¶æ€å’Œè¯´æ˜ä¿¡æ¯
    """
    current_version = version.parse(
        f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
    )
    min_version = version.parse("3.9.0")

    if current_version < min_version:
        msg = (
            f"âŒ Python ç‰ˆæœ¬è¿‡ä½:\n"
            f"   å½“å‰ç‰ˆæœ¬: {sys.version}\n"
            f"   æœ€ä½è¦æ±‚: Python {min_version}\n"
            f"\nè¯·å‡çº§ Python ç‰ˆæœ¬"
        )
        return False, msg

    msg = f"âœ… Python ç‰ˆæœ¬æ»¡è¶³è¦æ±‚: {sys.version.split()[0]}"
    return True, msg


def main(verbose: bool = False):
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰éªŒè¯æ£€æŸ¥"""
    print("ğŸ” SAGE ä¾èµ–ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥")
    print("=" * 60)

    checks = [
        ("Python ç‰ˆæœ¬", verify_python_version),
        ("Torch & vLLM å…¼å®¹æ€§", verify_torch_vllm_compatibility),
        ("torch._inductor.config", verify_torch_inductor),
    ]

    all_passed = True
    results = []

    for check_name, check_func in checks:
        print(f"\næ£€æŸ¥: {check_name}")
        print("-" * 60)
        try:
            passed, message = check_func()
            results.append((check_name, passed, message))
            print(message)
            if not passed:
                all_passed = False
        except Exception as e:
            results.append((check_name, False, f"æ£€æŸ¥å¤±è´¥: {e}"))
            print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
            all_passed = False
            if verbose:
                import traceback

                traceback.print_exc()

    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æ£€æŸ¥æ€»ç»“")
    print("=" * 60)

    for check_name, passed, _ in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{status} - {check_name}")

    print("=" * 60)

    if all_passed:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
        return 0
    else:
        print("âŒ å­˜åœ¨ä¾èµ–ç‰ˆæœ¬é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤")
        print("\nğŸ’¡ æç¤º: è¿è¡Œä»¥ä¸‹å‘½ä»¤è·å–è¯¦ç»†å¸®åŠ©:")
        print("   cat docs/dev-notes/l0-infra/vllm-torch-version-conflict.md")
        return 1


if __name__ == "__main__":
    verbose = "--verbose" in sys.argv or "-v" in sys.argv
    sys.exit(main(verbose=verbose))
