#!/bin/bash
################################################################################
# HDFS Docker äº¤äº’å¼ç®¡ç†è„šæœ¬ (å¢å¼ºç‰ˆ)
#
# åŠŸèƒ½:
#   - äº¤äº’å¼èœå•ç•Œé¢
#   - è¯¦ç»†çš„é”™è¯¯å¤„ç†å’Œè¯Šæ–­
#   - å¯åŠ¨çŠ¶æ€ç›‘æ§å’ŒéªŒè¯
#   - å¤šè½®å¯¹è¯å¼æ“ä½œ
################################################################################

set -e

# ==================== é…ç½®å˜é‡ ====================
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
COMPOSE_FILE="$SCRIPT_DIR/docker-compose.yml"
DATA_DIR="$SCRIPT_DIR/data"
CONFIG_DIR="$SCRIPT_DIR/config"
LOG_FILE="$SCRIPT_DIR/hdfs_operation.log"

# ==================== é¢œè‰²å®šä¹‰ ====================
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
BOLD='\033[1m'
NC='\033[0m'

# ==================== æ—¥å¿—å‡½æ•° ====================
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1" | tee -a "$LOG_FILE"
}

log_success() {
    echo -e "${GREEN}[âœ“ SUCCESS]${NC} $1" | tee -a "$LOG_FILE"
}

log_warn() {
    echo -e "${YELLOW}[âš  WARN]${NC} $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "${RED}[âœ— ERROR]${NC} $1" | tee -a "$LOG_FILE"
}

log_step() {
    echo -e "${CYAN}[â†’ STEP]${NC} $1" | tee -a "$LOG_FILE"
}

log_debug() {
    if [ "${DEBUG:-0}" == "1" ]; then
        echo -e "${MAGENTA}[DEBUG]${NC} $1" | tee -a "$LOG_FILE"
    fi
}

# ==================== é”™è¯¯å¤„ç† ====================
error_exit() {
    log_error "$1"
    echo ""
    log_info "æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: cat $LOG_FILE"
    exit 1
}

# æ•è·é”™è¯¯å¹¶æä¾›è¯Šæ–­ä¿¡æ¯
trap 'handle_error $? $LINENO' ERR

handle_error() {
    local exit_code=$1
    local line_no=$2
    log_error "è„šæœ¬åœ¨ç¬¬ $line_no è¡Œå‡ºé”™ (é€€å‡ºç : $exit_code)"
    log_info "å°è¯•è¿è¡Œä»¥ä¸‹å‘½ä»¤è¯Šæ–­é—®é¢˜:"
    echo "  1. sudo docker ps -a | grep hdfs"
    echo "  2. sudo docker logs hdfs-namenode"
    echo "  3. sudo docker logs hdfs-datanode"
    exit $exit_code
}

# ==================== ç¯å¢ƒæ£€æŸ¥ ====================
check_docker() {
    log_step "æ£€æŸ¥ Docker ç¯å¢ƒ..."

    if ! command -v docker &> /dev/null; then
        error_exit "Docker æœªå®‰è£…! è¯·å…ˆå®‰è£… Docker: https://docs.docker.com/get-docker/"
    fi

    if ! docker info &> /dev/null; then
        error_exit "Docker æœåŠ¡æœªè¿è¡Œæˆ–æ— æƒé™! è¯·è¿è¡Œ: sudo systemctl start docker"
    fi

    if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then
        error_exit "Docker Compose æœªå®‰è£…! è¯·å…ˆå®‰è£… Docker Compose"
    fi

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ sudo
    if ! docker ps &> /dev/null; then
        log_warn "éœ€è¦ sudo æƒé™è¿è¡Œ Docker å‘½ä»¤"
        export DOCKER_CMD="sudo docker"
        export COMPOSE_CMD="sudo docker compose"
    else
        export DOCKER_CMD="docker"
        export COMPOSE_CMD="docker compose"
    fi

    log_success "Docker ç¯å¢ƒæ£€æŸ¥é€šè¿‡ âœ“"
}


# ==================== Docker Compose é…ç½®ç®¡ç† ====================
create_docker_compose_file() {
    log_step "æ£€æŸ¥å¹¶åˆ›å»º Docker Compose é…ç½®æ–‡ä»¶..."

    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæˆ–æ›´æ–°é…ç½®
    local need_update=false

    if [ ! -f "$COMPOSE_FILE" ]; then
        log_info "Docker Compose é…ç½®æ–‡ä»¶ä¸å­˜åœ¨,å°†åˆ›å»º"
        need_update=true
    else
        # æ£€æŸ¥æ˜¯å¦åŒ…å« user: "0:0" é…ç½®
        if ! grep -q 'user: "0:0"' "$COMPOSE_FILE"; then
            log_warn "Docker Compose é…ç½®ç¼ºå°‘ç”¨æˆ·æƒé™è®¾ç½®,å°†æ›´æ–°"
            need_update=true
        fi
    fi

    if [ "$need_update" = true ]; then
        cat > "$COMPOSE_FILE" << 'EOF'
services:
  namenode:
    image: apache/hadoop:3
    container_name: hdfs-namenode
    hostname: namenode
    user: "0:0"  # ä»¥rootç”¨æˆ·è¿è¡Œ,é¿å…æƒé™é—®é¢˜
    ports:
      - "9870:9870"
      - "9000:9000"
    environment:
      - CLUSTER_NAME=sage-hdfs
    volumes:
      - ./data/namenode:/opt/hadoop/data/nameNode
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./config/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
    networks:
      - hadoop
    command: >
      bash -c "
      if [ ! -d /opt/hadoop/data/nameNode/current ]; then
        hdfs namenode -format -force;
      fi &&
      hdfs namenode
      "

  datanode:
    image: apache/hadoop:3
    container_name: hdfs-datanode
    hostname: datanode
    user: "0:0"  # ä»¥rootç”¨æˆ·è¿è¡Œ,é¿å…æƒé™é—®é¢˜
    ports:
      - "9864:9864"
    volumes:
      - ./data/datanode:/opt/hadoop/data/dataNode
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./config/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
    networks:
      - hadoop
    depends_on:
      - namenode
    command: >
      bash -c "
      sleep 15 &&
      hdfs datanode
      "

networks:
  hadoop:
    driver: bridge
EOF
        log_success "Docker Compose é…ç½®æ–‡ä»¶å·²åˆ›å»º/æ›´æ–° âœ“"
    else
        log_success "Docker Compose é…ç½®æ–‡ä»¶æ£€æŸ¥é€šè¿‡ âœ“"
    fi
}
check_requirements() {
    log_step "æ£€æŸ¥ç³»ç»Ÿè¦æ±‚..."

    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    local available_space=$(df "$SCRIPT_DIR" | tail -1 | awk '{print $4}')
    if [ "$available_space" -lt 1048576 ]; then  # å°äº 1GB
        log_warn "ç£ç›˜ç©ºé—´ä¸è¶³ 1GB,å¯èƒ½å½±å“ HDFS è¿è¡Œ"
    fi

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if [ ! -d "$CONFIG_DIR" ]; then
        log_warn "é…ç½®ç›®å½•ä¸å­˜åœ¨,å°†è‡ªåŠ¨åˆ›å»º"
        create_config_files
    fi

    # æ£€æŸ¥å¹¶åˆ›å»º docker-compose æ–‡ä»¶
    create_docker_compose_file

    log_success "ç³»ç»Ÿè¦æ±‚æ£€æŸ¥é€šè¿‡ âœ“"
}

# ==================== é…ç½®æ–‡ä»¶ç®¡ç† ====================
create_config_files() {
    log_step "åˆ›å»º Hadoop é…ç½®æ–‡ä»¶..."

    mkdir -p "$CONFIG_DIR"

    # åˆ›å»º core-site.xml
    cat > "$CONFIG_DIR/core-site.xml" << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://namenode:9000</value>
    <description>HDFS é»˜è®¤æ–‡ä»¶ç³»ç»Ÿåœ°å€</description>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/tmp/hadoop</value>
  </property>
</configuration>
EOF

    # åˆ›å»º hdfs-site.xml
    cat > "$CONFIG_DIR/hdfs-site.xml" << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
    <description>æ•°æ®å—å‰¯æœ¬æ•°é‡(å•èŠ‚ç‚¹æ¨¡å¼ä¸º1)</description>
  </property>
  <property>
    <name>dfs.permissions.enabled</name>
    <value>false</value>
    <description>ç¦ç”¨æƒé™æ£€æŸ¥,æ–¹ä¾¿æµ‹è¯•</description>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///opt/hadoop/data/nameNode</value>
    <description>NameNode å…ƒæ•°æ®å­˜å‚¨è·¯å¾„</description>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///opt/hadoop/data/dataNode</value>
    <description>DataNode æ•°æ®å—å­˜å‚¨è·¯å¾„</description>
  </property>
</configuration>
EOF

    chmod 644 "$CONFIG_DIR"/*.xml
    log_success "é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ âœ“"
}

# ==================== æ•°æ®ç›®å½•ç®¡ç† ====================
prepare_data_dir() {
    log_step "å‡†å¤‡æ•°æ®ç›®å½•..."

    mkdir -p "$DATA_DIR/namenode"
    mkdir -p "$DATA_DIR/datanode"

    # è®¾ç½®æƒé™ (é¿å…å®¹å™¨å†…æƒé™é—®é¢˜)
    chmod -R 777 "$DATA_DIR"

    log_success "æ•°æ®ç›®å½•å‡†å¤‡å®Œæˆ: $DATA_DIR âœ“"
}

# ==================== HDFS å¯åŠ¨ ====================
start_hdfs() {
    echo ""
    echo -e "${BOLD}========================================${NC}"
    echo -e "${BOLD}    å¯åŠ¨ HDFS é›†ç¾¤${NC}"
    echo -e "${BOLD}========================================${NC}"
    echo ""

    # ç¯å¢ƒæ£€æŸ¥
    check_docker
    check_requirements
    prepare_data_dir

    # æ£€æŸ¥æ˜¯å¦å·²ç»è¿è¡Œ
    if $DOCKER_CMD ps | grep -q hdfs-namenode; then
        log_warn "HDFS é›†ç¾¤å·²ç»åœ¨è¿è¡Œä¸­"
        read -p "æ˜¯å¦é‡å¯é›†ç¾¤? [y/N]: " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            stop_hdfs
            sleep 2
        else
            return 0
        fi
    fi

    # å¯åŠ¨å®¹å™¨
    log_step "å¯åŠ¨ Docker å®¹å™¨..."
    if docker compose version &> /dev/null; then
        $COMPOSE_CMD -f "$COMPOSE_FILE" up -d 2>&1 | tee -a "$LOG_FILE"
    else
        sudo docker-compose -f "$COMPOSE_FILE" up -d 2>&1 | tee -a "$LOG_FILE"
    fi

    if [ $? -ne 0 ]; then
        error_exit "å®¹å™¨å¯åŠ¨å¤±è´¥! æŸ¥çœ‹æ—¥å¿—: $LOG_FILE"
    fi

    # ç­‰å¾…æœåŠ¡å°±ç»ª
    wait_for_hdfs_ready

    # åˆå§‹åŒ– HDFS ç›®å½•
    initialize_hdfs

    # æ˜¾ç¤ºçŠ¶æ€
    echo ""
    show_status

    echo ""
    log_success "ğŸ‰ HDFS é›†ç¾¤å¯åŠ¨æˆåŠŸ!"
    echo ""
    echo -e "${CYAN}è®¿é—®åœ°å€:${NC}"
    echo "  â€¢ NameNode Web UI: http://localhost:9870"
    echo "  â€¢ NameNode RPC:    hdfs://localhost:9000"
    echo "  â€¢ DataNode Web UI: http://localhost:9864"
    echo ""
}

wait_for_hdfs_ready() {
    log_step "ç­‰å¾… HDFS æœåŠ¡å°±ç»ª..."

    local max_wait=90
    local waited=0
    local check_interval=3

    # è¿›åº¦æ¡
    echo -n "  "

    while [ $waited -lt $max_wait ]; do
        # æ£€æŸ¥ NameNode æ˜¯å¦å°±ç»ª
        if $DOCKER_CMD exec hdfs-namenode hdfs dfsadmin -report &> /dev/null; then
            echo ""
            log_success "NameNode å·²å°±ç»ª âœ“"
            break
        fi

        # æ£€æŸ¥å®¹å™¨æ˜¯å¦å¼‚å¸¸é€€å‡º
        if ! $DOCKER_CMD ps | grep -q hdfs-namenode; then
            echo ""
            log_error "NameNode å®¹å™¨å¼‚å¸¸é€€å‡º!"
            diagnose_container_failure "hdfs-namenode"
            error_exit "NameNode å¯åŠ¨å¤±è´¥"
        fi

        echo -n "."
        sleep $check_interval
        waited=$((waited + check_interval))
    done

    if [ $waited -ge $max_wait ]; then
        echo ""
        log_error "ç­‰å¾…è¶…æ—¶ (${max_wait}ç§’)"
        diagnose_container_failure "hdfs-namenode"
        error_exit "HDFS å¯åŠ¨è¶…æ—¶"
    fi

    # ç­‰å¾… DataNode æ³¨å†Œ
    log_step "ç­‰å¾… DataNode æ³¨å†Œ..."
    sleep 5

    if ! $DOCKER_CMD ps | grep -q hdfs-datanode; then
        log_warn "DataNode å®¹å™¨æœªè¿è¡Œ,æ­£åœ¨è¯Šæ–­..."
        diagnose_container_failure "hdfs-datanode"
    else
        log_success "DataNode å·²å°±ç»ª âœ“"
    fi
}

diagnose_container_failure() {
    local container_name=$1

    echo ""
    log_error "è¯Šæ–­ $container_name å®¹å™¨é—®é¢˜:"
    echo ""

    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
    echo -e "${YELLOW}å®¹å™¨çŠ¶æ€:${NC}"
    $DOCKER_CMD ps -a --filter "name=$container_name" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    echo ""

    # æ˜¾ç¤ºæœ€åçš„æ—¥å¿—
    echo -e "${YELLOW}æœ€å 20 è¡Œæ—¥å¿—:${NC}"
    $DOCKER_CMD logs --tail 20 "$container_name" 2>&1 | sed 's/^/  /'
    echo ""

    # å¸¸è§é”™è¯¯æç¤º
    echo -e "${CYAN}å¸¸è§é—®é¢˜æ’æŸ¥:${NC}"
    echo "  1. æƒé™é—®é¢˜: sudo chmod -R 777 $DATA_DIR"
    echo "  2. ç«¯å£å ç”¨: sudo lsof -i :9000,9870,9864"
    echo "  3. é…ç½®é”™è¯¯: æ£€æŸ¥ $CONFIG_DIR/*.xml"
    echo "  4. æŸ¥çœ‹å®Œæ•´æ—¥å¿—: sudo docker logs $container_name"
    echo ""
}

# ==================== HDFS åˆå§‹åŒ– ====================
initialize_hdfs() {
    log_step "åˆå§‹åŒ– HDFS ç›®å½•ç»“æ„..."

    # åˆ›å»ºé¡¹ç›®ç›®å½•
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -mkdir -p /sage 2>/dev/null || true
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -mkdir -p /sage/data 2>/dev/null || true
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -mkdir -p /sage/checkpoints 2>/dev/null || true
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -mkdir -p /user 2>/dev/null || true

    # è®¾ç½®æƒé™
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -chmod -R 777 /sage 2>/dev/null || true
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -chmod -R 777 /user 2>/dev/null || true

    log_success "HDFS ç›®å½•åˆå§‹åŒ–å®Œæˆ âœ“"
}

# ==================== HDFS åœæ­¢ ====================
stop_hdfs() {
    check_docker  # ç¡®ä¿ DOCKER_CMD å·²åˆå§‹åŒ–
    log_step "åœæ­¢ HDFS é›†ç¾¤..."

    if ! $DOCKER_CMD ps 2>/dev/null | grep -q "hdfs-namenode"; then
        log_warn "HDFS é›†ç¾¤æœªè¿è¡Œ"
        return 0
    fi

    if docker compose version &> /dev/null; then
        $COMPOSE_CMD -f "$COMPOSE_FILE" down 2>&1 | tee -a "$LOG_FILE"
    else
        sudo docker-compose -f "$COMPOSE_FILE" down 2>&1 | tee -a "$LOG_FILE"
    fi

    log_success "HDFS å·²åœæ­¢ âœ“"
}

# ==================== HDFS é‡å¯ ====================
restart_hdfs() {
    echo ""
    log_info "é‡å¯ HDFS é›†ç¾¤..."
    stop_hdfs
    sleep 3
    start_hdfs
}

# ==================== çŠ¶æ€æŸ¥çœ‹ ====================
show_status() {
    echo ""
    echo -e "${BOLD}========================================${NC}"
    echo -e "${BOLD}    HDFS é›†ç¾¤çŠ¶æ€${NC}"
    echo -e "${BOLD}========================================${NC}"
    echo ""

    # å®¹å™¨çŠ¶æ€
    if $DOCKER_CMD ps --filter "name=hdfs-" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep hdfs- > /dev/null; then
        echo -e "${CYAN}å®¹å™¨çŠ¶æ€:${NC}"
        $DOCKER_CMD ps --filter "name=hdfs-" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
        echo ""

        # HDFS é›†ç¾¤æŠ¥å‘Š
        echo -e "${CYAN}HDFS é›†ç¾¤æŠ¥å‘Š:${NC}"
        if $DOCKER_CMD exec hdfs-namenode hdfs dfsadmin -report 2>/dev/null; then
            :
        else
            log_warn "æ— æ³•è·å– HDFS æŠ¥å‘Š (æœåŠ¡å¯èƒ½æœªå®Œå…¨å¯åŠ¨)"
        fi

        echo ""
        echo -e "${CYAN}è®¿é—®åœ°å€:${NC}"
        echo "  â€¢ NameNode RPC:    hdfs://localhost:9000"
        echo "  â€¢ NameNode Web UI: http://localhost:9870"
        echo "  â€¢ DataNode Web UI: http://localhost:9864"

        echo ""
        echo -e "${CYAN}Python è¿æ¥ç¤ºä¾‹:${NC}"
        echo "  export HDFS_NAMENODE_HOST=localhost"
        echo "  export HDFS_NAMENODE_PORT=9000"
    else
        log_warn "HDFS å®¹å™¨æœªè¿è¡Œ"
        echo ""
        echo "ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨ HDFS:"
        echo "  bash $0 start"
    fi
    echo ""
}

# ==================== HDFS æµ‹è¯• ====================
test_hdfs() {
    echo ""
    echo -e "${BOLD}========================================${NC}"
    echo -e "${BOLD}    æµ‹è¯• HDFS åŠŸèƒ½${NC}"
    echo -e "${BOLD}========================================${NC}"
    echo ""

    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
    if ! $DOCKER_CMD ps --filter "name=hdfs-namenode" --format "{{.Names}}" | grep hdfs-namenode > /dev/null; then
        error_exit "HDFS NameNode å®¹å™¨æœªè¿è¡Œ! è¯·å…ˆå¯åŠ¨: bash $0 start"
    fi

    local test_file="/sage/test_$(date +%s).txt"
    local test_content="Hello HDFS from Docker! æµ‹è¯•æ—¶é—´: $(date)"

    # æµ‹è¯• 1: å†™å…¥æ–‡ä»¶
    log_step "æµ‹è¯• 1/4: å†™å…¥æ–‡ä»¶åˆ° HDFS..."
    echo "$test_content" | $DOCKER_CMD exec -i hdfs-namenode hdfs dfs -put - "$test_file"
    log_success "âœ“ æ–‡ä»¶å†™å…¥æˆåŠŸ: $test_file"

    # æµ‹è¯• 2: è¯»å–æ–‡ä»¶
    log_step "æµ‹è¯• 2/4: ä» HDFS è¯»å–æ–‡ä»¶..."
    local read_content=$($DOCKER_CMD exec hdfs-namenode hdfs dfs -cat "$test_file" 2>/dev/null)
    if [ "$read_content" == "$test_content" ]; then
        log_success "âœ“ æ–‡ä»¶è¯»å–æˆåŠŸ,å†…å®¹åŒ¹é…"
    else
        log_error "âœ— æ–‡ä»¶è¯»å–å¤±è´¥æˆ–å†…å®¹ä¸åŒ¹é…"
        return 1
    fi

    # æµ‹è¯• 3: åˆ—å‡ºæ–‡ä»¶
    log_step "æµ‹è¯• 3/4: åˆ—å‡º HDFS æ–‡ä»¶..."
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -ls /sage/ | grep test
    log_success "âœ“ æ–‡ä»¶åˆ—è¡¨è·å–æˆåŠŸ"

    # æµ‹è¯• 4: åˆ é™¤æ–‡ä»¶
    log_step "æµ‹è¯• 4/4: åˆ é™¤æµ‹è¯•æ–‡ä»¶..."
    $DOCKER_CMD exec hdfs-namenode hdfs dfs -rm "$test_file" &>/dev/null
    log_success "âœ“ æ–‡ä»¶åˆ é™¤æˆåŠŸ"

    echo ""
    log_success "ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! HDFS è¿è¡Œæ­£å¸¸"
    echo ""
}

# ==================== æŸ¥çœ‹æ—¥å¿— ====================
show_logs() {
    echo ""
    echo -e "${CYAN}é€‰æ‹©è¦æŸ¥çœ‹çš„æ—¥å¿—:${NC}"
    echo "  1) NameNode æ—¥å¿—"
    echo "  2) DataNode æ—¥å¿—"
    echo "  3) æ‰€æœ‰å®¹å™¨æ—¥å¿— (å®æ—¶)"
    echo "  4) è¿”å›"
    echo ""
    read -p "è¯·é€‰æ‹© [1-4]: " choice

    case $choice in
        1)
            echo ""
            log_info "æ˜¾ç¤º NameNode æ—¥å¿— (æœ€å 50 è¡Œ, Ctrl+C é€€å‡º)..."
            $DOCKER_CMD logs --tail 50 -f hdfs-namenode
            ;;
        2)
            echo ""
            log_info "æ˜¾ç¤º DataNode æ—¥å¿— (æœ€å 50 è¡Œ, Ctrl+C é€€å‡º)..."
            $DOCKER_CMD logs --tail 50 -f hdfs-datanode
            ;;
        3)
            echo ""
            log_info "æ˜¾ç¤ºæ‰€æœ‰å®¹å™¨æ—¥å¿— (Ctrl+C é€€å‡º)..."
            if docker compose version &> /dev/null; then
                $COMPOSE_CMD -f "$COMPOSE_FILE" logs -f
            else
                sudo docker-compose -f "$COMPOSE_FILE" logs -f
            fi
            ;;
        4)
            return
            ;;
        *)
            log_error "æ— æ•ˆé€‰æ‹©"
            ;;
    esac
}

# ==================== æ¸…ç†æ•°æ® ====================
clean_all() {
    echo ""
    echo -e "${RED}${BOLD}âš ï¸  è­¦å‘Š: è¿™å°†åˆ é™¤æ‰€æœ‰ HDFS æ•°æ®!${NC}"
    echo ""
    echo "å°†è¦åˆ é™¤:"
    echo "  â€¢ HDFS å®¹å™¨å’Œå·"
    echo "  â€¢ æ•°æ®ç›®å½•: $DATA_DIR"
    echo "  â€¢ æ‰€æœ‰å­˜å‚¨åœ¨ HDFS ä¸­çš„æ–‡ä»¶"
    echo ""
    read -p "ç¡®è®¤ç»§ç»­? è¾“å…¥ 'yes' ç¡®è®¤: " confirm

    if [ "$confirm" != "yes" ]; then
        log_info "å–æ¶ˆæ“ä½œ"
        return 0
    fi

    log_step "æ¸…ç† HDFS ç¯å¢ƒ..."

    # åœæ­¢å¹¶åˆ é™¤å®¹å™¨
    if docker compose version &> /dev/null; then
        $COMPOSE_CMD -f "$COMPOSE_FILE" down -v 2>&1 | tee -a "$LOG_FILE"
    else
        sudo docker-compose -f "$COMPOSE_FILE" down -v 2>&1 | tee -a "$LOG_FILE"
    fi

    # åˆ é™¤æ•°æ®ç›®å½•
    if [ -d "$DATA_DIR" ]; then
        rm -rf "$DATA_DIR"
        log_success "æ•°æ®ç›®å½•å·²åˆ é™¤"
    fi

    log_success "æ¸…ç†å®Œæˆ âœ“"
    echo ""
}

# ==================== é«˜çº§æ“ä½œèœå• ====================
advanced_menu() {
    while true; do
        echo ""
        echo -e "${BOLD}========================================${NC}"
        echo -e "${BOLD}    é«˜çº§æ“ä½œ${NC}"
        echo -e "${BOLD}========================================${NC}"
        echo ""
        echo "  1) è¿›å…¥ NameNode å®¹å™¨"
        echo "  2) è¿›å…¥ DataNode å®¹å™¨"
        echo "  3) æŸ¥çœ‹é…ç½®æ–‡ä»¶"
        echo "  4) é‡æ–°åˆ›å»ºé…ç½®æ–‡ä»¶"
        echo "  5) æŸ¥çœ‹æ•°æ®ç›®å½•"
        echo "  6) å¯¼å‡ºæ“ä½œæ—¥å¿—"
        echo "  7) è¿”å›ä¸»èœå•"
        echo ""
        read -p "è¯·é€‰æ‹© [1-7]: " choice

        case $choice in
            1)
                log_info "è¿›å…¥ NameNode å®¹å™¨ (è¾“å…¥ exit é€€å‡º)..."
                $DOCKER_CMD exec -it hdfs-namenode bash
                ;;
            2)
                log_info "è¿›å…¥ DataNode å®¹å™¨ (è¾“å…¥ exit é€€å‡º)..."
                $DOCKER_CMD exec -it hdfs-datanode bash
                ;;
            3)
                echo ""
                echo -e "${CYAN}core-site.xml:${NC}"
                cat "$CONFIG_DIR/core-site.xml"
                echo ""
                echo -e "${CYAN}hdfs-site.xml:${NC}"
                cat "$CONFIG_DIR/hdfs-site.xml"
                ;;
            4)
                log_info "é‡æ–°åˆ›å»ºé…ç½®æ–‡ä»¶..."
                create_config_files
                log_success "é…ç½®æ–‡ä»¶å·²æ›´æ–°,éœ€è¦é‡å¯ HDFS æ‰èƒ½ç”Ÿæ•ˆ"
                ;;
            5)
                echo ""
                log_info "æ•°æ®ç›®å½•å†…å®¹:"
                ls -lah "$DATA_DIR"
                ;;
            6)
                local export_file="$SCRIPT_DIR/hdfs_log_$(date +%Y%m%d_%H%M%S).txt"
                cp "$LOG_FILE" "$export_file"
                log_success "æ—¥å¿—å·²å¯¼å‡ºåˆ°: $export_file"
                ;;
            7)
                return
                ;;
            *)
                log_error "æ— æ•ˆé€‰æ‹©"
                ;;
        esac
    done
}

# ==================== ä¸»èœå• ====================
show_main_menu() {
    while true; do
        echo ""
        echo -e "${BOLD}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
        echo -e "${BOLD}â•‘   HDFS Docker é›†ç¾¤ç®¡ç†å·¥å…·             â•‘${NC}"
        echo -e "${BOLD}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        echo ""
        echo -e "  ${GREEN}1)${NC} ğŸš€ å¯åŠ¨ HDFS é›†ç¾¤"
        echo -e "  ${YELLOW}2)${NC} ğŸ›‘ åœæ­¢ HDFS é›†ç¾¤"
        echo -e "  ${CYAN}3)${NC} ğŸ”„ é‡å¯ HDFS é›†ç¾¤"
        echo -e "  ${BLUE}4)${NC} ğŸ“Š æŸ¥çœ‹é›†ç¾¤çŠ¶æ€"
        echo -e "  ${MAGENTA}5)${NC} ğŸ§ª æµ‹è¯• HDFS åŠŸèƒ½"
        echo -e "  ${CYAN}6)${NC} ğŸ“ æŸ¥çœ‹æ—¥å¿—"
        echo -e "  ${YELLOW}7)${NC} ğŸ§¹ æ¸…ç†æ‰€æœ‰æ•°æ®"
        echo -e "  ${BLUE}8)${NC} âš™ï¸  é«˜çº§æ“ä½œ"
        echo -e "  ${RED}9)${NC} ğŸ“– æŸ¥çœ‹å¸®åŠ©"
        echo -e "  ${RED}0)${NC} ğŸšª é€€å‡º"
        echo ""
        read -p "è¯·é€‰æ‹©æ“ä½œ [0-9]: " choice

        case $choice in
            1) start_hdfs ;;
            2) stop_hdfs ;;
            3) restart_hdfs ;;
            4) show_status ;;
            5) test_hdfs ;;
            6) show_logs ;;
            7) clean_all ;;
            8) advanced_menu ;;
            9) show_help ;;
            0)
                echo ""
                log_info "æ„Ÿè°¢ä½¿ç”¨! å†è§ ğŸ‘‹"
                echo ""
                exit 0
                ;;
            *)
                log_error "æ— æ•ˆé€‰æ‹©,è¯·è¾“å…¥ 0-9"
                ;;
        esac

        # æ“ä½œå®Œæˆåæš‚åœ
        echo ""
        read -p "æŒ‰ Enter ç»§ç»­..." dummy
    done
}

# ==================== å¸®åŠ©ä¿¡æ¯ ====================
show_help() {
    cat <<-EOF

${BOLD}HDFS Docker é›†ç¾¤ç®¡ç†å·¥å…·${NC}

${CYAN}ä½¿ç”¨æ–¹å¼:${NC}
  äº¤äº’æ¨¡å¼: bash $0
  å‘½ä»¤æ¨¡å¼: bash $0 <å‘½ä»¤>

${CYAN}å¯ç”¨å‘½ä»¤:${NC}
  start       - å¯åŠ¨ HDFS é›†ç¾¤
  stop        - åœæ­¢ HDFS é›†ç¾¤
  restart     - é‡å¯ HDFS é›†ç¾¤
  status      - æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
  test        - æµ‹è¯• HDFS åŠŸèƒ½
  logs        - æŸ¥çœ‹æ—¥å¿—
  clean       - æ¸…ç†æ‰€æœ‰æ•°æ®
  help        - æ˜¾ç¤ºæ­¤å¸®åŠ©

${CYAN}ç¤ºä¾‹:${NC}
  # äº¤äº’å¼å¯åŠ¨
  bash $0

  # ç›´æ¥å¯åŠ¨é›†ç¾¤
  bash $0 start

  # æŸ¥çœ‹çŠ¶æ€
  bash $0 status

  # æµ‹è¯•åŠŸèƒ½
  bash $0 test

${CYAN}é…ç½®æ–‡ä»¶:${NC}
  â€¢ Docker Compose: $COMPOSE_FILE
  â€¢ Hadoop é…ç½®:   $CONFIG_DIR/
  â€¢ æ•°æ®ç›®å½•:      $DATA_DIR/
  â€¢ æ“ä½œæ—¥å¿—:      $LOG_FILE

${CYAN}è®¿é—®åœ°å€:${NC}
  â€¢ NameNode Web UI: http://localhost:9870
  â€¢ NameNode RPC:    hdfs://localhost:9000
  â€¢ DataNode Web UI: http://localhost:9864

${CYAN}å¸¸è§é—®é¢˜:${NC}
  1. å®¹å™¨å¯åŠ¨å¤±è´¥?
     â†’ æ£€æŸ¥ç«¯å£å ç”¨: sudo lsof -i :9000,9870,9864
     â†’ æŸ¥çœ‹æ—¥å¿—: sudo docker logs hdfs-namenode

  2. æƒé™é—®é¢˜?
     â†’ è¿è¡Œ: sudo chmod -R 777 $DATA_DIR

  3. è¿æ¥å¤±è´¥?
     â†’ ç¡®è®¤å®¹å™¨è¿è¡Œ: bash $0 status
     â†’ ç­‰å¾…æœåŠ¡å°±ç»ª(çº¦15-30ç§’)

${CYAN}ç›¸å…³æ–‡æ¡£:${NC}
  â€¢ å¯åŠ¨æœºåˆ¶è¯´æ˜: $SCRIPT_DIR/HDFS_å¯åŠ¨æœºåˆ¶è¯´æ˜.md
  â€¢ å®˜æ–¹æ–‡æ¡£: https://hadoop.apache.org/docs/stable/

EOF
}

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
main() {
    # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
    echo "=== HDFS Docker ç®¡ç†æ—¥å¿— ===" > "$LOG_FILE"
    echo "æ—¶é—´: $(date)" >> "$LOG_FILE"
    echo "================================" >> "$LOG_FILE"

    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°,æ‰§è¡Œå¯¹åº”å‘½ä»¤
    if [ $# -gt 0 ]; then
        case "$1" in
            start) start_hdfs ;;
            stop) stop_hdfs ;;
            restart) restart_hdfs ;;
            status) show_status ;;
            test) test_hdfs ;;
            logs) show_logs ;;
            clean) clean_all ;;
            help|--help|-h) show_help ;;
            *)
                log_error "æœªçŸ¥å‘½ä»¤: $1"
                show_help
                exit 1
                ;;
        esac
    else
        # äº¤äº’å¼èœå•æ¨¡å¼
        show_main_menu
    fi
}

# æ‰§è¡Œä¸»ç¨‹åº
main "$@"
