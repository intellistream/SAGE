#!/bin/bash
# GPU æ£€æµ‹å’Œ CUDA ç‰ˆæœ¬ PyTorch å®‰è£…è„šæœ¬
# åœ¨ pip install ä¹‹å‰è°ƒç”¨ï¼Œç¡®ä¿å®‰è£…æ­£ç¡®ç‰ˆæœ¬çš„ PyTorch

# å¯¼å…¥é¢œè‰²å®šä¹‰ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if [ -f "$(dirname "${BASH_SOURCE[0]}")/../display_tools/colors.sh" ]; then
    source "$(dirname "${BASH_SOURCE[0]}")/../display_tools/colors.sh"
else
    # å®šä¹‰åŸºæœ¬é¢œè‰²
    GREEN='\033[0;32m'
    YELLOW='\033[1;33m'
    BLUE='\033[0;34m'
    RED='\033[0;31m'
    DIM='\033[2m'
    NC='\033[0m'
fi

# æ£€æµ‹ NVIDIA GPU
detect_nvidia_gpu() {
    # æ–¹æ³•1: æ£€æŸ¥ nvidia-smi
    if command -v nvidia-smi &>/dev/null; then
        if nvidia-smi &>/dev/null; then
            return 0
        fi
    fi

    # æ–¹æ³•2: æ£€æŸ¥ /dev/nvidia*
    if ls /dev/nvidia* &>/dev/null 2>&1; then
        return 0
    fi

    # æ–¹æ³•3: æ£€æŸ¥ lspci
    if command -v lspci &>/dev/null; then
        if lspci | grep -i nvidia &>/dev/null; then
            return 0
        fi
    fi

    return 1
}

# è·å– CUDA ç‰ˆæœ¬
get_cuda_version() {
    local cuda_version=""

    # æ–¹æ³•1: ä» nvidia-smi è·å–
    if command -v nvidia-smi &>/dev/null; then
        cuda_version=$(nvidia-smi 2>/dev/null | grep -oP "CUDA Version: \K[0-9]+\.[0-9]+" | head -1)
        if [ -n "$cuda_version" ]; then
            echo "$cuda_version"
            return 0
        fi
    fi

    # æ–¹æ³•2: ä» nvcc è·å–
    if command -v nvcc &>/dev/null; then
        cuda_version=$(nvcc --version 2>/dev/null | grep -oP "release \K[0-9]+\.[0-9]+" | head -1)
        if [ -n "$cuda_version" ]; then
            echo "$cuda_version"
            return 0
        fi
    fi

    # æ–¹æ³•3: ä» CUDA_HOME è·å–
    if [ -n "$CUDA_HOME" ] && [ -f "$CUDA_HOME/version.txt" ]; then
        cuda_version=$(cat "$CUDA_HOME/version.txt" | grep -oP "[0-9]+\.[0-9]+" | head -1)
        if [ -n "$cuda_version" ]; then
            echo "$cuda_version"
            return 0
        fi
    fi

    # æ–¹æ³•4: æ£€æŸ¥å¸¸è§è·¯å¾„
    for path in /usr/local/cuda /usr/local/cuda-*; do
        if [ -f "$path/version.txt" ]; then
            cuda_version=$(cat "$path/version.txt" | grep -oP "[0-9]+\.[0-9]+" | head -1)
            if [ -n "$cuda_version" ]; then
                echo "$cuda_version"
                return 0
            fi
        fi
    done

    return 1
}

# æ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹© PyTorch å®‰è£… URL
get_pytorch_index_url() {
    local cuda_version="$1"
    local major_version=$(echo "$cuda_version" | cut -d. -f1)
    local minor_version=$(echo "$cuda_version" | cut -d. -f2)

    # PyTorch æ”¯æŒçš„ CUDA ç‰ˆæœ¬æ˜ å°„
    # å‚è€ƒ: https://pytorch.org/get-started/locally/
    if [ "$major_version" -ge 12 ]; then
        if [ "$minor_version" -ge 4 ]; then
            echo "https://download.pytorch.org/whl/cu124"
        elif [ "$minor_version" -ge 1 ]; then
            echo "https://download.pytorch.org/whl/cu121"
        else
            echo "https://download.pytorch.org/whl/cu121"
        fi
    elif [ "$major_version" -eq 11 ]; then
        if [ "$minor_version" -ge 8 ]; then
            echo "https://download.pytorch.org/whl/cu118"
        else
            echo "https://download.pytorch.org/whl/cu118"
        fi
    else
        # æ—§ç‰ˆæœ¬ CUDAï¼Œå°è¯•ä½¿ç”¨ cu118
        echo "https://download.pytorch.org/whl/cu118"
    fi
}

# é¢„å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch
preinstall_pytorch_cuda() {
    local pip_cmd="${PIP_CMD:-pip}"
    local force_cpu="${SAGE_FORCE_CPU:-false}"

    echo ""
    echo -e "${BLUE}ğŸ” æ£€æµ‹ GPU ç¯å¢ƒ...${NC}"

    # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ CPU ç‰ˆæœ¬
    if [ "$force_cpu" = "true" ]; then
        echo -e "${DIM}SAGE_FORCE_CPU=trueï¼Œè·³è¿‡ GPU æ£€æµ‹${NC}"
        return 0
    fi

    # æ£€æµ‹ NVIDIA GPU
    if ! detect_nvidia_gpu; then
        echo -e "${YELLOW}âš ï¸  æœªæ£€æµ‹åˆ° NVIDIA GPUï¼Œå°†ä½¿ç”¨ CPU ç‰ˆæœ¬ PyTorch${NC}"
        echo -e "${DIM}æç¤º: å¦‚æœä½ çš„ç³»ç»Ÿæœ‰ GPUï¼Œè¯·ç¡®ä¿å®‰è£…äº† NVIDIA é©±åŠ¨${NC}"
        return 0
    fi

    echo -e "${GREEN}âœ… æ£€æµ‹åˆ° NVIDIA GPU${NC}"

    # è·å– CUDA ç‰ˆæœ¬
    local cuda_version=$(get_cuda_version)
    if [ -z "$cuda_version" ]; then
        echo -e "${YELLOW}âš ï¸  æ— æ³•è·å– CUDA ç‰ˆæœ¬ï¼Œå°†ä½¿ç”¨é»˜è®¤ CUDA 12.1${NC}"
        cuda_version="12.1"
    fi

    echo -e "${GREEN}âœ… CUDA ç‰ˆæœ¬: $cuda_version${NC}"

    # è·å–å¯¹åº”çš„ PyTorch å®‰è£… URL
    local index_url=$(get_pytorch_index_url "$cuda_version")
    echo -e "${DIM}PyTorch æº: $index_url${NC}"

    # æ£€æŸ¥æ˜¯å¦å·²ç»å®‰è£…äº†æ­£ç¡®ç‰ˆæœ¬çš„ PyTorch
    local current_torch=$($pip_cmd show torch 2>/dev/null | grep -oP "Version: \K.*" || echo "")
    if [ -n "$current_torch" ]; then
        # æ£€æŸ¥æ˜¯å¦æ˜¯ CUDA ç‰ˆæœ¬
        local is_cuda=$(python3 -c "import torch; print('cuda' if torch.cuda.is_available() else 'cpu')" 2>/dev/null || echo "unknown")
        if [ "$is_cuda" = "cuda" ]; then
            echo -e "${GREEN}âœ… PyTorch CUDA ç‰ˆæœ¬å·²å®‰è£… ($current_torch)${NC}"
            return 0
        else
            echo -e "${YELLOW}âš ï¸  å½“å‰ PyTorch æ˜¯ CPU ç‰ˆæœ¬ï¼Œå°†å‡çº§ä¸º CUDA ç‰ˆæœ¬${NC}"
        fi
    fi

    # å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch
    echo -e "${BLUE}ğŸ“¦ å®‰è£… PyTorch (CUDA $cuda_version)...${NC}"
    echo -e "${DIM}è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...${NC}"

    # å…ˆå¸è½½å·²æœ‰çš„ CPU ç‰ˆæœ¬
    $pip_cmd uninstall -y torch torchvision torchaudio 2>/dev/null || true

    # å®‰è£… CUDA ç‰ˆæœ¬
    local install_cmd="$pip_cmd install torch torchvision torchaudio --index-url $index_url"
    echo -e "${DIM}æ‰§è¡Œ: $install_cmd${NC}"

    if $install_cmd; then
        echo -e "${GREEN}âœ… PyTorch CUDA ç‰ˆæœ¬å®‰è£…æˆåŠŸ${NC}"

        # éªŒè¯å®‰è£…
        local verify=$(python3 -c "import torch; print(f'PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')" 2>/dev/null || echo "éªŒè¯å¤±è´¥")
        echo -e "${DIM}éªŒè¯: $verify${NC}"
    else
        echo -e "${RED}âŒ PyTorch CUDA ç‰ˆæœ¬å®‰è£…å¤±è´¥${NC}"
        echo -e "${YELLOW}å°†ç»§ç»­å®‰è£…ï¼Œä½† GPU åŠ é€Ÿå¯èƒ½ä¸å¯ç”¨${NC}"
        return 1
    fi

    return 0
}

# æ˜¾ç¤º GPU ä¿¡æ¯
show_gpu_info() {
    echo ""
    echo -e "${BLUE}ğŸ–¥ï¸  GPU ä¿¡æ¯${NC}"

    if command -v nvidia-smi &>/dev/null && nvidia-smi &>/dev/null; then
        nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader 2>/dev/null | while read line; do
            echo -e "   ${GREEN}$line${NC}"
        done
    else
        echo -e "   ${DIM}æ—  NVIDIA GPU æˆ–é©±åŠ¨æœªå®‰è£…${NC}"
    fi
}

# ä¸»å‡½æ•°ï¼ˆå¯å•ç‹¬è¿è¡Œæ­¤è„šæœ¬ï¼‰
main() {
    case "${1:-}" in
        "--detect")
            if detect_nvidia_gpu; then
                echo "GPU detected"
                get_cuda_version
                exit 0
            else
                echo "No GPU"
                exit 1
            fi
            ;;
        "--info")
            show_gpu_info
            ;;
        "--install"|"")
            preinstall_pytorch_cuda
            ;;
        *)
            echo "Usage: $0 [--detect|--info|--install]"
            exit 1
            ;;
    esac
}

# å¦‚æœç›´æ¥è¿è¡Œè„šæœ¬
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
